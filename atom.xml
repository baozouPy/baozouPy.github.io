<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>暴走的技术博客</title>
  <icon>https://www.gravatar.com/avatar/305a9f3fd1e1b86e4bcca2052a8ab203</icon>
  <subtitle>The people who are crazy enough to change the world are the ones who do！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://baozouai.com/"/>
  <updated>2019-02-27T07:18:19.192Z</updated>
  <id>https://baozouai.com/</id>
  
  <author>
    <name>暴走</name>
    <email>baoouai@mail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>第三周 序列模型和注意力机制（Sequence models &amp; Attention mechanism）(Course 5)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E4%B8%89%E5%91%A8-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88Sequence-models-Attention-mechanism%EF%BC%89-Course-5/"/>
    <id>https://baozouai.com/2019/02/28/第三周-序列模型和注意力机制（Sequence-models-Attention-mechanism）-Course-5/</id>
    <published>2019-02-27T22:18:00.000Z</published>
    <updated>2019-02-27T07:18:19.192Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3-1-基础模型（Basic-Models）"><a href="#3-1-基础模型（Basic-Models）" class="headerlink" title="3.1 基础模型（Basic Models）"></a>3.1 基础模型（Basic Models）</h2><h3 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h3><p>用<script type="math/tex">x^{<1>}</script> 到<script type="math/tex">x^{< 5>}</script>表示输入句子的单词，用<script type="math/tex">y^{<1>}</script>到<script type="math/tex">y^{<6>}</script>表示输出句子的单词：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2d41c0090fd3d71e6f28eade62b7c97b.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2d41c0090fd3d71e6f28eade62b7c97b.png" alt></a><br><a id="more"></a><br>首先，建立一个<strong>RNN</strong>编码网络（<strong>encoder network</strong>）（编号1），单元可以是<strong>GRU</strong>或<strong>LSTM</strong>。每次只向该网络中输入一个法语单词，将输入序列接收完毕后，这个<strong>RNN</strong>网络会输出一个向量来代表这个输入序列</p><p>之后建立一个解码网络（编号2），以编码网络的输出作为输入，之后它可以被训练为每次输出一个翻译后的单词，一直到它输出序列的结尾或者句子结尾标记</p><p>在给出足够的法语和英语文本的情况下，训练模型，通过输入一个法语句子来输出对应的英语翻译，这个模型将会非常有效。这个模型简单地用一个编码网络来对输入的法语句子进行编码，然后用一个解码网络来生成对应的英语翻译</p><h3 id="图像描述"><a href="#图像描述" class="headerlink" title="图像描述"></a>图像描述</h3><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b9492d18803ebe3853e936098f08661c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b9492d18803ebe3853e936098f08661c.png" alt></a></p><blockquote><p>给出猫的图片，能自动地输出该图片的描述：一只猫坐在椅子上</p></blockquote><p>通过输入图像来输出描述：</p><p>将图片输入到卷积神经网络中（一个预训练的<strong>AlexNet</strong>结构）（编号2），然后让其学习图片的编码，或者学习图片的一系列特征。去掉最后的<strong>softmax</strong>单元（编号3），这个预训练的<strong>AlexNet</strong>结构会输出4096维的特征向量，向量表示的就是这只猫的图片，这个预训练网络可以是图像的编码网络</p><p>接着把这个向量输入到<strong>RNN</strong>中（编号4），RNN要做的就是生成图像的描述，每次生成一个单词：输入一个描述输入的特征向量，然后让网络一个一个地输出单词序列</p><h2 id="3-2-选择最可能的句子（Picking-the-most-likely-sentence）"><a href="#3-2-选择最可能的句子（Picking-the-most-likely-sentence）" class="headerlink" title="3.2 选择最可能的句子（Picking the most likely sentence）"></a>3.2 选择最可能的句子（Picking the most likely sentence）</h2><p><strong>seq2seq</strong>机器翻译模型和第一周所用的语言模型之间有很多相似的地方，但也有许多重要的区别：</p><p>可以把机器翻译想成是建立一个条件语言模型，能够估计句子的可能性</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a8b8c64483ee84d57135829ab025da53.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a8b8c64483ee84d57135829ab025da53.png" alt></a></p><p>绿色（编号2）表示<strong>encoder</strong>网络，紫色（编号3）表示<strong>decoder</strong>网络。不同在于语言模型总是以零向量（编号4）开始，而<strong>encoder</strong>网络会计算出一系列向量（编号2）来表示输入的句子，以这个向量作为输入，这叫做条件语言模型（<strong>conditional language model</strong>）</p><p>相比语言模型输出任意句子的概率，翻译模型会输出句子的英文翻译（编号5），这取决于输入的法语句子（编号6）。即估计一个英文翻译的概率，比如估计”<strong>Jane is visiting Africa in September.</strong>“翻译的概率，这句翻译是取决于法语句子，”<strong>Jane visite I’Afrique en septembre.</strong>“，这就是英语句子相对于输入的法语句子的可能性，是一个条件语言模型</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/fd97f885fe1e6e1a7c70bb965595210a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/fd97f885fe1e6e1a7c70bb965595210a.png" alt></a></p><blockquote><p>模型将法语翻译成英文，通过输入的法语句子模型将会告诉你各种英文翻译所对应的可能性</p></blockquote><p>$x$是法语句子”<strong>Jane visite l’Afrique en septembre.</strong>“，它将告诉你不同的英语翻译所对应的概率：从这个分布中进行取样得到<script type="math/tex">P(y|x)</script>，但不是从得到的分布中进行随机取样，而是要找到一个英语句子<script type="math/tex">y</script>（编号1），使得条件概率最大化：</p><script type="math/tex; mode=display">max\ P(y^{<1>},y^{<2>},\cdots,y^{<T_y>}|x^{<1>},x^{<2>},\cdots,x^{<T_x>})</script><p>而解决这种问题最通用的算法就是束搜索(<strong>Beam Search</strong>)</p><p>为什么不用贪心搜索(<strong>Greedy Search</strong>)：</p><p>贪心搜索生成第一个词的分布以后，将会根据条件语言模型挑选出最有可能的第一个词进入机器翻译模型中，在挑选出第一个词之后将会继续挑选出最有可能的第二个词……这种算法就叫做贪心搜索，但是真正需要的是一次性挑选出整个单词序列，从<script type="math/tex">y^{<1>}</script>、<script type="math/tex">y^{<2>}</script>到<script type="math/tex">y^{<T_{y}>}</script>来使得整体的概率最大化。所以贪心算法先挑出最好的第一个词，在这之后再挑最好的第二词，然后再挑第三个，这种方法并不管用</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/c50a0e8948bbdb9a1d23f2f8a768bf5c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c50a0e8948bbdb9a1d23f2f8a768bf5c.png" alt></a></p><p>第一串（编号1）翻译明显比第二个（编号2）好，但如果贪心算法挑选出了”<strong>Jane is</strong>“作为前两个词，因为在英语中<strong>going</strong>更加常见，于是对于法语句子来说”<strong>Jane is going</strong>“相比”<strong>Jane is visiting</strong>“会有更高的概率作为法语的翻译，所以如果仅仅根据前两个词来估计第三个词的可能性，得到的更可能是<strong>going</strong>，最终得到一个欠佳的句子</p><p>当想得到单词序列<script type="math/tex">y^{<1>}</script>、<script type="math/tex">y^{<2>}</script>一直到最后一个词总体的概率时，一次仅仅挑选一个词并不是最佳的选择。如果字典中有10,000个单词，翻译有10个词，可能的组合就有10,000的10次方这么多，从这样大一个字典中来挑选单词，句子数量非常巨大，大大增加了运算成本，降低运算速度，不可能去计算每一种组合的可能性</p><p>所以最常用的办法就是用一个近似的搜索算法，它会尽力地将挑选出句子<script type="math/tex">y</script>使得条件概率最大化，尽管不能保证找到的<script type="math/tex">y</script>值一定可以使概率最大化</p><p>机器翻译模型和之前的语言模型一个主要的区别就是：相比之前的模型随机地生成句子，该模型是找到最有可能的翻译</p><h2 id="3-3-集束搜索（Beam-Search）"><a href="#3-3-集束搜索（Beam-Search）" class="headerlink" title="3.3 集束搜索（Beam Search）"></a>3.3 集束搜索（Beam Search）</h2><p>“<strong>Jane visite l’Afrique en Septembre.</strong>”翻译成英语”<strong>Jane is visiting Africa in September</strong>“.，集束搜索算法首先做的就是挑选要输出的英语翻译中的第一个单词。这里列出了10,000个词的词汇表，忽略大小写，在集束搜索的第一步中用这个网络来评估第一个单词的概率值，给定输入序列<script type="math/tex">x</script>，即法语作为输入，第一个输出<script type="math/tex">y</script>的概率值是多少</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8a22dfb5d3c0a4b5d2fdfa716dc3f3b2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8a22dfb5d3c0a4b5d2fdfa716dc3f3b2.png" alt></a></p><p>集束搜索会考虑多个选择，集束搜索算法会有一个参数<strong>B</strong>，叫做集束宽（<strong>beam width</strong>）。这个例子中集束宽设成3，意味着集束搜索一次会考虑3个可能结果，比如对第一个单词有不同选择的可能性，最后找到<strong>in</strong>、<strong>jane</strong>、<strong>september</strong>，是英语输出的第一个单词的最可能的三个选项，然后集束搜索算法会把结果存到计算机内存里以便后面尝试用这三个词。为了执行集束搜索的第一步，需要输入法语句子到编码网络，然后解码这个网络，<strong>softmax</strong>层会输出10,000个概率值，然后取前三个存起来，概率表示为：</p><script type="math/tex; mode=display">P(\hat y^{<1>} | x)</script><p>集束搜索算法的第二步：针对每个第一个单词考虑第二个单词是什么</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/14a940ae2ea7932b7b7190eceb79f79e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/14a940ae2ea7932b7b7190eceb79f79e.png" alt></a></p><p>为了评估第二个词的概率值，把<script type="math/tex">y^{<1>}</script>设为单词<strong>in</strong>（编号3），输出就是<script type="math/tex">y^{<2>}</script>（编号5），有了这个连接（编号6），这个网络就可以用来评估：在给定法语句子和翻译结果的第一个单词<strong>in</strong>的情况下第二个单词的概率</p><p>在第二步更关心的是要找到最可能的第一个和第二个单词对，所以不仅仅是第二个单词有最大的概率，而是第一个、第二个单词对有最大的概率（编号7）。可以表示成第一个单词的概率（编号8）乘以第二个单词的概率（编号9）：</p><script type="math/tex; mode=display">P(\hat y^{<1>},\hat y^{<2>}|x)=P(\hat y^{<1>} | x)\cdot P(\hat y^{<2>}|x,\hat y^{<1>})</script><p><strong>jane</strong>、<strong>september</strong>跟上面一样</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/507c9081ee77c686bb96a009248087fd.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/507c9081ee77c686bb96a009248087fd.png" alt></a></p><p>注意，如果集束搜索找到了第一个和第二个单词对最可能的三个选择是“<strong>in September</strong>”或者“<strong>jane is</strong>”或者“<strong>jane visits</strong>”，就意味着去掉了<strong>september</strong>作为英语翻译结果的第一个单词的选择，第一个单词现在减少到了两个可能结果，但是集束宽是3，还是有<script type="math/tex">y^{<1>}</script>，<script type="math/tex">y^{<2>}</script>对的三个选择</p><p>接着，再预测第三个单词。分别以in september，jane is，jane visits为条件，计算每个词汇表单词作为预测第三个单词的概率。从中选择概率最大的3个作为第三个单词的预测值，得到：in september jane，jane is visiting，jane visits africa</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6a0b785dd54fcbc439bd82794eeefcf8.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6a0b785dd54fcbc439bd82794eeefcf8.png" alt></a></p><p>概率表示为：</p><script type="math/tex; mode=display">P(\hat y^{<3>}|x,\hat y^{<1>},\hat y^{<2>})</script><p>此时，得到的前三个单词的3种情况的概率为：</p><script type="math/tex; mode=display">P(\hat y^{<1>},\hat y^{<2>},\hat y^{<3>}|x)=P(\hat y^{<1>} | x)\cdot P(\hat y^{<2>}|x,\hat y^{<1>})\cdot P(\hat y^{<3>}|x,\hat y^{<1>},\hat y^{<2>})</script><p>以此类推，每次都取概率最大的三种预测。最后，选择概率最大的那一组作为最终的翻译语句：</p><p><strong>Jane is visiting Africa in September.</strong></p><p>如果参数B=1，则就等同于greedy search。实际应用中，可以根据不同的需要设置B为不同的值。一般B越大，机器翻译越准确，但同时也会增加计算复杂度</p><h2 id="3-4-改进集束搜索（Refinements-to-Beam-Search）"><a href="#3-4-改进集束搜索（Refinements-to-Beam-Search）" class="headerlink" title="3.4 改进集束搜索（Refinements to Beam Search）"></a>3.4 改进集束搜索（Refinements to Beam Search）</h2><p>长度归一化（<strong>Length normalization</strong>）是对束搜索算法稍作调整的一种方式，使之得到更好的结果</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/725eec5b76123bf45c9495e1231b6584.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/725eec5b76123bf45c9495e1231b6584.png" alt></a></p><p><strong>束搜索</strong>就是最大化概率<script type="math/tex">P(y^{< 1 >}\ldots y^{< T_{y}>}|X)</script>，表示成:</p><script type="math/tex; mode=display">P(y^{<1>}|X)P(y^{< 2 >}|X,y^{< 1 >})P(y^{< 3 >}|X,y^{< 1 >},y^{< 2>})\cdots P(y^{< T_{y} >}|X,y^{<1 >},y^{<2 >}\ldots y^{< T_{y} - 1 >})</script><p>即乘积概率（<strong>the product probabilities</strong>）：</p><script type="math/tex; mode=display">arg\ max\prod_{t=1}^{T_y} P(\hat y^{< t>}|x,\hat y^{<1>},\cdots,\hat y^{<t-1>})</script><p>这些概率值通常都远小于1，会造成<strong>数值下溢</strong>（<strong>numerical underflow</strong>），即数值太小了，导致电脑的浮点表示不能精确地储存</p><p>因此在实践中,不会最大化这个乘积，而是取<script type="math/tex">log</script>值：</p><script type="math/tex; mode=display">arg\ max \sum_{t=1}^{T_y}\log P(\hat y^{<t>}|x,\hat y^{<1>},\cdots,\hat y^{<t-1>})</script><p>会得到一个数值上更稳定的算法，不容易出现数值的舍入误差（<strong>rounding errors</strong>）或者说数值下溢（<strong>numerical underflow</strong>）</p><p>参照原来的目标函数（<strong>this original objective</strong>），如果有一个很长的句子，那么这个句子的概率会很低，因为乘了很多项小于1的数字来估计句子的概率，就会得到一个更小的概率值，所以可能不自然地倾向于简短的翻译结果，因为短句子的概率是由更少数量的小于1的数字乘积得到的，所以乘积不会那么小。概率的<script type="math/tex">log</script>值也有同样的问题</p><p>解决：可以把它归一化，通过除以翻译结果的单词数量。即取每个单词的概率对数值的平均，这样很明显地减少了对输出长的结果的惩罚：</p><script type="math/tex; mode=display">arg\ max\ \frac{1}{T_y}\sum_{t=1}^{T_y}\log P(\hat y^{< t>}|x,\hat y^{<1>},\cdots,\hat y^{<t-1>})</script><p>在实践中，会用一个更柔和的方法（<strong>a softer approach</strong>），在<script type="math/tex">T_{y}</script>上加上指数<script type="math/tex">\alpha</script>：</p><script type="math/tex; mode=display">arg\ max\ \frac{1}{T_y^{\alpha}}\sum_{t=1}^{T_y}\log P(\hat y^{< t>}|x,\hat y^{<1>},\cdots,\hat y^{<t-1>})</script><p>$\alpha$可以等于0.7。如果<script type="math/tex">\alpha</script>等于1，就相当于完全用长度来归一化，如果<script type="math/tex">\alpha</script>等于0，<script type="math/tex">T_{y}</script>的0次幂就是1，就相当于完全没有归一化，<script type="math/tex">\alpha</script>就是算法另一个超参数（<strong>hyper parameter</strong>）</p><p>总结一下如何运行束搜索算法：</p><p>当运行束搜索时，会看到很多长度分别等于1、2、3…的句子等等，针对这些所有的可能的输出句子，取概率最大的几个句子，然后对这些句子计算目标函数<script type="math/tex">arg\ max\ \frac{1}{T_y^{\alpha}}\sum_{t=1}^{T_y}\log P(\hat y^{<t>}|x,\hat y^{<1>},\cdots,\hat y^{<t-1>})</script>，最后从经过评估的这些句子中挑选出在归一化的<script type="math/tex">log</script> 概率目标函数上得分最高的一个，也叫作<strong>归一化的对数似然目标函数</strong>（<strong>a normalized log likelihood objective</strong>）</p><p>如何选择束宽<strong>B：</strong></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/96e50aec6e1d7287e5bac70a0c4d92f4.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/96e50aec6e1d7287e5bac70a0c4d92f4.png" alt></a></p><ul><li><strong>B</strong>越大，考虑的选择越多，找到的句子可能越好，但是算法的计算代价越大，因为要把很多的可能选择保存起来，内存占用增大</li><li>如果用小的束宽<strong>B</strong>，结果会没那么好，因为在算法运行中，保存的选择更少，但是算法运行的更快，内存占用也小</li></ul><p>在产品中，经常可以看到把束宽设到10，当B很大的时候，性能提高会越来越少。对于很多应用来说，从束宽1，也就是贪心算法，到束宽为3、到10，会看到一个很大的改善。但是当束宽从1000增加到3000时，效果就没那么明显</p><p>相对广度优先搜索（<strong>BFS, Breadth First Search algorithms</strong>），深度优先搜索（<strong>DFS, Depth First Search</strong>）这些精确的搜索算法（<strong>exact search algorithms</strong>），束搜索运行的更快，但是不能保证一定能找到argmax的准确的最大值</p><h2 id="3-5-集束搜索的误差分析（Error-analysis-in-beam-search）"><a href="#3-5-集束搜索的误差分析（Error-analysis-in-beam-search）" class="headerlink" title="3.5 集束搜索的误差分析（Error analysis in beam search）"></a>3.5 集束搜索的误差分析（Error analysis in beam search）</h2><p>束搜索算法是一种<strong>近似搜索算法</strong>（<strong>an approximate search algorithm</strong>），也被称作<strong>启发式搜索算法</strong>（<strong>a heuristic search algorithm</strong>），它不总是输出可能性最大的句子，它仅记录着<strong>B</strong>为前3或者10或是100种可能</p><p>人工标记为<script type="math/tex">y^*</script>。束搜索算法翻译结果标记为<script type="math/tex">\hat y</script>，是一个十分糟糕的翻译，改变了句子的原意：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/748283d682db5be4855e61b90e96c427.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/748283d682db5be4855e61b90e96c427.png" alt></a></p><p>模型有两个主要部分，一个是神经网络模型，或说是序列到序列模型（<strong>sequence to sequence model</strong>），称作是<strong>RNN</strong>模型，另一部分是束搜索算法，以某个集束宽度<strong>B</strong>运行</p><p><strong>RNN</strong>(<strong>循环神经网络</strong>)实际上是个编码器和解码器（<strong>the encoder and the decoder</strong>），它会计算<script type="math/tex">P(y|x)</script>。如对于句子：<strong>Jane visits Africa in September</strong>，将<strong>Jane visits Africa</strong>填入这里（上图编号1），忽略字母的大小写，后面也是一样，计算得到<script type="math/tex">P(y^*|x)</script>，<script type="math/tex">P(\hat y|x)</script> 同样如此，然后比较一下这两个值哪个更大</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/1bc0b442db9d5a1aa19dfe9a477a3c3e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1bc0b442db9d5a1aa19dfe9a477a3c3e.png" alt></a></p><ul><li>若<script type="math/tex">P(y^*|x)</script> 大于<script type="math/tex">P(\hat y|x)</script>，可束搜索算法却选择了<script type="math/tex">\hat y</script> ， 因此能够得出束搜索算法实际上不能给出使<script type="math/tex">P(y|x)</script>最大化的<script type="math/tex">y</script>值，因为束搜索算法的任务就是寻找一个<script type="math/tex">y</script>的值来使这项更大，但是它却选择了<script type="math/tex">\hat y</script>，而<script type="math/tex">y^*</script>实际上能得到更大的值。因此这种情况下束搜索算法出错</li><li>若<script type="math/tex">P(y^*|x)</script>小于或等于<script type="math/tex">P(\hat y|x)</script>，<script type="math/tex">y^*</script> 是比 <script type="math/tex">\hat y</script>更好的翻译结果，不过根据RNN模型的结果，<script type="math/tex">P(y^*)</script> 是小于<script type="math/tex">P(\hat y)</script>的，即相比于<script type="math/tex">\hat y</script>，<script type="math/tex">y^*</script>成为输出的可能更小。因此在这种情况下是<strong>RNN</strong>模型出了问题</li></ul><p>以上都忽略了长度归一化（<strong>length normalizations</strong>）的细节，如果用了某种长度归一化，那么要比较长度归一化后的最优化目标函数值</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2689876529562b7d9a79bf868e7cbad7.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2689876529562b7d9a79bf868e7cbad7.png" alt></a></p><p>误差分析过程：</p><ol><li>先遍历开发集，找出算法产生的错误</li><li>假如<script type="math/tex">P(y^*|x)</script>的值为2 x 10<script type="math/tex">^{-10}</script>，而<script type="math/tex">P(\hat y|x)</script>的值为 1 x10<script type="math/tex">^{-10}</script>，得知束搜索算法实际上选择了比<script type="math/tex">y^*</script>可能性更低的<script type="math/tex">\hat y</script>，则束搜索算法出错，缩写为<strong>B</strong></li><li>接着继续遍历第二个错误，若对于第二个例子是<strong>RNN</strong>模型出现了问题，用缩写<strong>R</strong>来代表<strong>RNN</strong></li><li>接着遍历更多的例子，有时是束搜索算法出现了问题，有时是模型出现了问题，等等</li><li>执行误差分析，得出束搜索算法和<strong>RNN</strong>模型出错的比例是多少。对开发集中每一个错误例子，即算法输出了比人工翻译更差的结果的情况，尝试确定是搜索算法出了问题，还是生成目标函数(束搜索算法使之最大化)的<strong>RNN</strong>模型出了问题。找到这两个部分中哪个是产生更多错误的原因</li><li>只有当发现是束搜索算法造成了大部分错误时，才值得花费努力<strong>增大集束宽度B</strong>；如果发现是<strong>RNN</strong>模型出了更多错，那么可以进行更深层次的分析，来决定是需要<strong>增加正则化</strong>还是<strong>获取更多的训练数据</strong>，抑或是尝试一个<strong>不同的网络结构</strong></li></ol><h2 id="3-6-Bleu-得分（选修）（Bleu-Score-optional-）"><a href="#3-6-Bleu-得分（选修）（Bleu-Score-optional-）" class="headerlink" title="3.6 Bleu 得分（选修）（Bleu Score (optional)）"></a>3.6 Bleu 得分（选修）（Bleu Score (optional)）</h2><p>机器翻译（<strong>machine translation</strong>）的一大难题是一个法语句子可以有多种英文翻译而且都同样很好，常见的解决办法是通过一个<strong>BLEU</strong>得分（<strong>the BLEU score</strong>）的东西来解决，BLEU得分是一个有用的单一实数评估指标，用于评估生成文本的算法，判断输出的结果是否与人工写出的参考文本的含义相似</p><p>一般有多个人工翻译：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5e854a803e36991a6e0dd4e33ecab930.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5e854a803e36991a6e0dd4e33ecab930.png" alt></a></p><p>BLEU得分做的就是给定一个机器生成的翻译，它能够自动地计算一个分数来衡量机器翻译的好坏。只要机器生成的翻译与任何一个人工翻译的结果足够接近，那么它就会得到一个高的BLEU分数。<strong>BLEU</strong>代表<strong>bilingual evaluation understudy</strong>(双语评估替补)。且这些人工翻译的参考会包含在开发集或是测试集中</p><p>假设机器翻译 (<strong>MT</strong>)的输出是：<strong>the the the the the the the，</strong>是一个十分糟糕的翻译。衡量机器翻译输出质量的方法之一是<strong>观察输出结果的每一个词，看其是否出现在参考中</strong>，这被称做是机器翻译的精确度（<strong>a precision of the machine translation output</strong>）。这个情况下，机器翻译输出了七个单词并且这七个词中的每一个都出现在了参考1或是参考2，因此输出的精确度就是7/7，分母为机器翻译单词数目，分子为相应单词是否出现在参考翻译中。但是，这种方法很不科学，并不可取</p><p>改良后的精确度评估方法（<strong>the modified precision measure</strong>）：<strong>把每一个单词的记分上限定为它在参考句子中出现的最多次数</strong>。在参考1中，单词<strong>the</strong>出现了两次，在参考2中，单词<strong>the</strong>只出现了一次。单词<strong>the</strong>的得分上限为2。输出句子的得分为2/7，分母是7个词中单词<strong>the</strong>总共出现的次数，分子是单词<strong>the</strong>出现的计数，在达到<strong>上限</strong>时截断计数</p><p>上述都只是关注单独的单词，在<strong>BLEU</strong>得分中，另外一种更科学的打分方法是<strong>bleu score on bigrams（二元词组）</strong>，bigram的意思就是相邻的两个单词</p><p>定义<strong>截取计数</strong>（<strong>the clipped count</strong>），也就是<strong>Count_clip：</strong>给算法设置得分上限，上限值为二元词组出现在参考1<strong>或</strong>2中的最大次数</p><p>假定机器翻译输出了稍微好一点的翻译，对MT output进行分解，得到的bigrams及其出现在MT output中的次数count为：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0bc25316900ccd1d4dd25a35ec7c45c4.png" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0bc25316900ccd1d4dd25a35ec7c45c4.png" alt></a></p><p>相应的bigrams precision为4/6也就是2/3，为二元词组改良后的精确度</p><p>将改良后的一元词组精确度定义为<script type="math/tex">P_1</script>，<script type="math/tex">P</script>代表的是精确度。下标1的意思是一元词组，即考虑单独的词，<script type="math/tex">P_n</script> 定义为<script type="math/tex">n</script>元词组精确度，用<strong>n-gram</strong>替代掉一元词组。即机器翻译输出中的<script type="math/tex">n</script>元词组的<strong>countclip</strong>之和除以<script type="math/tex">n</script>元词组的出现次数之和</p><p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/7f48951acf8ca7c7b63f6c4c455ada18.png" alt></p><p>如果机器翻译输出与参考1或是参考2完全一致，那么所有的<script type="math/tex">P_1</script>、<script type="math/tex">P_2</script>等等的值，都会等于1.0</p><p>最终的BLEU得分：</p><p>将得到的<script type="math/tex">P_1</script>，<script type="math/tex">P_2</script>， <script type="math/tex">P_3</script>…<script type="math/tex">P_n</script> 相加再取平均值</p><p>BLEU得分被定义为：</p><script type="math/tex; mode=display">p=exp (\frac{1}{n}\sum\limits_{i=1}^{n}{P_i})</script><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0f9646d825a0c254376e094b48523ed3.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0f9646d825a0c254376e094b48523ed3.png" alt></a></p><p>然后用BP（“简短惩罚”brevity penalty） 的惩罚因子（the BP penalty）来调整。它能够惩罚输出了太短翻译结果的翻译系统：</p><script type="math/tex; mode=display">p=BP\cdot exp(\frac1n\sum_{i=1}^np_i)</script><p>BLEU得分被用来评估许多生成文本的系统（systems that generate text），比如说机器翻译系统（machine translation systems），图像描述系统（image captioning systems）。不过它并没有用于语音识别（speech recognition）。因为在语音识别当中，通常只有一个答案</p><h2 id="3-7-注意力模型直观理解（Attention-Model-Intuition）"><a href="#3-7-注意力模型直观理解（Attention-Model-Intuition）" class="headerlink" title="3.7 注意力模型直观理解（Attention Model Intuition）"></a>3.7 注意力模型直观理解（Attention Model Intuition）</h2><p>给定一个很长的法语句子，在神经网络中，绿色的编码器要做的就是读整个句子，然后记忆整个句子，再在感知机中传递。紫色的神经网络，即解码网络（<strong>the decoder network</strong>）将生成英文翻译</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/59279ff91bb69a94280e6735eba8ab99.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/59279ff91bb69a94280e6735eba8ab99.png" alt></a></p><p>对于短句子效果非常好，会有一个相对高的<strong>Bleu</strong>分（<strong>Bleu score</strong>），但是对于长句子而言，比如说大于30或者40词的句子，它的表现就会变差。<strong>Bleu</strong>评分随着单词数量变化，短的句子会难以翻译，因为很难得到所有词。对于长的句子，效果也不好，因为在神经网络中，记忆非常长句子是非常困难的。</p><p>而注意力模型翻译得很像人类，一次翻译句子的一部分。且机器翻译系统只会翻译句子的一部分，不会有一个巨大的下倾（<strong>huge dip</strong>），这个下倾衡量了神经网络记忆一个长句子的能力</p><p>对于句子里的每五个单词，使用双向的<strong>RNN</strong>（<strong>a bidirectional RNN</strong>），使用另一个<strong>RNN</strong>生成英文翻译：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/3dcdd58eaa544a09e67eb892f8c732bf.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/3dcdd58eaa544a09e67eb892f8c732bf.png" alt></a></p><p>S^{<t>}$由原语句附近单元共同决定，<strong>注意力权重（attention weights）</strong><script type="math/tex">\alpha^{<  t,t'>}</script> 表示尝试生成第<script type="math/tex">t</script>个英文词时应该花多少注意力在第<script type="math/tex">t'</script>个法语词上面。直到最终生成<script type="math/tex">< EOS></script>。离得越近，<strong>注意力权重</strong>越大，相当于当前的注意力区域有个滑动窗。<script type="math/tex">c</script>表示编码器激活函数在注意力权重加权后的结果，将<script type="math/tex">c</script>输入到解码器用来生成翻译语句， 同时上一个时间步输出的翻译结果也加入</t></p><h2 id="3-8-注意力模型（Attention-Model）"><a href="#3-8-注意力模型（Attention-Model）" class="headerlink" title="3.8 注意力模型（Attention Model）"></a>3.8 注意力模型（Attention Model）</h2><p>注意力模型让一个神经网络只注意到一部分的输入句子。当它在生成句子的时候，更像人类翻译</p><p>假定有一个输入句子，并使用双向的<strong>RNN</strong>，或者双向的<strong>GRU</strong>或者双向的<strong>LSTM</strong>，去计算每个词的特征：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/1e6b86a4e3690b4a0c6b8146ffa2f791.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1e6b86a4e3690b4a0c6b8146ffa2f791.png" alt></a></p><p>用<script type="math/tex">a^{<t{'}>}</script>表示时间步<script type="math/tex">t</script>上的特征向量。用<script type="math/tex">t{'}</script>来索引法语句子里面的词，由于是双向RNN，每个<script type="math/tex">a^{<t{'}>}</script>：</p><script type="math/tex; mode=display">a^{<t{'}>}=(a^{\rightarrow <t{'}>},a^{\leftarrow <t{'}>})</script><p>注意力权重用<script type="math/tex">\alpha</script>表示，C是各个RNN神经元经过注意力权重得到的参数值。例如<script type="math/tex">\alpha^{<1,t{'}>}</script>表示机器翻译的第一个单词“jane”对应的第<script type="math/tex">t{'}</script>个RNN神经元，<script type="math/tex">C^{<1>}</script>表示机器翻译第一个单词“jane”对应的解码网络输入参数。满足：</p><script type="math/tex; mode=display">\sum_{t{'}}\alpha^{<1,t{'}>}=1</script><script type="math/tex; mode=display">C^{<1>}=\sum_{t{'}}\alpha^{<1,t{'}>}\cdot a^{<t{'}>}</script><p>用状态<script type="math/tex">S</script>表示生成翻译。<script type="math/tex">\alpha^{<t,t{'}>}</script>是输出<script type="math/tex">\hat y^{<t>}</script>在<script type="math/tex">t{'}</script>时对RNN单元花在<script type="math/tex">a^{< t{ '}>}</script>上的注意力权重因子。即在<script type="math/tex">t</script>处生成输出词应该花多少注意力在第<script type="math/tex">t{'}</script>个输入词上面</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b22dff4a3b1a4ea8c1ab201446e98889.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b22dff4a3b1a4ea8c1ab201446e98889.png" alt></a></p><p>为了让<script type="math/tex">\alpha^{<t,t{'}>}</script>之和为1，利用softamx思想，引入参数<script type="math/tex">e^{<t,t{'}>}</script>，使得：</p><script type="math/tex; mode=display">a^{<t,t'>} = \frac{\text{exp}(e^{<t,t'>})}{\sum^{T_x}_{t'=1} \text{exp}(e^{<t,t'>})}</script><p>只要求出<script type="math/tex">e^{<t,t{'}>}</script>，就能得到<script type="math/tex">\alpha^{<t,t{'}>}</script></p><p>如何求出<script type="math/tex">e^{<t,t{'}>}</script>：</p><p>建立一个简单的神经网络</p><p><img src="/images/pasted-166.png" alt="upload successful"></p><p>输入<script type="math/tex">s^{<t-1>}</script>，即神经网络在上个时间步的状态和<script type="math/tex">a^{<t{'}>}</script>，训练一个很小的神经网络，利用反向传播算法、梯度下降算法迭代优化，学到一个正确的函数<script type="math/tex">e^{<t,t{'}>}</script> 和<script type="math/tex">\alpha^{<t,t{'}>}</script></p><p>缺点：计算量较大，<script type="math/tex">T_x</script>个输入单词和<script type="math/tex">T_y</script>个输出单词的注意力参数的总数是<script type="math/tex">T_x\times T_y</script>，但是在机器翻译的应用上，输入和输出的句子一般不会太长，消耗还是可以接受</p><p>注意力模型在图像捕捉方面也有应用。比如图片加标题（<strong>image captioning</strong>），即看一张图，写下这张图的标题</p><p>Attention model还能处理日期标准化的问题（<strong>the date normalization problem</strong>）：</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/fa6769127cd98ea0058f600449833a21.png" alt></a></p><p>训练一个神经网络，输入任何形式的日期，生成标准化的日期形式</p><p>还有可视化的注意力权重（<strong>the visualizations of the attention weights</strong>）。颜色越白表示注意力权重越大，颜色越深表示权重越小。输出语句单词与其输入语句单词对应位置的注意力权重较大，即对角线附近</p><h2 id="3-9-语音识别（Speech-recognition）"><a href="#3-9-语音识别（Speech-recognition）" class="headerlink" title="3.9 语音识别（Speech recognition）"></a>3.9 语音识别（Speech recognition）</h2><p>输入音频片段<script type="math/tex">x</script>（<strong>an audio clip,x</strong>），生成文本<script type="math/tex">y</script>：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8da3e9cf049139a8e4a78503bd72e7fd.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8da3e9cf049139a8e4a78503bd72e7fd.png" alt></a></p><p>音频片段横轴是时间。麦克风的作用是测量出微小的气压变化，而气压随着时间而变化。音频数据的常见预处理步骤就是运行这个原始的音频片段，然后生成一个声谱图（<strong>a spectrogram</strong>），横轴是时间，纵轴是声音的频率（<strong>frequencies</strong>），图中不同的颜色显示了声波能量的大小（<strong>the amount of energy</strong>），也就是在不同的时间和频率上这些声音有多大</p><p>在<strong>end-to-end</strong>模型中，可以构建一个系统，通过向系统中输入音频片段（<strong>audio clip</strong>），然后直接输出音频的文本（<strong>a transcript</strong>）。这种方法要用一个很大的数据集，需要上千上万个小时的语音素材</p><p>如何建立一个语音识别系统：</p><p>在输入音频的不同时间帧上，用一个注意力模型来输出文本描述，如”<strong>the quick brown fox</strong>“</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/4130b85a0694549f02bdf60f7c47a3d7.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/4130b85a0694549f02bdf60f7c47a3d7.png" alt></a></p><p>另一种方法是<strong>CTC</strong>损失函数（<strong>CTC cost</strong>），即<strong>Connectionist Temporal Classification</strong></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8f409fc3980b0be00dca49bf4fac2659.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8f409fc3980b0be00dca49bf4fac2659.png" alt></a></p><p>输入<script type="math/tex">x</script>和输出<script type="math/tex">y</script>的数量都是一样，这里只是一个简单的单向<strong>RNN</strong>结构，在实际中有可能是双向的<strong>LSTM、GRU</strong>结构，并且通常是很深的模型</p><p>在语音识别中，通常输入的时间步数量（<strong>the number of input time steps</strong>）要比输出的时间步的数量（<strong>the number of output time steps</strong>）多出很多。如一段10秒的音频，并且特征（<strong>features</strong>）是100赫兹的，即每秒有100个样本，于是这段10秒的音频片段就会有1000个输入</p><p>算法思想如下：</p><p>把输出相应字符重复并加入空白（blank），形如：</p><script type="math/tex; mode=display">ttt \_ h\_eee\_ \_ \_ \sqcup\_ \_ \_ qqq\_ \_ \cdots</script><p>下划线”_“表示空白，“<script type="math/tex">\sqcup</script>“表示两个单词之间的空字符</p><p>CTC损失函数的一个基本规则是没有被空白符”_“分割的重复字符将被折叠到一起，即表示一个字符。<strong>the</strong>和<strong>quick</strong>之间有一个空格符，这段序列折叠成”the q<strong>“</strong></p><h2 id="3-10-触发字检测（Trigger-Word-Detection）"><a href="#3-10-触发字检测（Trigger-Word-Detection）" class="headerlink" title="3.10 触发字检测（Trigger Word Detection）"></a>3.10 触发字检测（Trigger Word Detection）</h2><p>触发字系统的例子如下：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/28443f8b28afa63adb6cf89ce19c4f6d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/28443f8b28afa63adb6cf89ce19c4f6d.png" alt></a></p><p>对于这样的<strong>RNN</strong>结构，要做的就是计算出一个音频片段（an audio clip）的声谱图特征（spectrogram features），得到特征向量<script type="math/tex">x^{<1>}</script>, <script type="math/tex">x^{<2>}</script>, <script type="math/tex">x^{<3>}</script>..，然后把它放到<strong>RNN</strong>中，最后定义目标标签<script type="math/tex">y</script></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f2da69f9fa6462c8e591e79db452f6c1.png" target="_blank" rel="noopener"><img src="/assets/505import.png" alt></a></p><p>假如音频片段中的这一点是某人刚刚说完一个触发字，比如”<strong>Alexa</strong>“，那么在这一点之前，可以在训练集中把目标标签都设为0，在这个点之后把目标标签设为1。假如在一段时间之后，触发字又被说了一次，那么就可以再次在这个点之后把目标标签设为1</p><p>不过该算法一个明显的缺点：它构建了一个很不平衡的训练集（<strong>a very imbalanced training set</strong>），0的数量比1多太多</p><p>解决方法：在输出变回0之前，多次输出1，或说在固定的一段时间内输出多个1，就稍微提高了1与0的比例，即在音频片段中，触发字刚被说完之后，就把多个目标标签设为1</p><p><img src="/images/pasted-167.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;3-1-基础模型（Basic-Models）&quot;&gt;&lt;a href=&quot;#3-1-基础模型（Basic-Models）&quot; class=&quot;headerlink&quot; title=&quot;3.1 基础模型（Basic Models）&quot;&gt;&lt;/a&gt;3.1 基础模型（Basic Models）&lt;/h2&gt;&lt;h3 id=&quot;机器翻译&quot;&gt;&lt;a href=&quot;#机器翻译&quot; class=&quot;headerlink&quot; title=&quot;机器翻译&quot;&gt;&lt;/a&gt;机器翻译&lt;/h3&gt;&lt;p&gt;用&lt;script type=&quot;math/tex&quot;&gt;x^{&lt;1&gt;}&lt;/script&gt; 到&lt;script type=&quot;math/tex&quot;&gt;x^{&lt; 5&gt;}&lt;/script&gt;表示输入句子的单词，用&lt;script type=&quot;math/tex&quot;&gt;y^{&lt;1&gt;}&lt;/script&gt;到&lt;script type=&quot;math/tex&quot;&gt;y^{&lt;6&gt;}&lt;/script&gt;表示输出句子的单词：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2d41c0090fd3d71e6f28eade62b7c97b.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2d41c0090fd3d71e6f28eade62b7c97b.png&quot; alt&gt;&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第二周 自然语言处理与词嵌入（Natural Language Processing and Word Embeddings）(Course 5)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E4%BA%8C%E5%91%A8-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E8%AF%8D%E5%B5%8C%E5%85%A5%EF%BC%88Natural-Language-Processing-and-Word-Embeddings%EF%BC%89-Course-5/"/>
    <id>https://baozouai.com/2019/02/28/第二周-自然语言处理与词嵌入（Natural-Language-Processing-and-Word-Embeddings）-Course-5/</id>
    <published>2019-02-27T22:17:00.000Z</published>
    <updated>2019-02-27T07:18:29.888Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-1-词汇表征（Word-Representation）"><a href="#2-1-词汇表征（Word-Representation）" class="headerlink" title="2.1 词汇表征（Word Representation）"></a>2.1 词汇表征（Word Representation）</h2><p><strong>one-hot</strong>向量表示：单词Man，Woman，King，Queen，Apple，Orange分别出现在词汇表的第5391，9853，4914，7157，456，6257的位置，则它们分别用<script type="math/tex">O_{5391}</script>,<script type="math/tex">O_{9853}</script> 等表示，<script type="math/tex">O</script>代表<strong>one-hot：</strong><br><a id="more"></a><br><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/68d7c930146724f39782cb57d33161e9.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/68d7c930146724f39782cb57d33161e9.png" alt></a></p><p>缺点是把每个词孤立起来，使得算法对相关词的泛化能力不强</p><p>因为任何两个one-hot向量的内积都是0，例如king和queen，词性相近，但是单从one-hot编码上来看，内积为零，无法知道二者的相似性</p><p>因此用<strong>特征表征（Featurized representation）</strong>的方法对每个单词进行编码。也就是使用一个特征向量表征单词，特征向量的每个元素都是对该单词某一特征的量化描述，量化范围可以是[-1,1]之间，而单词使用这种高维特征表示时，就叫做<strong>词嵌入（word embedding）， </strong>词嵌入可以让算法自动的理解一些类似的词，比如男人对女人，国王对王后：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ce30c9ae7912bdb3562199bf85eca1cd.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ce30c9ae7912bdb3562199bf85eca1cd.png" alt></a></p><blockquote><p>以上举例的特征实际上并不是手工设计的，而是算法（word embedding）学习而来；而且这些学习的特征，可能并不具有良好的解释性，但无论如何，算法都可以快速找到哪些单词是类似的</p></blockquote><p>特征向量的长度依情况而定，特征元素越多则对单词表征得越全面。这里的特征向量长度设定为300。使用特征表征之后，词汇表中的每个单词都可以使用对应的300 x 1的向量来表示，该向量的每个元素表示该单词对应的某个特征值。每个单词用e+词汇表索引的方式标记，例如<script type="math/tex">e_{5391}</script>，<script type="math/tex">e_{9853}</script>，<script type="math/tex">e_{4914}</script>，<script type="math/tex">e_{7157}</script>，<script type="math/tex">e_{456}</script>，<script type="math/tex">e_{6257}</script></p><p>用这种表示方法来表示<strong>apple</strong>和<strong>orange</strong>这些词，那么<strong>apple</strong>和<strong>orange</strong>的这种表示肯定会非常相似，可能有些特征不太一样，如颜色口味，但总的来说<strong>apple</strong>和<strong>orange</strong>的大部分特征实际上都一样，或者说都有相似的值。这样对于已经知道<strong>orange juice</strong>的算法很大几率上也会明白<strong>apple juice</strong>这个东西，这样对于不同的单词算法会泛化的更好</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/59fb45cfdf7faa53571ec7b921b78358.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/59fb45cfdf7faa53571ec7b921b78358.png" alt></a></p><p>如果能够学习到一个300维的特征向量，或者说300维的<strong>词嵌入</strong>，把这300维的数据嵌入到一个二维空间里，就可以可视化了。常用的可视化算法是<strong>t-SNE算法</strong>，会发现<strong>man</strong>和<strong>woman</strong>这些词聚集在一块，<strong>king</strong>和<strong>queen</strong>聚集在一块等等</p><p>在对这些概念可视化的时候，词嵌入算法对于相近的概念，学到的特征也比较类似，最终把它们映射为相似的特征向量</p><h2 id="2-2-使用词嵌入（Using-Word-Embeddings）"><a href="#2-2-使用词嵌入（Using-Word-Embeddings）" class="headerlink" title="2.2 使用词嵌入（Using Word Embeddings）"></a>2.2 使用词嵌入（Using Word Embeddings）</h2><p>之前Named entity识别的例子（即找出语句中的人名），每个单词采用的是one-hot编码。RNN模型能确定<strong>Sally Johnson</strong>是一个人名而不是一个公司名，是因为“orange farmer”是份职业，很明显“Sally Johnson”是一个人名（输出1）</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b4bf4b0cdcef0c9d021707c47d5aecda.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b4bf4b0cdcef0c9d021707c47d5aecda.png" alt></a></p><p>如果用特征化表示方法，即用<strong>词嵌入</strong>作为输入训练好的模型，如果一个新的输入：“<strong>Robert Lin is an apple farmer.</strong>”，因为知道<strong>orange</strong>和<strong>apple</strong>很相近，那么算法很容易就知道<strong>Robert Lin</strong>也是一个人的名字</p><p><strong>featurized representation</strong>的优点是可以减少训练样本的数目，前提是对海量单词建立特征向量表述。即使训练样本不够多，测试时遇到陌生单词，例如“durian cultivator”，根据之前海量词汇特征向量就判断出“durian”也是一种水果，与“apple”类似，而“cultivator”与“farmer”也很相似。从而得到与“durian cultivator”对应的应该也是一个人名。这种做法将单词用不同的特征来表示，即使是训练样本中没有的单词，也可以根据word embedding的结果得到与其词性相近的单词，从而得到与该单词相近的结果，有效减少了训练样本的数量</p><p>词嵌入能够达到这种效果，原因是学习词嵌入的算法会考察非常大的文本集</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8a1d58b7ade17208053c10728b2bf3b6.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8a1d58b7ade17208053c10728b2bf3b6.png" alt></a></p><p>词嵌入做迁移学习的步骤：</p><ol><li>先从大量的文本集中学习词嵌入，或者下载网上预训练好的词嵌入模型</li><li>用这些词嵌入模型迁移到新的只有少量标注训练集的任务中，比如用300维的词嵌入来表示单词。好处就是可以用更低维度的特征向量代替原来的10000维的<strong>one-hot</strong>向量。尽管<strong>one-hot</strong>向量很快计算，但学到的用于词嵌入的300维的向量会更加紧凑</li><li>当在新的任务上训练模型，而在命名实体识别任务上只有少量的标记数据集，可以选择要不要继续微调，用新的数据调整词嵌入。但实际中只有第二步中有很大的数据集才会这样做，如果标记的数据集不是很大，通常不会在微调词嵌入上费力气</li></ol><p>当任务的训练集相对较小时，词嵌入的作用最明显，所以它广泛用于<strong>NLP</strong>领域</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/43943c791844cc7f077f6c6f98f1f629.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/43943c791844cc7f077f6c6f98f1f629.png" alt></a></p><p>词嵌入和人脸编码有很多相似性，训练了一个<strong>Siamese</strong>网络结构，这个网络会学习不同人脸的一个128维表示，然后通过比较编码结果来判断两个图片是否是同一个人脸，在人脸识别领域用编码指代向量<script type="math/tex">f(x^{\left(i \right)})</script>，<script type="math/tex">f(x^{\left( j\right)})</script>，词嵌入的意思和这个差不多</p><p>人脸识别领域和词嵌入不同就是：</p><ul><li>在人脸识别中训练一个网络，任给一个人脸照片，甚至是没有见过的照片，神经网络都会计算出相应的一个编码结果</li><li>学习词嵌入则是有一个固定的词汇表，比如10000个单词，学习向量<script type="math/tex">e_{1}</script>到<script type="math/tex">e_{10000}</script>，学习一个固定的编码，即每一个词汇表的单词的固定嵌入</li><li>人脸识别中的算法未来可能涉及到海量的人脸照片，而自然语言处理有一个固定的词汇表，没有出现过的单词就记为未知单词</li></ul><h2 id="2-3-词嵌入的特性（Properties-of-Word-Embeddings）"><a href="#2-3-词嵌入的特性（Properties-of-Word-Embeddings）" class="headerlink" title="2.3 词嵌入的特性（Properties of Word Embeddings）"></a>2.3 词嵌入的特性（Properties of Word Embeddings）</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/12242657bd982acd1d80570cc090b4fe.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/12242657bd982acd1d80570cc090b4fe.png" alt></a></p><p>该例中，假设用的是四维的嵌入向量，假如向量<script type="math/tex">e_{\text{man}}</script>和<script type="math/tex">e_{\text{woman}}</script>、<script type="math/tex">e_{\text{king}}</script>和<script type="math/tex">e_{\text{queen}}</script> 分别进行减法运算，相减结果表明，“Man”与“Woman”的主要区别是性别，“King”与“Queen”也是一样</p><p>所以当算法被问及<strong>man</strong>对<strong>woman</strong>相当于<strong>king</strong>对什么时，算法所做的就是计算<script type="math/tex">e_{\text{man}}-e_{\text{woman}}</script>，然后找出一个向量也就是找出一个词，使得：</p><script type="math/tex; mode=display">e_{\text{man}}-e_{\text{woman}}\approx e_{\text{king}} - e_{?}</script><p>即当这个新词是<strong>queen</strong>时，式子的左边会近似地等于右边</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5a42eea162ddc75a1d37520618b4bcd2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5a42eea162ddc75a1d37520618b4bcd2.png" alt></a></p><p>在图中，词嵌入向量在一个可能有300维的空间里，箭头代表的是向量在<strong>gender</strong>（<strong>性别</strong>）这一维的差，为了得出类比推理，计算当<strong>man</strong>对于<strong>woman</strong>，<strong>king</strong>对于什么，要做的就是找到单词<strong>w</strong>来使得</p><script type="math/tex; mode=display">e_{\text{man}}-e_{\text{woman}}\approx e_{\text{king}} - e_{w}</script><p>等式成立，即找到单词<strong>w</strong>来最大化<script type="math/tex">e_{w}</script>与<script type="math/tex">e_{\text{king}} - e_{\text{man}} + e_{\text{woman}}</script>的相似度，即</p><script type="math/tex; mode=display">Find\ word\ w:argmax\ Sim(e_{w},e_{\text{king}} - e_{\text{man}} + e_{\text{woman}})</script><p>即把<script type="math/tex">e_{w}</script>全部放到等式的一边，另一边是<script type="math/tex">e_{\text{king}}- e_{\text{man}} + e_{\text{woman}}</script>。应用相似度函数，通过方程找到一个使得相似度最大的单词，如果结果理想的话会得到单词<strong>queen</strong></p><p><strong>t-SNE算法</strong>所做的就是把这些300维的数据用一种非线性的方式映射到2维平面上，可以得知<strong>t-SNE</strong>中这种映射很复杂而且很非线性。在大多数情况下，由于<strong>t-SNE</strong>的非线性映射，不能总是期望使等式成立的关系会像左边那样成一个平行四边形</p><p>关于相似函数，比较常用的是余弦相似度，假如在向量<script type="math/tex">u</script>和<script type="math/tex">v</script>之间定义相似度：</p><script type="math/tex; mode=display">Sim(u,v)=\frac{u^Tv}{||u||\cdot ||v||}</script><p>分子是<script type="math/tex">u</script>和<script type="math/tex">v</script>的内积。如果<script type="math/tex">u</script>和<script type="math/tex">v</script>非常相似，那么它们的内积将会很大，把整个式子叫做余弦相似度，是因为该式是<script type="math/tex">u</script>和<script type="math/tex">v</script>的夹角的余弦值</p><p><strong>参考资料：</strong> 给定两个向量<script type="math/tex">u</script>和<script type="math/tex">v</script>，余弦相似度定义如下：</p><script type="math/tex; mode=display">{CosineSimilarity(u, v)} = \frac {u . v} {||u||_2 ||v||_2} = cos(\theta)</script><p>$u.v$ 是两个向量的点积（或内积），<script type="math/tex">||u||_2</script>是向量<script type="math/tex">u</script>的范数（或长度）， <script type="math/tex">\theta</script> 是向量<script type="math/tex">u</script>和<script type="math/tex">v</script>之间的角度。这种相似性取决于角度在向量<script type="math/tex">u</script>和<script type="math/tex">v</script>之间。如果向量<script type="math/tex">u</script>和<script type="math/tex">v</script>非常相似，它们的余弦相似性将接近1; 如果它们不相似，则余弦相似性将取较小的值</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/markdown/..\images\cosine_sim.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/markdown/..\images\cosine_sim.png" alt title="osine\_si"></a></p><blockquote><p>两个向量之间角度的余弦是衡量它们有多相似的指标，角度越小，两个向量越相似</p></blockquote><p>还可以计算Euclidian distance来比较相似性，即<script type="math/tex">||u-v||^2</script>。距离越大，相似性越小</p><h2 id="2-4-嵌入矩阵（Embedding-Matrix）"><a href="#2-4-嵌入矩阵（Embedding-Matrix）" class="headerlink" title="2.4 嵌入矩阵（Embedding Matrix）"></a>2.4 嵌入矩阵（Embedding Matrix）</h2><p>当应用算法来学习词嵌入时，实际上是学习一个<strong>嵌入矩阵</strong></p><p>假设某个词汇库包含了10000个单词，每个单词包含的特征维度为300，那么表征所有单词的<strong>embedding matrix</strong>维度为300 x 10000，用<script type="math/tex">E</script>来表示。某单词<script type="math/tex">w</script>的one-hot向量表示为<script type="math/tex">O_w</script>，维度为10000 x 1</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ad1c7b1e85d39f56756c28787ccef892.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ad1c7b1e85d39f56756c28787ccef892.png" alt></a></p><p>则该单词的嵌入向量(embedding vector)表达式为：</p><script type="math/tex; mode=display">e_w=E\cdot O_w</script><p>只要知道了embedding matrix<script type="math/tex">E</script>，就能计算出所有单词的embedding vector <script type="math/tex">e_w</script></p><p>不过上述这种矩阵乘积运算<script type="math/tex">E\cdot O_w</script>效率并不高，矩阵维度很大，且<script type="math/tex">O_w</script>大部分元素为零。通常做法是直接从<script type="math/tex">E</script>中选取第<script type="math/tex">w</script>列作为<script type="math/tex">e_w</script></p><h2 id="2-5-学习词嵌入（Learning-Word-Embeddings）"><a href="#2-5-学习词嵌入（Learning-Word-Embeddings）" class="headerlink" title="2.5 学习词嵌入（Learning Word Embeddings）"></a>2.5 学习词嵌入（Learning Word Embeddings）</h2><p>embedding matrix <script type="math/tex">E</script>可以通过构建自然语言模型，运用梯度下降算法得到。若输入样本是：</p><p><strong>I want a glass of orange (juice).</strong></p><p>通过这句话的前6个单词，预测最后的单词“juice”。<script type="math/tex">E</script>未知待求，每个单词可用embedding vector <script type="math/tex">e_w</script>表示。构建的神经网络模型结构如下图所示：</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/31347eca490e0ae8541140fb01c04d72.png" alt></a></p><p>神经网络输入层包含6个embedding vectors，每个embedding vector维度是300，则输入层总共有1800个输入。Softmax层有10000个概率输出，与词汇表包含的单词数目一致。正确的输出label是“juice”。其中$E,W^{[1]},b^{[1]},W^{[2]},b^{[2]}$为待求值。对足够的训练例句样本，运用梯度下降算法，迭代优化，最终求出embedding matrix<script type="math/tex">E</script></p><p>这种算法的效果还不错，能够保证具有相似属性单词的embedding vector相近</p><p>为了让神经网络输入层数目固定，可以选择只取预测单词的前4个单词作为输入，例如该句中只选择“a glass of orange”四个单词作为输入。这里的4是超参数，可调</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/747e619260737ded586ae51b3b4f07d6.png" alt></a></p><p>把输入叫做<strong>context</strong>，输出叫做<strong>target</strong>。对应到上面这句话里：</p><ul><li><p><strong>context: a glass of orange</strong></p></li><li><p><strong>target: juice</strong></p></li></ul><p>关于context的选择有多种方法：</p><ul><li><p><strong>target前n个单词或后n个单词，n可调</strong></p></li><li><p><strong>target前1个单词</strong></p></li><li><p><strong>target附近某1个单词（Skip-Gram）</strong><script type="math/tex">E</script></p></li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/638c103855ffeb25122259dd6b669850.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/638c103855ffeb25122259dd6b669850.png" alt></a></p><p>事实证明，不同的context选择方法都能计算出较准确的embedding matrix <script type="math/tex">E</script></p><h2 id="2-6-Word2Vec"><a href="#2-6-Word2Vec" class="headerlink" title="2.6 Word2Vec"></a>2.6 Word2Vec</h2><p>选择context和target的方法中，比较流行的是采用<strong>Skip-Gram</strong>模型</p><p>Skip-Gram模型的做法是：首先随机选择一个单词作为context，例如“orange”；然后使用一个宽度为5或10（自定义）的滑动窗，在context附近选择一个单词作为target，可以是“juice”、“glass”、“my”等等。最终得到了多个context—target对作为监督式学习样本：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0800c19895cbf1a360379b5dc5493902.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0800c19895cbf1a360379b5dc5493902.png" alt></a></p><p>训练的过程是构建自然语言模型，经过softmax单元的输出为：</p><script type="math/tex; mode=display">\hat y=\frac{e^{\theta_t^T\cdot e_c}}{\sum_{j=1}^{10000}e^{\theta_j^T\cdot e_c}}</script><p>$\theta_t$为target对应的参数，<script type="math/tex">e_c</script>为context的embedding vector，且<script type="math/tex">e_c=E\cdot O_c</script></p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/4ebf216a59d46efa2136f72b51fd49bd.png" alt></a></p><p>相应的loss function为：</p><script type="math/tex; mode=display">L(\hat y,y)=-\sum_{i=1}^{10000}y_ilog\ \hat y_i</script><blockquote><p>由于</p><script type="math/tex; mode=display">y</script><p>是一个one-hot向量，所以上式实际上10000个项里面只有一项是非0的</p></blockquote><p>然后，运用梯度下降算法，迭代优化，最终得到embedding matrix <script type="math/tex">E</script></p><p>然而，这种算法计算量大，影响运算速度。主要因为softmax输出单元为10000个，<script type="math/tex">\hat y</script>计算公式中包含了大量的求和运算</p><p>解决的办法之一是使用<strong>hierarchical softmax classifier</strong>，即<strong>树形分类器</strong>：</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/89743b5ade106cad1318b8f3f4547a7f.png" alt></a></p><p>这种树形分类器是一种二分类。它在每个数节点上对目标单词进行区间判断，最终定位到目标单词。最多需要<script type="math/tex">\log_2 N</script>步就能找到目标单词，N为单词总数</p><p>实际应用中，对树形分类器做了一些改进。改进后的树形分类器是非对称的，通常选择把比较常用的单词放在树的顶层，而把不常用的单词放在树的底层。这样更能提高搜索速度</p><p>关于context的采样：如果使用均匀采样，那么一些常用的介词、冠词，例如the, of, a, and, to等出现的概率更大一些。但是这些单词的embedding vectors通常不是最关心的，更关心的例如orange, apple， juice等这些名词。所以实际应用中一般不选择随机均匀采样的方式来选择context，而是使用其它算法来处理这类问题</p><h2 id="2-7-负采样（Negative-Sampling）"><a href="#2-7-负采样（Negative-Sampling）" class="headerlink" title="2.7 负采样（Negative Sampling）"></a>2.7 负采样（Negative Sampling）</h2><p>算法要做的是构造一个新的监督学习问题：给定一对单词，比如<strong>orange</strong>和<strong>juice</strong>，去预测这是否是一对上下文词-目标词（<strong>context-target</strong>）</p><p>在这个例子中<strong>orange</strong>和<strong>juice</strong>就是个正样本，用1作为标记，<strong>orange</strong>和<strong>king</strong>就是个负样本，标为0。要做的就是采样得到一个上下文词和一个目标词，中间列叫做词（<strong>word</strong>）。然后：</p><ul><li>生成一个正样本，先抽取一个context，在一定词距内比如说正负10个词距内选一个target，生成这个表的第一行，即<strong>orange– juice -1</strong>的过程</li><li>生成一个负样本，用相同的context，再在字典中随机选一个词，如<strong>king、book、the、of</strong>，标记为0。因为如果随机选一个词，它很可能跟<strong>orange</strong>没关联</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/54beb302688f6a298b63178534281575.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/54beb302688f6a298b63178534281575.png" alt></a></p><p>如果从字典中随机选到的词，正好出现在了词距内，比如说在上下文词<strong>orange</strong>正负10个词之内，也没关系，如<strong>of</strong>被标记为0，即使<strong>of</strong>的确出现在<strong>orange</strong>词的前面</p><p>接下来将构造一个监督学习问题，学习算法输入<script type="math/tex">x</script>，即输入这对词（编号7），要去预测目标的标签（编号8），即预测输出<script type="math/tex">y</script></p><p>如何选取<script type="math/tex">K</script>：</p><ul><li>小数据集的话，<script type="math/tex">K</script>从5到20，数据集越小<script type="math/tex">K</script>就越大</li><li>如果数据集很大，<script type="math/tex">K</script>就选的小一点。对于更大的数据集<script type="math/tex">K</script>就从2到5</li></ul><p>学习从<script type="math/tex">x</script>映射到<script type="math/tex">y</script>的监督学习模型：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f36df292b7444e9b7379fa7c14626fa2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f36df292b7444e9b7379fa7c14626fa2.png" alt></a></p><p>编号2是新的输入<script type="math/tex">x</script>，编号3是要预测的值<script type="math/tex">y</script>。记号<script type="math/tex">c</script>表示context，记号<script type="math/tex">t</script>表示可能的target，<script type="math/tex">y</script>表示0和1，即是否是一对context-target。要做的是定义一个逻辑回归模型，给定输入的<script type="math/tex">c</script>，<script type="math/tex">t</script>对的条件下，<script type="math/tex">y=1</script>的概率，即：</p><script type="math/tex; mode=display">P\left( y = 1 \middle| c,t \right) = \sigma(\theta_{t}^{T}e_{c})</script><p>如果输入词是<strong>orange</strong>，即词6257，要做的就是输入<strong>one-hot</strong>向量，和<script type="math/tex">E</script>相乘获得嵌入向量<script type="math/tex">e_{6257}</script>，最后得到10,000个可能的逻辑回归分类问题，其中一个（编号4）将会是用来判断目标词是否是<strong>juice</strong>的分类器，其他的词比如下面的某个分类器（编号5）是用来预测<strong>king</strong>是否是目标词</p><p>negative sampling中某个固定的正样本对应<script type="math/tex">k</script>个负样本，即模型总共包含了<script type="math/tex">k+1</script>个<strong>binary classification</strong>。对比之前10000个输出单元的softmax分类，negative sampling转化为<script type="math/tex">k+1</script>个二分类问题，每次迭代并不是训练10000个，而仅训练其中<script type="math/tex">k+1</script>个，计算量要小很多，大大提高了模型运算速度</p><p>这种方法就叫做<strong>负采样（Negative Sampling）: </strong>选择一个正样本，随机采样<script type="math/tex">k</script>个负样本</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b05dd0362a19496bb0ad91b8494e374c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b05dd0362a19496bb0ad91b8494e374c.png" alt></a></p><p>选取了context <strong>orange</strong>之后，如何选取负样本：</p><ul><li>通过单词出现的频率进行采样：导致一些类似a、the、of等词的频率较高</li><li>均匀随机地抽取负样本：没有很好的代表性</li></ul><p><strong>（推荐）</strong>：</p><script type="math/tex; mode=display">P(w_{i}) = \frac{f( w_{i})^{\frac{3}{4}}}{\sum_{j = 1}^{10,000}{f( w_{j} )^{\frac{3}{4}}}}</script><p>这种方法处于上面两种极端采样方法之间，即不用频率分布，也不用均匀分布，而采用的是对词频的<script type="math/tex">\frac{3}{4}</script>除以词频<script type="math/tex">\frac{3}{4}</script>整体的和进行采样的。其中，<script type="math/tex">f(w_j)</script>是语料库中观察到的某个词的词频</p><h2 id="2-8-GloVe-词向量（GloVe-Word-Vectors）"><a href="#2-8-GloVe-词向量（GloVe-Word-Vectors）" class="headerlink" title="2.8 GloVe 词向量（GloVe Word Vectors）"></a>2.8 GloVe 词向量（GloVe Word Vectors）</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/70e282d4d1abb86fd15ff7b175f4e579.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/70e282d4d1abb86fd15ff7b175f4e579.png" alt></a></p><p><strong>GloVe</strong>代表用词表示的全局变量（<strong>global vectors for word representation</strong>）</p><p>假定<script type="math/tex">X_{ij}</script>是单词<script type="math/tex">i</script>在单词<script type="math/tex">j</script>上下文中出现的次数，<script type="math/tex">i</script>和<script type="math/tex">j</script> 与<script type="math/tex">t</script>和<script type="math/tex">c</script>的功能一样，可以认为<script type="math/tex">X_{ij}</script>等同于<script type="math/tex">X_{tc}</script>。根据context和target的定义，会得出<script type="math/tex">X_{ij}</script>等于<script type="math/tex">X_{ji}</script></p><ul><li>如果将context和target的范围定义为出现于左右各10词以内的话，就有对称关系<script type="math/tex">X_{ij}=X_{ji}</script></li><li>如果对context的选择是context总是目target前一个单词，那么<script type="math/tex">X_{ij}\neq X_{ji}</script></li></ul><p>对于<strong>GloVe</strong>算法，可以定义context和target为任意两个位置相近的单词，假设是左右各10词的距离，那么<script type="math/tex">X_{ij}</script>就是一个能够获取单词<script type="math/tex">i</script>和单词<script type="math/tex">j</script>彼此接近的频率计数器</p><p><strong>GloVe</strong>模型做的就是进行优化，将差距进行最小化处理：</p><script type="math/tex; mode=display">\text{mini}\text{mize}\sum_{i = 1}^{10,000}{\sum_{j = 1}^{10,000}}{f\left( X_{ij}\right)\left( \theta_{i}^{T}e_{j} + b_{i} + b_{j}^{'} - \log X_{ij} \right)^{2}}</script><p>$\theta_{i}^{T}e_{j}$即<script type="math/tex">\theta_{t}^{T}e_{c}</script>。对于<script type="math/tex">\theta_{t}^{T}e_{c}</script>，这两个单词同时出现的频率是多少受<script type="math/tex">X_{ij}</script>影响，若两个词的embedding vector越相近，同时出现的次数越多，则对应的loss越小</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f6fc2cec52f4ecb15567511aae822914.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f6fc2cec52f4ecb15567511aae822914.png" alt></a></p><p>当<script type="math/tex">X_{ij}=0</script>时，权重因子<script type="math/tex">f(X_{ij})=0</script>。这种做法直接忽略了无任何相关性的context和target，只考虑<script type="math/tex">X_{ij}>0</script>的情况</p><p>出现频率较大的单词相应的权重因子<script type="math/tex">f(X_{ij})</script>较大，出现频率较小的单词相应的权重因子<script type="math/tex">f(X_{ij})</script>较小一些</p><p>因为<script type="math/tex">\theta</script>和<script type="math/tex">e</script>是完全对称的，所以<script type="math/tex">\theta_{i}</script>和<script type="math/tex">e_{j}</script>是对称的。因此训练算法的方法是一致地初始化<script type="math/tex">\theta</script>和<script type="math/tex">e</script>，然后使用梯度下降来最小化输出，当每个词都处理完之后取平均值：</p><script type="math/tex; mode=display">e_{w}^{(final)}= \frac{e_{w} +\theta_{w}}{2}</script><p><strong>GloVe</strong>算法不能保证嵌入向量的独立组成部分：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ec4b604d619dd617f14c2a34945c075d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ec4b604d619dd617f14c2a34945c075d.png" alt></a></p><p>通过上面的很多算法得到的词嵌入向量，无法保证词嵌入向量的每个独立分量是能够理解的。但能够确定是每个分量和所想的一些特征是有关联的，可能是一些我们能够理解的特征的组合而构成的一个组合分量</p><p>使用上面的GloVe模型，从线性代数的角度解释如下：</p><script type="math/tex; mode=display">\Theta_{i}^{T}e_{j} = \Theta_{i}^{T}A^{T}A^{-T}e_{j}=(A\Theta_{i})^{T}(A^{-T}e_{j})</script><p>加入的<script type="math/tex">A</script>项，可能构成任意的分量组合</p><h2 id="2-9-情感分类（Sentiment-Classification）"><a href="#2-9-情感分类（Sentiment-Classification）" class="headerlink" title="2.9 情感分类（Sentiment Classification）"></a>2.9 情感分类（Sentiment Classification）</h2><p>情感分类任务就是看一段文本，然后分辨这个人是否喜欢他们在讨论的这个东西，最大的挑战就是可能标记的训练集没有那么多，但是有了词嵌入，即使只有中等大小标记的训练集，也能构建一个不错的情感分类器</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/bf6f5879d33ae4ef09b32f77df84948e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/bf6f5879d33ae4ef09b32f77df84948e.png" alt></a></p><blockquote><p>输入<script type="math/tex">x</script>是一段文本，输出<script type="math/tex">y</script>是要预测的相应情感。比如一个餐馆评价的星级</p></blockquote><p>情感分类一个最大的挑战就是可能标记的训练集没有那么多。对于情感分类任务来说，训练集大小从10,000到100,000个单词都很常见，甚至有时会小于10,000个单词，采用了词嵌入能够带来更好的效果，尤其是只有很小的训练集</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ea844a0290e66d1c76a31e34b632dc0c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ea844a0290e66d1c76a31e34b632dc0c.png" alt></a></p><p>给定四个词（”<strong>dessert is excellent</strong>“），通常用10,000个词的词汇表，找到相应的<strong>one-hot</strong>向量，再乘以嵌入矩阵<script type="math/tex">E</script>，<script type="math/tex">E</script>可以从一个很大的文本集里学习到，比如它可以从一亿个词或者一百亿个词里学习嵌入，然后用来提取单词<strong>the</strong>的嵌入向量<script type="math/tex">e_{8928}</script>，对<strong>dessert</strong>、<strong>is</strong>、<strong>excellent</strong>做同样的步骤</p><p>然后取这些向量（编号2），如300维度的向量，通过平均值计算单元（编号3），求和并平均，再送进<strong>softmax</strong>分类器，然后输出<script type="math/tex">\hat y</script>。这个<strong>softmax</strong>能够输出5个可能结果的概率值，从一星到五星</p><p>这个算法适用于任何长短的评论，因为即使评论是100个词长，也可以对这一百个词的特征向量求和取平均，得到一个300维的特征向量，然后送进<strong>softmax</strong>分类器</p><p>但问题是没考虑词序，如负面的评价，”<strong>Completely lacking in good taste, good service, and good ambiance.</strong>“，<strong>good</strong>这个词出现了很多次，但算法忽略词序，仅仅把所有单词的词嵌入加起来或者平均下来，最后的特征向量会有很多<strong>good</strong>的表示，分类器很可能认为这是一个好的评论，尽管事实上这是一个差评，只有一星的评价</p><p>为了解决这一问题，情感分类的另一种模型是RNN：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/de4b6513a8d1866bccf1fac3c0d0d6d2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/de4b6513a8d1866bccf1fac3c0d0d6d2.png" alt></a></p><p>首先取这条评论，”<strong>Completely lacking in good taste, good service, and good ambiance.</strong>“，找出每一个<strong>one-hot</strong>向量，乘以词嵌入矩阵<script type="math/tex">E</script>，得到词嵌入表达<script type="math/tex">e</script>，然后把它们送进<strong>RNN</strong></p><p><strong>RNN</strong>的工作就是在最后一步（编号1）计算一个特征表示，用来预测<script type="math/tex">\hat y</script>。这样的算法考虑词的顺序效果更好，能意识到”<strong>things are lacking in good taste</strong>“是个负面的评价，“<strong>not good</strong>”也是一个负面的评价。而不像原来的算法一样，只是把所有的加在一起得到一个大的向量，根本意识不到“<strong>not good</strong>”和 “<strong>good</strong>”不是一个意思，”<strong>lacking in good taste</strong>“也是如此，等等</p><p>如果训练一个这样的算法，最后会得到一个很合适的情感分类的算法。由于词嵌入是在一个更大的数据集里训练的，这样会更好的泛化一些没有见过的新的单词。比如”<strong>Completely absent of good taste, good service, and good ambiance.</strong>“，即使<strong>absent</strong>这个词不在标记的训练集里</p><p>如果是在一亿或者一百亿单词集里训练词嵌入，它仍然可以正确判断，并且泛化的很好，甚至这些词是在训练集中用于训练词嵌入，但不在专门做情感分类问题标记的训练集</p><h2 id="2-10-词嵌入除偏（Debiasing-Word-Embeddings）"><a href="#2-10-词嵌入除偏（Debiasing-Word-Embeddings）" class="headerlink" title="2.10 词嵌入除偏（Debiasing Word Embeddings）"></a>2.10 词嵌入除偏（Debiasing Word Embeddings）</h2><p>根据训练模型所使用的文本，词嵌入能够反映出性别、种族、年龄、性取向等其他方面的偏见：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/25430afa93f24dc6caa6f85503bbad27.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/25430afa93f24dc6caa6f85503bbad27.png" alt></a></p><p>假设已经完成一个词嵌入的学习，各个词的位置如图：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/cf60f429ef532a2b3bbad3db98b054c5.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/cf60f429ef532a2b3bbad3db98b054c5.png" alt></a></p><p>首先做的事就是辨别出想要减少或想要消除的特定偏见的趋势</p><p>怎样辨别出偏见相似的趋势：</p><p>一、对于性别歧视，对所有性别对立的单词求差值，再平均：</p><script type="math/tex; mode=display">bias\ direction=\frac1N ((e_{he}-e_{she})+(e_{male}-e_{female})+\cdots)</script><p>二、中和步骤，对于定义不确切的词可以将其处理一下，避免偏见。像<strong>doctor</strong>和<strong>babysitter</strong>使之在性别方面中立。将它们在这个轴（编号1）上进行处理，减少或是消除他们的性别歧视趋势的成分，即减少在水平方向上的距离（编号2方框内所示的投影）</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/4102795b004ff090ed83dc654f585852.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/4102795b004ff090ed83dc654f585852.png" alt></a></p><p>三、均衡步，<strong>babysitter</strong>和<strong>grandmother</strong>之间的距离或者说是相似度实际上是小于<strong>babysitter</strong>和<strong>grandfather</strong>之间的（编号1），因此这可能会加重不良状态，或者非预期的偏见，也就是说<strong>grandmothers</strong>相比于<strong>grandfathers</strong>最终更有可能输出<strong>babysitting</strong>。所以在最后的均衡步中，想要确保的是像<strong>grandmother</strong>和<strong>grandfather</strong>这样的词都能够有一致的相似度，或者说是相等的距离，做法是将<strong>grandmother</strong>和<strong>grandfather</strong>移至与中间轴线等距的一对点上（编号2），现在性别歧视的影响也就是这两个词与<strong>babysitter</strong>的距离就完全相同了（编号3）</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/9b27d865dff73a2f10abbdc1c7fc966b.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/9b27d865dff73a2f10abbdc1c7fc966b.png" alt></a></p><p>最后，掌握哪些单词需要中立化非常重要。一般来说，大部分英文单词，例如职业、身份等都需要中立化，消除embedding vector中性别这一维度的影响</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2-1-词汇表征（Word-Representation）&quot;&gt;&lt;a href=&quot;#2-1-词汇表征（Word-Representation）&quot; class=&quot;headerlink&quot; title=&quot;2.1 词汇表征（Word Representation）&quot;&gt;&lt;/a&gt;2.1 词汇表征（Word Representation）&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;one-hot&lt;/strong&gt;向量表示：单词Man，Woman，King，Queen，Apple，Orange分别出现在词汇表的第5391，9853，4914，7157，456，6257的位置，则它们分别用&lt;script type=&quot;math/tex&quot;&gt;O_{5391}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;O_{9853}&lt;/script&gt; 等表示，&lt;script type=&quot;math/tex&quot;&gt;O&lt;/script&gt;代表&lt;strong&gt;one-hot：&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习 " scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第一周 循环序列模型（Recurrent Neural Networks）(Course 5)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E4%B8%80%E5%91%A8-%E5%BE%AA%E7%8E%AF%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%88Recurrent-Neural-Networks%EF%BC%89-Course-5/"/>
    <id>https://baozouai.com/2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/</id>
    <published>2019-02-27T22:17:00.000Z</published>
    <updated>2019-02-27T06:52:28.922Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-1-为什么选择序列模型？（Why-Sequence-Models-）"><a href="#1-1-为什么选择序列模型？（Why-Sequence-Models-）" class="headerlink" title="1.1 为什么选择序列模型？（Why Sequence Models?）"></a>1.1 为什么选择序列模型？（Why Sequence Models?）</h2><p>语音识别：给定一个输入音频片段 <script type="math/tex">X</script>，要求输出对应的文字记录 <script type="math/tex">Y</script>。输入和输出数据都是序列模型，因为 <script type="math/tex">X</script>是一个按时播放的音频片段，输出 <script type="math/tex">Y</script>是一系列单词<br><a id="more"></a><br>音乐生成问题：只有输出数据 <script type="math/tex">Y</script>是序列，而输入数据可以是空集，也可以是个单一的整数，这个数可能指代想要生成的音乐风格，或者想要生成的那首曲子的头几个音符</p><p>处理情感分类：输入数据 <script type="math/tex">X</script>是序列，会得到类似这样的输入：“<strong>There is nothing to like in this movie.</strong>”，你认为这句评论对应几星？</p><p><strong>DNA</strong>序列分析：<strong>DNA</strong>用<strong>A</strong>、<strong>C</strong>、<strong>G</strong>、<strong>T</strong>四个字母来表示。给定一段<strong>DNA</strong>序列，能够标记出哪部分是匹配某种蛋白质？</p><p>机器翻译：输入句：“<strong>Voulez-vou chante avecmoi?</strong>”（法语：要和我一起唱么？），要求输出另一种语言的翻译结果</p><p>视频行为识别：得到一系列视频帧，要求识别其中的行为</p><p>命名实体识别：给定一个句子，要求识别出句中的人名</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ae2970d80a119cd341ef31c684bfac49.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ae2970d80a119cd341ef31c684bfac49.png" alt></a></p><p>这些问题都可以被称作使用标签数据 <script type="math/tex">(X,Y)</script>作为训练集的监督学习。但序列问题有很多不同类型。有些问题里，输入数据 <script type="math/tex">X</script>和输出数据<script type="math/tex">Y</script>都是序列，但就算在那种情况下，<script type="math/tex">X</script>和<script type="math/tex">Y</script>有时也会不一样长。或者像上图编号1和编号2所示的<script type="math/tex">X</script>和<script type="math/tex">Y</script>有相同的数据长度。在另一些问题里，只有 <script type="math/tex">X</script>或者只有<script type="math/tex">Y</script>是序列</p><h2 id="1-2-数学符号（Notation）"><a href="#1-2-数学符号（Notation）" class="headerlink" title="1.2 数学符号（Notation）"></a>1.2 数学符号（Notation）</h2><p>序列模型的输入语句是：“<strong>Harry Potter and Herminoe Granger invented a new spell.</strong>”。假如想要建立一个能够自动识别句中人名位置的序列模型，那么这就是一个命名实体识别问题</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/cccbc03192af67a089b53d7940659505.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/cccbc03192af67a089b53d7940659505.png" alt></a></p><p>该句话包含9个单词，输出y即为1 x 9向量，每位表征对应单词是否为人名的一部分，对应的输出y表示为：</p><script type="math/tex; mode=display">y=[1\ \ 1\ \ 0\ \ 1\ \ 1\ \ 0\ \ 0\ \ 0\ \ 0]^T</script><p>$y^{&lt; t&gt;}$表示序列对应位置的输出，<script type="math/tex">T_y</script>表示输出序列长度，<script type="math/tex">1\leq t\leq T_y</script></p><p>对于输入<script type="math/tex">x</script>，表示为：</p><script type="math/tex; mode=display">[x^{<1>}\ \ x^{<2>}\ \ x^{<3>}\ \ x^{<4>}\ \ x^{<5>}\ \ x^{<6>}\ \ x^{<7>}\ \ x^{<8>}\ \ x^{<9>}]</script><p>$x^{&lt; t&gt;}$表示序列对应位置的输入，<script type="math/tex">T_x</script>表示输入序列长度。此例中<script type="math/tex">T_x=T_y</script>，但是也存在<script type="math/tex">T_x\neq T_y</script></p><p>如何表示每个<script type="math/tex">x^{<t>}</script>：</p><p>建立一个词汇库vocabulary，尽可能包含更多的词汇。例如一个包含10000个词汇的词汇库为：</p><script type="math/tex; mode=display">\left[\begin{matrix}a \\and \\\cdot \\\cdot \\\cdot \\harry \\\cdot \\\cdot \\\cdot \\potter \\\cdot \\\cdot \\\cdot \\zulu\end{matrix}\right]</script><p>然后使用one-hot编码，词汇表中与<script type="math/tex">x^{<t>}</script>对应的位置为1，其它位置为0。如果出现词汇表之外的单词，可以使用UNK或其他字符串来表示</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8deca8a84f06466155d2d8d53d26e05d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8deca8a84f06466155d2d8d53d26e05d.png" alt></a></p><p>对于多样本：对应的命名规则可表示为：<script type="math/tex">X^{(i)<t>}</script>，<script type="math/tex">Y^{(i)<t>}</script>，<script type="math/tex">T_x^{(i)}</script>，<script type="math/tex">T_y^{(i)}</script>，<script type="math/tex">i</script>表示第<script type="math/tex">i</script>个样本。不同样本的<script type="math/tex">T_x^{(i)}</script>或<script type="math/tex">T_y^{(i)}</script>都有可能不同</p><h2 id="1-3-循环神经网络模型（Recurrent-Neural-Network-Model）"><a href="#1-3-循环神经网络模型（Recurrent-Neural-Network-Model）" class="headerlink" title="1.3 循环神经网络模型（Recurrent Neural Network Model）"></a>1.3 循环神经网络模型（Recurrent Neural Network Model）</h2><p>序列模型从左到右，依次传递，此例中，<script type="math/tex">T_x=T_y</script>。<script type="math/tex">x^{<t>}</script>到<script type="math/tex">\hat y^{<t>}</script>之间是隐藏神经元。<script type="math/tex">a^{<t>}</script>会传入到第<script type="math/tex">t+1</script>元素中，作为输入。其中，<script type="math/tex">a^{<0>}</script>一般为零向量</p><p><img src="/images/pasted-156.png" alt="upload successful"></p><p>循环神经网络是从左向右扫描数据，同时每个时间步的参数也是共享的，用<script type="math/tex">W_{\text{ax}}</script>来表示管理着从<script type="math/tex">x^{<1>}</script>到隐藏层的连接的一系列参数，每个时间步使用的都是相同的参数<script type="math/tex">W_{\text{ax}}</script>。而激活值是由参数<script type="math/tex">W_{aa}</script>决定，同时每一个时间步都使用相同的参数<script type="math/tex">W_{aa}</script>，同样的输出结果由<script type="math/tex">W_{\text{ya}}</script>决定：</p><p><img src="/images/pasted-157.png" alt="upload successful"></p><p>预测<script type="math/tex">{\hat{y}}^{< 3 >}</script>时，不仅要使用<script type="math/tex">x^{<3>}</script>的信息，还要使用来自<script type="math/tex">x^{<1>}</script>和<script type="math/tex">x^{<2>}</script>的信息，而这个循环神经网络的一个缺点是只使用了这个序列中之前的信息来做出预测，因为如果给定了这个句子，“<strong>Teddy Roosevelt was a great President.</strong>”，为了判断<strong>Teddy</strong>是否是人名的一部分，仅仅知道句中前两个词是完全不够的，还需要知道句中后部分的信息，因为句子也可能是这样的，“<strong>Teddy bears are on sale!</strong>”。因此如果只给定前三个单词，是不可能确切地知道<strong>Teddy</strong>是否是人名的一部分，第一个例子是人名，第二个例子就不是，所以不可能只看前三个单词就能分辨出其中的区别</p><p>所以这样特定的神经网络结构的一个限制是它在某一时刻的预测仅使用了从序列之前的输入信息，并没有使用序列中后部分的信息</p><p>RNN的正向传播（Forward Propagation）过程为：</p><script type="math/tex; mode=display">a^{<t>}=g(W_{aa}\cdot a^{<t-1>}+W_{ax}\cdot x^{<t>}+b_a)</script><script type="math/tex; mode=display">\hat y^{<t>}=g(W_{ya}\cdot a^{<t>}+b_y)</script><p><img src="/images/pasted-158.png" alt="upload successful"></p><p>为了简化表达式，可以对<script type="math/tex">a^{<t>}</script>项进行整合：</p><script type="math/tex; mode=display">W_{aa}\cdot a^{<t-1>}+W_{ax}\cdot x^{<t>}=[W_{aa}\ \ W_{ax}]\left[\begin{matrix}a^{<t-1>} \\x^{<t>}\end{matrix}\right]\rightarrow W_a[a^{<t-1>},x^{<t>}]</script><p>则正向传播可表示为：</p><script type="math/tex; mode=display">a^{<t>}=g(W_a[a^{<t-1>},x^{<t>}]+b_a)</script><script type="math/tex; mode=display">\hat y^{<t>}=g(W_{y}\cdot a^{<t>}+b_y)</script><p><img src="/images/pasted-159.png" alt="upload successful">)</p><p><strong>RNN</strong>前向传播示意图：</p><p><img src="/images/pasted-160.png" alt="upload successful"></p><h2 id="1-4-通过时间的反向传播（Backpropagation-through-time）"><a href="#1-4-通过时间的反向传播（Backpropagation-through-time）" class="headerlink" title="1.4 通过时间的反向传播（Backpropagation through time）"></a>1.4 通过时间的反向传播（Backpropagation through time）</h2><p>反向传播计算方向与前向传播基本上是相反：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/998c7af4f90cd0de0c88f138b61f0168.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/998c7af4f90cd0de0c88f138b61f0168.png" alt></a></p><p>识别人名的例子，经过RNN正向传播，单个元素的Loss function为：</p><script type="math/tex; mode=display">L^{<t>}(\hat y^{<t>},y^{<t>})=-y^{<t>}log\ \hat y^{<t>}-(1-y^{<t>})log\ (1-\hat y^{<t>})</script><blockquote><p>这是 binary classification 的 Loss Function，注意与1.6 的softmax Loss Function区别</p></blockquote><p>该样本所有元素的Loss function为：</p><script type="math/tex; mode=display">L(\hat y,y)=\sum_{t=1}^{T_y}L^{<t>}(\hat y^{<t>},y^{<t>})</script><p>反向传播（Backpropagation）过程就是从右到左分别计算<script type="math/tex">L(\hat y,y)</script>对参数<script type="math/tex">W_{a}</script>，<script type="math/tex">W_{y}</script>，<script type="math/tex">b_a</script>，<script type="math/tex">b_y</script>的偏导数，这种从右到左的求导过程被称为Backpropagation through time</p><p><strong>RNN</strong>反向传播示意图：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/rnn_cell_backprop.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/rnn_cell_backprop.png" alt title="nn\_cell\_backpro"></a></p><h2 id="1-5-不同类型的循环神经网络（Different-types-of-RNNs）"><a href="#1-5-不同类型的循环神经网络（Different-types-of-RNNs）" class="headerlink" title="1.5 不同类型的循环神经网络（Different types of RNNs）"></a>1.5 不同类型的循环神经网络（Different types of RNNs）</h2><p>RNN模型包含以下几个类型：</p><ul><li><strong>一对一，</strong>当去掉<script type="math/tex">a^{<0>}</script>时它就是一种标准类型的神经网络</li><li><strong>一对多</strong>，比如音乐生成或者序列生成</li><li><strong>多对一</strong>，如是情感分类的例子，首先读取输入，一个电影评论的文本，然后判断他们是否喜欢电影还是不喜欢</li><li><strong>多对多</strong>，如命名实体识别，<script type="math/tex">T_{x}=T_{y}</script></li><li><strong>多对多，</strong>如机器翻译，<script type="math/tex">T_x\neq T_y</script></li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/1daa38085604dd04e91ebc5e609d1179.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1daa38085604dd04e91ebc5e609d1179.png" alt></a></p><h2 id="1-6-语言模型和序列生成（Language-model-and-sequence-generation）"><a href="#1-6-语言模型和序列生成（Language-model-and-sequence-generation）" class="headerlink" title="1.6 语言模型和序列生成（Language model and sequence generation）"></a>1.6 语言模型和序列生成（Language model and sequence generation）</h2><p>在语音识别中，某句语音有两种翻译：</p><ul><li><strong>the apple and pair salad</strong></li><li><strong>the apple and pear salad</strong></li></ul><p>语言模型会计算出这两句话各自的出现概率：</p><ul><li><script type="math/tex; mode=display">P( \text{The apple and pair salad}) = 3.2 \times 10^{-13}</script></li><li><script type="math/tex; mode=display">P\left(\text{The apple and pear salad} \right) = 5.7 \times 10^{-10}</script></li></ul><p>选择概率最大的语句作为正确的翻译</p><p>概率计算的表达式为：</p><script type="math/tex; mode=display">P(y^{<1>},y^{<2>},\cdots,y^{<T_y>})</script><p>如何使用RNN构建语言模型：</p><p>首先需要一个足够大的训练集，训练集由大量的单词语句语料库（corpus）构成。然后，对corpus的每句话进行切分词（tokenize），建立vocabulary，对每个单词进行one-hot编码。例如下面这句话：</p><p><strong>The Egyptian Mau is a bread of cat.</strong></p><p>每句话结束末尾，需要加上<strong>&lt; EOS &gt;</strong>作为语句结束符。若语句中有词汇表中没有的单词，用<strong>&lt; UNK &gt;</strong>表示。假设单词“Mau”不在词汇表中，则上面这句话可表示为：</p><p><strong>The Egyptian &lt; UNK &gt; is a bread of cat. &lt; EOS &gt;</strong></p><p>准备好训练集并对语料库进行切分词等处理之后，接下来构建相应的RNN模型：</p><p><img src="/images/pasted-161.png" alt="upload successful"><br>$x^{<1>}$和<script type="math/tex">a^{<0>}</script>均为零向量。Softmax输出层<script type="math/tex">\hat y^{<1>}</script>表示出现该语句第一个单词的概率，softmax输出层<script type="math/tex">\hat y^{<2>}</script>表示在第一个单词基础上出现第二个单词的概率，即条件概率，以此类推，最后是出现<strong>&lt; EOS &gt;</strong>的条件概率</1></p><p>单个元素的softmax loss function为：</p><script type="math/tex; mode=display">L^{<t>}(\hat y^{<t>},y^{<t>})=-\sum_iy_i^{<t>}log\ \hat y_i^{<t>}</script><blockquote><p>这是softmax Loss Function ，注意与1.4 binary classification 的 Loss Function区别</p></blockquote><p>该样本所有元素的Loss function为：</p><script type="math/tex; mode=display">L(\hat y,y)=\sum_tL^{<t>}(\hat y^{<t>},y^{<t>})</script><p>对语料库的每条语句进行RNN模型训练，最终得到的模型可以根据给出语句的前几个单词预测其余部分，将语句补充完整。例如给出<strong>“Cats average 15”</strong>，RNN模型可能预测完整的语句是<strong>“Cats average 15 hours of sleep a day.”</strong></p><p>整个语句出现的概率等于语句中所有元素出现的条件概率乘积。例如某个语句包含<script type="math/tex">y^{<1>},y^{<2>},y^{<3>}</script>，则整个语句出现的概率为：</p><script type="math/tex; mode=display">P(y^{<1>},y^{<2>},y^{<3>})=P(y^{<1>})\cdot P(y^{<2>}|y^{<1>})\cdot P(y^{<3>}|y^{<1>},y^{<2>})</script><h2 id="1-7-对新序列采样（Sampling-novel-sequences）"><a href="#1-7-对新序列采样（Sampling-novel-sequences）" class="headerlink" title="1.7 对新序列采样（Sampling novel sequences）"></a>1.7 对新序列采样（Sampling novel sequences）</h2><h3 id="基于词汇的RNN模型"><a href="#基于词汇的RNN模型" class="headerlink" title="基于词汇的RNN模型"></a>基于词汇的RNN模型</h3><p>序列模型模拟了任意特定单词序列的概率，要做的是对这些概率分布进行采样来生成一个新的单词序列。编号1所示的网络已经被上方所展示的结构训练过，编号2是进行采样</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8b901fc8fcab9e16b1fe26b92f4ec546.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8b901fc8fcab9e16b1fe26b92f4ec546.png" alt></a></p><p>第一步要做的是对想要模型生成的第一个词进行采样，输入<script type="math/tex">x^{<1>} =0</script>，<script type="math/tex">a^{<0>} =0</script>，第一个时间步得到的是所有可能的输出，是经过<strong>softmax</strong>层后得到的概率，然后根据这个<strong>softmax</strong>的分布进行随机采样。对这个向量使用<code>np.random.choice</code>，来根据向量中这些概率的分布进行采样，就能对第一个词进行采样</p><p>然后继续下一个时间步，<script type="math/tex">\hat y^{<1>}</script>作为输入（编号4），然后<strong>softmax</strong>层就会预测<script type="math/tex">\hat y^{<2>}</script>是什么。假如第一个词进行抽样后得到的是<strong>The</strong>，现在要计算出在第一词是<strong>The</strong>的情况下，第二个词应该是什么（编号5），然后再用采样函数来对<script type="math/tex">\hat y^{<2>}</script>进行采样</p><p>即无论得到什么样的用<strong>one-hot</strong>码表示的选择结果，都把它传递到下一个时间步，然后进行采样，直到最后一个时间步</p><p>怎样知道一个句子结束：</p><ul><li>如果代表句子结尾的标识在字典中，可以一直进行采样直到得到<strong>EOS</strong>标识（编号6），代表着已经抵达结尾，可以停止采样</li><li>如果字典中没有这个词，可以决定从20个或100个或其他个单词进行采样，然后一直将采样进行下去直到达到所设定的时间步。不过这种过程有时候会产生一些未知标识（编号7），如果要确保算法不会输出这种标识，要做的是拒绝采样过程中产生任何未知的标识，一旦出现就继续在剩下的词中进行重采样，直到得到一个不是未知标识的词</li></ul><p>这就是如何从<strong>RNN</strong>语言模型中生成一个随机选择的句子。以上所建立的是基于词汇的<strong>RNN</strong>模型，意思就是字典中的词都是英语单词（下图编号1）</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/1d31771da8ced333968541fbbf67e6f1.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1d31771da8ced333968541fbbf67e6f1.png" alt></a></p><h3 id="基于字符的RNN结构"><a href="#基于字符的RNN结构" class="headerlink" title="基于字符的RNN结构"></a>基于字符的<strong>RNN</strong>结构</h3><p>用以上字符组成字典（上图编号2所示）</p><p>序列<script type="math/tex">\hat y^{<1>}</script>，<script type="math/tex">\hat y^{<2>}</script>，<script type="math/tex">\hat y^{<3>}</script>在训练数据中是单独的字符，对于“<strong>Cats average 15 hours of sleep a day.</strong>”，<strong>C</strong>是<script type="math/tex">\hat y^{<1>}</script>，<strong>a</strong>就是<script type="math/tex">\hat y^{<2>}</script>，<strong>t</strong>就是<script type="math/tex">\hat y^{<3>}</script>等等</p><p>优点：</p><p>不必担心会出现未知的标识，基于字符的语言模型会将<strong>Mau</strong>这样的序列也视为可能性非零的序列。而基于词汇的语言模型，如果<strong>Mau</strong>不在字典中，只能当作未知标识<strong>UNK</strong></p><p>缺点：</p><p>最后会得到太多太长的序列，基于字符的语言模型在捕捉句子中的依赖关系也就是句子较前部分如何影响较后部分不如基于词汇的语言模型那样可以捕捉长范围的关系，并且基于字符的语言模型训练起来计算成本比较高</p><h2 id="1-8-循环神经网络的梯度消失（Vanishing-gradients-withRNNs）"><a href="#1-8-循环神经网络的梯度消失（Vanishing-gradients-withRNNs）" class="headerlink" title="1.8 循环神经网络的梯度消失（Vanishing gradients withRNNs）"></a>1.8 循环神经网络的梯度消失（Vanishing gradients withRNNs）</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8fb1c4afe30b7a0ede26522b355068ba.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8fb1c4afe30b7a0ede26522b355068ba.png" alt></a></p><p>编号1<strong>cat</strong>是单数，应该用<strong>was，</strong>编号2 <strong>cats</strong>是复数，用<strong>were</strong></p><p>这个例子中的句子有长期的依赖，最前面的单词对句子后面的单词有影响。但基本的<strong>RNN</strong>模型（编号3）不擅长捕获长期依赖效应</p><p><strong>RNN</strong>反向传播很困难，会有梯度消失的问题，后面层的输出误差（编号6）很难影响前面层（编号7）的计算。即很难让一个神经网络能够意识到它要记住看到的是单数名词还是复数名词，然后在序列后面生成依赖单复数形式的<strong>was</strong>或者<strong>were</strong>。且在英语里面中间的内容（编号8）可以任意长，所以基本的<strong>RNN</strong>模型会有很多局部影响，输出<script type="math/tex">\hat y^{<3>}</script>主要受附近的值（编号10）的影响，编号6所示的输出很难受到序列靠前的输入（编号10）的影响，因为不管输出是什么，对的还是错的，这个区域都很难反向传播到序列的前面部分，也因此网络很难调整序列前面的计算</p><p>在反向传播的时候，随着层数的增多，梯度不仅可能指数型的下降，也可能指数型的上升。梯度消失在训练<strong>RNN</strong>时是首要的问题，不过梯度爆炸也会出现，但是梯度爆炸很明显，因为指数级大的梯度会让参数变得极其大，以至于网络参数崩溃。参数大到崩溃会看到很多<strong>NaN</strong>，或者不是数字的情况，这意味着网络计算出现了数值溢出</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ac5d647140997ba713c376fb097ea0e2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ac5d647140997ba713c376fb097ea0e2.png" alt></a></p><p>解决方法：用<strong>梯度修剪</strong>。梯度向量如果大于某个阈值，缩放梯度向量，保证不会太大</p><h2 id="1-9-GRU单元（Gated-Recurrent-Unit（GRU））"><a href="#1-9-GRU单元（Gated-Recurrent-Unit（GRU））" class="headerlink" title="1.9 GRU单元（Gated Recurrent Unit（GRU））"></a>1.9 GRU单元（Gated Recurrent Unit（GRU））</h2><p>门控循环单元：改变了<strong>RNN</strong>的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题</p><h3 id="简化的GRU模型"><a href="#简化的GRU模型" class="headerlink" title="简化的GRU模型"></a>简化的GRU模型</h3><p><strong>RNN</strong>隐藏层的单元的可视化：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/1521560729.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1521560729.png" alt title="1521560729"></a></p><p>$a^{&lt; t&gt;}$表达式为：</p><script type="math/tex; mode=display">a^{<t>}=tanh(W_a[a^{<t-1>},x^{<t>}]+b_a)</script><p>为了解决梯度消失问题，对上述单元进行修改，添加了记忆单元，构建GRU，如下图所示：</p><p><img src="/assets/501import.png" alt></p><p>表达式为：</p><script type="math/tex; mode=display">\tilde c^{<t>}=tanh(W_c[c^{<t-1>},x^{<t>}]+b_c)</script><script type="math/tex; mode=display">\Gamma_u=\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)</script><script type="math/tex; mode=display">c^{<t>}=\Gamma_u*\tilde c^{<t>}+(1-\Gamma_u)*c^{<t-1>}</script><p>$c^{<t-1>}=a^{<t-1>}$，<script type="math/tex">c^{<t>}=a^{<t>}</script>。符号<script type="math/tex">c</script>表示记忆细胞的值，<script type="math/tex">a</script>表示输出的激活值，<script type="math/tex">\tilde c^{<t>}</script>是个候选值，替代了c的值，<script type="math/tex">\Gamma_u</script>（0到1）意为gate，<strong>u</strong>表示“<strong>update</strong>”，当<script type="math/tex">\Gamma_u=1</script>时，代表更新；当<script type="math/tex">\Gamma_u=0</script>时，代表记忆，保留之前的模块输出。<script type="math/tex">\Gamma_u</script>能够保证RNN模型中跨度很大的依赖关系不受影响，消除梯度消失问题</t-1></t-1></p><h3 id="完整的GRU"><a href="#完整的GRU" class="headerlink" title="完整的GRU"></a>完整的GRU</h3><p>完整的GRU添加了另外一个gate，即<script type="math/tex">\Gamma_r</script>，表达式如下：</p><script type="math/tex; mode=display">\tilde c^{<t>}=tanh(W_c[\Gamma_r*c^{<t-1>},x^{<t>}]+b_c)</script><script type="math/tex; mode=display">\Gamma_u=\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)</script><script type="math/tex; mode=display">\Gamma_r=\sigma(W_r[c^{<t-1>},x^{<t>}]+b_r)</script><script type="math/tex; mode=display">c^{<t>}=\Gamma_u*\tilde c^{<t>}+(1-\Gamma_u)*c^{<t-1>}</script><script type="math/tex; mode=display">a^{<t>}=c^{<t>}</script><p>$\Gamma_{r}$门：计算出的下一个<script type="math/tex">c^{<t>}</script>的候选值<script type="math/tex">{\tilde{c}}^{<t>}</script>跟<script type="math/tex">c^{<t-1>}</script>有多大的相关性</p><p>$c^{&lt; t&gt;}$可以是一个向量（编号1），如果有100维的隐藏的激活值，那么<script type="math/tex">c^{<t>}</script>、<script type="math/tex">{\tilde{c}}^{<t>}</script>、<script type="math/tex">\Gamma_{u}</script>还有画在框中的其他值也是100维</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/c1df3f793dcb1ec681db6757b4974cee.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c1df3f793dcb1ec681db6757b4974cee.png" alt></a></p><p>$*$实际上就是元素对应的乘积（<script type="math/tex">c^{< t>}=\Gamma_u*\tilde c^{< t>}+(1-\Gamma_u)*c^{<t-1>}</script>），若<script type="math/tex">\Gamma_{u}</script>（<script type="math/tex">\Gamma_u=\sigma(W_u[c^{<t-1>},x^{< t>}]+b_u)</script>）是一个100维的向量，而里面的值<strong>几乎</strong>都是0或者1，则这100维的记忆细胞<script type="math/tex">c^{< t>}</script>（<script type="math/tex">c^{< t>}=a^{< t>}</script>，编号1）就是要更新的比特</p><h2 id="1-10-长短期记忆（LSTM（long-short-term-memory）unit）"><a href="#1-10-长短期记忆（LSTM（long-short-term-memory）unit）" class="headerlink" title="1.10 长短期记忆（LSTM（long short term memory）unit）"></a>1.10 长短期记忆（LSTM（long short term memory）unit）</h2><p>LSTM是另一种更强大的解决梯度消失问题的方法。它对应的RNN隐藏层单元结构如下图所示：</p><p><img src="/images/pasted-164.png" alt="upload successful"></p><p>相应的表达式为：</p><script type="math/tex; mode=display">\tilde c^{<t>}=tanh(W_c[a^{<t-1>},x^{<t>}]+b_c)</script><script type="math/tex; mode=display">\Gamma_u=\sigma(W_u[a^{<t-1>},x^{< t>}]+b_u)</script><script type="math/tex; mode=display">\Gamma_f=\sigma(W_f[a^{<t-1>},x^{< t>}]+b_f)</script><script type="math/tex; mode=display">\Gamma_o=\sigma(W_o[a^{<t-1>},x^{< t>}]+b_o)</script><script type="math/tex; mode=display">c^{< t>}=\Gamma_u*\tilde c^{< t>}+\Gamma_f*c^{<t-1>}</script><script type="math/tex; mode=display">a^{< t>}=\Gamma_o*c^{< t>}</script><p>LSTM包含三个gates：<script type="math/tex">\Gamma_u,\Gamma_f,\Gamma_o</script>，分别对应update gate，forget gate和output gate</p><p>在<strong>LSTM</strong>中不再有<script type="math/tex">a^{< t>} = c^{< t>}</script>的情况</p><p>红线显示了只要正确地设置了遗忘门和更新门，<strong>LSTM</strong>很容易把<script type="math/tex">c^{<0>}</script>的值一直往下传递到右边，比如<script type="math/tex">c^{<3>} = c^{<0>}</script>。这就是为什么<strong>LSTM</strong>和<strong>GRU</strong>非常擅长于长时间记忆某个值</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/94e871edbd87337937ce374e71d56e42.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/94e871edbd87337937ce374e71d56e42.png" alt></a></p><p>“<strong>窥视孔连接</strong>”（<strong>peephole connection</strong>）:门值不仅取决于<script type="math/tex">a^{<t-1>}</script>和<script type="math/tex">x^{< t>}</script>，也取决于上一个记忆细胞的值（<script type="math/tex">c^{<t-1>}</script>），即<script type="math/tex">c^{<t-1>}</script>也能影响门值</p><p>如果考虑<script type="math/tex">c^{<t-1>}</script>对<script type="math/tex">\Gamma_u,\Gamma_f,\Gamma_o</script>的影响，可加入“窥视孔连接”，对LSTM的表达式进行修改：</p><script type="math/tex; mode=display">\tilde c^{< t>}=tanh(W_c[a^{<t-1>},x^{< t>}]+b_c)</script><script type="math/tex; mode=display">\Gamma_u=\sigma(W_u[a^{<t-1>},x^{< t>},c^{<t-1>}]+b_u)</script><script type="math/tex; mode=display">\Gamma_f=\sigma(W_f[a^{<t-1>},x^{< t>},c^{<t-1>}]+b_f)</script><script type="math/tex; mode=display">\Gamma_o=\sigma(W_o[a^{<t-1>},x^{< t>},c^{<t-1>}]+b_o)</script><script type="math/tex; mode=display">c^{< t>}=\Gamma_u*\tilde c^{< t>}+\Gamma_f*c^{<t-1>}</script><script type="math/tex; mode=display">a^{< t>}=\Gamma_o*c^{<t>}</script><p><strong>LSTM</strong>主要的区别：比如（上图编号13）有一个100维的隐藏记忆细胞单元，第<script type="math/tex">i</script>个<script type="math/tex">c^{<t-1>}</script>的元素只会影响第<script type="math/tex">i</script>个元素对应的那个门，所以关系是一对一的，并不是任意这100维的<script type="math/tex">c^{<t-1>}</script>可以影响所有的门元素</p><p><strong>LSTM</strong>前向传播图：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/LSTM.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/LSTM.png" alt title="ST"></a></p><p><img src="/images/pasted-165.png" alt="upload successful"><br><strong>GRU</strong>：模型简单，更容易创建一个更大的网络，只有两个门，在计算上运行得更快，且可以扩大模型的规模</p><p><strong>LSTM：</strong>更加强大和灵活，因为它有三个门而不是两个</p><h2 id="1-11-双向循环神经网络（Bidirectional-RNN）"><a href="#1-11-双向循环神经网络（Bidirectional-RNN）" class="headerlink" title="1.11 双向循环神经网络（Bidirectional RNN）"></a>1.11 双向循环神经网络（Bidirectional RNN）</h2><p>双向<strong>RNN</strong>模型在序列的某点处不仅可以获取之前的信息，还可以获取未来的信息</p><p>用只有4个单词的句子，<script type="math/tex">x^{<1>}</script>到<script type="math/tex">x^{<4>}</script>。这个网络有一个前向的循环单元<script type="math/tex">a^{\rightarrow <1>}</script>，<script type="math/tex">a^{\rightarrow <2>}</script>，<script type="math/tex">a^{\rightarrow <3>}</script>，<script type="math/tex">a^{\rightarrow <4>}</script>，这四个循环单元都有一个当前输入<script type="math/tex">x</script>输入进去，得到预测的<script type="math/tex">\hat y^{<1>}</script>，<script type="math/tex">\hat y^{<2>}</script>，<script type="math/tex">\hat y^{<3>}</script>和<script type="math/tex">\hat y^{<4>}</script></p><p>再增加一个反向循环层：<script type="math/tex">a^{\leftarrow <1>}</script>，<script type="math/tex">a^{\leftarrow <2>}</script>，<script type="math/tex">a^{\leftarrow <3>}</script>，<script type="math/tex">a^{\leftarrow <4>}</script></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/48c787912f7f8daee638dd311583d6cf.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/48c787912f7f8daee638dd311583d6cf.png" alt></a></p><p>给定一个输入序列<script type="math/tex">x^{<1>}</script>到<script type="math/tex">x^{<4>}</script>，这个序列先后计算前向的<script type="math/tex">a^{\rightarrow <1>}</script>，<script type="math/tex">a^{\rightarrow <2>}</script>，<script type="math/tex">a^{\rightarrow <3>}</script>，<script type="math/tex">a^{\rightarrow <4>}</script>，而反向序列从<script type="math/tex">a^{\leftarrow <4>}</script>开始，计算完了反向的<script type="math/tex">a^{\leftarrow <4>}</script>，可以用这些激活值计算反向<script type="math/tex">a^{\leftarrow <3>},a^{\leftarrow <2>},a^{\leftarrow <1>}</script></p><p>值得注意的是计算的是网络激活值，这不是反向传播而是前向的传播，图中前向传播一部分计算是从左到右，一部分计算是从右到左。把所有激活值都计算完了就可以计算预测结果</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/053831ff43d039bd5e734df96d8794cb.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/053831ff43d039bd5e734df96d8794cb.png" alt></a></p><p>预测结果：</p><script type="math/tex; mode=display">\hat y^{} =g(W_{g}\left\lbrack a^{\rightarrow <t>},a^{\leftarrow <t>} \right\rbrack +b_{y})</script><p>这些基本单元不仅仅是标准<strong>RNN</strong>单元，也可以是<strong>GRU</strong>单元或者<strong>LSTM</strong>单元</p><p>双向<strong>RNN</strong>网络模型的缺点是需要完整的数据的序列才能预测任意位置。比如要构建一个语音识别系统，双向<strong>RNN</strong>模型需要等待整个语音说完，获取整个语音表达才能处理这段语音，并进一步做语音识别</p><h2 id="1-12-深层循环神经网络（Deep-RNNs）"><a href="#1-12-深层循环神经网络（Deep-RNNs）" class="headerlink" title="1.12 深层循环神经网络（Deep RNNs）"></a>1.12 深层循环神经网络（Deep RNNs）</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8378c2bfe73e1ac9f85d6aa79b71b5eb.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8378c2bfe73e1ac9f85d6aa79b71b5eb.png" alt></a></p><p>$a^{\lbrack l\rbrack }$表示第<script type="math/tex">l</script>层的激活值，&lt;t&gt;表示第<script type="math/tex">t</script>个时间点</p><p>激活值<script type="math/tex">a^{[l]< t>}</script>有两个输入:</p><script type="math/tex; mode=display">a^{[l]< t>}=g(W_a^{[l]}[a^{[l]<t-1>},a^{[l-1]< t>}]+b_a^{[l]})</script><p>对于<strong>RNN</strong>来说，有三层就已经不少了。由于时间的维度，<strong>RNN</strong>网络会变得相当大，即使只有很少的几层</p><p>另外一种Deep RNNs结构是每个输出层上还有一些垂直单元：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/455863a3c8c2dfaa0e5474bfa2c6824d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/455863a3c8c2dfaa0e5474bfa2c6824d.png" alt></a></p><p>即把输出去掉（编号1），在每一个上面堆叠循环层，然后换成一些深的层，这些层并不水平连接，只是一个深层的网络，然后用来预测<script type="math/tex">y^{< t>}</script></p><p>这些单元（编号3）没必要是标准的<strong>RNN</strong>，也可以是<strong>GRU</strong>单元或者<strong>LSTM</strong>单元，也可以构建深层的双向<strong>RNN</strong>网络，但深层的<strong>RNN</strong>训练需要很多计算资源，需要很长的时间</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-1-为什么选择序列模型？（Why-Sequence-Models-）&quot;&gt;&lt;a href=&quot;#1-1-为什么选择序列模型？（Why-Sequence-Models-）&quot; class=&quot;headerlink&quot; title=&quot;1.1 为什么选择序列模型？（Why Sequence Models?）&quot;&gt;&lt;/a&gt;1.1 为什么选择序列模型？（Why Sequence Models?）&lt;/h2&gt;&lt;p&gt;语音识别：给定一个输入音频片段 &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;，要求输出对应的文字记录 &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt;。输入和输出数据都是序列模型，因为 &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;是一个按时播放的音频片段，输出 &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt;是一系列单词&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第四周 特殊应用：人脸识别和神经风格转换（Special applications: Face recognition &amp;Neural style transfer）(Course 4)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E5%9B%9B%E5%91%A8-%E7%89%B9%E6%AE%8A%E5%BA%94%E7%94%A8%EF%BC%9A%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E5%92%8C%E7%A5%9E%E7%BB%8F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E6%8D%A2%EF%BC%88Special-applications-Face-recognition-Neural-style-transfer%EF%BC%89-Course-4/"/>
    <id>https://baozouai.com/2019/02/28/第四周-特殊应用：人脸识别和神经风格转换（Special-applications-Face-recognition-Neural-style-transfer）-Course-4/</id>
    <published>2019-02-27T22:09:00.000Z</published>
    <updated>2019-02-27T06:23:33.604Z</updated>
    
    <content type="html"><![CDATA[<h2 id="4-1-什么是人脸识别？（What-is-face-recognition-）"><a href="#4-1-什么是人脸识别？（What-is-face-recognition-）" class="headerlink" title="4.1 什么是人脸识别？（What is face recognition?）"></a>4.1 什么是人脸识别？（What is face recognition?）</h2><ul><li>人脸验证（<strong>face verification</strong>）问题：如果有一张输入图片以及某人的<strong>ID</strong>或者是名字，系统要做的是验证输入图片是否是这个人，也被称作1对1问题，只需要弄明白这个人是否和他声称的身份相符<a id="more"></a></li><li>人脸识别（<strong>face recognition</strong>）问题：（1对多问题（<script type="math/tex">1:K</script>））输入一张人脸图片，验证输出是否为K个模板中的某一个，即一对多问题</li></ul><p>一般人脸识别比人脸验证更难。因为假设人脸验证系统的错误率是1%，那么在人脸识别中，输出分别与K个模板都进行比较，则相应的错误率就会增加，约K%。模板个数越多，错误率越大一些</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b0d5f91254b48dcc44944bfbdc05992b.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b0d5f91254b48dcc44944bfbdc05992b.png" alt></a></p><p>什么是人脸识别？（What is face recognition?）<br>人脸验证（face verification）问题：如果有一张输入图片以及某人的ID或者是名字，系统要做的是验证输入图片是否是这个人，也被称作1对1问题，只需要弄明白这个人是否和他声称的身份相符<br>人脸识别（face recognition）问题：（1对多问题（1:K））输入一张人脸图片，验证输出是否为K个模板中的某一个，即一对多问题<br>一般人脸识别比人脸验证更难。因为假设人脸验证系统的错误率是1%，那么在人脸识别中，输出分别与K个模板都进行比较，则相应的错误率就会增加，约K%。模板个数越多，错误率越大一些</p><h2 id="4-2-One-Shot学习（One-shot-learning）"><a href="#4-2-One-Shot学习（One-shot-learning）" class="headerlink" title="4.2 One-Shot学习（One-shot learning）"></a>4.2 One-Shot学习（One-shot learning）</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8b3b58571307fce29dbced077bd86ea7.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8b3b58571307fce29dbced077bd86ea7.png" alt></a></p><p>要让人脸识别能够做到一次学习，要做的是学习<strong>Similarity</strong>函数</p><p>让神经网络学习用<script type="math/tex">d</script>表示的函数：</p><script type="math/tex; mode=display">d(img1,img2) = degree\ of\ difference\ between\ images</script><p>以两张图片作为输入，然后输出这两张图片的差异值</p><ul><li>如果这两张图片的差异值小于某个阈值<script type="math/tex">\tau</script>，就能预测这两张图片是同一个人</li><li>如果差异值大于τ，就能预测这是不同的两个人</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f46e9ff3ef4819665b487a81784ab821.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f46e9ff3ef4819665b487a81784ab821.png" alt></a></p><p>对于人脸识别问题，只需计算测试图片与数据库中K个目标的相似函数，取其中d(img1,img2)最小的目标为匹配对象。若所有的d(img1,img2)都很大，则表示数据库没有这个人</p><p>如果之后有新人加入了团队（编号5），只需将他的照片加入数据库，系统依然能照常工作</p><h2 id="4-3-Siamese-网络（Siamese-network）"><a href="#4-3-Siamese-网络（Siamese-network）" class="headerlink" title="4.3 Siamese 网络（Siamese network）"></a>4.3 Siamese 网络（Siamese network）</h2><p>函数d的作用是输入两张人脸，然后输出相似度。实现这个功能的一个方式是用<strong>Siamese</strong>网络</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/18679869eb23651215b517b0f00806f5.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/18679869eb23651215b517b0f00806f5.png" alt></a></p><p>向量（编号1）是由网络深层的全连接层计算出来的，叫做<script type="math/tex">f(x^{(1)})</script>。可以把<script type="math/tex">f(x^{(1)})</script>看作是输入图像<script type="math/tex">x^{(1)}</script>的编码，即取输入图像（编号2），然后表示成128维的向量</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ecd4f7ca6487b4ccb19c1f5039e9d876.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ecd4f7ca6487b4ccb19c1f5039e9d876.png" alt></a></p><p>如果要比较两个图片，要做的是把第二张图片喂给有同样参数的同样的神经网络，得到一个不同的128维的向量（编号3），第二张图片的编码叫做<script type="math/tex">f(x^{(2)})</script></p><p>然后定义<script type="math/tex">d</script>，将<script type="math/tex">x^{(1)}</script>和<script type="math/tex">x^{(2)}</script>的距离定义为两幅图片的编码之差的范数：</p><script type="math/tex; mode=display">d( x^{( 1)},x^{( 2)}) =|| f( x^{( 1)}) - f( x^{( 2)})||_{2}^{2}</script><p>对于两个不同的输入，运行相同的卷积神经网络，然后比较它们，就叫做<strong>Siamese</strong>网络架构</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/214e009729b015bc6088200e3c1ca3cd.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/214e009729b015bc6088200e3c1ca3cd.png" alt></a></p><p>训练<strong>Siamese</strong>神经网络：不同图片的CNN网络所有结构和参数都是一样的。所以要做的是训练一个网络，利用梯度下降算法不断调整网络参数，使得属于同一人的图片之间<script type="math/tex">d(x^{(1)},x^{(2)})</script> 很小，而不同人的图片之间<script type="math/tex">d(x^{(1)},x^{(2)})</script>很大</p><p>即神经网络的参数定义了一个编码函数<script type="math/tex">f(x^{(i)})</script>，如果给定输入图像<script type="math/tex">x^{(i)}</script>，这个网络会输出<script type="math/tex">x^{(i)}</script>的128维的编码。然后要做的就是学习参数</p><ul><li>使得如果两个图片<script type="math/tex">x^{( i)}</script>和<script type="math/tex">x^{( j)}</script>是同一个人，那么得到的两个编码的距离就小</li><li>如果<script type="math/tex">x^{(i)}</script>和<script type="math/tex">x^{(j)}</script>是不同的人，那么编码距离就大</li></ul><p>如果改变这个网络所有层的参数，会得到不同的编码结果，要做的是用反向传播来改变这些所有的参数，以确保满足这些条件</p><h2 id="4-4-Triplet-损失（Triplet-损失）"><a href="#4-4-Triplet-损失（Triplet-损失）" class="headerlink" title="4.4 Triplet 损失（Triplet 损失）"></a>4.4 Triplet 损失（Triplet 损失）</h2><p>要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是定义三元组损失函数然后应用梯度下降</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d56e1c92b45d8b9e76c1592fdbf0fc7f.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d56e1c92b45d8b9e76c1592fdbf0fc7f.png" alt></a></p><p>三元组损失每个样本包含三张图片：靶目标（Anchor）、正例（Positive）、反例（Negative），简写成<script type="math/tex">A</script>、<script type="math/tex">P</script>、<script type="math/tex">N</script></p><p>网络的参数或者编码应满足：</p><p>让<script type="math/tex">|| f(A) - f(P) ||^{2}</script>很小，即：</p><script type="math/tex; mode=display">|| f(A) - f(P)||^{2} \leq ||f(A) - f(N)||^{2}</script><script type="math/tex; mode=display">||f(A)-f(P)||^2-||f(A)-F(N)||^2\leq 0</script><p>$|| f(A) - f(P) ||^{2}$是<script type="math/tex">d(A,P)</script>，<script type="math/tex">|| f(A) - f(N) ||^{2}</script>是<script type="math/tex">d(A,N)</script></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/76d6eaae60caea5f2c4fcca0db226737.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/76d6eaae60caea5f2c4fcca0db226737.png" alt></a></p><p>如果所有的图片都是零向量，即<script type="math/tex">f(A)=0,f(P)=0,f(N)=0</script>那么上述不等式也满足。但是对进行人脸识别没有任何作用，所以添加一个超参数<script type="math/tex">\alpha</script>，且<script type="math/tex">\alpha>0</script>，对上述不等式做出如下修改：</p><script type="math/tex; mode=display">||f(A)-f(P)||^2-||f(A)-F(N)||^2\leq -\alpha</script><script type="math/tex; mode=display">||f(A)-f(P)||^2-||f(A)-F(N)||^2+\alpha \leq 0</script><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/eadc17c7748d8d2c36d74fa95e317e0d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/eadc17c7748d8d2c36d74fa95e317e0d.png" alt></a></p><p>间隔参数<script type="math/tex">\alpha</script>也被称为边界margin，类似于支持向量机中的margin，拉大了<strong>Anchor</strong>和<strong>Positive</strong>图片对和<strong>Anchor</strong>与<strong>Negative</strong>图片对之间的差距。若<script type="math/tex">d(A,P)=0.5</script>，<script type="math/tex">\alpha=0.2</script>，则<script type="math/tex">d(A,N)\geq0.7</script></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6a701944309f6dce72d03f5070275d5f.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6a701944309f6dce72d03f5070275d5f.png" alt></a></p><p>损失函数的定义基于三元图片组，即取这个和0的最大值：</p><script type="math/tex; mode=display">L( A,P,N) = max(|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + \alpha,0)</script><p>$max$函数的作用是只要<script type="math/tex">|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + \alpha\leq0</script>，损失函数就是0</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/16bd20003ac6e93b71abb565ac4fd98e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/16bd20003ac6e93b71abb565ac4fd98e.png" alt></a></p><p>如果<script type="math/tex">|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + \alpha\leq0</script>，最终会得到<script type="math/tex">|| f(A) - f( P)||^{2} -|| f( A) - f( N)||^{2} +\alpha</script>，即正的损失值。通过最小化这个损失函数达到的效果就是使这部分<script type="math/tex">|| f( A) - f( P)||^{2} -||f( A) - f( N)||^{2} +\alpha</script>成为0，或者小于等于0</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/bb258e78602ca65b6556a502da731764.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/bb258e78602ca65b6556a502da731764.png" alt></a></p><p>整个网络的代价函数是训练集中单个三元组损失的总和</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5d0ec945435eeb29f78463e38c58e90d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5d0ec945435eeb29f78463e38c58e90d.png" alt></a></p><p>如何选择三元组来形成训练集：如果从训练集中随机地选择<script type="math/tex">A</script>、<script type="math/tex">P</script>和<script type="math/tex">N</script>，遵守<script type="math/tex">A</script>和<script type="math/tex">P</script>是同一个人，而<script type="math/tex">A</script>和<script type="math/tex">N</script>是不同的人这一原则。那么约束条件（<script type="math/tex">d(A,P) + \alpha \leq d(A,N)</script>）很容易达到，因为随机选择的图片，<script type="math/tex">A</script>和<script type="math/tex">N</script>比<script type="math/tex">A</script>和<script type="math/tex">P</script>差别很大的概率很大，而且差距远大于<script type="math/tex">\alpha</script>，这样网络并不能从中学到什么</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8d010b8d7ee7011cf7f5d1889af0e4ce.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8d010b8d7ee7011cf7f5d1889af0e4ce.png" alt></a></p><p>所以为了构建一个数据集，要做的就是尽可能选择难训练的三元组<script type="math/tex">A</script>、<script type="math/tex">P</script>和<script type="math/tex">N</script>：</p><p>想要所有的三元组都满足条件（<script type="math/tex">d(A,P) + a \leq d(A,N)</script>），<script type="math/tex">A</script>、<script type="math/tex">P</script>和<script type="math/tex">N</script>的选择应使得<script type="math/tex">d(A,P)</script>很接近<script type="math/tex">d(A,N)</script>，即<script type="math/tex">d(A,P) \approx d(A,N)</script>，这样学习算法会竭尽全力使右边式子变大（<script type="math/tex">d(A,N)</script>），或者使左边式子（<script type="math/tex">d(A,P)</script>）变小，这样左右两边至少有一个<script type="math/tex">\alpha</script>的间隔。并且选择这样的三元组还可以增加学习算法的计算效率</p><p>总结：</p><p>训练三元组损失需要把训练集做成很多三元组，这就是一个三元组（编号1），有一个<strong>Anchor</strong>图片和<strong>Positive</strong>图片，这两个（<strong>Anchor</strong>和<strong>Positive</strong>）是同一个人，还有一张另一个人的<strong>Negative</strong>图片。这是另一组（编号2），其中<strong>Anchor</strong>和<strong>Positive</strong>图片是同一个人，但是<strong>Anchor</strong>和<strong>Negative</strong>不是同一个人，等等。</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/347cf0fc665abe47fa0999d8bf771d26.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/347cf0fc665abe47fa0999d8bf771d26.png" alt></a></p><p>定义了这些包括<script type="math/tex">A</script>、<script type="math/tex">P</script>和<script type="math/tex">N</script>图片的数据集之后，还需要用梯度下降最小化代价函数<script type="math/tex">J</script>，这样做的效果就是反向传播到网络中的所有参数来学习到一种编码，使得如果两个图片是同一个人，那么它们的<script type="math/tex">d</script>就会很小，如果两个图片不是同一个人，它们的<script type="math/tex">d</script> 就会很大</p><h2 id="4-5-面部验证与二分类（Face-verification-and-binary-classification）"><a href="#4-5-面部验证与二分类（Face-verification-and-binary-classification）" class="headerlink" title="4.5 面部验证与二分类（Face verification and binary classification）"></a>4.5 面部验证与二分类（Face verification and binary classification）</h2><p>另一个训练神经网络的方法是选取一对神经网络，选取<strong>Siamese</strong>网络，使其同时计算这些嵌入，比如说128维的嵌入（编号1），或者更高维，然后将其输入到逻辑回归单元进行预测，如果是相同的人，那么输出是1，若是不同的人，输出是0。这就把人脸识别问题转换为一个二分类问题，训练这种系统时可以替换<strong>Triplet loss</strong>的方法</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/c3bf61934da2f20a7d15e183c1d1d2ab.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c3bf61934da2f20a7d15e183c1d1d2ab.png" alt></a></p><p>最后的逻辑回归单元怎么处理：</p><p>比如说<strong>sigmoid</strong>函数应用到某些特征上，输出<script type="math/tex">\hat y</script>会变成：</p><script type="math/tex; mode=display">\hat y = \sigma(\sum_{k = 1}^{128}{w_{i}\| f( x^{( i)})_{k} - f( x^{( j)})_{k}\| + b})</script><p>把这128个元素当作特征，然后把他们放入逻辑回归中，最后的逻辑回归可以增加参数<script type="math/tex">w_{i}</script>和<script type="math/tex">b</script>，就像普通的逻辑回归一样。然后在这128个单元上训练合适的权重，用来预测两张图片是否是一个人</p><p>$\hat y$的另外一种表达式为：</p><script type="math/tex; mode=display">\hat y=\sigma(\sum_{k=1}^Kw_k\frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b)</script><p>这个公式也被叫做<script type="math/tex">\chi^{2}</script>公式，也被称为<script type="math/tex">\chi</script>平方相似度</p><p>上面神经网络拥有的参数和下面神经网络的相同（编号3和4所示的网络），两组参数是绑定的，这样的系统效果很好</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/3054acaedc374b50c13ece55b7e1ff27.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/3054acaedc374b50c13ece55b7e1ff27.png" alt></a></p><p>如果这是一张新图片（编号1），当员工走进门时，希望门可以自动为他们打开，这个（编号2）是在数据库中的图片，不需要每次都计算这些特征（编号6），可以提前计算好，当一个新员工走近时，使用上方的卷积网络来计算这些编码（编号5），和预先计算好的编码进行比较，然后输出预测值<script type="math/tex">\hat y</script></p><p>总结：把人脸验证当作一个监督学习，创建一个只有成对图片的训练集，不是三个一组，而是成对的图片，目标标签是1表示一对图片是一个人，目标标签是0表示图片中是不同的人。利用不同的成对图片，使用反向传播算法去训练<strong>Siamese</strong>神经网络</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/bb970476d7de45a473a1c98b8d87b23a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/bb970476d7de45a473a1c98b8d87b23a.png" alt></a></p><h2 id="4-6-什么是深度卷积网络？（What-are-deep-ConvNets-learning-）"><a href="#4-6-什么是深度卷积网络？（What-are-deep-ConvNets-learning-）" class="headerlink" title="4.6 什么是深度卷积网络？（What are deep ConvNets learning?）"></a>4.6 什么是深度卷积网络？（What are deep ConvNets learning?）</h2><p>假如训练了一个<strong>Alexnet</strong>轻量级网络，不同层之间隐藏单元的计算结果如下：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6d489f040214efb27bf0f109874b3918.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6d489f040214efb27bf0f109874b3918.png" alt></a></p><p>从第一层的隐藏单元开始，将训练集经过神经网络，然后弄明白哪一张图片最大限度地激活特定的单元。在第一层的隐藏单元，只能看到小部分卷积神经，只有一小块图片块是有意义的，因为这就是特定单元所能看到的全部</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/1472cbf93948173ac314ceb4eb5e4c97.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1472cbf93948173ac314ceb4eb5e4c97.png" alt></a></p><p>然后选一个另一个第一层的隐藏单元，重复刚才的步骤：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5b097161aa8a3e22c081185a69a367a3.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5b097161aa8a3e22c081185a69a367a3.png" alt></a></p><p>对其他隐藏单元也进行处理，会发现其他隐藏单元趋向于激活类似于这样的图片：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/eb711a9de1a7c8681c25c9c6e3bf71cd.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/eb711a9de1a7c8681c25c9c6e3bf71cd.png" alt></a></p><p>以此类推，这是9个不同的代表性神经元，每一个不同的图片块都最大化地激活了。可以理解为第一层的隐藏单元通常会找一些简单的特征，比如说边缘或者颜色阴影</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/4000d4a71a5820691197d506654216bd.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/4000d4a71a5820691197d506654216bd.png" alt></a></p><p>在深层部分，一个隐藏单元会看到一张图片更大的部分，在极端的情况下，可以假设每一个像素都会影响到神经网络更深层的输出，靠后的隐藏单元可以看到更大的图片块</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2ccff4b8e125893f330414574cd03af8.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2ccff4b8e125893f330414574cd03af8.png" alt></a></p><p>第一层，第一个被高度激活的单元：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d7fd293116929c0e6e807e10156d7e5a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d7fd293116929c0e6e807e10156d7e5a.png" alt></a></p><p>第二层检测的特征变得更加复杂：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/83f73c165fe6ec9c98ab2993d3efaf7f.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/83f73c165fe6ec9c98ab2993d3efaf7f.png" alt></a></p><p>第三层明显检测到更复杂的模式</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/62ac4181d43c9f937b33a70428d1fca1.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/62ac4181d43c9f937b33a70428d1fca1.png" alt></a></p><p>第四层，检测到的模式和特征更加复杂：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/96585e7bfa539245870080d4db16f255.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/96585e7bfa539245870080d4db16f255.png" alt></a></p><p>第五层检测到更加复杂的事物：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ac77f5f5dd63264cf8af597c3aa20d59.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ac77f5f5dd63264cf8af597c3aa20d59.png" alt></a></p><h2 id="4-7-代价函数（Cost-function）"><a href="#4-7-代价函数（Cost-function）" class="headerlink" title="4.7 代价函数（Cost function）"></a>4.7 代价函数（Cost function）</h2><p>为了实现神经风格迁移，需要定义一个关于<script type="math/tex">G</script>的代价函数<script type="math/tex">J</script>用来评判某个生成图像的好坏，使用梯度下降法去最小化<script type="math/tex">J(G)</script>，以便于生成图像</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/dd9dc6d164ca059f7996a6cbf58997a5.jpg" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/dd9dc6d164ca059f7996a6cbf58997a5.jpg" alt></a></p><p>代价函数定义为两个部分：</p><ul><li><script type="math/tex">J_{\text{content}}(C,G)</script>，被称作内容代价，是一个关于内容图片和生成图片的函数，用来度量生成图片<script type="math/tex">G</script>的内容与内容图片<script type="math/tex">C</script>的内容有多相似</li><li>然后把结果加上一个风格代价函数<script type="math/tex">J_{\text{style}}(S,G)</script>，用来度量图片<script type="math/tex">G</script>的风格和图片<script type="math/tex">S</script>的风格的相似度</li></ul><script type="math/tex; mode=display">J( G) = \alpha J_{\text{content}}( C,G) + \beta J_{\text{style}}(S,G)</script><p>最后用两个超参数<script type="math/tex">\alpha</script>和<script type="math/tex">\beta</script>来来确定内容代价和风格代价</p><p>对于代价函数<script type="math/tex">J(G)</script>，为了生成一个新图像，要做的是随机初始化生成图像<script type="math/tex">G</script>，可能是100×100×3、500×500×3，或任何想要的尺寸</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b8dafd082111a86c00066dedd1033ef1.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b8dafd082111a86c00066dedd1033ef1.png" alt></a></p><p>然后使用之前定义的代价函数<script type="math/tex">J(G)</script>，用梯度下降的方法将其最小化，更新：</p><script type="math/tex; mode=display">G:= G - \frac{\partial}{\partial G}J(G)</script><p>即更新图像<script type="math/tex">G</script>的像素值，也就是100×100×3，比如<strong>RGB</strong>通道的图片</p><p>比如从内容图片（编号1）和风格（编号2）图片开始，当随机初始化<script type="math/tex">G</script>，生成图像就是随机选取像素的白噪声图（编号3）。接下来运行梯度下降算法，最小化代价函数<script type="math/tex">J(G)</script>，逐步处理像素，慢慢得到一个生成图片（编号4、5、6），越来越像用风格图片的风格画出来的内容图片</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/dd376e74155008845e96d662cc45493a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/dd376e74155008845e96d662cc45493a.png" alt></a></p><h2 id="4-8-内容代价函数（Content-cost-function）"><a href="#4-8-内容代价函数（Content-cost-function）" class="headerlink" title="4.8 内容代价函数（Content cost function）"></a>4.8 内容代价函数（Content cost function）</h2><p>$J(G)$的第一部分<script type="math/tex">J_{content}(C,G)</script>，它表示内容图片C与生成图片G之间的相似度</p><p>使用的CNN网络是之前训练好的模型，例如Alex-Net。C，S，G共用相同模型和参数</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d54256309adfc1e140390a334bfc49ee.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d54256309adfc1e140390a334bfc49ee.png" alt></a></p><p>CNN的每个隐藏层分别提取原始图片的不同深度特征，由简单到复杂。如果<script type="math/tex">l</script>太小，则G与C在像素上会非常接近，没有迁移效果；如果<script type="math/tex">l</script>太深，则G上某个区域将直接会出现C中的物体。所以在实际中，层<script type="math/tex">l</script>在网络中既不会选的太浅也不会选的太深</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5b63e8b0c5c991bc19838b709524b79d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5b63e8b0c5c991bc19838b709524b79d.png" alt></a></p><p>衡量内容图片和生成图片在内容上的相似度：</p><p>令<script type="math/tex">a^{[l][C]}</script>和<script type="math/tex">a^{[l][G]}</script>代表图片<script type="math/tex">C</script>和<script type="math/tex">G</script>的<script type="math/tex">l</script>层的激活函数值。如果这两个激活值相似，意味着两个图片的内容相似</p><p>定义：</p><script type="math/tex; mode=display">J_{content}(C,G) = \frac{1}{4 \times n_H \times n_W \times n_C}\sum _{ \text{all entries}} (a^{[l][C]} - a^{[l][C]})^2</script><p>为两个激活值不同或者相似的程度</p><p>后面如果对<script type="math/tex">J(G)</script>做梯度下降来找<script type="math/tex">G</script>的值时，整个代价函数会激励这个算法来找到图像<script type="math/tex">G</script>，使得隐含层的激活值和内容图像的相似</p><h2 id="4-9-风格代价函数（Style-cost-function）"><a href="#4-9-风格代价函数（Style-cost-function）" class="headerlink" title="4.9 风格代价函数（Style cost function）"></a>4.9 风格代价函数（Style cost function）</h2><p>利用CNN网络模型，图片的风格可以定义成第<script type="math/tex">l</script>层隐藏层不同通道间激活函数的乘积（相关性）</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/efa0f6e81320966647658cba96ff28ee.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/efa0f6e81320966647658cba96ff28ee.png" alt></a></p><p>选取第<script type="math/tex">l</script>层隐藏层，各通道使用不同颜色标注。因为每个通道提取图片的特征不同，比如1通道（红色）提取的是图片的垂直纹理特征，2通道（黄色）提取的是图片的橙色背景特征。那么这两个通道的相关性越大，表示原始图片及既包含了垂直纹理也包含了该橙色背景；相关性越小，表示原始图片并没有同时包含这两个特征。即计算不同通道的相关性，反映了原始图片特征间的相互关系，从某种程度上刻画了图片的“风格”</p><p><img src="/images/pasted-154.png" alt="upload successful"></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e3d74c1ce2393ae4e706a1cc4024f311.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e3d74c1ce2393ae4e706a1cc4024f311.png" alt></a></p><p>接下来定义图片的风格矩阵（style matrix）为：</p><script type="math/tex; mode=display">G_{kk^{'}}^{[l]} = \sum_{i = 1}^{n_{H}^{[l]}}{\sum_{j = 1}^{n_{W}^{[l]}}{a_{i, j,k}^{[l]}a_{i, j, k^{'}}^{[l]}}}</script><script type="math/tex; mode=display">a_{i, j, k}^{[l]}$$为隐藏层$$l$$中$$(i,j,k)$$位置的激活项，$$i$$，$$j$$，$$k$$分别代表该位置的高度、宽度以及对应的通道数，k，$$k^{'}$$分别表示不同通道。风格矩阵$$G_{kk^{'}}^{[l]}$$计算第$$l$$层隐藏层不同通道对应的所有激活函数输出和，$$l$$层风格图像的矩阵$$G^{[l]}$$是一个$$n_{c} \times n_{c}$$的矩阵：![upload successful](/images/pasted-155.png)若两个通道之间相似性高，则对应的$$G_{kk^{'}}^{[l]}$$较大；若两个通道之间相似性低，则对应的$$G_{kk^{'}}^{[l]}$$较小风格矩阵$$G_{kk'}^{[l](S)}$$表征了风格图片$$S$$第$$l$$层隐藏层的“风格”。生成图片$$G$$也有$$G_{kk'}^{[l](G)}$$，$$G_{kk'}^{[l](S)}$$与$$G_{kk'}^{[l](G)}$$越相近，则表示$$G$$的风格越接近$$S$$。即$$J^{[l]}_{style}(S,G)$$定义为：</script><p>J_{style}^{[l]}(S,G) = \frac{1}{4 \times {n_C}^2 \times (n_H \times n_W)^2} \sum _{i=1}^{n_C}\sum_{j=1}^{n_C}(G^{(S)}_{ij} - G^{(G)}_{ij})^2</p><script type="math/tex; mode=display">然后使用梯度下降算法，不断迭代修正$$G$$的像素值，使$$J^{[l]}_{style}(S,G)$$不断减小为了提取更多的“风格”，可以使用多层隐藏层，然后相加，表达式为：</script><p>J_{style}(S,G)=\sum_l\lambda^{[l]}\cdot J^{[l]}_{style}(S,G)</p><script type="math/tex; mode=display">$$\lambda^{[l]}$$表示累加过程中各层$$J^{[l]}_{style}(S,G)$$的权重系数，为超参数最终的cost function为：</script><p>J(G)=\alpha \cdot J_{content}(C,G)+\beta \cdot J_{style}(S,G)</p><p>$$</p><p>之后用梯度下降法，或者更复杂的优化算法来找到一个合适的图像<script type="math/tex">G</script>，并计算<script type="math/tex">J(G)</script>的最小值，这样将能够得到非常好看的结果</p><h2 id="4-10-一维到三维推广（1D-and-3D-generalizations-of-models）"><a href="#4-10-一维到三维推广（1D-and-3D-generalizations-of-models）" class="headerlink" title="4.10 一维到三维推广（1D and 3D generalizations of models）"></a>4.10 一维到三维推广（1D and 3D generalizations of models）</h2><h2 id="1D卷积"><a href="#1D卷积" class="headerlink" title="1D卷积"></a>1D卷积</h2><p>将2D卷积推广到1D卷积：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/155e535d0d3725181e7c080707acd84f.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/155e535d0d3725181e7c080707acd84f.png" alt></a></p><p>二维数据的卷积是将同一个5×5特征检测器应用于图像中不同的位置（编号1所示），最后得到10×10的输出结果。1维过滤器可以在不同的位置中应用类似的方法（编号3，4，5所示）</p><p>当对这个1维信号使用卷积，将一个14维的数据与5维数据进行卷积，并产生一个10维输出：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/eeb764b9c08e48aa2bac70eb76110979.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/eeb764b9c08e48aa2bac70eb76110979.png" alt></a></p><p>如果有16个过滤器，最后会获得一个10×16的数据：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e8274e05078653cf68313e891c79796c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e8274e05078653cf68313e891c79796c.png" alt></a></p><p>对于卷积网络的下一层，如果输入一个10×16数据，可以使用一个5维过滤器进行卷积，需要16个通道进行匹配，如果有32个过滤器，另一层的输出结果就是6×32：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8b2d8ac94e71fb591c44c29ded5d6b7e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8b2d8ac94e71fb591c44c29ded5d6b7e.png" alt></a></p><h3 id="3D卷积"><a href="#3D卷积" class="headerlink" title="3D卷积"></a>3D卷积</h3><p>当进行<strong>CT</strong>扫描时，人体躯干的不同切片数据本质上是3维的</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/38e111b08f94c905ff97f627a4b986ff.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/38e111b08f94c905ff97f627a4b986ff.png" alt></a></p><p>如果有一个<strong>3D</strong>对象是14×14×14：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8323f5f9c33edb284eb038020f3ff7e7.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8323f5f9c33edb284eb038020f3ff7e7.png" alt></a></p><p>过滤器也是3D的，如果使用5×5×5过滤器进行卷积，将会得到一个10×10×10的结果输出，如果使用16个过滤器，输出将是10×10×10×16</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/49076b88b9ecbd1597f6ae37e8d87dc3.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/49076b88b9ecbd1597f6ae37e8d87dc3.png" alt></a></p><p>如果下一层卷积使用5×5×5×16维度的过滤器再次卷积，如果有32个过滤器，最终将得到一个6×6×6×32的输出</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;4-1-什么是人脸识别？（What-is-face-recognition-）&quot;&gt;&lt;a href=&quot;#4-1-什么是人脸识别？（What-is-face-recognition-）&quot; class=&quot;headerlink&quot; title=&quot;4.1 什么是人脸识别？（What is face recognition?）&quot;&gt;&lt;/a&gt;4.1 什么是人脸识别？（What is face recognition?）&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;人脸验证（&lt;strong&gt;face verification&lt;/strong&gt;）问题：如果有一张输入图片以及某人的&lt;strong&gt;ID&lt;/strong&gt;或者是名字，系统要做的是验证输入图片是否是这个人，也被称作1对1问题，只需要弄明白这个人是否和他声称的身份相符
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第三周 目标检测（Object detection)(Course 4)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E4%B8%89%E5%91%A8-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88Object-detection-Course-4/"/>
    <id>https://baozouai.com/2019/02/28/第三周-目标检测（Object-detection-Course-4/</id>
    <published>2019-02-27T22:01:00.000Z</published>
    <updated>2019-02-27T06:23:48.816Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3-1-目标定位（Object-localization）"><a href="#3-1-目标定位（Object-localization）" class="headerlink" title="3.1 目标定位（Object localization）"></a>3.1 目标定位（Object localization）</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0107af10b33fcb955cc3c588dfb78d49.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0107af10b33fcb955cc3c588dfb78d49.png" alt></a><br><a id="more"></a><br>定位分类问题：不仅要用算法判断图片中是不是一辆汽车，还要在图片中标记出它的位置，用边框或红色方框把汽车圈起来，“定位”的意思是判断汽车在图片中的具体位置</p><p>定位分类问题通常只有一个较大的对象位于图片中间位置，对它进行识别和定位。对象检测问题中图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d4a47c2041807f891c0a606d246330c5.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d4a47c2041807f891c0a606d246330c5.png" alt></a></p><p>构建汽车自动驾驶系统，对象可能包括以下几类：行人、汽车、摩托车和背景</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6461ff27c00dff4205688de4cf9d8803.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6461ff27c00dff4205688de4cf9d8803.png" alt></a></p><p>定位图片中汽车的位置：让神经网络输出一个边界框，标记为<script type="math/tex">b_{x}</script>,<script type="math/tex">b_{y}</script>,<script type="math/tex">b_{h}</script>和<script type="math/tex">b_{w}</script>，是被检测对象的边界框的参数化表示</p><p>红色方框的中心点表示为(<script type="math/tex">b_{x}</script>,<script type="math/tex">b_{y}</script>)，边界框的高度为<script type="math/tex">b_{h}</script>，宽度为<script type="math/tex">b_{w}</script>。训练集不仅包含神经网络要预测的对象分类标签，还要包含表示边界框的这四个数字，接着采用监督学习算法，输出一个分类标签，还有四个参数值，从而给出检测对象的边框位置</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/21b37dcb413e7c86464f88484796420c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/21b37dcb413e7c86464f88484796420c.png" alt></a></p><p>如何为监督学习任务定义目标标签 <script type="math/tex">y</script>：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/02d85ab36285cd21b5df4d1c253df57e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/02d85ab36285cd21b5df4d1c253df57e.png" alt></a></p><p>目标标签<script type="math/tex">y</script>的定义：<script type="math/tex">y= \begin{bmatrix} p_{c} \\ b_{x} \\ b_{y}\\ b_{h}\\ b_{w} \\ c_{1}\\ c_{2}\\ c_{3} \end{bmatrix}</script></p><p>$p_{c}$表示是否含有对象，如果对象属于前三类（行人、汽车、摩托车），则<script type="math/tex">p_{c}= 1</script>，如果是背景，则<script type="math/tex">p_{c} =0</script>。<script type="math/tex">p_{c}</script>表示被检测对象属于某一分类的概率，背景分类除外</p><p>如果检测到对象，就输出被检测对象的边界框参数<script type="math/tex">b_{x}</script>、<script type="math/tex">b_{y}</script>、<script type="math/tex">b_{h}</script>和<script type="math/tex">b_{w}</script>。<script type="math/tex">p_{c}=1</script>，同时输出<script type="math/tex">c_{1}</script>、<script type="math/tex">c_{2}</script>和<script type="math/tex">c_{3}</script>，表示该对象属于行人，汽车还是摩托车</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/fd37e4750b64a07cc1f29880c9b97261.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/fd37e4750b64a07cc1f29880c9b97261.png" alt></a></p><p>如果图片中没有检测对象:</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/131239883224f03709ddc66d9481c3c7.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/131239883224f03709ddc66d9481c3c7.png" alt></a></p><p>$p_{c} =0$，<script type="math/tex">y</script>的其它参数全部写成问号，表示“毫无意义”的参数</p><p>神经网络的损失函数，如果采用平方误差策略：</p><script type="math/tex; mode=display">L\left(\hat{y},y \right) = \left( \hat{y_1} - y_{1} \right)^{2} + \left(\hat{y_2} - y_{2}\right)^{2} + \ldots+\left( \hat{y_8} - y_{8}\right)^{2}</script><p>损失值等于每个元素相应差值的平方和</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d50ae3ee809da4c728837fee2d055f00.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d50ae3ee809da4c728837fee2d055f00.png" alt></a></p><p>如果图片中存在定位对象，<script type="math/tex">y_{1} =p_{c}=1</script>，损失值是不同元素的平方和</p><p>$y_{1}= p_{c} = 0$，损失值是<script type="math/tex">\left(\hat{y_1} - y_{1}\right)^{2}</script>，只需要关注神经网络输出<script type="math/tex">p_{c}</script>的准确度</p><p>这里用平方误差简化了描述过程。实际应用中可以不对<script type="math/tex">c_{1}</script>、<script type="math/tex">c_{2}</script>、<script type="math/tex">c_{3}</script>和<strong>softmax</strong>激活函数应用对数损失函数，并输出其中一个元素值，通常做法是对边界框坐标应用平方差，对<script type="math/tex">p_{c}</script>应用逻辑回归函数，甚至采用平方预测误差</p><h2 id="3-2-特征点检测（Landmark-detection）"><a href="#3-2-特征点检测（Landmark-detection）" class="headerlink" title="3.2 特征点检测（Landmark detection）"></a>3.2 特征点检测（Landmark detection）</h2><p>仅对目标的关键特征点坐标进行定位，这些关键点被称为landmarks</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/100b265aefc4b0170fb39ed339e5181a.png" target="_blank" rel="noopener"><img src="/assets/1231import.png" alt></a></p><p>选定特征点个数，并生成包含特征点的标签训练集，利用神经网络输出脸部关键特征点的位置</p><p>具体做法:准备一个卷积网络和一些特征集，将人脸图片输入卷积网络，输出1表示有人脸，0表示没有人脸，然后输出（<script type="math/tex">l_{1x}</script>，<script type="math/tex">l_{1y}</script>）……直到（<script type="math/tex">l_{64x}</script>，<script type="math/tex">l_{64y}</script>），<script type="math/tex">l</script>代表一个特征，即该网络模型共检测人脸上64处特征点，加上是否为face的标志位，输出label共有64x2+1=129个值，即有129个输出单元，由此实现对图片的人脸检测和定位</p><p>检测人体姿势动作：</p><p><img src="/images/pasted-153.png" alt="upload successful"></p><p>特征点的特性在所有图片中必须保持一致</p><h2 id="3-3-目标检测（Object-detection）"><a href="#3-3-目标检测（Object-detection）" class="headerlink" title="3.3 目标检测（Object detection）"></a>3.3 目标检测（Object detection）</h2><p>通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2f4e567978bb62fcbec093887de37783.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2f4e567978bb62fcbec093887de37783.png" alt></a></p><p>构建汽车检测算法步骤：</p><ol><li>首先创建一个标签训练集，<script type="math/tex">x</script>和<script type="math/tex">y</script>表示适当剪切的汽车图片样本，一开始可以使用适当剪切的图片，就是整张图片<script type="math/tex">x</script>几乎都被汽车占据，使汽车居于中间位置，并基本占据整张图片</li><li>开始训练卷积网络，输入这些适当剪切过的图片（编号6），卷积网络输出<script type="math/tex">y</script>，0或1表示图片中有汽车或没有汽车</li></ol><p>训练完这个卷积网络，用它来实现滑动窗口目标检测，具体步骤如下：</p><p>1.首先选定一个特定大小的窗口，将红色小方块输入卷积神经网络，卷积网络开始判断红色方框内有没有汽车</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2ac2ab6dcdcc0fe26a9833ff9da49bd2.png" alt></a></p><p>2.滑动窗口目标检测算法继续处理第二个图像，红色方框稍向右滑动之后的区域，并输入给卷积网络，再次运行卷积网络，然后处理第三个图像，依次重复操作，直到这个窗口滑过图像的每一个角落</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c55f22f302899d5f9d77bef958465660.png" alt></a></p><p>思路是以固定步幅移动窗口，遍历图像的每个区域，把这些剪切后的小图像输入卷积网络，对每个位置按0或1进行分类</p><p>3.重复上述操作，选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，输出0或1</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/34507c03fbda16049faeb3caf075fe50.png" alt></a></p><p>4.再以某个固定步幅滑动窗口，重复以上操作，遍历整个图像，输出结果</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f2b6d5bfedc5298160bc2628544e315c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f2b6d5bfedc5298160bc2628544e315c.png" alt></a></p><p>5.第三次重复操作，选用更大的窗口</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/c14524aa0534ed78c433e1cd0a8dff50.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c14524aa0534ed78c433e1cd0a8dff50.png" alt></a></p><p>这样不论汽车在图片的什么位置，总有一个窗口可以检测到</p><p>这种算法叫作滑动窗口目标检测：以某个步幅滑动这些方框窗口遍历整张图片，对这些方形区域进行分类，判断里面有没有汽车</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ef8afff4e50fc1c50a46b8443f1d6976.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ef8afff4e50fc1c50a46b8443f1d6976.png" alt></a></p><p>滑动窗口目标检测算法缺点：<strong>计算成本</strong></p><ul><li>如果选用的步幅很大，会减少输入卷积网络的窗口个数，粗糙间隔尺寸可能会影响性能</li><li>如果采用小粒度或小步幅，传递给卷积网络的小窗口会特别多，这意味着超高的计算成本</li></ul><h2 id="3-4-卷积的滑动窗口实现（Convolutional-implementation-of-sliding-windows）"><a href="#3-4-卷积的滑动窗口实现（Convolutional-implementation-of-sliding-windows）" class="headerlink" title="3.4 卷积的滑动窗口实现（Convolutional implementation of sliding windows）"></a>3.4 卷积的滑动窗口实现（Convolutional implementation of sliding windows）</h2><h3 id="把神经网络的全连接层转化成卷积层"><a href="#把神经网络的全连接层转化成卷积层" class="headerlink" title="把神经网络的全连接层转化成卷积层"></a>把神经网络的全连接层转化成卷积层</h3><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/38be387e37d131e44aff9d7fc9e3488a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/38be387e37d131e44aff9d7fc9e3488a.png" alt></a></p><p>前几层和之前的一样，下一层全连接层用5×5×16的过滤器来实现，数量是400个（编号1），输入图像大小为5×5×16，输出维度是1×1×400，这400个节点中每个节点都是上一层5×5×16激活值经过某个任意线性函数的输出结果</p><p>再添加另外一个卷积层（编号2），用1×1卷积，假设有400个1×1的过滤器，在这400个过滤器的作用下，下一层的维度是1×1×400，是上个网络中的这一全连接层经由1×1过滤器的处理，得到一个<strong>softmax</strong>激活值，通过卷积网络，最终得到1×1×4的输出层，而不是这4个数字（编号3）</p><p>以上就是用卷积层代替全连接层的过程，结果这几个单元集变成了1×1×400和1×1×4的维度</p><h3 id="通过卷积实现滑动窗口对象检测算法"><a href="#通过卷积实现滑动窗口对象检测算法" class="headerlink" title="通过卷积实现滑动窗口对象检测算法"></a>通过卷积实现滑动窗口对象检测算法</h3><p>假设向滑动窗口卷积网络输入14×14×3的图片，神经网络最后的输出层，即<strong>softmax</strong>单元的输出是1×1×4</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/00c4fb1a1af9b50f0fd0bcf5eacca6ff.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/00c4fb1a1af9b50f0fd0bcf5eacca6ff.png" alt></a></p><p>假设测试集图片是16×16×3，给输入图片加上黄色条块，在最初的滑动窗口算法中，把蓝色区域输入卷积网络（红色笔标记）生成0或1分类。接着滑动窗口，步幅为2个像素，向右滑动2个像素，将绿框区域输入给卷积网络，运行整个卷积网络，得到另外一个标签0或1。继续将这个橘色区域输入给卷积网络，卷积后得到另一个标签，最后对右下方的紫色区域进行最后一次卷积操作。在这个16×16×3的小图像上滑动窗口，卷积网络运行了4次，于是输出了了4个标签</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2a8750d733379aebf58f4354203153f2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2a8750d733379aebf58f4354203153f2.png" alt></a></p><p>这4次卷积操作中很多计算都是重复的。执行滑动窗口的卷积时使得卷积网络在这4次前向传播过程中共享很多计算，尤其是在编号1，卷积网络运行同样的参数，使用相同的5×5×16过滤器进行卷积操作，得到12×12×16的输出层。然后执行同样的最大池化（编号2），输出结果6×6×16。照旧应用400个5×5的过滤器（编号3），得到一个2×2×400的输出层，现在输出层为2×2×400，应用1×1过滤器（编号4）得到另一个2×2×400的输出层。再做一次全连接的操作（编号5），最终得到2×2×4的输出层，在输出层4个子方块中，蓝色的是图像左上部分14×14的输出（红色箭头标识），右上角方块是图像右上部分（绿色箭头标识）的对应输出，左下角方块是输入层左下角（橘色箭头标识），右下角是卷积网络处理输入层右下角14×14区域(紫色箭头标识)的结果</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ad1743ff113f9d30080f63a16c74ed64.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ad1743ff113f9d30080f63a16c74ed64.png" alt></a></p><p>具体的计算步骤：以绿色方块为例，假设剪切出这块区域（编号1），传递给卷积网络，第一层的激活值就是这块区域（编号2），最大池化后的下一层的激活值是这块区域（编号3），这块区域对应着后面几层输出的右上角方块（编号4，5，6）</p><p>该卷积操作的原理是不需要把输入图像分割成四个子集，分别执行前向传播，而是把它们作为一张图片输入给卷积网络进行计算，其中的公共区域可以共享很多计算</p><p>假如对一个28×28×3的图片应用滑动窗口操作，以14×14区域滑动窗口，以大小为2的步幅不断地向右移动窗口，直到第8个单元格，得到输出层的第一行。然后向图片下方移动，最终输出8×8×4的结果</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5fd2f8d039a3bfc5187dfe33f5276235.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5fd2f8d039a3bfc5187dfe33f5276235.png" alt></a></p><p>总结滑动窗口的实现过程：</p><p>在图片上剪切出一块区域，假设大小是14×14，把它输入到卷积网络。继续输入下一块区域，大小同样是14×14，重复操作，直到某个区域识别到汽车</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/84a6a0505acc165c6600d4b6f03d5e3c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/84a6a0505acc165c6600d4b6f03d5e3c.png" alt></a></p><p>但是不能依靠连续的卷积操作来识别图片中的汽车，可以对大小为28×28的整张图片进行卷积操作，一次得到所有预测值，如果足够幸运，神经网络便可以识别出汽车的位置</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/447080411189a0a4544747c2380fbda4.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/447080411189a0a4544747c2380fbda4.png" alt></a></p><p>在卷积层上应用滑动窗口算法提高了整个算法的效率，缺点是边界框的位置可能不够准确</p><h2 id="3-5-Bounding-Box预测（Bounding-box-predictions）"><a href="#3-5-Bounding-Box预测（Bounding-box-predictions）" class="headerlink" title="3.5 Bounding Box预测（Bounding box predictions）"></a>3.5 Bounding Box预测（Bounding box predictions）</h2><p>滑动窗口法的卷积实现算法效率很高，但不能输出最精准的边界框</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/cd3e263bf279739afe62eb8730b4e167.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/cd3e263bf279739afe62eb8730b4e167.png" alt></a></p><p>输入图像是100×100的，用3×3网格，实际实现时会用更精细的网格（19×19）。使用图像分类和定位算法</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e4bebc707829a1610572f43f8e0995c9.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e4bebc707829a1610572f43f8e0995c9.png" alt></a></p><p>编号1什么也没有，左上格子的标签向量<script type="math/tex">y</script>是<script type="math/tex">\begin{bmatrix}0\ ?\ ?\ ?\ ?\ ?\ ?\ ? \end{bmatrix}</script>。其他什么也没有的格子都一样</p><p>图中有两个对象，<strong>YOLO</strong>算法做的是取两个对象的中点，将对象分配给包含对象中点的格子。即使中心格子（编号5）同时有两辆车的一部分，分类标签<script type="math/tex">y</script>也为<script type="math/tex">y= \begin{bmatrix}0\ ?\ ?\ ?\ ?\ ?\ ?\ ? \end{bmatrix}</script>。编号4目标标签<script type="math/tex">y= \begin{bmatrix} 1\ b_{x}\ b_{y}\ b_{h}\ b_{w}\ 0\ 1\ 0 \end{bmatrix}</script>，编号6类似</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/fb08477cd3937f7df0deddc1de1d2920.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/fb08477cd3937f7df0deddc1de1d2920.png" alt></a></p><p>3×3中9个格子都对应一个8维输出目标向量<script type="math/tex">y</script>，其中一些值可以是<strong>dont care-s</strong>（即？）所以总的目标输出尺寸就是3×3×8</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/98633e9df22fd06cfc21af2e7d39bbb6.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/98633e9df22fd06cfc21af2e7d39bbb6.png" alt></a></p><p>如果要训练一个输入为100×100×3的神经网络，输入图像通过普通的卷积网络，卷积层，最大池化层等等，最后映射到一个3×3×8输出尺寸。然后用反向传播训练神经网络，将任意输入<script type="math/tex">x</script>映射到输出向量<script type="math/tex">y</script></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/404fdcba2685b830ae3718d348ab1d75.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/404fdcba2685b830ae3718d348ab1d75.png" alt></a></p><p>这个算法的优点在于神经网络可以输出精确的边界框，测试的时候有要做的是喂入输入图像<script type="math/tex">x</script>，然后跑正向传播，直到得到输出<script type="math/tex">y</script>。然后3×3位置对应的9个输出，只要每个格子中对象数目没有超过1个，这个算法应该是没问题的。但实践中会使用更精细的19×19网格，输出就是19×19×8，多个对象分配到同一个格子得概率就小得多</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a6d32959543c502ee18765cf20495bc2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a6d32959543c502ee18765cf20495bc2.png" alt></a></p><p>即使对象可以横跨多个格子，也只会被分配到9个格子其中之一，或者19×19网络的其中一个格子。在19×19网格中，两个对象的中点（图中蓝色点所示）处于同一个格子的概率就会更低。</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b6b6ca6167596a180c7bab7296ea850c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b6b6ca6167596a180c7bab7296ea850c.png" alt></a></p><p>优点：</p><ul><li>显式地输出边界框坐标，可以具有任意宽高比，并且能输出更精确的坐标，不会受到滑动窗口分类器的步长大小限制</li><li>并没有在3×3网格上跑9次算法，而是单次卷积实现，但在处理这3×3计算中很多计算步骤是共享的，所以这个算法效率很高</li><li>因为是卷积实现，运行速度非常快，可以达到实时识别</li></ul><p>如何编码这些边界框<script type="math/tex">b_{x}</script>、<script type="math/tex">b_{y}</script>、<script type="math/tex">b_{h}</script>和<script type="math/tex">b_{w}</script>：</p><p>在<strong>YOLO</strong>算法中，编号1约定左上点是<script type="math/tex">(0,0)</script>，右下点是<script type="math/tex">(1,1)</script>，橙色中点的位置<script type="math/tex">b_{x}</script>大概是0.4，<script type="math/tex">b_{y}</script>大概是0.3，<script type="math/tex">b_{w}</script>是0.9，<script type="math/tex">b_{h}</script>是0.5。<script type="math/tex">b_{x}</script>、<script type="math/tex">b_{y}</script>、<script type="math/tex">b_{h}</script>和<script type="math/tex">b_{w}</script>单位是相对于格子尺寸的比例，所以<script type="math/tex">b_{x}</script>和<script type="math/tex">b_{y}</script>必须在0和1之间，因为从定义上看，橙色点位于对象分配到格子的范围内，如果它不在0和1之间，即它在方块外，那么这个对象就应该分配到另一个格子上。这个值（<script type="math/tex">b_{h}</script>和<script type="math/tex">b_{w}</script>）可能会大于1，特别是如果有一辆汽车的边界框是这样的（编号3所示），那么边界框的宽度和高度有可能大于1</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0d7ee9b9f455338a8724520841223b11.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0d7ee9b9f455338a8724520841223b11.png" alt></a></p><h2 id="3-6-交并比（Intersection-over-union）"><a href="#3-6-交并比（Intersection-over-union）" class="headerlink" title="3.6 交并比（Intersection over union）"></a>3.6 交并比（Intersection over union）</h2><p>并交比函数可以用来评价对象检测算法</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/38eea69baa46091d516a0b7a33e5379e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/38eea69baa46091d516a0b7a33e5379e.png" alt></a></p><p>交并比（<strong>loU</strong>）函数是计算两个边界框交集和并集之比。两个边界框的并集是两个边界框绿色阴影区域，而交集是这个橙色阴影区域，交并比就是交集的大小（橙色阴影面积）除以绿色阴影的并集面积</p><p>一般约定，在计算机检测任务中，如果loU≥0.5，就说检测正确，如果预测器和实际边界框完美重叠，<strong>loU</strong>就是1，因为交集就等于并集</p><h2 id="3-7-非极大值抑制（Non-max-suppression）"><a href="#3-7-非极大值抑制（Non-max-suppression）" class="headerlink" title="3.7 非极大值抑制（Non-max suppression）"></a>3.7 非极大值抑制（Non-max suppression）</h2><p>对象检测中的一个问题是算法可能对同一个对象做出多次检测，非极大值抑制可以确保算法对每个对象只检测一次</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a86a2edbb89014e193ab613a162cff58.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a86a2edbb89014e193ab613a162cff58.png" alt></a></p><p>实践中当运行对象分类和定位算法时，对于每个格子都运行一次，编号1、2、3可能会认为这辆车中点应该在格子内部</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/78f2b2a2efdbd6aebe034ce30cda440b.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/78f2b2a2efdbd6aebe034ce30cda440b.png" alt></a></p><p>这个算法做的是：</p><p>1.首先看哪个检测结果相关的概率<script type="math/tex">p_{c}</script>（实际上是<script type="math/tex">p_{c}</script>乘以<script type="math/tex">c_{1}</script>、<script type="math/tex">c_{2}</script>或<script type="math/tex">c_{3}</script>）概率最大，右边车辆中是0.9，即最可靠的检测，用高亮标记，之后非极大值抑制逐一审视剩下的矩形，所有和这个最大的边框有很高交并比，高度重叠的其他边界框输出就会被抑制</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/074beeacfd9d400fc580171b09a6f3e9.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/074beeacfd9d400fc580171b09a6f3e9.png" alt></a></p><p>2.逐一审视剩下的矩形，找出概率<script type="math/tex">p_{c}</script>最高的一个，在这种情况下是0.8，就认为检测出一辆车（左边车辆），然后非极大值抑制算法就会去掉其他<strong>loU</strong>值很高的矩形。现在每个矩形都会被高亮显示或者变暗，如果直接抛弃变暗的矩形，就剩下高亮显示的那些是最后得到的两个预测结果</p><p>非最大值意味着只输出概率最大的分类结果，但抑制很接近，不是最大的其他预测结果</p><p>算法的细节：</p><p>首先在19×19网格上执行算法，会得到19×19×8的输出尺寸。简化成只做汽车检测，会得到输出预测概率（<script type="math/tex">p_{c}</script>）和边界框参数（<script type="math/tex">b_{x}</script>、<script type="math/tex">b_{y}</script>、<script type="math/tex">b_{h}</script>和<script type="math/tex">b_{w}</script>）</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/514cfeb2d7315eba2b6a29f68eae2879.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/514cfeb2d7315eba2b6a29f68eae2879.png" alt></a></p><p>1.将所有的预测值<script type="math/tex">p_{c}</script>小于或等于某个阈值，如<script type="math/tex">p_{c}\le 0.6</script>的边界框去掉</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6d0fa2073b280cd0bb111485ee1639e5.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6d0fa2073b280cd0bb111485ee1639e5.png" alt></a></p><p>2.剩下的边界框就一直选择概率<script type="math/tex">p_{c}</script>最高的边界框，把它输出成预测结果，取一个边界框，让它高亮显示，就可以确定输出有一辆车的预测</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/549430cf442163c7f44ae648e625ca10.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/549430cf442163c7f44ae648e625ca10.png" alt></a></p><p>3.去掉所有剩下的边界框</p><p>如果同时检测三个对象，比如说行人、汽车、摩托，输出向量就会有三个额外的分量。正确的做法是独立进行三次非极大值抑制，对每个输出类别都做一次</p><h2 id="3-9-Anchor-Boxes"><a href="#3-9-Anchor-Boxes" class="headerlink" title="3.9 Anchor Boxes"></a>3.9 Anchor Boxes</h2><p>对象检测存在的一个问题是每个格子只能检测出一个对象，如果想让一个格子检测出多个对象，可以使用<strong>anchor box</strong></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/49b7d68a17e89dd109f96efecc223f5a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/49b7d68a17e89dd109f96efecc223f5a.png" alt></a></p><blockquote><p>行人的中点和汽车的中点都落入到同一个格子中</p></blockquote><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e001f5f3d2afa76a1c3710bd60bcad00.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e001f5f3d2afa76a1c3710bd60bcad00.png" alt></a></p><p><strong>anchor box</strong>的思路是：预先定义两个不同形状的<strong>anchor box</strong>，把预测结果和这两个<strong>anchor box</strong>关联起来</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2e357b5b92122660c550dcfb0901519c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2e357b5b92122660c550dcfb0901519c.png" alt></a></p><p>定义类别标签：</p><script type="math/tex; mode=display">y= \begin{bmatrix} p_{c} & b_{x} & b_{y} &b_{h} & b_{w} & c_{1} & c_{2} & c_{3} & p_{c} & b_{x} & b_{y} & b_{h} & b_{w} &c_{1} & c_{2} & c_{3} \end{bmatrix}^{T}</script><p>前面的<script type="math/tex">p_{c},b_{x},b_{y},b_{h},b_{w},c_{1},c_{2},c_{3}</script>（绿色方框标记的参数）是和<strong>anchor box 1</strong>关联的8个参数，后面的8个参数（橙色方框标记的元素）是和<strong>anchor box 2</strong>相关联</p><p>行人：<script type="math/tex">p_{c}= 1,b_{x},b_{y},b_{h},b_{w},c_{1} = 1,c_{2} = 0,c_{3} = 0</script></p><p>车子的边界框更像<strong>anchor box 2</strong>，(<script type="math/tex">p_{c}= 1,b_{x},b_{y},b_{h},b_{w},c_{1} = 0,c_{2} = 1,c_{3} = 0</script>)</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e94aa7ea75300ea4692682b179834bb4.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e94aa7ea75300ea4692682b179834bb4.png" alt></a></p><p>现在每个对象都分配到对象中点所在的格子中，以及分配到和对象形状交并比最高的<strong>anchor box</strong>中。然后观察哪个<strong>anchor box</strong>和实际边界框（编号1，红色框）的交并比更高</p><p>编号1对应同时有车和行人，编号3对应只有车：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/322b15fe615c739ebd1d36b669748618.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/322b15fe615c739ebd1d36b669748618.png" alt></a>:</p><p><strong>anchor box</strong>是为了处理两个对象出现在同一个格子的情况，实践中这种情况很少发生，特别用的是19×19网格</p><p>怎么选择<strong>anchor box：</strong></p><ul><li>一般手工指定<strong>anchor box</strong>形状，可以选择5到10个<strong>anchor box</strong>形状，覆盖到想要检测的对象的各种形状</li><li>更高级的是使用<strong>k-平均算法</strong>，将两类对象形状聚类，选择最具有代表性的一组<strong>anchor box</strong></li></ul><h2 id="3-9-YOLO-算法（Putting-it-together-YOLO-algorithm）"><a href="#3-9-YOLO-算法（Putting-it-together-YOLO-algorithm）" class="headerlink" title="3.9 YOLO 算法（Putting it together: YOLO algorithm）"></a>3.9 YOLO 算法（Putting it together: YOLO algorithm）</h2><p>假设要在图片中检测行人、汽车，同时使用两种不同的Anchor box</p><p><strong>训练集：</strong></p><ul><li>输入X：同样大小的完整图片</li><li><p>目标Y：使用<script type="math/tex">3\times3</script>网格划分，输出大小<script type="math/tex">3\times3\times2\times8</script>，或者<script type="math/tex">3\times3\times16</script></p></li><li><p>对不同格子中的小图，定义目标输出向量Y</p></li></ul><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/36ff927836cfcd7fee9413e2d34757d8.png" alt></a></p><p>编号2目标向量<script type="math/tex">y =\begin{bmatrix} 0 & ? & ? & ? & ? & ? & ? & ? & 1 & b_{x} & b_{y} & b_{h} &b_{w} & 0 & 1 & 0 \end{bmatrix}^{T}</script>，假设训练集中对于车子有一个边界框（编号3），水平方向更长一点，红框和<strong>anchor box 2</strong>的交并比更高，车子和向量的下半部分相关</p><p><strong>模型预测：</strong></p><p>输入与训练集中相同大小的图片，然后训练一个卷积网络，遍历9个格子，得到每个格子中不同的输出结果：<script type="math/tex">3\times3\times2\times8</script></p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e23084f4a75246f08ea4cedef55f60ab.png" alt></a></p><p><strong>运行非最大值抑制（NMS）：</strong></p><ol><li>假设使用了2个Anchor box，每一个网格都会得到预测输出的2个bounding boxes，其中一个<script type="math/tex">P_{c}</script>比较高</li><li>抛弃概率<script type="math/tex">P_{c}</script>值低的预测bounding boxes</li><li>对每个对象分别使用NMS算法得到最终的预测边界框</li></ol><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/23256c4b7b28d62d34a744f5fb5e9c3b.png" alt></a></p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/66f8cf8e55eadc1ac01f773515bfbc45.png" alt></a></p><p>如果有三个对象检测类别，希望检测行人，汽车和摩托车：对于每个类别单独运行非极大值抑制，处理预测结果所属类别的边界框，用非极大值抑制来处理行人类别、车子类别、摩托车类别，运行三次来得到最终的预测结果</p><h2 id="3-10-候选区域（选修）（Region-proposals-Optional-）"><a href="#3-10-候选区域（选修）（Region-proposals-Optional-）" class="headerlink" title="3.10 候选区域（选修）（Region proposals (Optional)）"></a>3.10 候选区域（选修）（Region proposals (Optional)）</h2><p>滑动窗法会对原始图片的每个区域都进行扫描，即使是一些空白的或明显没有目标的区域，这样会降低算法运行效率，耗费时间</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/838a6aeb35865f9cfecac8dc593b565b.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/838a6aeb35865f9cfecac8dc593b565b.png" alt></a></p><p><strong>R-CNN</strong>算法，即带区域的卷积网络，或者带区域的<strong>CNN</strong>。这个算法尝试选出一些区域，在少数窗口上运行卷积网络分类器</p><p>选出候选区域的方法是运行图像分割算法，找出各个尺度的色块，然后在色块上运行分类器，即首先得到候选区域，然后再分类</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e78e4465af892d0965e2b0863263ef8c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e78e4465af892d0965e2b0863263ef8c.png" alt></a></p><p><strong>R-CNN</strong>算法很慢，基本的<strong>R-CNN</strong>算法是使用某种算法求出候选区域，然后对每个候选区域运行一下分类器，每个区域会输出一个标签，有没有车子、行人、摩托车？并输出一个边界框，就能在确实存在对象的区域得到一个精确的边界框</p><p><strong>R-CNN</strong>算法不会直接信任输入的边界框，也会输出一个边界框<script type="math/tex">b_{x}</script>，<script type="math/tex">b_{y}</script>，<script type="math/tex">b_{h}</script>和<script type="math/tex">b_{w}</script>，这样得到的边界框比较精确，比单纯使用图像分割算法给出的色块边界要好</p><p><strong>Fast R-CNN</strong>算法基本上是<strong>R-CNN</strong>算法，最初的算法是逐一对区域分类，快速<strong>R-CNN</strong>用的是滑动窗法的一个卷积实现，和<strong>3.4 卷积的滑动窗口实现</strong>的相似，显著提升了<strong>R-CNN</strong>的速度，问题是得到候选区域的聚类步骤仍然非常缓慢</p><p>更快的<strong>R-CNN</strong>算法（<strong>Faster R-CNN</strong>），使用的是卷积神经网络，而不是更传统的分割算法来获得候选区域色块，比<strong>Fast R-CNN</strong>算法快得多</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e6ed1aa3263107d4e189dd75adc060b4.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e6ed1aa3263107d4e189dd75adc060b4.png" alt></a></p><p>不过大多数更快<strong>R-CNN</strong>的算法实现还是比<strong>YOLO</strong>算法慢很多</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;3-1-目标定位（Object-localization）&quot;&gt;&lt;a href=&quot;#3-1-目标定位（Object-localization）&quot; class=&quot;headerlink&quot; title=&quot;3.1 目标定位（Object localization）&quot;&gt;&lt;/a&gt;3.1 目标定位（Object localization）&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0107af10b33fcb955cc3c588dfb78d49.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0107af10b33fcb955cc3c588dfb78d49.png&quot; alt&gt;&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）(Course 4)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E4%BA%8C%E5%91%A8-%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6%EF%BC%88Deep-convolutional-models-case-studies%EF%BC%89-Course-4/"/>
    <id>https://baozouai.com/2019/02/28/第二周-深度卷积网络：实例探究（Deep-convolutional-models-case-studies）-Course-4/</id>
    <published>2019-02-27T21:54:00.000Z</published>
    <updated>2019-02-27T06:24:06.999Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-1-经典网络（Classic-networks）"><a href="#2-1-经典网络（Classic-networks）" class="headerlink" title="2.1 经典网络（Classic networks）"></a>2.1 经典网络（Classic networks）</h2><h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p><strong>LeNet-5</strong>可以识别图中的手写数字，是针对灰度图片训练的，所以图片的大小只有32×32×1。该LeNet模型总共包含了大约6万个参数，典型的LeNet-5结构包含CONV layer，POOL layer和FC layer，顺序一般是CONV layer-&gt;POOL layer-&gt;CONV layer-&gt;POOL layer-&gt;FC layer-&gt;FC layer-&gt;OUTPUT layer，即<script type="math/tex">\hat y</script>：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5e59b38c9b2942a407b49da84677dae9.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5e59b38c9b2942a407b49da84677dae9.png" alt></a><br><a id="more"></a><br>随着网络越来越深，图像的高度和宽度在缩小，从最初的32×32缩小到28×28，再到14×14、10×10，最后只有5×5，通道数量一直在增加，从1增加到6个，再到16个</p><p>这个神经网络中还有一种模式就是一个或多个卷积层后面跟着一个池化层，然后又是若干个卷积层再接一个池化层，然后是全连接层，最后是输出</p><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p><strong>AlexNet</strong>包含约6000万个参数。当用于训练图像和数据集时，<strong>AlexNet</strong>能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，<strong>AlexNet</strong>比<strong>LeNet</strong>表现更为出色的另一个原因是它使用了<strong>ReLu</strong>激活函数</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/92575493ecd20003b0b76ac51de0efbb.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/92575493ecd20003b0b76ac51de0efbb.png" alt></a></p><h2 id="VGG-16"><a href="#VGG-16" class="headerlink" title="VGG-16"></a>VGG-16</h2><p><strong>VGG</strong>，也叫作<strong>VGG-16</strong>网络。<strong>VGG-16</strong>网络没有那么多超参数，是一种只需要专注于构建卷积层的简单网络。首先用3×3，步幅为1的过滤器构建卷积层，<strong>padding</strong>参数为<strong>same</strong>卷积中的参数。然后用一个2×2，步幅为2的过滤器构建最大池化层。<strong>VGG</strong>网络的一大优点是简化了神经网络结构</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a645bff2623ba6f30f01fbc6e3149484.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a645bff2623ba6f30f01fbc6e3149484.png" alt></a></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/781ddc74bcc8da430c99b196d0c4c6d4.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/781ddc74bcc8da430c99b196d0c4c6d4.png" alt></a></p><p>假设要识别这个图像，在最开始的两层用64个3×3的过滤器对输入图像进行卷积，输出结果是224×224×64，因为使用了<strong>same</strong>卷积，通道数量也一样</p><p>接下来创建一个池化层，池化层将输入图像进行压缩，减少到112×112×64。然后又是若干个卷积层，使用128个过滤器，以及一些<strong>same</strong>卷积，输出112×112×128。然后进行池化，池化后的结果是56×56×128。再用256个相同的过滤器进行三次卷积操作，然后再池化，然后再卷积三次，再池化。如此进行几轮操作后，将最后得到的7×7×512的特征图进行全连接操作，得到4096个单元，然后进行<strong>softmax</strong>激活，输出从1000个对象中识别的结果</p><p><img src="/images/pasted-149.png" alt="upload successful"></p><p><strong>VGG-16</strong>的数字16指在这个网络中有13个卷积层和3个全链接层</p><p><img src="/images/pasted-150.png" alt="upload successful"></p><p>总共包含约1.38亿个参数，这种网络结构很规整，都是几个卷积层后面跟着可以压缩图像大小的池化层，池化层缩小图像的高度和宽度。同时，卷积层的过滤器数量变化存在一定的规律，由64翻倍变成128，再到256和512。主要缺点是需要训练的特征数量非常巨大</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0a29aeae65a311c56675ad8f1fec2824.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0a29aeae65a311c56675ad8f1fec2824.png" alt></a></p><p>随着网络的加深，图像的高度和宽度都在以一定的规律不断缩小，每次池化后刚好缩小一半，而通道数量在不断增加，而且刚好也是在每组卷积操作后增加一倍。即图像缩小的比例和通道数增加的比例是有规律的</p><h2 id="2-2-残差网络（Residual-Networks-ResNets-）"><a href="#2-2-残差网络（Residual-Networks-ResNets-）" class="headerlink" title="2.2 残差网络（Residual Networks (ResNets)）"></a>2.2 残差网络（Residual Networks (ResNets)）</h2><p>人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系，这种神经网络被称为<strong>Residual Networks(ResNets)</strong></p><p>Residual Networks由许多隔层相连的神经元子模块组成，称之为Residual block（残差块）。单个Residual block的结构如下图所示：</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f0a8471f869d8062ba59598c418da7fb.png" alt></a></p><p>紫色线是skip connection（跳跃连接），直接建立<script type="math/tex">a^{[l]}</script>与<script type="math/tex">a^{[l+2]}</script>之间的隔层联系。相应的表达式如下：</p><script type="math/tex; mode=display">z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}</script><script type="math/tex; mode=display">a^{[l+1]}=g(z^{[l+1]})</script><script type="math/tex; mode=display">z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}</script><script type="math/tex; mode=display">a^{[l+2]}=g(z^{[l+2]}+a^{[l]})</script><p>$a^{[l]}$直接隔层与下一层的线性输出相连，<script type="math/tex">a^{[l]}</script>插入的时机是在线性激活之后，<strong>ReLU</strong>激活之前，与<script type="math/tex">z^{[l+2]}</script>共同通过激活函数（ReLU）输出<script type="math/tex">a^{[l+2]}</script></p><p>这种模型结构对于训练非常深的神经网络效果很好。非Residual Networks称为Plain Network</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/131e538bb527859430280becd65b049b.png" alt></a></p><blockquote><p>Residual Network的结构</p></blockquote><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/48bded15cca17581084e3fe0853673b5.png" alt></a></p><blockquote><p>Plain Network</p></blockquote><p>与Plain Network相比，Residual Network能够训练更深层的神经网络，有效避免发生发生梯度消失和梯度爆炸</p><ul><li>随着神经网络层数增加，Plain Network实际性能会变差，training error甚至会变大</li><li>Residual Network的训练效果却很好，training error一直呈下降趋势</li></ul><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6077958a616425d76284cecb43c2f458.png" alt></a></p><h2 id="2-3-残差网络为什么有用？（Why-ResNets-work-）"><a href="#2-3-残差网络为什么有用？（Why-ResNets-work-）" class="headerlink" title="2.3 残差网络为什么有用？（Why ResNets work?）"></a>2.3 残差网络为什么有用？（Why ResNets work?）</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e1106db40c78c2e384305d6474c40d69.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e1106db40c78c2e384305d6474c40d69.png" alt></a></p><p>输入<script type="math/tex">X</script> 经过一个大型神经网络输出激活值<script type="math/tex">a^{[l]}</script>，再给这个网络额外添加两层作为一个<strong>ResNets</strong>块，输出<script type="math/tex">a^{\left\lbrack l + 2 \right\rbrack}</script>：</p><script type="math/tex; mode=display">a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})</script><p>假设在整个网络中使用<strong>ReLU</strong>激活函数，所以激活值都大于等于0，包括输入<script type="math/tex">X</script>的非零异常值。因为<strong>ReLU</strong>激活函数输出的数字要么是0，要么是正数</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f60f5ca514d4bad1288fc7cbd666dd99.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f60f5ca514d4bad1288fc7cbd666dd99.png" alt></a></p><p>如果使用L2正则化或权重衰减，会压缩<script type="math/tex">W^{\left\lbrack l + 2\right\rbrack}</script>的值。<script type="math/tex">W</script>是关键项，如果<script type="math/tex">W^{\left\lbrack l + 2 \right\rbrack} = 0</script>，方便起见，假设<script type="math/tex">b^{\left\lbrack l + 2 \right\rbrack} = 0</script>，假定使用ReLU激活函数，并且所有激活值都是非负的，<script type="math/tex">g\left(a^{[l]} \right)</script>是应用于非负数的ReLU函数，所以<script type="math/tex">a^{[l+2]} =a^{[l]}</script></p><p>可以看出，即使发生了梯度消失，<script type="math/tex">W^{[l+2]}\approx0</script>，<script type="math/tex">b^{[l+2]}\approx0</script>，也能直接建立<script type="math/tex">a^{[l+2]}</script>与<script type="math/tex">a^{[l]}</script>的线性关系，且<script type="math/tex">a^{[l+2]}=a^{[l]}</script>，这就是identity function（恒等函数）。<script type="math/tex">a^{[l]}</script>直接连到<script type="math/tex">a^{[l+2]}</script>，相当于直接忽略了<script type="math/tex">a^{[l]}</script>之后的这两层神经层。这样看似很深的神经网络，由于许多Residual blocks的存在，弱化削减了某些神经层之间的联系，实现隔层线性传递，而不是一味追求非线性关系，模型本身也就能“容忍”更深层的神经网络了。从性能上来说，这两层额外的Residual blocks也不会降低Big NN的性能，所以给大型神经网络增加两层，不论是把残差块添加到神经网络的中间还是末端位置，都不会影响网络的表现</p><p>如果Residual blocks确实能训练得到非线性关系，那么也会忽略short cut，跟Plain Network起到同样的效果</p><p>如果Residual blocks中<script type="math/tex">a^{[l+2]}</script>与<script type="math/tex">a^{[l]}</script>的维度不同，可以引入矩阵<script type="math/tex">W_s</script>与<script type="math/tex">a^{[l]}</script>相乘，使得<script type="math/tex">W_s*a^{[l]}</script>的维度与<script type="math/tex">a^{[l+2]}</script>一致</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/cefcaece17927e14eb488cb52d99aaef.png" alt></a></p><p>参数矩阵<script type="math/tex">W_s</script>有来两种方法得到：</p><ul><li>将<script type="math/tex">W_s</script>作为学习参数，通过模型训练得到</li><li>固定<script type="math/tex">W_s</script>值（类似单位矩阵），不需要训练，<script type="math/tex">W_s</script>与<script type="math/tex">a^{[l]}</script>的乘积仅使得<script type="math/tex">a^{[l]}</script>截断或者补零</li></ul><p>CNN中ResNets的结构：</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/70062fa97916ab79c7ad37282ba1a5f4.png" alt></a></p><p>ResNets同类型层之间，例如CONV layers，大多使用same类型，这也解释了添加项<script type="math/tex">z^{[l+2]}+a^{[l]}</script>（维度相同所以能够相加）。如果是不同类型层之间的连接，例如CONV layer与POOL layer之间，如果维度不同，则引入矩阵<script type="math/tex">W_s</script></p><h2 id="2-4-网络中的网络以及-1×1-卷积（Network-in-Network-and-1×1-convolutions）"><a href="#2-4-网络中的网络以及-1×1-卷积（Network-in-Network-and-1×1-convolutions）" class="headerlink" title="2.4 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）"></a>2.4 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）</h2><p>如果是一张6×6×32的图片，使用1×1过滤器进行卷积效果更好。1×1卷积所实现的功能是遍历这36个单元格，计算左图中32个数字和过滤器中32个数字的元素积之和，然后应用<strong>ReLU</strong>非线性函数</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/7522d4cbc42b7db1c5a05bc461106590.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/7522d4cbc42b7db1c5a05bc461106590.png" alt></a></p><p>1×1×32过滤器中的32个数字可以理解为一个神经元的输入是32个数字，这32个数字具有不同通道，乘以32个权重（将过滤器中的32个数理解为权重），然后应用<strong>ReLU</strong>非线性函数，输出相应的结果</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f97e6c31c2b27a2d4ef9610b8f32b335.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f97e6c31c2b27a2d4ef9610b8f32b335.png" alt></a></p><p>如果过滤器是多个，就好像有多个输入单元，其输入内容为一个切片上所有数字，输出结果是6×6×#filters</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/70eba35d0705dc681c40f09a0926061a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/70eba35d0705dc681c40f09a0926061a.png" alt></a></p><p>1×1卷积可以从根本上理解为对这32个不同的位置都应用一个全连接层，全连接层的作用是输入32个数字（过滤器数量标记为<script type="math/tex">n\_{C}^{\left\lbrack l + 1\right\rbrack}</script>，在这36个单元上重复此过程）,输出结果是6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（<strong>non-trivial</strong>）计算</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/46698c486da9ae184532d773716c77e9.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/46698c486da9ae184532d773716c77e9.png" alt></a></p><p>这种方法通常称为1×1卷积，也被称为<strong>Network in Network</strong></p><p>假设一个28×28×192的输入层，如果通道数量很大，可以用32个大小为1×1×192的过滤器，使输出层为28×28×32，这就是压缩通道数（<script type="math/tex">n_{C}</script>）的方法</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/49a16fdc10769a86355911f9e324c728.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/49a16fdc10769a86355911f9e324c728.png" alt></a></p><p>如果想保持通道数192不变，也是可行的，1×1卷积只是添加了非线性函数，也可以让网络学习更复杂的函数</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/70f3b26fe86c3ec2507b8bb85be8d30c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/70f3b26fe86c3ec2507b8bb85be8d30c.png" alt></a></p><p>1×1卷积层给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，也可以增加通道数量</p><h2 id="2-5-谷歌-Inception-网络简介（Inception-network-motivation）"><a href="#2-5-谷歌-Inception-网络简介（Inception-network-motivation）" class="headerlink" title="2.5 谷歌 Inception 网络简介（Inception network motivation）"></a>2.5 谷歌 Inception 网络简介（Inception network motivation）</h2><p><strong>Inception</strong>网络或<strong>Inception</strong>层的作用是代替人工来确定卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/99f8fc7dbe7cd0726f5271aae11b9872.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/99f8fc7dbe7cd0726f5271aae11b9872.png" alt></a></p><p>基本思想是<strong>Inception</strong>网络在单层网络上可以使用多个不同尺寸的filters，进行same convolutions，把各filter下得到的输出拼接起来。还可以将CONV layer与POOL layer混合，同时实现各种效果，但是要注意使用same pool。Inception Network不需要人为决定使用哪个过滤器或者是否需要池化，它使用不同尺寸的filters并将CONV和POOL混合起来，将所有功能输出组合拼接，再由神经网络本身去学习参数并选择最好的模块</p><p>Inception Network在提升性能的同时，会带来计算量大的问题：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/27894eae037f4fd859d33ebdda1cac9a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/27894eae037f4fd859d33ebdda1cac9a.png" alt></a></p><p>乘法运算的总次数为每个输出值所需要执行的乘法运算次数（5×5×192）乘以输出值个数（28×28×32），结果等于1.2亿。</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5b3df2904b9d8dc51bd99ccb45ac9f5b.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5b3df2904b9d8dc51bd99ccb45ac9f5b.png" alt></a></p><p>为此，引入1x1 Convolutions来减少计算量，对于输入层，使用1×1卷积把输入值从192个通道减少到16个通道。然后对这个较小层运行5×5卷积，得到最终输出</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/1fec66d984a3c8c47ff459775d411e71.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1fec66d984a3c8c47ff459775d411e71.png" alt></a></p><p>把该1x1 Convolution称为“瓶颈层”（bottleneck layer），瓶颈层是网络中最小的部分，即先缩小网络，然后再扩大</p><p>引入bottleneck layer之后，第一个卷积层计算成本：1×1×192×输出28×28×16，相乘结果约等于240万，第二个卷积层的计算成本是：28×28×32×5×5×16，计算结果为1000万，总次数是1204万，计算成本从1.2亿下降到了原来的十分之一</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/7d160f6eab22e4b9544b28b44da686a6.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/7d160f6eab22e4b9544b28b44da686a6.png" alt></a></p><p>总结：</p><ul><li>如果在构建神经网络层的时候，不想决定池化层是使用1×1，3×3还是5×5的过滤器，<strong>Inception</strong>模块是最好的选择。可以应用各种类型的过滤器，只需要把输出连接起来</li><li>计算成本问题，通过使用1×1卷积来构建瓶颈层，大大降低计算成本</li></ul><p>只要合理构建瓶颈层，既可以显著缩小表示层规模，又不会降低网络性能，从而节省了计算</p><h2 id="2-6-Inception-网络（Inception-network）"><a href="#2-6-Inception-网络（Inception-network）" class="headerlink" title="2.6 Inception 网络（Inception network）"></a>2.6 Inception 网络（Inception network）</h2><p>引入1x1 Convolution后的Inception module如下图所示：</p><p><img src="/images/pasted-151.png" alt="upload successful"></p><p><strong>Inception</strong>模块会将之前层的激活或者输出作为它的输入，为了能在最后将这些输出都连接起来，会使用<strong>same</strong>类型的<strong>padding</strong>来池化，使得输出的高和宽依然是28×28，这样才能将它与其他输出连接起来。如果进行了最大池化，即便用了<strong>same padding</strong>，3×3的过滤器，<strong>stride</strong>为1，其输出将会是28×28×192，其通道数与输入（通道数）相同。要做的是再加上一个1×1的卷积层，将通道的数量缩小到28×28×32，避免了最后输出时，池化层占据所有的通道</p><p>最后把得到的各个层的通道都加起来，得到一个28×28×256的输出。这就是一个<strong>Inception</strong>模块</p><p><strong>Inception</strong>网络只是很多在不同的位置重复组成的网络：</p><p><img src="/images/pasted-152.png" alt="upload successful"></p><p>中间隐藏层也可以作为输出层Softmax，确保了即便是隐藏单元和中间层也参与了特征计算，也能预测图片的分类，起到一种调整的效果，有利于防止发生过拟合</p><h2 id="2-7-迁移学习（Transfer-Learning）"><a href="#2-7-迁移学习（Transfer-Learning）" class="headerlink" title="2.7 迁移学习（Transfer Learning）"></a>2.7 迁移学习（Transfer Learning）</h2><p>训练集很小的情况：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8f0e69f085991cfc74726983418f6569.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8f0e69f085991cfc74726983418f6569.png" alt></a></p><p>建议：从网上下载一些神经网络开源的实现，不仅把代码下载下来，也把权重下载下来。然后去掉<strong>Softmax</strong>层，创建自己的<strong>Softmax</strong>单元，用来输出<strong>Tigger</strong>、<strong>Misty</strong>和<strong>neither</strong>三个类别。把所有的层看作是冻结的，冻结网络中所有层的参数，只需要训练和<strong>Softmax</strong>层有关的参数。这个<strong>Softmax</strong>层有三种可能的输出，<strong>Tigger</strong>、<strong>Misty</strong>或者<strong>Neither</strong>。</p><p>通过使用其他人预训练的权重，很可能得到很好的性能，即使只有一个小的数据集。大多数深度学习框架会有<code>trainableParameter=0</code>的参数，对于前面的层，可以设置这个参数。为了不训练这些权重，会有<code>freeze=1</code>的参数。只需要训练<strong>softmax</strong>层的权重，把前面这些层的权重都冻结</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ac520bf9e9facfc026db46b187b513bd.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ac520bf9e9facfc026db46b187b513bd.png" alt></a></p><p>由于前面的层都冻结了，相当于一个固定的函数，因此不需要改变和训练它，取输入图像<script type="math/tex">X</script>，然后把它映射到<strong>softmax</strong>前一层的激活函数。能加速训练的技巧是如果先计算这一层（紫色箭头标记），计算特征或者激活值，然后把它们存到硬盘里。所做的就是用这个固定的函数，在这个神经网络的前半部分（<strong>softmax</strong>层之前的所有层视为一个固定映射），取任意输入图像<script type="math/tex">X</script>，然后计算它的某个特征向量，这样训练的就是一个很浅的<strong>softmax</strong>模型，用这个特征向量来做预测。对计算有用的一步就是对训练集中所有样本的这一层的激活值进行预计算，然后存储到硬盘里，在此之上训练<strong>softmax</strong>分类器。存储到硬盘或者说预计算方法的优点是不需要每次遍历训练集再重新计算这个激活值</p><p>更大的训练集：应该冻结更少的层，然后训练后面的层。如果输出层的类别不同，那么需要构建自己的输出单元，<strong>Tigger</strong>、<strong>Misty</strong>或者<strong>Neither</strong>三个类别。可以取后面几层的权重，用作初始化，然后从这里开始梯度下降</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e7079af956d884d6184c4bde62271175.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e7079af956d884d6184c4bde62271175.png" alt></a></p><p>也可以直接去掉这几层，换成自己的隐藏单元和<strong>softmax</strong>输出层，如果有越来越多的数据，那么需要冻结的层数就越少，能够训练的层数就越多。如果有一个更大的数据集，那么不要单单训练一个<strong>softmax</strong>单元，而是考虑训练中等大小的网络，包含最终要用的网络的后面几层</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/7cf0e18b739684106548cbbf0c1dd500.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/7cf0e18b739684106548cbbf0c1dd500.png" alt></a></p><p>如果有大量数据：应该做的就是用开源的网络和它的权重，把所有的权重当作初始化，然后训练整个网络</p><p>如果有越多的标定的数据，可以训练越多的层。极端情况下，可以用下载的权重只作为初始化，用它们来代替随机初始化，接着用梯度下降训练，更新网络所有层的所有权重</p><h2 id="2-8-数据扩充（Data-augmentation）"><a href="#2-8-数据扩充（Data-augmentation）" class="headerlink" title="2.8 数据扩充（Data augmentation）"></a>2.8 数据扩充（Data augmentation）</h2><p>当下计算机视觉的主要问题是没有办法得到充足的数据</p><p>最简单的数据扩充方法就是垂直镜像对称</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f92337ae2e50a0896d42d45cc7951e43.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f92337ae2e50a0896d42d45cc7951e43.png" alt></a></p><p>另一个经常使用的技巧是随机裁剪，给定一个数据集，然后开始随机裁剪，得到不同的图片放在数据集中，随机裁剪并不是一个完美的数据扩充的方法，如果随机裁剪的那一部分（红色方框标记部分，编号4）看起来不像猫。但在实践中，这个方法还是很实用的，随机裁剪构成了很大一部分的真实图片</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/709aa552b6a5f4715620047bacf64753.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/709aa552b6a5f4715620047bacf64753.png" alt></a></p><p>也可以使用旋转，剪切（仅水平或垂直坐标发生变化）图像，扭曲变形，引入很多形式的局部弯曲等等，但在实践中太复杂所以使用的很少</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e7e2d497b751f798e77e1b040ebbf358.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e7e2d497b751f798e77e1b040ebbf358.png" alt></a></p><p>彩色转换：给<strong>R</strong>、<strong>G</strong>和<strong>B</strong>三个通道上加上不同的失真值</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a5bcde6f0d2c2326be700c0ca441c934.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a5bcde6f0d2c2326be700c0ca441c934.png" alt></a></p><p>实践中对<strong>R</strong>、<strong>G</strong>和<strong>B</strong>的变化是基于某些分布，改变可能很小，<strong>R</strong>、<strong>G</strong>和<strong>B</strong>的值是根据某种概率分布来决定，这样会使得学习算法对照片的颜色更改更具鲁棒性</p><p>对<strong>R、G和B</strong>有不同的采样方式，其中一种影响颜色失真的算法是<strong>PCA</strong>，即主成分分析，<strong>PCA</strong>颜色增强的大概含义是，如果图片呈现紫色，即主要含有红色和蓝色，绿色很少，然后<strong>PCA</strong>颜色增强算法就会对红色和蓝色增减很多，绿色变化相对少一点，所以使总体的颜色保持一致</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d69cfc9648f3a37eede074bd28c74c0d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d69cfc9648f3a37eede074bd28c74c0d.png" alt></a></p><p>如果有特别大的训练数据，可以使用<strong>CPU</strong>线程，不停的从硬盘中读取数据，用<strong>CPU</strong>线程来实现失真变形，可以是随机裁剪、颜色变化，或者是镜像</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2d9b9ca15ce25598d229470494d796ee.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2d9b9ca15ce25598d229470494d796ee.png" alt></a></p><p>同时<strong>CPU</strong>线程持续加载数据，然后实现任意失真变形，从而构成批数据或者最小批数据，这些数据持续的传输给其他线程或者其他的进程，然后开始训练，可以在<strong>CPU</strong>或者<strong>GPU</strong>上实现一个大型网络的训练</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5ee17d350497cb8cf52881f14cb0d9e8.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5ee17d350497cb8cf52881f14cb0d9e8.png" alt></a></p><p>常用的实现数据扩充的方法是使用一个线程或者是多线程来加载数据，实现变形失真，然后传给其他的线程或者其他进程，来训练编号2和这个编号1，可以并行实现</p><p>在数据扩充过程中也有一些超参数，比如说颜色变化了多少，以及随机裁剪的时候使用的参数</p><h2 id="2-9-计算机视觉现状（The-state-of-computer-vision）"><a href="#2-9-计算机视觉现状（The-state-of-computer-vision）" class="headerlink" title="2.9 计算机视觉现状（The state of computer vision）"></a>2.9 计算机视觉现状（The state of computer vision）</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/7e51335f705120b35fa4ed5444ec5cda.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/7e51335f705120b35fa4ed5444ec5cda.png" alt></a></p><p>大部分机器学习问题是介于少量数据和大量数据范围之间的。</p><ul><li>语音识别有很大数量的数据</li><li>虽然现在图像识别或图像分类方面有相当大的数据集，但因为图像识别是一个复杂的问题，通过分析像素并识别出它是什么，即使在线数据集非常大，如超过一百万张图片，仍然希望能有更多的数据</li><li>物体检测拥有的数据更少</li><li>图像识别是如何看图片的问题，并且告诉你这张图是不是猫，而对象检测则是看一幅图，画一个框，告诉你图片里的物体，比如汽车等等。因为获取边框的成本比标记对象的成本更高，所以进行对象检测的数据往往比图像识别数据要少</li></ul><p>当有很多数据时，倾向于使用更简单的算法和更少的手工工程，只要有一个大型的神经网络，甚至一个更简单的架构，就可以去学习它想学习的东西</p><p>当没有那么多的数据时，更多的是手工工程</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e6701cf4129576648941bfd593a13c77.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e6701cf4129576648941bfd593a13c77.png" alt></a></p><p>对机器学习应用时，通常学习算法有两种知识来源：</p><ul><li>一个来源是被标记的数据，像<script type="math/tex">(x,y)</script>应用在监督学习</li><li>第二个来源是手工工程，有很多方法去建立一个手工工程系统，它可以是源于精心设计的特征，手工精心设计的网络体系结构或者是系统的其他组件。当没有太多标签数据时，只需要更多地考虑手工工程</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/c87f6cc9ec9c45ad57a049b6baf0b86d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c87f6cc9ec9c45ad57a049b6baf0b86d.png" alt></a></p><p>在基准研究和比赛中，下面的tips可能会有较好的表现：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0d0a3e182ddb9e995af3c6a68c7a72eb.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0d0a3e182ddb9e995af3c6a68c7a72eb.png" alt></a></p><ul><li>集成，意味着想好了要的神经网络之后，可以独立训练几个神经网络，并平均它们的输出。比如说随机初始化三个、五个或者七个神经网络，然后训练所有这些网络，对输出<script type="math/tex">\hat y</script>进行平均计算，而不要平均权重，可能会在基准上提高1%，2%或者更好。但因为集成意味着要对每张图片进行测试，可能需要在从3到15个不同的网络中运行一个图像，会让运行时间变慢</li><li><strong>Multi-crop at test time</strong>，<strong>Multi-crop</strong>是一种将数据扩充应用到测试图像中的一种形式，在测试图片的多种版本上运行分类器，输出平均结果</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6027faa79b81f9940281ea36ca901504.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6027faa79b81f9940281ea36ca901504.png" alt></a></p><p>如把猫的图片复制四遍，包括两个镜像版本。如取中心的<strong>crop</strong>，然后取四个角落的<strong>crop，</strong>通过分类器来运行它</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/fbb8d5acae8a02c366cea92000577d62.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/fbb8d5acae8a02c366cea92000577d62.png" alt></a></p><p>编号1和编号3是中心<strong>crop</strong>，编号2和编号4是四个角落的<strong>crop</strong>。把这些加起来会有10种不同的图像的<strong>crop</strong>，命名为<strong>10-crop</strong>。通过分类器来运行这十张图片，然后对结果进行平均</p><p>集成的一个大问题是需要保持所有这些不同的神经网络，占用了更多的计算机内存。<strong>multi-crop</strong>，只保留一个网络，不会占用太多的内存，但仍然会让运行时间变慢</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2-1-经典网络（Classic-networks）&quot;&gt;&lt;a href=&quot;#2-1-经典网络（Classic-networks）&quot; class=&quot;headerlink&quot; title=&quot;2.1 经典网络（Classic networks）&quot;&gt;&lt;/a&gt;2.1 经典网络（Classic networks）&lt;/h2&gt;&lt;h3 id=&quot;LeNet-5&quot;&gt;&lt;a href=&quot;#LeNet-5&quot; class=&quot;headerlink&quot; title=&quot;LeNet-5&quot;&gt;&lt;/a&gt;LeNet-5&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;LeNet-5&lt;/strong&gt;可以识别图中的手写数字，是针对灰度图片训练的，所以图片的大小只有32×32×1。该LeNet模型总共包含了大约6万个参数，典型的LeNet-5结构包含CONV layer，POOL layer和FC layer，顺序一般是CONV layer-&amp;gt;POOL layer-&amp;gt;CONV layer-&amp;gt;POOL layer-&amp;gt;FC layer-&amp;gt;FC layer-&amp;gt;OUTPUT layer，即&lt;script type=&quot;math/tex&quot;&gt;\hat y&lt;/script&gt;：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5e59b38c9b2942a407b49da84677dae9.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5e59b38c9b2942a407b49da84677dae9.png&quot; alt&gt;&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习Z" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Z/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第一周 卷积神经网络（Foundations of Convolutional Neural Networks）(Course 4)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E4%B8%80%E5%91%A8-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88Foundations-of-Convolutional-Neural-Networks%EF%BC%89-Course-4/"/>
    <id>https://baozouai.com/2019/02/28/第一周-卷积神经网络（Foundations-of-Convolutional-Neural-Networks）-Course-4/</id>
    <published>2019-02-27T21:43:00.000Z</published>
    <updated>2019-02-27T07:20:10.348Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-1-计算机视觉（Computer-vision）"><a href="#1-1-计算机视觉（Computer-vision）" class="headerlink" title="1.1 计算机视觉（Computer vision）"></a>1.1 计算机视觉（Computer vision）</h2><p>图片分类，或图片识别：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/373615de4e30035c662958ce39115fb4.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/373615de4e30035c662958ce39115fb4.png" alt></a><br><a id="more"></a><br>目标检测：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f8ff84bc95636d9e37e35daef5149164.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f8ff84bc95636d9e37e35daef5149164.png" alt></a></p><p>神经网络实现图片风格迁移：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/bf57536975bce32f78c9e66a2360e8a1.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/bf57536975bce32f78c9e66a2360e8a1.png" alt></a></p><p>使用传统神经网络处理机器视觉的一个主要问题是输入层维度很大。例如一张64x64x3的图片，神经网络输入层的维度为12288。如果图片尺寸较大，例如一张1000x1000x3的图片，神经网络输入层的维度将达到3百万，使得网络权重W非常庞大。这样会造成两个后果，一是神经网络结构复杂，数据量相对不够，容易出现过拟合；二是所需内存、计算量较大。解决这一问题的方法就是使用卷积神经网络（CNN）。</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f126bca19d15f113c0f0371fdf0833d8.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f126bca19d15f113c0f0371fdf0833d8.png" alt></a></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/9dc51757210398f26ec96d13540beacb.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/9dc51757210398f26ec96d13540beacb.png" alt></a></p><h2 id="1-2边缘检测示例（Edge-detection-example）"><a href="#1-2边缘检测示例（Edge-detection-example）" class="headerlink" title="1.2边缘检测示例（Edge detection example）"></a>1.2边缘检测示例（Edge detection example）</h2><p>对于CV问题，神经网络由浅层到深层，分别可以检测出图片的边缘特征 、局部特征（例如眼睛、鼻子等）、整体面部轮廓</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a4b8429a41f31afb14adaa9204f98c66.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a4b8429a41f31afb14adaa9204f98c66.png" alt></a></p><h2 id="图片的边缘检测"><a href="#图片的边缘检测" class="headerlink" title="图片的边缘检测"></a>图片的边缘检测</h2><p>最常检测的图片边缘有两类：一是<strong>垂直边缘（vertical edges）</strong>，二是<strong>水平边缘（horizontal edges）</strong></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/47c14f666d56e509a6863e826502bda2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/47c14f666d56e509a6863e826502bda2.png" alt></a></p><p>图片的边缘检测可以通过与相应滤波器进行卷积来实现。以垂直边缘检测为例，原始图片尺寸为6x6，滤波器filter尺寸为3x3，卷积后的图片尺寸为4x4，得到结果如下：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5f9c10d0986f003e5bd6fa87a9ffe04b.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5f9c10d0986f003e5bd6fa87a9ffe04b.png" alt></a></p><p>∗表示卷积操作。python中，卷积用conv_forward()表示；tensorflow中，卷积用tf.nn.conv2d()表示；keras中，卷积用Conv2D()表示</p><p>垂直边缘是一个3×3的区域，左边是明亮的像素，中间的并不需要考虑，右边是深色像素。在这个6×6图像的中间部分，明亮的像素在左边，深色的像素在右边，就被视为一个垂直边缘</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0c8b5b8441557b671431d515aefa1e8a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0c8b5b8441557b671431d515aefa1e8a.png" alt></a></p><h2 id="1-3-更多边缘检测内容（More-edge-detection）"><a href="#1-3-更多边缘检测内容（More-edge-detection）" class="headerlink" title="1.3 更多边缘检测内容（More edge detection）"></a>1.3 更多边缘检测内容（More edge detection）</h2><p>图片边缘有两种渐变方式，一种是由明变暗，另一种是由暗变明。实际应用中，这两种渐变方式并不影响边缘检测结果，可以对输出图片取绝对值操作，得到同样的结果</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/783267536976c27544bbe36ac758a48e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/783267536976c27544bbe36ac758a48e.png" alt></a></p><blockquote><p>由亮向暗</p></blockquote><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6a248e5698d1f61ac4ba0238363c4a37.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6a248e5698d1f61ac4ba0238363c4a37.png" alt></a></p><blockquote><p>由暗向亮</p></blockquote><p>下图的垂直边缘过滤器是一个3×3的区域，左边相对较亮，右边相对较暗。右图的水平边缘过滤器也是一个3×3的区域，上边相对较亮，而下方相对较暗</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/199323db1d4858ef2463f34323e1d85f.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/199323db1d4858ef2463f34323e1d85f.png" alt></a></p><p>30（右边矩阵中绿色方框标记元素）代表了左边这块3×3的区域（左边矩阵绿色方框标记部分），这块区域是上边比较亮，下边比较暗，所以它在这里发现了一条正边缘。而-30（右边矩阵中紫色方框标记元素）代表了左边另一块区域（左边矩阵紫色方框标记部分），这块区域是底部比较亮，而上边则比较暗，所以在这里它是一条负边</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/eb8668010205b08fbcbcde7c2bb1fee2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/eb8668010205b08fbcbcde7c2bb1fee2.png" alt></a></p><p>10（右边矩阵中黄色方框标记元素）代表的是左边这块区域（左边6×6矩阵中黄色方框标记的部分）。这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这是一个非常大的1000×1000大图，就不会出现亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小</p><p>对于这个3×3的过滤器来说，使用了其中的一种数字组合：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/20cea5b23b32153fe2a8b8707ef21b6f.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/20cea5b23b32153fe2a8b8707ef21b6f.png" alt></a></p><p>还可以使用这种：</p><script type="math/tex; mode=display">\begin{bmatrix}1 & 0 & - 1 \\ 2 & 0 & - 2 \\ 1 & 0 & - 1 \end{bmatrix}</script><p>叫做<strong>Sobel</strong>过滤器，优点在于增加了中间一行元素的权重，使得结果的鲁棒性会更高一些</p><p>或者：</p><script type="math/tex; mode=display">\begin{bmatrix} 3& 0 & - 3 \\ 10 & 0 & - 10 \\ 3 & 0 & - 3 \end{bmatrix}</script><p>叫做<strong>Scharr过滤器</strong>，也是一种垂直边缘检测，如果将其翻转90度，就能得到对应水平边缘检测</p><p>随着深度学习的发展，如果想检测图片的各种边缘特征，而不仅限于垂直边缘和水平边缘，那么filter的数值一般需要通过模型训练得到，将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，类似于标准神经网络中的权重<script type="math/tex">W</script>一样由梯度下降算法反复迭代求得，会发现神经网络可以学习一些低级的特征，例如这些边缘的特征。CNN的主要目的就是计算出这些filter的数值，确定得到了这些filter后，CNN浅层网络也就实现了对图片所有边缘特征的检测</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f889ad7011738a23d78070e8ed2df04e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f889ad7011738a23d78070e8ed2df04e.png" alt></a></p><h2 id="1-4-Padding"><a href="#1-4-Padding" class="headerlink" title="1.4 Padding"></a>1.4 Padding</h2><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d21e2642815d03b15396f7998ba4459a.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d21e2642815d03b15396f7998ba4459a.png" alt></a></p><p>如果有一个<script type="math/tex">n\times n</script>的图像，用<script type="math/tex">f\times f</script>的过滤器做卷积，输出的维度就是<script type="math/tex">(n-f+1)\times (n-f+1)</script></p><p>这样的话会有两个缺点:</p><ul><li>每次做卷积操作，<strong>输出图片尺寸缩小</strong></li><li><strong>原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息</strong></li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/170e076ceaeb70339baa7b25ad5f5e6c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/170e076ceaeb70339baa7b25ad5f5e6c.png" alt></a></p><blockquote><p>角落边缘的像素（绿色阴影标记）只被一个输出所触碰或者使用，中间的像素点（红色方框标记）会有许多3×3的区域与之重叠。角落或者边缘区域的像素点在输出中采用较少，丢掉了图像边缘位置的许多信息</p></blockquote><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/208104bae9256fba5d8e37e22a9f5408.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/208104bae9256fba5d8e37e22a9f5408.png" alt></a></p><p>可以在卷积操作之前填充这幅图像。沿着图像边缘再填充一层像素,6×6的图像填充成8×8的图像。就得到了一个尺寸和原始图像6×6的图像。习惯上，可以用0去填充，如果<script type="math/tex">p</script>是填充的数量，输出也就变成了<script type="math/tex">(n+2p-f+1)\times (n+2p-f+1)</script>。涂绿的像素点（左边矩阵）影响了输出中的这些格子（右边矩阵）。这样角落或图像边缘的信息发挥的作用较小的这一缺点就被削弱了</p><p>选择填充多少像素，通常有两个选择，分别叫做<strong>Valid</strong>卷积和<strong>Same</strong>卷积</p><p><strong>Valid</strong>卷积意味着不填充，如果有一个<script type="math/tex">n\times n</script>的图像，用一个<script type="math/tex">f\times f</script>的过滤器卷积，会给一个<script type="math/tex">(n-f+1)\times (n-f+1)</script>维的输出</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/0663e1a9e477e2737067d9e79194208d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/0663e1a9e477e2737067d9e79194208d.png" alt></a></p><p>另一个叫做<strong>Same</strong>卷积，填充后输出大小和输入大小是一样的。由<script type="math/tex">n-f+1</script>，当填充<script type="math/tex">p</script>个像素点，<script type="math/tex">n</script>就变成了<script type="math/tex">n+2p</script>，公式变为：</p><script type="math/tex; mode=display">n+2p-f+1</script><p>即：</p><script type="math/tex; mode=display">p=\frac{f-1}{2}</script><p>当<script type="math/tex">f</script>是一个奇数，只要选择相应的填充尺寸就能确保得到和输入相同尺寸的输出</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ca5382358f30c1349fff98d1e52366b4.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ca5382358f30c1349fff98d1e52366b4.png" alt></a></p><p>计算机视觉中，<script type="math/tex">f</script>通常是奇数，有两个原因：</p><ul><li>如果<script type="math/tex">f</script>是偶数，只能使用一些不对称填充</li><li>当有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点，便于指出过滤器的位置</li></ul><h2 id="1-5-卷积步长（Strided-convolutions）"><a href="#1-5-卷积步长（Strided-convolutions）" class="headerlink" title="1.5 卷积步长（Strided convolutions）"></a>1.5 卷积步长（Strided convolutions）</h2><p>Stride表示filter在原图片中水平方向和垂直方向每次的步进长度。之前默认stride=1。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次</p><p><img src="/images/pasted-141.png" alt="upload successful"></p><p>用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为：</p><script type="math/tex; mode=display">\lfloor\frac{n+2p-f}{s}+1\rfloor\ \times\ \lfloor\frac{n+2p-f}{s}+1\rfloor</script><p>真正的卷积运算会先将filter绕其中心旋转180度，然后再将旋转后的filter在原始图片上进行滑动计算。filter旋转如下所示：</p><p><img src="/images/pasted-142.png" alt="upload successful"></p><p>相关系数的计算过程则不会对filter进行旋转，而是直接在原始图片上进行滑动计算</p><p>目前为止介绍的CNN卷积实际上计算的是相关系数，而不是数学意义上的卷积。为了简化计算，一般把CNN中的这种“相关系数”就称作卷积运算。之所以可以这么等效，是因为滤波器算子一般是水平或垂直对称的，180度旋转影响不大；而且最终滤波器算子需要通过CNN网络梯度下降算法计算得到，旋转部分可以看作是包含在CNN模型算法中。忽略旋转运算可以大大提高CNN网络运算速度，而且不影响模型性能。</p><p>卷积运算服从分配律：</p><script type="math/tex; mode=display">(A*B)*C=A*(B*C)</script><h2 id="1-6三维卷积（Convolutions-over-volumes）"><a href="#1-6三维卷积（Convolutions-over-volumes）" class="headerlink" title="1.6三维卷积（Convolutions over volumes）"></a>1.6三维卷积（Convolutions over volumes）</h2><p>3通道的RGB图片对应的滤波器算子也是3通道的。例如一个图片是6 x 6 x 3，分别表示图片的高度（height）、宽度（weight）和通道（#channel）</p><p>3通道图片的卷积运算与单通道图片的卷积运算基本一致。过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/9b0b0e9062f8814a6a462ea64449f89e.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/9b0b0e9062f8814a6a462ea64449f89e.png" alt></a></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2fd0c97947a3e8222e78d550a317366d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2fd0c97947a3e8222e78d550a317366d.png" alt></a></p><p>不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d088cafb50cabd6837d95c03c953e920.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d088cafb50cabd6837d95c03c953e920.png" alt></a></p><p>为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。做完卷积，然后把这两个4×4的输出堆叠在一起，第一个放到前面，第二个放到后面，就得到一个4×4×2的输出立方体</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/794b25829ae809f93ac69f81eee79cd1.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/794b25829ae809f93ac69f81eee79cd1.png" alt></a></p><p>不同滤波器组卷积得到不同的输出，个数由滤波器组决定</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/d590398749e3f5f3ac230ab25116c4b7.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/d590398749e3f5f3ac230ab25116c4b7.png" alt></a></p><p>若输入图片的尺寸为n x n x<script type="math/tex">n_c</script>，filter尺寸为f x f x <script type="math/tex">n_c</script>，则卷积后的图片尺寸为(n-f+1) x (n-f+1) x <script type="math/tex">{n}'_c</script>(默认padding为1）。<script type="math/tex">n_c</script>为图片通道数目，<script type="math/tex">{n}'_c</script>为滤波器组个数</p><h2 id="1-7单层卷积网络（One-layer-of-a-convolutional-network）"><a href="#1-7单层卷积网络（One-layer-of-a-convolutional-network）" class="headerlink" title="1.7单层卷积网络（One layer of a convolutional network）"></a>1.7单层卷积网络（One layer of a convolutional network）</h2><p>卷积神经网络的单层结构如下所示：</p><p><img src="/images/pasted-143.png" alt="upload successful"></p><p>相比之前的卷积过程，CNN的单层结构多了激活函数<script type="math/tex">ReLU</script>和偏移量<script type="math/tex">b</script>。整个过程与标准的神经网络单层结构非常类似：</p><script type="math/tex; mode=display">Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}</script><script type="math/tex; mode=display">A^{[l]}=g^{[l]}(Z^{[l]})</script><p>卷积运算对应着上式中的乘积运算，滤波器组数值对应着权重<script type="math/tex">W^{[l]}</script>，所选的激活函数为<script type="math/tex">ReLU</script></p><p>每个滤波器组有3x3x3=27个参数，还有1个偏移量<script type="math/tex">b</script>，则每个滤波器组有27+1=28个参数，两个滤波器组总共包含28x2=56个参数。选定滤波器组后，参数数目与输入图片尺寸无关。所以不存在由于图片尺寸过大，造成参数过多的情况，这就是卷积神经网络的一个特征，叫作“<strong>避免过拟合</strong>”。例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，参数数目只由滤波器组决定，数目相对来说要少得多，这是CNN的优势之一</p><p>设层数为<script type="math/tex">l</script>，CNN单层结构的所有标记符号：</p><ul><li><script type="math/tex">f^{[l]}</script><strong>= filter size</strong></li><li><script type="math/tex">p^{[l]}</script><strong>= padding</strong></li><li><script type="math/tex">s^{[l]}</script><strong>= stride</strong></li><li><script type="math/tex">n_c^{[l]}</script><strong>= number of filters</strong></li></ul><p>输入维度为：<script type="math/tex">n_H^{[l-1]}\times n_W^{[l-1]}\times n_c^{[l-1]}</script>，因为是上一层的激活值<br>每个滤波器组维度为：<script type="math/tex">f^{[l]}\times f^{[l]}\times n_c^{[l-1]}</script></p><p>权重维度为：<script type="math/tex">f^{[l]}\times f^{[l]}\times n_c^{[l-1]}\times n_c^{[l]}</script></p><p>偏置维度为：<script type="math/tex">1 \times 1\times 1 \times n_c^{[l]}</script></p><p>输出维度为：<script type="math/tex">n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}</script></p><p>其中：</p><script type="math/tex; mode=display">n_H^{[l]}=\lfloor \frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor</script><script type="math/tex; mode=display">n_W^{[l]}=\lfloor \frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor</script><p>如果有<script type="math/tex">m</script>个样本，进行向量化运算，相应的输出维度为：</p><script type="math/tex; mode=display">m \times n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}</script><h2 id="1-8-简单卷积网络示例（A-simple-convolution-network-example）"><a href="#1-8-简单卷积网络示例（A-simple-convolution-network-example）" class="headerlink" title="1.8 简单卷积网络示例（A simple convolution network example）"></a>1.8 简单卷积网络示例（A simple convolution network example）</h2><p>简单的CNN网络模型：</p><p><img src="/images/pasted-144.png" alt="upload successful"></p><script type="math/tex; mode=display">a^{[3]}$$的维度是7 x 7 x 40，将$$a^{[3]}$$排列成1列，维度为1960 x 1，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出$$\hat y</script><p>随着CNN层数增加，<script type="math/tex">n_H^{[l]}</script>和<script type="math/tex">n_W^{[l]}</script>一般逐渐减小，而<script type="math/tex">n_c^{[l]}</script>一般逐渐增大</p><p>CNN有三种类型的layer：</p><ul><li><p><strong>Convolution层（CONV）</strong></p></li><li><p><strong>Pooling层（POOL）</strong></p></li><li><p><strong>Fully connected层（FC）</strong></p></li></ul><p>CONV最为常见也最重要</p><h2 id="1-9-池化层（Pooling-layers）"><a href="#1-9-池化层（Pooling-layers）" class="headerlink" title="1.9 池化层（Pooling layers）"></a>1.9 池化层（Pooling layers）</h2><p>Pooling layers是CNN中用来减小尺寸，提高运算速度的，同样能减小noise影响，让各特征更具有健壮性</p><p>Pooling layers没有卷积运算，仅在滤波器算子滑动区域内取最大值，即max pooling，这是最常用的做法。超参数p很少在pooling layers中使用</p><p><img src="/images/pasted-145.png" alt="upload successful"></p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a800c70b250dc43b7003aaeebb4eefc2.png" alt></a></p><p>Max pooling的好处是只保留区域内的最大值（特征），数字大意味着可能探测到了某些特定的特征，忽略了其它值，降低了noise影响，提高了模型健壮性。max pooling需要的超参数仅为滤波器尺寸f和滤波器步进长度s，没有其他参数需要模型训练得到，计算量很小</p><p>如果是多个通道，每个通道单独进行max pooling操作：</p><p><a href="https://legacy.gitbook.com/book/baozou/neural-networks-and-deep-learning/edit#" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c225755635059449e2a9a84135e2548e.png" alt></a></p><p>average pooling是在滤波器算子滑动区域计算平均值：</p><p><img src="/images/pasted-146.png" alt="upload successful"><br>实际应用中，max pooling比average pooling更为常用，也有例外，深度很深的神经网络可以用平均池化来分解规模为7×7×1000的网络的表示层，在整个空间内求平均值，得到1×1×1000</p><p>总结：</p><p>池化的超级参数包括过滤器大小<script type="math/tex">f</script>和步幅<script type="math/tex">s</script>，常用的参数值为<script type="math/tex">f=2</script>，<script type="math/tex">s=2</script>，应用频率非常高，其效果相当于高度和宽度缩减一半。最大池化时，往往很少用到超参数<strong>padding</strong>，<script type="math/tex">p</script>最常用的值是0，即<script type="math/tex">p=0</script>。最大池化的输入就是：</p><script type="math/tex; mode=display">n_{H} \times n_{W} \times n_{c}</script><p>假设没有<strong>padding</strong>，则输出：</p><script type="math/tex; mode=display">\lfloor\frac{n_{H} - f}{s} +1\rfloor \times \lfloor\frac{n_{w} - f}{s} + 1\rfloor \times n_{c}</script><p>输入通道与输出通道个数相同，因为对每个通道都做了池化。最大池化只是计算神经网络某一层的静态属性，池化过程中没有需要学习的参数。执行反向传播时，反向传播没有参数适用于最大池化</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6bd58a754152e7f5cf55a8c5bbac3100.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6bd58a754152e7f5cf55a8c5bbac3100.png" alt></a></p><h2 id="1-10-卷积神经网络示例（Convolutional-neural-network-example）"><a href="#1-10-卷积神经网络示例（Convolutional-neural-network-example）" class="headerlink" title="1.10 卷积神经网络示例（Convolutional neural network example）"></a>1.10 卷积神经网络示例（Convolutional neural network example）</h2><p>简单的数字识别CNN例子：</p><p><img src="/images/pasted-147.png" alt="upload successful"></p><p>CONV层后面紧接一个POOL层，CONV1和POOL1构成第一层，CONV2和POOL2构成第二层。FC3和FC4为全连接层FC，跟标准的神经网络结构一致。最后的输出层（softmax）由10个神经元构成</p><p>整个网络各层的尺寸和参数如下表格所示：</p><p><img src="/images/pasted-148.png" alt="upload successful"></p><p>池化层和最大池化层没有参数；卷积层的参数相对较少，许多参数都存在于神经网络的全连接层。随着神经网络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能</p><p>尽量不要自己设置超参数，而是查看文献中别人采用了哪些超参数，选一个在别人任务中效果很好的架构，也可能适用于自己的应用程序</p><p>在神经网络中，另一种常见模式就是一个或多个卷积后面跟随一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个<strong>softmax</strong></p><h2 id="1-11-为什么使用卷积？（Why-convolutions-）"><a href="#1-11-为什么使用卷积？（Why-convolutions-）" class="headerlink" title="1.11 为什么使用卷积？（Why convolutions?）"></a>1.11 为什么使用卷积？（Why convolutions?）</h2><p>和只用全连接层相比，卷积层的两个主要优势在于参数共享和稀疏连接</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/beedba9de67752b61ad0eede899eb4de.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/beedba9de67752b61ad0eede899eb4de.png" alt></a></p><p>如果这是一张1000×1000的图片，权重矩阵会变得非常大。而卷积层的参数数量：每个过滤器都是5×5，一个过滤器有25个参数，再加上偏差参数，那么每个过滤器就有26个参数，一共有6个过滤器，所以参数共计156个，参数数量很少</p><p>卷积网络映射这么少参数有两个原因：</p><ul><li><strong>参数共享：一个特征检测器（例如垂直边缘检测）对图片某块区域有用，同时也可能作用在图片其它区域。</strong></li></ul><p>特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。如果用一个3×3的过滤器检测垂直边缘，那么图片的左上角区域，以及旁边的各个区域（左边矩阵中蓝色方框标记的部分）都可以使用这个3×3的过滤器。每个特征检测器以及输出都可以在输入图片的不同区域中使用同样的参数，以便提取垂直边缘或其它特征。它不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征，例如提取脸上的眼睛，猫或者其他特征对象。即使减少参数个数，这9个参数同样能计算出16个输出。直观感觉是，一个特征检测器，如垂直边缘检测器用于检测图片左上角区域的特征，这个特征很可能也适用于图片的右下角区域。因此在计算图片左上角和右下角区域时，不需要添加其它特征检测器</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/dad50972904bcd2131657db7798595b7.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/dad50972904bcd2131657db7798595b7.png" alt></a></p><ul><li><strong>连接的稀疏性：因为滤波器算子尺寸限制，每一层的每个输出只与输入部分区域内有关</strong></li></ul><p>右边输出单元（元素0）仅与36个输入特征中9个相连接。其它像素值都不会对输出产生任何影响，输出（右边矩阵中红色标记的元素 30）仅仅依赖于这9个特征（左边矩阵红色方框标记的区域），只有这9个输入特征与输出相连接，其它像素对输出没有任何影响</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/7503372ab986cd3aedda7674bedfd5f0.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/7503372ab986cd3aedda7674bedfd5f0.png" alt></a></p><p>神经网络可以通过这两种机制减少参数，以便用更小的训练集来训练它，从而预防过拟合。CNN比较擅长捕捉区域位置偏移，也就是说CNN进行物体检测时，不太受物体所处图片位置的影响，增加检测的准确性和系统的健壮性。通过观察可以发现，向右移动两个像素，图片中的猫依然清晰可见，因为神经网络的卷积结构使得即使移动几个像素，这张图片依然具有非常相似的特征，应该属于同样的输出标记</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/8fd4c61773f0245c87871de14f0a2d03.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8fd4c61773f0245c87871de14f0a2d03.png" alt></a></p><p>最后，把这些层整合起来，比如要构建一个猫咪检测器，<script type="math/tex">x</script>表示一张图片，<script type="math/tex">\hat{y}</script>是二进制标记或某个重要标记。选定一个卷积神经网络，输入图片，增加卷积层和池化层，然后添加全连接层，并随机初始化参数<script type="math/tex">w</script>和<script type="math/tex">b</script>，最后输出一个<strong>softmax</strong>，即<script type="math/tex">\hat{y}</script>，代价函数<script type="math/tex">J</script>等于神经网络对整个训练集的预测的损失总和再除以<script type="math/tex">m</script>（即<script type="math/tex">\text{Cost} J = \frac{1}{m}\sum_{i = 1}^{m}{L(\hat{y}^{(i)},y^{(i)})}</script>）。所以训练神经网络，要做的就是使用梯度下降法，或其它算法，例如<strong>Momentum</strong>梯度下降法，含<strong>RMSProp</strong>或其它因子的梯度下降来优化神经网络中所有参数，以减少代价函数<script type="math/tex">J</script>的值</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-1-计算机视觉（Computer-vision）&quot;&gt;&lt;a href=&quot;#1-1-计算机视觉（Computer-vision）&quot; class=&quot;headerlink&quot; title=&quot;1.1 计算机视觉（Computer vision）&quot;&gt;&lt;/a&gt;1.1 计算机视觉（Computer vision）&lt;/h2&gt;&lt;p&gt;图片分类，或图片识别：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/373615de4e30035c662958ce39115fb4.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/373615de4e30035c662958ce39115fb4.png&quot; alt&gt;&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第二周：机器学习策略（2）(ML Strategy (2))(Course 3)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89-ML-Strategy-2-Course-2/"/>
    <id>https://baozouai.com/2019/02/28/第二周：机器学习策略（2）-ML-Strategy-2-Course-2/</id>
    <published>2019-02-27T21:08:00.000Z</published>
    <updated>2019-02-27T05:40:50.062Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-1-进行误差分析（Carrying-out-error-analysis）"><a href="#2-1-进行误差分析（Carrying-out-error-analysis）" class="headerlink" title="2.1 进行误差分析（Carrying out error analysis）"></a>2.1 进行误差分析（Carrying out error analysis）</h2><p>如果希望让学习算法能够胜任人类能做的任务，但学习算法还没有达到人类的表现，那么人工检查一下算法犯的错误可以了解接下来应该做什么，这个过程称为<strong>错误分析</strong><br><a id="more"></a><br>假设正在调试猫分类器，取得了90%准确率，相当于10%错误，注意到算法将一些狗分类为猫，需要对模型的一些部分做相应调整，才能更好地提升分类的精度</p><p><img src="/images/pasted-119.png" alt="upload successful"></p><p><strong>收集错误样例</strong>：</p><p>在开发集（测试集）中，获取大约100个错误标记的例子，然后手动检查，一次只看一个，看看开发集里有多少错误标记的样本是狗</p><ul><li>100个数据中有5个样例是狗，如果对数据集的错误标记做努力去改进模型的精度，可以提升的上限是5%，仅可以达到9.5%的错误率，称为性能上限（ceiling on performance）。<br>这种情况下，这样耗时的努力方向不是很值得的事</li><li>100个数据中，有50多个样例是狗，改进数据集的错误标记是一个值得的改进方向，可以将模型的精确度提升至95</li></ul><p><strong>并行分析</strong>：</p><ul><li>修改那些被分类成猫的狗狗图片标签</li><li>修改那些被错误分类的大型猫科动物，如：狮子，豹子等</li><li>提升模糊图片的质量</li></ul><p><img src="/images/pasted-120.png" alt="upload successful"></p><p>为了并行的分析，可以建立表格来进行。在最左边，人工过一遍想分析的图像集，电子表格的每一列对应要评估的想法，如狗的问题，猫科动物的问题，模糊图像的问题，最后一列写评论</p><p><img src="/images/pasted-121.png" alt="upload successful"></p><p>在这个步骤做到一半时，可能会发现其他错误类型，比如可能发现有Instagram滤镜，那些花哨的图像滤镜，干扰了分类器。在这种情况下可以在错误分析途中，增加一列多色滤镜 Instagram滤镜和Snapchat滤镜，再过一遍，并确定新的错误类型百分比，这个分析步骤的结果可以给出一个估计，是否值得去处理每个不同的错误类型</p><p><img src="/images/pasted-122.png" alt="upload successful"></p><p>可以把团队可以分成两个团队，其中一个改善大猫的识别，另一个改善模糊图片的识别</p><p><strong>总结：</strong></p><p>进行错误分析，应该找一组错误样本，可能在开发集或者测试集，观察错误标记的样本，看看<strong>假阳性（false positives）</strong>和<strong>假阴性（false negatives）</strong>，统计属于不同错误类型的错误数量。在这个过程中，可能会得到启发，归纳出新的错误类型，通过统计不同错误标记类型的百分比，可以发现哪些问题需要优先解决</p><h2 id="2-2-清楚标注错误的数据（Cleaning-up-Incorrectly-labeled-data）"><a href="#2-2-清楚标注错误的数据（Cleaning-up-Incorrectly-labeled-data）" class="headerlink" title="2.2 清楚标注错误的数据（Cleaning up Incorrectly labeled data）"></a>2.2 清楚标注错误的数据（Cleaning up Incorrectly labeled data）</h2><p>监督学习问题的数据由输入<script type="math/tex">x</script>和输出标签<script type="math/tex">y</script> 构成，如果发现有些输出标签 <script type="math/tex">y</script> 是错的，是否值得花时间去修正这些标签？</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/56f907e76f4fc8f589f1930128f77a98.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/56f907e76f4fc8f589f1930128f77a98.png" alt></a></p><p>倒数第二不是猫，是标记错误的样本。“标记错误的样本”表示学习算法输出了错误的 <script type="math/tex">y</script> 值，如果数据有一些标记错误的样本，该怎么办？</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a9cd24c7602100aaa8fb69eb03a3c47c.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a9cd24c7602100aaa8fb69eb03a3c47c.png" alt></a></p><p>训练集：深度学习算法对于训练集中的随机错误是相当健壮的（<strong>robust</strong>）。只要这些错误样本离随机错误不太远，有时可能做标记的人没有注意或者不小心，按错键了，如果错误足够随机，放着这些错误不管可能也没问题，而不要花太多时间修复它们，只要总数据集足够大，实际错误率可能不会太高</p><p>深度学习算法对随机误差很健壮，但对系统性的错误没那么健壮。如果做标记的人一直把白色的狗标记成猫，那就成问题。因为分类器学习之后，会把所有白色的狗都分类为猫。但随机错误或近似随机错误，对于大多数深度学习算法来说不成问题</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e5c7f1005d695914f4a2fc988aa46821.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e5c7f1005d695914f4a2fc988aa46821.png" alt></a></p><p>开发集和测试集有标记出错的样本：在错误分析时，添加一个额外的列，统计标签 <script type="math/tex">y=1</script>错误的样本数。统计因为标签错误所占的百分比，解释为什么学习算法做出和数据集的标记不一样的预测1</p><p>是否值得修正6%标记出错的样本：</p><ul><li>如果标记错误严重影响了在开发集上评估算法的能力，应该去花时间修正错误的标签</li><li>如果没有严重影响到用开发集评估成本偏差的能力，不应该花时间去处理</li></ul><p>看3个数字来确定是否值得去人工修正标记出错的数据：</p><ul><li>看整体的开发集错误率，系统达到了90%整体准确度，10%错误率，应该看错误标记引起的错误的数量或者百分比。6％的错误来自标记出错，10%的6%是0.6%，剩下的占9.4%，是其他原因导致的，比如把狗误认为猫，大猫图片。即有9.4%错误率需要集中精力修正，而标记出错导致的错误是总体错误的一小部分而已，应该看其他原因导致的错误</li><li>错误率降到了2％，但总体错误中的0.6%还是标记出错导致的。修正开发集里的错误标签更有价值</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/fc5d8fbd1124120e01fc4287896faa44.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/fc5d8fbd1124120e01fc4287896faa44.png" alt></a></p><p>开发集的主要目的是从两个分类器<script type="math/tex">A</script>和<script type="math/tex">B</script>中选择一个。当测试两个分类器<script type="math/tex">A</script>和<script type="math/tex">B</script>时，在开发集上一个有2.1%错误率，另一个有1.9%错误率，但是不能再信任开发集，因为它无法告诉你这个分类器是否比这个好，因为0.6%的错误率是标记出错导致的。现在就有很好的理由去修正开发集里的错误标签，因为右边这个样本标记出错对算法错误的整体评估标准有严重的影响，而左边相对较小</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/08c2b44a5718781eb81fe4d0a2bccdde.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/08c2b44a5718781eb81fe4d0a2bccdde.png" alt></a></p><p>如果决定要去修正开发集数据，手动重新检查标签，并尝试修正一些标签，这里还有一些额外的方针和原则需要考虑：</p><ul><li>不管用什么修正手段，都要同时作用到开发集和测试集上，开发和测试集必须来自相同的分布。开发集确定了目标，当击中目标后，希望算法能够推广到测试集上，这样能够更高效的在来自同一分布的开发集和测试集上迭代</li><li>如果打算修正开发集上的部分数据，最好也对测试集做同样的修正以确保它们继续来自相同的分布。可以让一个人来仔细检查这些标签，但必须同时检查开发集和测试集</li><li>要同时检验算法判断正确和判断错误的样本，如果只修正算法出错的样本，算法的偏差估计可能会变大，会让算法有一点不公平的优势</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/9d5b710121594f5a1e1bc5e901be52a8.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/9d5b710121594f5a1e1bc5e901be52a8.png" alt></a></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/55478871edfd7d384494967008c96972.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/55478871edfd7d384494967008c96972.png" alt></a></p><p>修正训练集中的标签相对没那么重要，如果训练集来自稍微不同的分布，对于这种情况学习算法其实相当健壮，通常是一件很合理的事情</p><p>几个建议：</p><ul><li>构造实际系统时，需要更多的人工错误分析，更多的人类见解来架构这些系统</li><li>搭建机器学习系统时，花时间亲自检查数据非常值得，可以帮你找到需要优先处理的任务，然后确定应该优先尝试哪些想法，或者哪些方向</li></ul><h2 id="2-3-快速搭建你的第一个系统，并进行迭代（Build-your-first-system-quickly-then-iterate）"><a href="#2-3-快速搭建你的第一个系统，并进行迭代（Build-your-first-system-quickly-then-iterate）" class="headerlink" title="2.3 快速搭建你的第一个系统，并进行迭代（Build your first system quickly, then iterate）"></a>2.3 快速搭建你的第一个系统，并进行迭代（Build your first system quickly, then iterate）</h2><p>如果正在开发全新的机器学习应用，应该尽快建立第一个系统原型，然后快速迭代</p><p>改进语音识别系统特定的技术:</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/9a5fd355b0d3a39a021ded507178343d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/9a5fd355b0d3a39a021ded507178343d.png" alt></a></p><p>对于几乎所有的机器学习程序可能会有50个不同的方向可以前进，并且每个方向都是相对合理的可以改善系统。但挑战在于如何选择一个方向集中精力处理。如果想搭建全新的机器学习程序，就是快速搭好第一个系统，然后开始迭代。首先快速设立开发集和测试集还有指标，决定目标所在，如果目标定错，之后改也可以。但一定要设立某个目标，然后马上搭好一个机器学习系统原型，找到训练集训练一下，看算法表现如何，在开发集测试集，评估指标表现如何。当建立第一个系统后，就可以马上用到偏差方差分析和错误分析，来确定下一步优先做什么。如果错误分析到大部分的错误来源是说话人远离麦克风，就有很好的理由去集中精力研究这些技术，所谓远场语音识别的技术，就是处理说话人离麦克风很远的情况</p><p>建立初始系统所有意义：是一个快速和粗糙的实现（<strong>quick and dirty implementation</strong>），有一个学习过的系统，有一个训练过的系统，确定偏差方差的范围，知道下一步应该优先做什么，能够进行错误分析，观察一些错误，然后想出所有能走的方向，哪些是实际上最有希望的方向</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/4307a97cb4f2e2d6abc7b8ff28b0ca87.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/4307a97cb4f2e2d6abc7b8ff28b0ca87.png" alt></a></p><p>当这个领域有很多可以借鉴的学术文献，处理的问题和要解决的几乎完全相同，比如人脸识别有很多学术文献，如果搭建一个人脸识别设备，可以从现有大量学术文献为基础出发，一开始就搭建比较复杂的系统。但如果第一次处理某个新问题，还是构建一些快速而粗糙的实现，然后用来找到改善系统要优先处理的方向</p><p><img src="/images/pasted-123.png" alt="upload successful"></p><h2 id="2-4-在不同的划分上进行训练并测试（Training-and-testing-on-different-distributions）"><a href="#2-4-在不同的划分上进行训练并测试（Training-and-testing-on-different-distributions）" class="headerlink" title="2.4 在不同的划分上进行训练并测试（Training and testing on different distributions）"></a>2.4 在不同的划分上进行训练并测试（Training and testing on different distributions）</h2><h3 id="猫咪识别"><a href="#猫咪识别" class="headerlink" title="猫咪识别"></a>猫咪识别</h3><p>假设只收集到10,000张用户上传的照片和超过20万张网上下载的高清猫图：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/9a6cbca750b289408a25789e224aeefc.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/9a6cbca750b289408a25789e224aeefc.png" alt></a></p><p><strong>做法一</strong>：将两组数据合并在一起，把这21万张照片随机分配到训练、开发和测试集中。假设已经确定开发集和测试集各包含2500个样本，训练集有205000个样本。</p><ul><li>好处：训练集、开发集和测试集都来自同一分布</li><li>坏处：开发集的2500个样本中很多图片都来自网页下载的图片，并不是真正关心的数据分布，因为真正要处理的是来自手机的图片</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/9a6cbca750b289408a25789e224aeefc.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/9a6cbca750b289408a25789e224aeefc.png" alt></a></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/57c4cad6f0df4dc06ecf90c4f2d81a68.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/57c4cad6f0df4dc06ecf90c4f2d81a68.png" alt></a></p><p>2500个样本有<script type="math/tex">2500\times \frac{200k}{210k} =2381</script>张图来自网页下载，平均只有119张图来自手机上传。设立开发集的目的是告诉团队去瞄准的目标，而瞄准目标的大部分精力却都用在优化来自网页下载的图片</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/eb0178687dedc450e1c184b958adeef3.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/eb0178687dedc450e1c184b958adeef3.png" alt></a></p><p>建议：开发集和测试集都是2500张来自应用的图片，训练集包含来自网页的20万张图片还有5000张来自应用的图片，现在瞄准的目标就是想要处理的目标，才是真正关心的图片分布</p><h3 id="语音激活后视镜"><a href="#语音激活后视镜" class="headerlink" title="语音激活后视镜"></a>语音激活后视镜</h3><p>假设有很多不是来自语音激活后视镜的数据</p><p>分配：</p><ul><li>训练集500k段语音，开发集和测试集各包含10k段语音（从实际的语音激活后视镜收集）</li><li>也可以拿一半放训练集里，训练集51万段语音，开发集和测试集各5000</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ca34742f5f0b19239de5779dc80ad4d9.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ca34742f5f0b19239de5779dc80ad4d9.png" alt></a></p><p><img src="/images/pasted-124.png" alt="upload successful"></p><p><img src="/images/pasted-125.png" alt="upload successful"></p><h2 id="2-5-不匹配数据划分的偏差和方差（Bias-and-Variance-with-mismatched-data-distributions）"><a href="#2-5-不匹配数据划分的偏差和方差（Bias-and-Variance-with-mismatched-data-distributions）" class="headerlink" title="2.5 不匹配数据划分的偏差和方差（Bias and Variance with mismatched data distributions）"></a>2.5 不匹配数据划分的偏差和方差（Bias and Variance with mismatched data distributions）</h2><p>当训练集和开发集、测试集不同分布时，分析偏差和方差的方式：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5cbede5222b199f84dc491e0550435b6.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5cbede5222b199f84dc491e0550435b6.png" alt></a></p><p>分析的问题在于，当看训练误差，再看开发误差，有两件事变了，很难确认这增加的9%误差率有多少是因为：</p><ul><li>算法只见过训练集数据，没见过开发集数据（方差）</li><li>开发集数据来自不同的分布</li></ul><p>为了弄清楚哪个因素影响更大，定义一组新的数据，称之为<strong>训练-开发集</strong>，是一个新的数据子集。从训练集的分布里分出来，但不会用来训练网络</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/66fcfec7152b504adb2e6124291f4a68.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/66fcfec7152b504adb2e6124291f4a68.png" alt></a></p><p>随机打散训练集，分出一部分训练集作为训练-开发集（training-dev），训练集、训练-开发集来自同一分布</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/6a3c48f8a71b678c2769165f38523635.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/6a3c48f8a71b678c2769165f38523635.png" alt></a></p><p>只在训练集训练神经网络，不让神经网络在训练-开发集上跑后向传播。为了进行误差分析，应该看分类器在训练集上的误差、训练-开发集上的误差、开发集上的误差</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/c5d2293143857294c49859eb875272f5.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c5d2293143857294c49859eb875272f5.png" alt></a></p><ul><li>假设训练误差是1%，训练-开发集上的误差是9%，开发集误差是10%，存在方差，因为训练-开发集的错误率是在和训练集来自同一分布的数据中测得的，尽管神经网络在训练集中表现良好，但无法泛化到来自相同分布的训练-开发集</li><li>假设训练误差为1%，训练-开发误差为1.5%，开发集错误率10%。方差很小，当转到开发集时错误率大大上升，是<strong>数据不匹配</strong>的问题</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b997fa8695062ca7332b18d51767b7df.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b997fa8695062ca7332b18d51767b7df.png" alt></a></p><ul><li>如果训练集误差是10%，训练-开发误差是11%，开发误差为12%，人类水平对贝叶斯错误率的估计大概是0%，存在可避免偏差问题</li><li>如果训练集误差是10%，训练-开发误差是11%，开发误差是20%，有两个问题</li><li>可避免偏差问题</li><li>数据不匹配问题</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/5bbfa44bc294dd33f01346b1aa87d930.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/5bbfa44bc294dd33f01346b1aa87d930.png" alt></a></p><p>如果加入测试集错误率，而开发集表现和测试集表现有很大差距，可能对开发集过拟合，需要一个更大的开发集</p><p>如果人类的表现是4%，训练错误率是7%，训练-开发错误率是10%。开发集是6%。可能开发测试集分布比实际处理的数据容易得多，错误率可能会下降</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/347df851fe3809b308850a9e14cfdbb0.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/347df851fe3809b308850a9e14cfdbb0.png" alt></a></p><p>Human level 4%和Training error 7%衡量了可避免偏差大小，Training error 7%和Training-dev error 10%衡量了方差大小，Training-dev error 10%和Dev/Test dev 6%衡量了数据不匹配问题的大小</p><p>rearview mirror speech data 6%和Error on examples trained on 6%：获得这个数字的方式是让一些人标记他们的后视镜语音识别数据，看看人类在这个任务里能做多好，然后收集一些后视镜语音识别数据，放在训练集中，让神经网络去学习，测量那个数据子集上的错误率，如果得到rearview mirror speech data 6%和Error on examples trained on 6%，说明在后视镜语音数据上达到人类水平</p><p>General speech recognition Human level 4%和rearview mirror speech data 6%：说明后视镜的语音数据比一般语音识别更难，因为人类都有6%的错误，而不是4%的错误</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/347df851fe3809b308850a9e14cfdbb0.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/347df851fe3809b308850a9e14cfdbb0.png" alt></a></p><p><strong>总结</strong>：</p><p>开发集、测试集不同分布：</p><ul><li>可以提供更多训练数据，有助于提高学习算法的性能</li><li>潜在问题不只是偏差和方差问题，还有数据不匹配</li></ul><p><img src="/images/pasted-126.png" alt="upload successful"></p><p><img src="/images/pasted-127.png" alt="upload successful"></p><p><img src="/images/pasted-128.png" alt="upload successful"></p><p><img src="/images/pasted-129.png" alt="upload successful"></p><h2 id="2-6-定位数据不匹配（Addressing-data-mismatch）"><a href="#2-6-定位数据不匹配（Addressing-data-mismatch）" class="headerlink" title="2.6 定位数据不匹配（Addressing data mismatch）"></a>2.6 定位数据不匹配（Addressing data mismatch）</h2><p>解决train set与dev/test set样本分布不一致的两条建议：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/019a324b983247e11da7ad373426b756.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/019a324b983247e11da7ad373426b756.png" alt></a></p><p>为了让训练数据更接近开发集，可以人工合成数据（<strong>artificial data synthesis</strong>）。例如说话人识别问题，实际应用场合（dev/test set）是包含背景噪声的，而训练样本train set很可能没有背景噪声。为了让train set与dev/test set分布一致，可以在train set上人工添加背景噪声，合成类似实际场景的声音。这样会让模型训练的效果更准确。但是不能给每段语音都增加同一段背景噪声，会出现对背景噪音过拟合，这就是人工数据合成需要注意的地方</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e8e1e932abb7a0bb44cab6403657321d.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e8e1e932abb7a0bb44cab6403657321d.png" alt></a></p><p>研发无人驾驶汽车，用计算机合成图像</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/cfd503f877d21d96821a81293ab0fdeb.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/cfd503f877d21d96821a81293ab0fdeb.png" alt></a></p><p>如果只合成这些车中很小的子集，学习算法可能会对合成的这一个小子集过拟合</p><p><img src="/images/pasted-130.png" alt="upload successful"></p><h2 id="2-7-迁移学习（Transfer-learning）"><a href="#2-7-迁移学习（Transfer-learning）" class="headerlink" title="2.7 迁移学习（Transfer learning）"></a>2.7 迁移学习（Transfer learning）</h2><p>将已经训练好的模型的一部分知识（网络结构）直接应用到另一个类似模型中去。比如已经训练好一个猫类识别的神经网络模型，直接把该模型中的一部分网络结构应用到使用X光片预测疾病的模型中去，这种学习方法被称为<strong>迁移学习（Transfer Learning）</strong></p><p>如果已经有一个训练好的神经网络用来做图像识别。想要构建另一个X光片进行诊断的模型。迁移学习的做法是无需重新构建新的模型，而是利用之前的神经网络模型，只改变样本输入、输出以及输出层的权重系数<script type="math/tex">W^{[L]},\ b^{[L]}</script>，即对新的样本(X,Y)，重新训练输出层权重系数<script type="math/tex">W^{[L]},\ b^{[L]}</script>，其它层所有的权重系数<script type="math/tex">W^{[L]},\ b^{[L]}</script>保持不变</p><p><img src="/images/pasted-131.png" alt="upload successful"></p><ul><li>如果需要构建新模型的样本数量较少，可以只训练输出层的权重系数<script type="math/tex">W^{[L]},\ b^{[L]}</script>，保持其它层所有的权重系数<script type="math/tex">W^{[l]},\ b^{[l]}</script>不变</li><li><p>如果样本数量足够多，可以只保留网络结构，重新训练所有层的权重系数。这种做法使得模型更加精确，因为样本对模型的影响最大</p></li><li><p>择哪种方法通常由数据量决定</p></li></ul><p>如果重新训练所有权重系数，初始<script type="math/tex">W^{[l]},\ b^{[l]}</script>由之前的模型训练得到，这一过程称为pre-training。之后，不断调试、优化<script type="math/tex">W^{[l]},\ b^{[l]}</script>的过程称为fine-tuning。pre-training和fine-tuning分别对应上图中的黑色箭头和红色箭头</p><p>迁移学习能这么做的原因是神经网络浅层部分能够检测出许多图片固有特征，例如图像边缘、曲线等。使用之前训练好的神经网络部分结果有助于更快更准确地提取X光片特征。二者处理的都是图片，而图片处理是有相同的地方，第一个训练好的神经网络已经实现如何提取图片有用特征。即便是即将训练的第二个神经网络样本数目少，仍然可以根据第一个神经网络结构和权重系数得到健壮性好的模型</p><p>迁移学习可以保留原神经网络的一部分，再添加新的网络层，可以去掉输出层后再增加额外一些神经层</p><p><img src="/images/pasted-132.png" alt="upload successful"></p><p>迁移学习的应用场合主要包括三点：</p><ul><li><p><strong>Task A and B have the same input x.</strong></p></li><li><p><strong>You have a lot more data for Task A than Task B.</strong></p></li><li><p><strong>Low level features from A could be helpful for learning B.</strong></p></li></ul><p><img src="/images/pasted-133.png" alt="upload successful"></p><p><img src="/images/pasted-134.png" alt="upload successful"></p><p><img src="/images/pasted-135.png" alt="upload successful"></p><h2 id="2-8-多任务学习（Multi-task-learning）"><a href="#2-8-多任务学习（Multi-task-learning）" class="headerlink" title="2.8 多任务学习（Multi-task learning）"></a>2.8 多任务学习（Multi-task learning）</h2><p>在迁移学习中，步骤是串行的，从任务<script type="math/tex">A</script>里学习然后只是迁移到任务<script type="math/tex">B</script>。在多任务学习中是同时开始学习的，试图让单个神经网络同时做几件事情，希望每个任务都能帮到其他所有任务</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a4e496893ed0fb928300f59f26f89cf1.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a4e496893ed0fb928300f59f26f89cf1.png" alt></a></p><p>假设无人驾驶需要同时检测行人、车辆、停车标志，还有交通灯各种其他东西</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f82865ea25c1f62b7e1981df0609a3e2.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f82865ea25c1f62b7e1981df0609a3e2.png" alt></a></p><p>如果输入图像<script type="math/tex">x^{(i)}</script>，那么 <script type="math/tex">y^{(i)}</script>不再是一个标签，而是有4个标签。在这个例子中，没有行人，有一辆车，有一个停车标志，没有交通灯。所以 <script type="math/tex">y^{(i)}</script>是个4×1向量。将训练集的标签水平堆叠起来，从<script type="math/tex">y^{(1)}</script>一直到<script type="math/tex">y^{(m)}</script>：</p><script type="math/tex; mode=display">\begin{bmatrix}\vdots & \vdots & \vdots & \vdots & \vdots\\y^{(1)} & y^{(2)} & y^{(3)} & \cdots & y^{(m)}\\\vdots & \vdots & \vdots & \vdots & \vdots\end{bmatrix}</script><p>矩阵<script type="math/tex">Y</script>变成<script type="math/tex">4\times m</script>矩阵</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/c818eb171eff10f2762ede47c5a28a6f.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c818eb171eff10f2762ede47c5a28a6f.png" alt></a></p><p>输出四个节点，第一个节点是预测图中有没有行人，第二个预测有没有车，第三预测有没有停车标志，第四预测有没有交通灯，所以<script type="math/tex">\hat y</script>是四维</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/f25a0a781024508b02c8ff42011474e0.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/f25a0a781024508b02c8ff42011474e0.png" alt></a></p><p>整个训练集的平均损失：</p><script type="math/tex; mode=display">\frac{1}{m}\sum_{i = 1}^{m}{\sum_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}}</script><p>$\sum_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}$是单个预测的损失，所以这是对四个分量的求和，行人、车、停车标志、交通灯，标志<script type="math/tex">L</script>指的是<strong>logistic损失</strong>：</p><script type="math/tex; mode=display">L(\hat y_{j}^{(i)},y_{j}^{(i)}) = - y_{j}^{(i)}\log\hat y_{j}^{(i)} - (1 - y_{j}^{(i)})log(1 - \hat y_{j}^{(i)})</script><p>Multi-task learning与Softmax regression的区别在于：</p><ul><li>Multi-task learning是multiple labels的，即输出向量y可以有多个元素为1</li><li>Softmax regression是single label的，即输出向量y只有一个元素为1</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/91f56940e94af25b0d7a46fa8dde9075.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/91f56940e94af25b0d7a46fa8dde9075.png" alt></a></p><p>神经网络一些早期特征，在识别不同物体时都会用到，训练一个神经网络做四件事情会比训练四个完全独立的神经网络分别做四件事性能要更好</p><p>多任务学习也可以处理图像只有部分物体被标记的情况。比如没有标记是否有停车标志，或者是否有交通灯。也许有些样本都有标记，有些样本只标记了有没有车，然后还有一些是问号</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/dbca02c8a624c00bdf088c56c8122609.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/dbca02c8a624c00bdf088c56c8122609.png" alt></a></p><p>即使是这样的数据集，也可以在上面训练算法，同时做四个任务，即使一些图像只有一小部分标签，其他是问号。训练算法的方式是对<script type="math/tex">j</script>从1到4只对带0和1标签的<script type="math/tex">j</script>值求和，当有问号就在求和时忽略那个项</p><p>多任务学习当三件事为真时有意义的：</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/a4f0d10a340481a4189328870259d0ed.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/a4f0d10a340481a4189328870259d0ed.png" alt></a></p><ul><li>训练的一组任务，可以共用低层次特征。对于无人驾驶的例子，同时识别交通灯、汽车和行人是有道理的，这些物体有相似的特征</li><li>如果每个任务的数据量很接近，这个准则没那么绝对，不一定对</li><li>想要从多任务学习得到很大性能提升，其他任务加起来必须要有比单个任务大得多的数据量</li></ul><p>多任务学习会降低性能的唯一情况是神经网络还不够大。但如果可以训练一个足够大的神经网络，多任务学习肯定不会或者很少会降低性能</p><p>在实践中，多任务学习的使用频率要低于迁移学习。因为很难找到那么多相似且数据量对等的任务可以用单一神经网络训练。不过在计算机视觉领域，物体检测这个例子是最显著的例外情况</p><p><img src="/images/pasted-136.png" alt="upload successful"></p><p><img src="/images/pasted-137.png" alt="upload successful"></p><p><img src="/images/pasted-138.png" alt="upload successful"></p><h2 id="2-9-什么是端到端的深度学习？（What-is-end-to-end-deep-learning-）"><a href="#2-9-什么是端到端的深度学习？（What-is-end-to-end-deep-learning-）" class="headerlink" title="2.9 什么是端到端的深度学习？（What is end-to-end deep learning?）"></a>2.9 什么是端到端的深度学习？（What is end-to-end deep learning?）</h2><p>以前有一些数据处理系统或者学习系统需要多个阶段的处理。端到端深度学习就是忽略所有这些不同的阶段，用单个神经网络代替它</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/925b9078df981f43f5c573833d0aa9ff.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/925b9078df981f43f5c573833d0aa9ff.png" alt></a></p><h3 id="语音识别"><a href="#语音识别" class="headerlink" title="语音识别"></a>语音识别</h3><p>目标是输入<script type="math/tex">x</script>，比如说一段音频，然后把它映射到一个输出<script type="math/tex">y</script>，就是这段音频的听写文本:</p><ul><li>传统上语音识别需要很多阶段的处理。首先提取一些特征，一些手工设计的音频特征，比如<strong>MFCC</strong>，这种算法是用来从音频中提取一组特定的人工设计的特征。在提取出一些低层次特征之后，应用机器学习算法在音频片段中找到音位（声音的基本单位），比如“<strong>Cat</strong>”这个词是三个音节构成的，<strong>Cu-</strong>、<strong>Ah-和</strong>Tu-，算法把这三个音位提取出来，然后将音位串在一起构成独立的词，然后将词串起来构成音频片段的听写文本</li></ul><p><img src="/images/pasted-139.png" alt="upload successful">)</p><ul><li>端到端深度学习是训练一个巨大的神经网络，输入一段音频，输出直接是听写文本。只需要把训练集拿过来，直接学到了<script type="math/tex">x</script>和<script type="math/tex">y</script>之间的函数映射，绕过了其中很多步骤</li></ul><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/4ad6502dd05f5aac0c2d649d3c126250.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/4ad6502dd05f5aac0c2d649d3c126250.png" alt></a></p><p>端到端深度学习的挑战之一是需要大量数据才能让系统表现良好，比如只有3000小时数据去训练语音识别系统，那传统的流水线效果很好。但当有非常大的数据集时，比如10,000小时数据或者100,000小时数据，端到端方法突然开始很厉害。所以当数据集较小时，传统流水线方法效果更好。如果数据量适中，也可以用中间件方法，如输入还是音频，然后绕过特征提取，直接尝试从神经网络输出音位</p><h3 id="门禁识别系统"><a href="#门禁识别系统" class="headerlink" title="门禁识别系统"></a>门禁识别系统</h3><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/cf8285f8ce5a45ba016d3b8509a766be.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/cf8285f8ce5a45ba016d3b8509a766be.png" alt></a></p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/06720034b609c3c637afcbc15c44fe72.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/06720034b609c3c637afcbc15c44fe72.png" alt></a></p><p>最好的方法是一个多步方法，首先运行一个软件来检测人脸，然后放大图像并裁剪图像，使人脸居中显示，然后红线框起来的照片再喂到神经网络里，让网络去学习，或估计那人的身份</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/4ca915fa995cc2b6edb8b0282cdaf7c5.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/4ca915fa995cc2b6edb8b0282cdaf7c5.png" alt></a></p><p>比起一步到位，一步学习，把这个问题分解成两个更简单的步骤更好：</p><ul><li>首先弄清楚脸在哪里</li><li>第二步是看着脸，弄清楚这是谁</li></ul><p>这种方法让两个学习算法分别解决两个更简单的任务，并在整体上得到更好的表现</p><p>训练第二步的方式：输入两张图片，网络将两张图比较一下，判断是否是同一个人。比如记录了10,000个员工<strong>ID</strong>，可以把红色框起来的图像快速比较，看看红线内的照片是不是那10000个员工之一，判断是否应该允许其进入</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/803377bbfc2a9f9608cd9ac4dbfaefc3.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/803377bbfc2a9f9608cd9ac4dbfaefc3.png" alt></a></p><p>为什么两步法更好：</p><ul><li>解决的两个问题，每个问题实际上要简单得多</li><li>两个子任务的训练数据都很多</li></ul><h3 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h3><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/188a6112bc3e3065f5ddfca87d8c9064.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/188a6112bc3e3065f5ddfca87d8c9064.png" alt></a></p><p>传统上机器翻译系统也有一个很复杂的流水线，比如英语机翻得到文本，然后做文本分析，基本上要从文本中提取一些特征之类的，经过很多步骤，最后会将英文文本翻译成法文。因为对于机器翻译来说有很多(英文,法文)的数据对，端到端深度学习在机器翻译领域非常好用</p><h2 id="2-10-是否要使用端到端的深度学习？（Whether-to-use-end-to-end-learning-）"><a href="#2-10-是否要使用端到端的深度学习？（Whether-to-use-end-to-end-learning-）" class="headerlink" title="2.10 是否要使用端到端的深度学习？（Whether to use end-to-end learning?）"></a>2.10 是否要使用端到端的深度学习？（Whether to use end-to-end learning?）</h2><h3 id="端到端学习的优点"><a href="#端到端学习的优点" class="headerlink" title="端到端学习的优点"></a>端到端学习的优点</h3><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/2211e8807cc6d4c2c0941625e2de4860.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/2211e8807cc6d4c2c0941625e2de4860.png" alt></a></p><ul><li><p><strong>端到端学习只是让数据说话</strong>。如果有足够多的<script type="math/tex">(x,y)</script>数据，不管从<script type="math/tex">x</script>到<script type="math/tex">y</script>最适合的函数映射是什么，如果训练一个足够大的神经网络，希望这个神经网络能自己搞清楚。使用纯机器学习方法，直接从<script type="math/tex">x</script>到<script type="math/tex">y</script>输入去训练神经网络，可能更能够捕获数据中的任何统计信息，而不是被迫引入人类的成见。例如在语音识别领域，早期的识别系统有这个音位概念，如果让学习算法学习它想学习的任意表示方式，而不是强迫使用音位作为表示方式，其整体表现可能会更好</p></li><li><p><strong>所需手工设计的组件更少</strong>，能够简化设计工作流程，不需要花太多时间去手工设计功能，手工设计中间表示方式</p></li></ul><h3 id="端到端学习的缺点"><a href="#端到端学习的缺点" class="headerlink" title="端到端学习的缺点"></a>端到端学习的缺点</h3><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/b73c65c89f8af6e000369e12f0303409.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/b73c65c89f8af6e000369e12f0303409.png" alt></a></p><ul><li>直接学到<script type="math/tex">x</script>到<script type="math/tex">y</script>的映射，<strong>需要大量</strong><script type="math/tex">(x,y)</script><strong>数据</strong></li><li><strong>排除了可能有用的手工设计组件</strong>。当有大量数据时，手工设计不太重要，当没有太多的数据时，构造一个精心设计的系统，可以将人类对这个问题的很多认识直接注入到问题里，对算法很有帮助</li></ul><p>端到端深度学习的弊端之一是它把可能有用的人工设计的组件排除在外，精心设计的人工组件可能非常有用，但也可能真的影响算法表现。例如，强制算法以音位为单位思考，也许让算法自己找到更好的表示方法更好。但往往好处更多，手工设计的组件往往在训练集更小的时候帮助更大</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/93e5f8097f3246be83f704e468e72d76.png" target="_blank" rel="noopener"><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/93e5f8097f3246be83f704e468e72d76.png" alt></a></p><p>决定是否使用端到端深度学习，关键的问题是<strong>是否有足够的数据能够直接学到从</strong><script type="math/tex">x</script><strong>映射到</strong><script type="math/tex">y</script><strong>足够复杂的函数</strong>。识别图中骨头位置是相对简单的问题，系统不需要那么多数据。但把手的X射线照片直接映射到孩子的年龄，直接去找这种函数，就是更为复杂的问题。如果用纯端到端方法，需要很多数据去学习</p><p><img src="/images/pasted-140.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2-1-进行误差分析（Carrying-out-error-analysis）&quot;&gt;&lt;a href=&quot;#2-1-进行误差分析（Carrying-out-error-analysis）&quot; class=&quot;headerlink&quot; title=&quot;2.1 进行误差分析（Carrying out error analysis）&quot;&gt;&lt;/a&gt;2.1 进行误差分析（Carrying out error analysis）&lt;/h2&gt;&lt;p&gt;如果希望让学习算法能够胜任人类能做的任务，但学习算法还没有达到人类的表现，那么人工检查一下算法犯的错误可以了解接下来应该做什么，这个过程称为&lt;strong&gt;错误分析&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第 三 周 超 参 数 调 试 、 Batch 正 则 化 和 程 序 框 架 （Hyperparameter tuning）(Course 2)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC-%E4%B8%89-%E5%91%A8-%E8%B6%85-%E5%8F%82-%E6%95%B0-%E8%B0%83-%E8%AF%95-%E3%80%81-Batch-%E6%AD%A3-%E5%88%99-%E5%8C%96-%E5%92%8C-%E7%A8%8B-%E5%BA%8F-%E6%A1%86-%E6%9E%B6-%EF%BC%88Hyperparameter-tuning%EF%BC%89-Course-2/"/>
    <id>https://baozouai.com/2019/02/28/第-三-周-超-参-数-调-试-、-Batch-正-则-化-和-程-序-框-架-（Hyperparameter-tuning）-Course-2/</id>
    <published>2019-02-27T20:22:00.000Z</published>
    <updated>2019-02-27T05:39:52.207Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3-1-调试处理（Tuning-process）"><a href="#3-1-调试处理（Tuning-process）" class="headerlink" title="3.1 调试处理（Tuning process）"></a>3.1 调试处理（Tuning process）</h2><p>深度神经网络需要调试的超参数（Hyperparameters）包括：</p><ul><li><script type="math/tex">\alpha</script><strong>：学习因子</strong></li><li><script type="math/tex">\beta</script><strong>：动量梯度下降因子</strong></li><li><script type="math/tex">\beta_1,\beta_2,\varepsilon</script><strong>：Adam算法参数</strong></li><li><strong>#layers：神经网络层数</strong></li><li><strong>#hidden units：各隐藏层神经元个数</strong></li><li><strong>learning rate decay：学习因子下降参数</strong></li><li><strong>mini-batch size：批量训练样本包含的样本个数</strong></li></ul><a id="more"></a><p>学习因子<script type="math/tex">\alpha</script>是最重要的超参数，也是需要重点调试的超参数。动量梯度下降因子<script type="math/tex">\beta</script>、各隐藏层神经元个数#hidden units和mini-batch size的重要性仅次于,然后就是神经网络层数#layers和学习因子下降参数learning rate decay。最后，Adam算法的三个参数<script type="math/tex">\beta_1,\beta_2,\varepsilon</script>一般常设置为0.9，0.999和<script type="math/tex">10^{-8}</script></p><p>传统的机器学习中，对每个参数等距离选取任意个数的点，分别使用不同点对应的参数组合进行训练，最后根据验证集上的表现好坏来选定最佳的参数。例如有两个待调试的参数，分别在每个参数上选取5个点，这样构成了5x5=25中参数组合：</p><p><img src="/images/pasted-69.png" alt="upload successful"></p><blockquote><p>这种做法在参数比较少的时候效果较好</p></blockquote><p>深度神经网络模型中是使用随机选择。随机选择25个点，作为待调试的超参数：</p><p><img src="/images/pasted-70.png" alt="upload successful">)</p><p>随机化选择参数是为了尽可能地得到更多种参数组合。如果使用均匀采样，每个参数只有5种情况；而使用随机采样的话，每个参数有25种可能的情况，更可能得到最佳的参数组合</p><p>另外一个好处是对重要性不同的参数之间的选择效果更好。假设hyperparameter1为<script type="math/tex">\alpha</script>，hyperparameter2为<script type="math/tex">\varepsilon</script>，显然二者的重要性是不一样的。如果使用第一种均匀采样的方法，<script type="math/tex">\varepsilon</script>的影响很小，相当于只选择了5个<script type="math/tex">\alpha</script>值。而如果使用第二种随机采样的方法，<script type="math/tex">\varepsilon</script>和<script type="math/tex">\alpha</script>都有可能选择25种不同值。这大大增加了<script type="math/tex">\alpha</script>调试的个数，更有可能选择到最优值</p><p>在实际应用中完全不知道哪个参数更加重要的情况下，随机采样的方式能有效解决这一问题，但是均匀采样做不到这点</p><p>随机采样之后，可能得到某些区域模型的表现较好。为了得到更精确的最佳参数，继续对选定的区域进行由粗到细的采样（coarse to fine sampling scheme）。就是放大表现较好的区域，对此区域做更密集的随机采样</p><p>如对下图中右下角的方形区域再做25点的随机采样，以获得最佳参数：</p><p><img src="/images/pasted-71.png" alt="upload successful"></p><h2 id="3-2-为超参数选择合适的范围（Using-an-appropriate-scale-to-pick-hyperparameters）"><a href="#3-2-为超参数选择合适的范围（Using-an-appropriate-scale-to-pick-hyperparameters）" class="headerlink" title="3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）"></a>3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）</h2><p>随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数</p><p>对于超参数#layers和#hidden units，都是正整数，是可以进行均匀随机采样的，即超参数每次变化的尺度都是一致</p><p>对于某些超参数，可能需要非均匀随机采样（即非均匀刻度尺）。例如超参数<script type="math/tex">\alpha</script>，待调范围是[0.0001, 1]。如果使用均匀随机采样，90%的采样点分布在[0.1, 1]之间，只有10%分布在[0.0001, 0.1]之间。而最佳的<script type="math/tex">\alpha</script>值可能主要分布在[0.0001, 0.1]之间，因此更应在区间[0.0001, 0.1]内细分更多刻度</p><p>通常的做法是将linear scale转换为log scale，将均匀尺度转化为非均匀尺度，然后再在log scale下进行均匀采样。这样，[0.0001, 0.001]，[0.001, 0.01]，[0.01, 0.1]，[0.1, 1]各个区间内随机采样的超参数个数基本一致，扩大了之前[0.0001, 0.1]区间内采样值个数</p><p><img src="/images/pasted-72.png" alt="upload successful"></p><p>如果线性区间为[a, b]，令m=log(a)，n=log(b)，则对应的log区间为[m,n]。对log区间的[m,n]进行随机均匀采样，得到的采样值r，最后反推到线性区间，即<script type="math/tex">10^r</script>.<script type="math/tex">10^r</script>是最终采样的超参数。代码为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">m = np.log10(a)</span><br><span class="line">n = np.log10(b)</span><br><span class="line">r = np.random.rand()</span><br><span class="line">r = m + (n-m)*r</span><br><span class="line">r = np.power(<span class="number">10</span>,r)</span><br></pre></td></tr></table></figure><p>动量梯度因子<script type="math/tex">\beta</script>在超参数调试也需要进行非均匀采样。一般<script type="math/tex">\beta</script>的取值范围在[0.9, 0.999]之间，1−<script type="math/tex">\beta</script>的取值范围在[0.001, 0.1]。那么直接对1−<script type="math/tex">\beta</script>在[0.001, 0.1]区间内进行log变换</p><p>为什么<script type="math/tex">\beta</script>也需要向<script type="math/tex">\alpha</script>那样做非均匀采样：</p><p>假设<script type="math/tex">\beta</script>从0.9000变化为0.9005，那么<script type="math/tex">\frac{1}{1-\beta}</script>基本没有变化。但假设β从0.9990变化为0.9995，那么<script type="math/tex">\frac{1}{1-\beta}</script>前后差别1000。<script type="math/tex">\beta</script>越接近1，指数加权平均的个数越多，变化越大。所以对<script type="math/tex">\beta</script>接近1的区间，应该采集得更密集一些</p><h2 id="3-3-超参数训练的实践：-Pandas-VS-Caviar（Hyperparameters-tuning-in-practice-Pandas-vs-Caviar）"><a href="#3-3-超参数训练的实践：-Pandas-VS-Caviar（Hyperparameters-tuning-in-practice-Pandas-vs-Caviar）" class="headerlink" title="3.3 超参数训练的实践： Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）"></a>3.3 超参数训练的实践： Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）</h2><p>经过调试选择完最佳的超参数不是一成不变的，一段时间之后（例如一个月），需要根据新的数据和实际情况，再次调试超参数，以获得实时的最佳模型</p><p>在训练深度神经网络时，一种情况是有庞大的数据组，但没有许多计算资源或足够的 CPU 和<br>GPU 的前提下，只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳的表现。称之为Babysitting one model。另外一种情况是可以对多个模型同时进行训练，每个模型上调试不同的超参数，根据表现情况，选择最佳的模型。称之为Training many models in parallel</p><p><img src="/images/pasted-73.png" alt="upload successful"></p><p>第一种情况只使用一个模型，类比做Panda approach；第二种情况同时训练多个模型，类比做Caviar approach。使用哪种模型是由计算资源、计算能力所决定的。一般来说，对于非常复杂或者数据量很大的模型，使用Panda approach更多一些</p><h2 id="3-4-归一化网络的激活函数（-Normalizing-activations-in-a-network）"><a href="#3-4-归一化网络的激活函数（-Normalizing-activations-in-a-network）" class="headerlink" title="3.4 归一化网络的激活函数（ Normalizing activations in a network）"></a>3.4 归一化网络的激活函数（ Normalizing activations in a network）</h2><p>在神经网络中，第<script type="math/tex">l</script>层隐藏层的输入就是第<script type="math/tex">l-1</script>层隐藏层的输出<script type="math/tex">A^{[l-1]}</script>。对<script type="math/tex">A^{[l-1]}</script>进行标准化处理，从原理上来说可以提高<script type="math/tex">W^{[l]}</script>和<script type="math/tex">b^{[l]}</script>的训练速度和准确度。这种对各隐藏层的标准化处理就是Batch Normalization。一般是对<script type="math/tex">Z^{[l-1]}</script>进行标准化处理而不是<script type="math/tex">A^{[l-1]}</script></p><p>Batch Normalization对第<script type="math/tex">l</script>层隐藏层的输入<script type="math/tex">Z^{[l-1]}</script>做如下标准化处理，忽略上标<script type="math/tex">[l-1]</script>：</p><script type="math/tex; mode=display">\mu=\frac1m\sum_iz^{(i)}</script><script type="math/tex; mode=display">\sigma^2=\frac1m\sum_i(z_i-\mu)^2</script><script type="math/tex; mode=display">z^{(i)}_{norm}=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\varepsilon}}</script><p>m是单个mini-batch包含样本个数，ε是为了防止分母为零，可取值<script type="math/tex">10^{-8}</script>。使得该隐藏层的所有输入<script type="math/tex">z^{(i)}</script>均值为0，方差为1</p><p>大部分情况下并不希望所有的<script type="math/tex">z^{(i)}</script>均值都为0，方差都为1，也不太合理。通常需要对<script type="math/tex">z^{(i)}</script>进行进一步处理：</p><script type="math/tex; mode=display">\tilde z^{(i)}=\gamma\cdot z^{(i)}_{norm}+\beta</script><p>$\gamma$和<script type="math/tex">\beta</script>是learnable parameters，可以通过梯度下降等算法求得。<script type="math/tex">\gamma</script>和<script type="math/tex">\beta</script>是让<script type="math/tex">\tilde z^{(i)}</script>的均值和方差为任意值，只需调整其值。如：</p><script type="math/tex; mode=display">\gamma=\sqrt{\sigma^2+\varepsilon},\ \ \beta=u</script><p>则<script type="math/tex">\tilde z^{(i)}=z^{(i)}</script>，即identity function。设置<script type="math/tex">\gamma</script>和<script type="math/tex">\beta</script>为不同的值，可以得到任意的均值和方差</p><p>通过Batch Normalization，对隐藏层的各个<script type="math/tex">z^{[l](i)}</script>进行标准化处理，得到<script type="math/tex">\tilde z^{[l](i)}</script>，替代<script type="math/tex">z^{[l](i)}</script></p><p>输入的标准化处理Normalizing inputs和隐藏层的标准化处理Batch Normalization是有区别的。Normalizing inputs使所有输入的均值为0，方差为1。而Batch Normalization可使各隐藏层输入的均值和方差为任意值。从激活函数的角度来说，如果各隐藏层的输入均值在靠近0的区域即处于激活函数的线性区域，这样不利于训练好的非线性神经网络，得到的模型效果也不会太好</p><h2 id="3-5-将-Batch-Norm-拟合进神经网络（Fitting-Batch-Norm-into-a-neural-network）"><a href="#3-5-将-Batch-Norm-拟合进神经网络（Fitting-Batch-Norm-into-a-neural-network）" class="headerlink" title="3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）"></a>3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）</h2><p>前向传播的计算流程：</p><p><img src="/images/pasted-74.png" alt="upload successful"></p><p><strong>实现梯度下降：</strong></p><p>for t = 1 … num （这里num 为Mini Batch 的数量）：</p><ul><li><p>在每一个<script type="math/tex">X^t</script> 上进行前向传播（forward prop）的计算：</p></li><li><p>在每个隐藏层都用 Batch Norm 将<script type="math/tex">z^{[l]}</script>替换为</p><script type="math/tex; mode=display">\widetilde{z}^{[l]}</script></li><li><p>使用反向传播（Back prop）计算各个参数的梯度：<script type="math/tex">dw^{[l]},d\gamma^{[l]},d\beta^{[l]}</script></p></li><li><p>更新参数：</p></li><li><script type="math/tex; mode=display">w^{[l]}:=w^{[l]}-\alpha dw^{[l]}</script></li><li><script type="math/tex; mode=display">\gamma^{[l]}:=\gamma^{[l]}-\alpha d\gamma^{[l]}</script></li><li><script type="math/tex; mode=display">\beta^{[l]}:=\beta^{[l]}-\alpha d\beta^{[l]}</script></li></ul><p>经过Batch Norm的作用，整体流程如下：</p><p><img src="/images/pasted-76.png" alt="upload successful">)</p><p>Batch Norm对各隐藏层<script type="math/tex">Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}</script>有去均值的操作，Batch Norm 要做的就是将<script type="math/tex">z^{[l]}</script>归一化，结果成为均值为0，标准差为1的分布，再由<script type="math/tex">\beta</script> 和<script type="math/tex">\gamma</script> 进行重新的分布缩放，意味着无论<script type="math/tex">b^{[l]}</script> 值为多少，在这个过程中都会被减去，不会再起作用。所以常数项<script type="math/tex">b^{[l]}</script>可以消去，其数值效果完全可以由<script type="math/tex">\widetilde{z}^{[l]}</script>中的<script type="math/tex">\beta</script>来实现。在使用Batch Norm的时候，可以忽略各隐藏层的常数项<script type="math/tex">b^{[l]}</script>。在使用梯度下降算法时，分别对<script type="math/tex">W^{[l]}</script>,<script type="math/tex">\beta^{[l]}</script>和<script type="math/tex">\gamma^{[l]}</script>进行迭代更新</p><p>除了传统的梯度下降算法之外，还可以使用动量梯度下降、RMSprop或者Adam等优化算法</p><h2 id="3-6-Batch-Norm-为什么奏效？（Why-does-Batch-Norm-work-）"><a href="#3-6-Batch-Norm-为什么奏效？（Why-does-Batch-Norm-work-）" class="headerlink" title="3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）"></a>3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）</h2><h3 id="Batch-Norm-可以加速神经网络训练的原因："><a href="#Batch-Norm-可以加速神经网络训练的原因：" class="headerlink" title="Batch Norm 可以加速神经网络训练的原因："></a>Batch Norm 可以加速神经网络训练的原因：</h3><ul><li>和输入层的输入特征进行归一化，从而改变Cost function的形状，使得每一次梯度下降都可以更快的接近函数的最小值点，从而加速模型训练过程的原理有相同的道理，只是Batch Norm是将各个隐藏层的激活函数的激活值进行的归一化，并调整到另外的分布</li><li>Batch Norm 可以使权重比网络更滞后或者更深层</li></ul><h4 id="判别是否是猫的分类问题："><a href="#判别是否是猫的分类问题：" class="headerlink" title="判别是否是猫的分类问题："></a>判别是否是猫的分类问题：</h4><p>假设第一训练样本的集合中的猫均是黑猫，而第二个训练样本集合中的猫是各种颜色的猫。如果将第二个训练样本直接输入到用第一个训练样本集合训练出的模型进行分类判别，在很大程度上无法保证能够得到很好的判别结果</p><p>因为训练样本不具有一般性（即不是所有的猫都是黑猫），第一个训练集合中均是黑猫，而第二个训练集合中各色猫均有，虽然都是猫，但是很大程度上样本的分布情况是不同的，无法保证模型可以仅仅通过黑色猫的样本就可以完美的找到完整的决策边界</p><p><img src="/images/pasted-77.png" alt="upload successful"></p><p>这种训练样本（黑猫）和测试样本（猫）分布的变化称之为<strong>covariate shift</strong>。如下图所示：</p><p><img src="/images/pasted-78.png" alt="upload successful"></p><p>深度神经网络中，covariate shift会导致模型预测效果变差，重新训练的模型各隐藏层的<script type="math/tex">W^{[l]}</script>和<script type="math/tex">B^{[l]}</script>均产生偏移、变化。而Batch Norm的作用恰恰是减小covariate shift的影响，让模型变得更加健壮，鲁棒性更强</p><p>使用深层神经网络，使用Batch Norm，该模型对花猫的识别能力应该也是不错</p><h3 id="Batch-Norm-解决Covariate-shift的问题"><a href="#Batch-Norm-解决Covariate-shift的问题" class="headerlink" title="Batch Norm 解决Covariate shift的问题"></a>Batch Norm 解决Covariate shift的问题</h3><p><img src="/images/pasted-79.png" alt="upload successful">)</p><p>网络的目的是通过不断的训练，最后输出一个更加接近于真实值的<script type="math/tex">\hat y</script>，以第2个隐藏层为输入来看：</p><p><img src="/images/pasted-80.png" alt="upload successful"><br><img src="/images/pasted-81.png" alt="upload successful"></p><p>对于后面的神经网络，是以第二层隐层的输出值<script type="math/tex">a^{[2]}</script>作为输入特征的，通过前向传播得到最终的<script type="math/tex">\hat y</script>，但是网络还有前面两层，由于训练过程，参数<script type="math/tex">w^{[1]},w^{[2]}</script>是不断变化的，对于后面的网络，<script type="math/tex">a^{[2]}</script>的值也是处于不断变化之中，所以就有了Covariate shift的问题</p><p>如果对<script type="math/tex">z^{[2]}</script>使用了Batch Norm，即使其值不断的变化，其均值和方差却会保持。Batch Norm的作用是限制前层的参数更新导致对后面网络数值分布程度的影响，使得输入后层的数值变得更加稳定。Batch Norm减少了各层<script type="math/tex">W^{[l]},B^{[l]}</script>之间的耦合性，让各层更加独立，实现自我训练学习的效果。如果输入发生covariate shift，Batch Norm的作用是对个隐藏层输出<script type="math/tex">Z^{[l]}</script>进行均值和方差的归一化处理，让<script type="math/tex">W^{[l]},B^{[l]}</script>更加稳定，使得原来的模型也有不错的表现</p><p>Batch Norm 削弱了前层参数与后层参数之间的联系，使得网络的每层都可以自己进行学习，相对其他层有一定的独立性，有助于加速整个网络的学习</p><h2 id="Batch-Norm-正则化效果"><a href="#Batch-Norm-正则化效果" class="headerlink" title="Batch Norm 正则化效果"></a>Batch Norm 正则化效果</h2><ul><li>使用Mini-batch梯度下降，每次计算均值和偏差都是在一个Mini-batch上进行计算，而不是在整个数据样集上。这样在均值和偏差上带来一些比较小的噪声。那么用均值和偏差计算得到的<script type="math/tex">\widetilde{z}^{[l]}</script>也将会加入一定的噪声</li><li>和Dropout相似，其在每个隐藏层的激活值上加入了一些噪声，（Dropout以一定的概率给神经元乘上0或者1）。Batch Norm 也有轻微的正则化效果</li><li>如果使用Batch Norm ，使用大的Mini-batch如256，相比使用小的Mini-batch如64，会引入更少的噪声，会减少正则化的效果</li><li>Batch Norm的正则化效果比较微弱，正则化不是Batch Norm的主要功能</li></ul><h2 id="3-7-测试时的-Batch-Norm（Batch-Norm-at-test-time）"><a href="#3-7-测试时的-Batch-Norm（Batch-Norm-at-test-time）" class="headerlink" title="3.7 测试时的 Batch Norm（Batch Norm at test time）"></a>3.7 测试时的 Batch Norm（Batch Norm at test time）</h2><p>训练过程中Batch Norm的主要过程：</p><script type="math/tex; mode=display">\mu=\frac1m\sum_iz^{(i)}</script><script type="math/tex; mode=display">\sigma^2=\frac1m\sum_i(z^{(i)}-\mu)^2</script><script type="math/tex; mode=display">z_{norm}^{(i)}=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\varepsilon}}</script><script type="math/tex; mode=display">\tilde z^{(i)}=\gamma\cdot z^{(i)}_{norm}+\beta</script><p>$\mu$和<script type="math/tex">\sigma^2</script>是对单个mini-batch中所有m个样本求得的。在测试过程中，如果只有一个样本，求其均值和方差是没有意义的，就需要对<script type="math/tex">\mu</script>和<script type="math/tex">\sigma^2</script>进行估计。实际应用是使用指数加权平均（exponentially weighted average）的方法来预测测试过程单个样本的<script type="math/tex">\mu</script>和<script type="math/tex">\sigma^2</script></p><p>对于第<script type="math/tex">l</script>层隐藏层，在训练的过程中, ，对于训练集的Mini-batch，考虑所有mini-batch在该隐藏层下的<script type="math/tex">\mu^{[l]}</script>和<script type="math/tex">{\sigma^{2}}^{[l]}</script>，使用指数加权平均，当训练结束的时候，得到指数加权平均后当前单个样本的<script type="math/tex">\mu^{[l]}</script>和<script type="math/tex">{\sigma^{2}}^{[l]}</script>,这些值直接用于Batch Norm公式的计算，用以对测试样本进行预测，再利用训练过程得到的<script type="math/tex">\gamma</script>和<script type="math/tex">\beta</script>计算出各层的<script type="math/tex">\tilde z^{(i)}</script>值</p><h2 id="3-8-Softmax-回归（Softmax-regression）"><a href="#3-8-Softmax-回归（Softmax-regression）" class="headerlink" title="3.8 Softmax 回归（Softmax regression）"></a>3.8 Softmax 回归（Softmax regression）</h2><p>Softmax 回归，能在识别多种分类中的一个时做出预测，对于多分类问题，用C表示种类个数，神经网络中输出层就有C个神经元，即<script type="math/tex">n^{[L]}=C</script>，每个神经元的输出依次对应属于该类的概率，即<script type="math/tex">P(y=c|x)</script>，处理多分类问题一般使用Softmax回归模型</p><p><img src="/images/pasted-83.png" alt="upload successful"></p><blockquote><p>把猫做类 1，狗为类 2，小鸡 是类 3， 如果不属于以上任何一类， 就分到“其它”或者“以上均不符合”这一类，叫 做类 0</p></blockquote><p>用大写C表示输入会被分入的类别总个数,当有 4 个分类时，指示类别的数字，就是从 0 到C − 1( 0、 1、 2、 3)</p><p>Softmax回归模型输出层的激活函数：</p><script type="math/tex; mode=display">z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]}</script><script type="math/tex; mode=display">a^{[L]}_i=\frac{e^{z^{[L]}_i}}{\sum_{i=1}^Ce^{z^{[L]}_i}}</script><p>输出层每个神经元的输出<script type="math/tex">a^{[L]}_i</script>对应属于该类的概率，满足：</p><script type="math/tex; mode=display">\sum_{i=1}^Ca^{[L]}_i=1</script><p>所有的<script type="math/tex">a^{[L]}_i</script>，即<script type="math/tex">\hat y</script>，维度为(C, 1)</p><p><img src="/images/pasted-84.png" alt="upload successful"></p><p>在没有隐藏隐藏层的时候，直接对Softmax层输入样本的特点，则在不同数量的类别下，Sotfmax层的作用：</p><p><img src="/images/pasted-85.png" alt="upload successful"></p><p>图中的颜色显示了 Softmax 分类器的输出的阈值，输入的着色是基于三种输出中概率最高的那种，任何两个分类之间的决策边界都是线性的</p><p>如果使用神经网络，特别是深层神经网络，可以得到更复杂、更精确的非线性模型</p><h2 id="3-9-训练一个-Softmax-分类器（Training-a-Softmax-classifier）"><a href="#3-9-训练一个-Softmax-分类器（Training-a-Softmax-classifier）" class="headerlink" title="3.9 训练一个 Softmax 分类器（Training a Softmax classifier）"></a>3.9 训练一个 Softmax 分类器（Training a Softmax classifier）</h2><p>C=4，某个样本的预测输出<script type="math/tex">\hat y</script>和真实输出<script type="math/tex">y</script>：</p><script type="math/tex; mode=display">\hat y=\left[\begin{matrix}0.3 \\0.2 \\0.1 \\0.4\end{matrix}\right]</script><script type="math/tex; mode=display">y=\left[\begin{matrix}0 \\1 \\0 \\0\end{matrix}\right]</script><p>从<script type="math/tex">\hat y</script>值来看，<script type="math/tex">P(y=4|x)=0.4</script>，概率最大，而真实样本属于第2类，该预测效果不佳</p><p>定义softmax classifier的loss function为：</p><script type="math/tex; mode=display">L(\hat y,y)=-\sum_{j=1}^4y_j\cdot log\ \hat y_j</script><p>$L(\hat y,y)$简化为：</p><script type="math/tex; mode=display">L(\hat y,y)=-y_2\cdot log\ \hat y_2=-log\ \hat y_2</script><p>让<script type="math/tex">L(\hat y,y)</script>更小，就应该让<script type="math/tex">\hat y_2</script>越大越好。<script type="math/tex">\hat y_2</script>反映的是概率</p><p>m个样本的cost function为：</p><script type="math/tex; mode=display">J=\frac{1}{m}\sum_{i=1}^mL(\hat y,y)</script><p>预测输出向量<script type="math/tex">A^{[L]}</script>即<script type="math/tex">\hat Y</script>的维度为(4, m)</p><p>softmax classifier的反向传播过程:</p><p>先推导<script type="math/tex">dZ^{[L]}</script>：</p><script type="math/tex; mode=display">da^{[L]}=-\frac{1}{a^{[L]}}</script><p><img src="/images/pasted-86.png" alt="upload successful"></p><script type="math/tex; mode=display">\frac{\partial a^{[L]}}{\partial z^{[L]}}=\frac{\partial}{\partial z^{[L]}}\cdot (\frac{e^{z^{[L]}_i}}{\sum_{i=1}^Ce^{z^{[L]}_i}})=a^{[L]}\cdot (1-a^{[L]})</script><p><img src="/images/pasted-87.png" alt="upload successful"></p><p><img src="/images/pasted-88.png" alt="upload successful"></p><p><img src="/images/pasted-89.png" alt="upload successful"></p><p>所有m个训练样本：</p><script type="math/tex; mode=display">dZ^{[L]}=A^{[L]}-Y</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;3-1-调试处理（Tuning-process）&quot;&gt;&lt;a href=&quot;#3-1-调试处理（Tuning-process）&quot; class=&quot;headerlink&quot; title=&quot;3.1 调试处理（Tuning process）&quot;&gt;&lt;/a&gt;3.1 调试处理（Tuning process）&lt;/h2&gt;&lt;p&gt;深度神经网络需要调试的超参数（Hyperparameters）包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;&lt;strong&gt;：学习因子&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt;&lt;strong&gt;：动量梯度下降因子&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\beta_1,\beta_2,\varepsilon&lt;/script&gt;&lt;strong&gt;：Adam算法参数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;#layers：神经网络层数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;#hidden units：各隐藏层神经元个数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;learning rate decay：学习因子下降参数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mini-batch size：批量训练样本包含的样本个数&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第四周：深层神经网络(Deep Neural Networks)(Course 1)</title>
    <link href="https://baozouai.com/2019/02/28/%E7%AC%AC%E5%9B%9B%E5%91%A8%EF%BC%9A%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Deep-Neural-Networks/"/>
    <id>https://baozouai.com/2019/02/28/第四周：深层神经网络-Deep-Neural-Networks/</id>
    <published>2019-02-27T18:17:00.000Z</published>
    <updated>2019-02-27T05:45:37.502Z</updated>
    
    <content type="html"><![CDATA[<h2 id="4-1-深层神经网络（Deep-L-layer-neural-network）"><a href="#4-1-深层神经网络（Deep-L-layer-neural-network）" class="headerlink" title="4.1 深层神经网络（Deep L-layer neural network）"></a>4.1 深层神经网络（Deep L-layer neural network）</h2><p><img src="/images/pasted-27.png" alt="upload successful"></p><a id="more"></a><p>$L-layer\quad NN$，则包含了<script type="math/tex">L-1</script>个隐藏层，最后的<script type="math/tex">L</script>层是输出层</p><p>$a^{[l]}$和<script type="math/tex">W^{[l]}</script>中的上标<script type="math/tex">l</script>都是从<script type="math/tex">1</script>开始的，<script type="math/tex">l=1,\cdots,L</script></p><p>输入<script type="math/tex">x</script>记为<script type="math/tex">a^{[0]}</script>​​，把输出层<script type="math/tex">\hat y</script>记为<script type="math/tex">a^{[L]}</script></p><p><img src="/images/pasted-28.png" alt="upload successful"></p><p>$X$：<script type="math/tex">(12288, 209)</script>(with <script type="math/tex">m=209</script> examples)</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center"><strong>Shape of W</strong></th><th style="text-align:center"><strong>Shape of b</strong></th><th style="text-align:center"><strong>Activation</strong></th><th style="text-align:center"><strong>Shape of Activation</strong></th></tr></thead><tbody><tr><td style="text-align:center"><strong>Layer 1</strong></td><td style="text-align:center"><script type="math/tex">(n^{[1]},12288)</script></td><td style="text-align:center"><script type="math/tex">(n^{[1]},1)</script></td><td style="text-align:center"><script type="math/tex">Z^{[1]} = W^{[1]} X + b^{[1]}</script></td><td style="text-align:center"><script type="math/tex">(n^{[1]},209)</script></td></tr><tr><td style="text-align:center"><strong>Layer 2</strong></td><td style="text-align:center"><script type="math/tex">(n^{[2]}, n^{[1]})</script></td><td style="text-align:center"><script type="math/tex">(n^{[2]},1)</script></td><td style="text-align:center"><script type="math/tex">Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}</script></td><td style="text-align:center"><script type="math/tex">(n^{[2]},209)</script></td></tr><tr><td style="text-align:center"><script type="math/tex">\vdots</script></td><td style="text-align:center"><script type="math/tex">\vdots</script></td><td style="text-align:center"><script type="math/tex">\vdots</script></td><td style="text-align:center"><script type="math/tex">\vdots</script></td><td style="text-align:center"><script type="math/tex">\vdots</script></td></tr><tr><td style="text-align:center"><strong>Layer L-1</strong></td><td style="text-align:center"><script type="math/tex">(n^{[L-1]}, n^{[L-2]})</script></td><td style="text-align:center"><script type="math/tex">(n^{[L-1]}, 1)</script></td><td style="text-align:center"><script type="math/tex">Z^{[L-1]} = W^{[L-1]} A^{[L-2]} + b^{[L-1]}</script></td><td style="text-align:center"><script type="math/tex">(n^{[L-1]}, 209)</script></td></tr><tr><td style="text-align:center"><strong>Layer L</strong></td><td style="text-align:center"><script type="math/tex">(n^{[L]}, n^{[L-1]})</script></td><td style="text-align:center"><script type="math/tex">(n^{[L]}, 1)</script></td><td style="text-align:center"><script type="math/tex">Z^{[L]} = W^{[L]} A^{[L-1]} + b^{[L]}</script></td><td style="text-align:center"><script type="math/tex">(n^{[L]}, 209)</script></td></tr></tbody></table></div><h2 id="4-2-前向传播和反向传播（Forward-and-backward-propagation）"><a href="#4-2-前向传播和反向传播（Forward-and-backward-propagation）" class="headerlink" title="4.2 前向传播和反向传播（Forward and backward propagation）"></a>4.2 前向传播和反向传播（Forward and backward propagation）</h2><h3 id="正向传播过程"><a href="#正向传播过程" class="headerlink" title="正向传播过程"></a>正向传播过程</h3><script type="math/tex; mode=display">z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}</script><script type="math/tex; mode=display">a^{[l]}=g^{[l]}(z^{[l]})</script><p>$m$个训练样本，向量化形式为：</p><script type="math/tex; mode=display">Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}</script><script type="math/tex; mode=display">A^{[l]}=g^{[l]}(Z^{[l]})</script><h3 id="反向传播过程"><a href="#反向传播过程" class="headerlink" title="反向传播过程"></a>反向传播过程</h3><script type="math/tex; mode=display">dz^{[l]}=da^{[l]}\ast g^{[l]'}(z^{[l]})</script><script type="math/tex; mode=display">dW^{[l]}=dz^{[l]}\cdot {a^{[l-1]}}^T</script><script type="math/tex; mode=display">db^{[l]}=dz^{[l]}</script><script type="math/tex; mode=display">da^{[l-1]}=W^{[l]T}\cdot dz^{[l]}</script><p>得到：</p><script type="math/tex; mode=display">dz^{[l]}=W^{[l+1]T}\cdot dz^{[l+1]}\ast g^{[l]'}(z^{[l]})</script><p>$m$个训练样本，向量化形式为：</p><script type="math/tex; mode=display">dZ^{[l]}=dA^{[l]}\ast g^{[l]'}(Z^{[l]})</script><script type="math/tex; mode=display">dW^{[l]}=\frac1mdZ^{[l]}\cdot A^{[l-1]T}</script><script type="math/tex; mode=display">db^{[l]}=\frac1mnp.sum(dZ^{[l]},axis=1,keepdim=True)</script><script type="math/tex; mode=display">dA^{[l-1]}=W^{[l]T}\cdot dZ^{[l]}</script><script type="math/tex; mode=display">dZ^{[l]}=W^{[l+1]T}\cdot dZ^{[l+1]}\ast g^{[l]'}(Z^{[l]})</script><p><img src="/images/pasted-29.png" alt="upload successful"></p><h2 id="4-3-深层网络中的前向传播（Forward-propagation-in-a-Deep-Network-）"><a href="#4-3-深层网络中的前向传播（Forward-propagation-in-a-Deep-Network-）" class="headerlink" title="4.3 深层网络中的前向传播（Forward propagation in a Deep Network ）"></a>4.3 深层网络中的前向传播（Forward propagation in a Deep Network ）</h2><p>对于第<script type="math/tex">l</script>层，其正向传播过程的<script type="math/tex">Z^{[l]}</script>和<script type="math/tex">A^{[l]}</script>可以表示为：</p><script type="math/tex; mode=display">Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}</script><script type="math/tex; mode=display">A^{[l]}=g^{[l]}(Z^{[l]})</script><p>其中<script type="math/tex">l=1,\cdots,L</script></p><h2 id="4-4-为什么使用深层表示？（Why-deep-representations-）"><a href="#4-4-为什么使用深层表示？（Why-deep-representations-）" class="headerlink" title="4.4 为什么使用深层表示？（Why deep representations?）"></a>4.4 为什么使用深层表示？（Why deep representations?）</h2><h3 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h3><p><img src="/images/pasted-30.png" alt="upload successful"><br>经过训练，神经网络第一层所做的事就是从原始图片中提取出人脸的轮廓与边缘，即<strong>边缘检测</strong>。这样每个神经元得到的是一些边缘信息。神经网络第二层所做的事情就是将前一层的边缘进行组合，组合成人脸一些局部特征，比如眼睛、鼻子、嘴巴等。再往后面，就将这些局部特征组合起来，融合成人脸的模样。</p><p>随着层数由浅到深，神经网络提取的特征也是从边缘到局部特征到整体，由简单到复杂。如果隐藏层足够多，那么能够提取的特征就越丰富、越复杂，模型的准确率就会越高。</p><h3 id="语音识别模型"><a href="#语音识别模型" class="headerlink" title="语音识别模型"></a>语音识别模型</h3><p>浅层的神经元能够检测一些简单的音调，较深的神经元能够检测出基本的音素，更深的神经元就能够检测出单词信息。如果网络够深，还能对短语、句子进行检测。</p><p>神经网络从左到右，神经元提取的特征从简单到复杂。特征复杂度与神经网络层数成正相关。特征越来越复杂，功能也越来越强大</p><p>深层网络另外一个优点:减少神经元个数，从而减少计算量</p><p>使用电路理论，计算逻辑输出：</p><script type="math/tex; mode=display">y=x_1\oplus x_2\oplus x_3\oplus\cdots\oplus x_n</script><p>对于这个逻辑运算，深度网络的结构是每层将前一层的两两单元进行异或，最后得到一个输出</p><p>整个深度网络的层数是<script type="math/tex">log_2(n)</script>，不包含输入层。总共使用的神经元个数为：</p><script type="math/tex; mode=display">1+2+\cdots+2^{log_2(n)-1}=1\cdot\frac{1-2^{log_2(n)}}{1-2}=2^{log_2(n)}-1=n-1</script><p>输入个数是<script type="math/tex">n</script>，这种深层网络所需的神经元个数仅仅是<script type="math/tex">n-1</script>个</p><p>如果不用深层网络，使用单个隐藏层，需要的神经元个数将是指数级别那么大。由于包含了所有的逻辑位（<script type="math/tex">0</script>和<script type="math/tex">1</script>），则需要<script type="math/tex">2^{n-1}</script>个神经元</p><p>处理同一逻辑问题，深层网络所需的神经元个数比浅层网络要少很多</p><h2 id="4-5-搭建神经网络块（Building-blocks-of-deep-neural-networks）"><a href="#4-5-搭建神经网络块（Building-blocks-of-deep-neural-networks）" class="headerlink" title="4.5 搭建神经网络块（Building blocks of deep neural networks）"></a>4.5 搭建神经网络块（Building blocks of deep neural networks）</h2><p>第<script type="math/tex">l</script>层的流程块图</p><p><img src="/images/pasted-31.png" alt="upload successful"></p><p>对于神经网络所有层，整体的流程块图正向传播过程和反向传播过程如下所示：</p><p><img src="/images/pasted-32.png" alt="upload successful"></p><p><img src="/images/pasted-33.png" alt="upload successful"></p><h2 id="4-6-参数-VS-超参数（Parameters-vs-Hyperparameters）"><a href="#4-6-参数-VS-超参数（Parameters-vs-Hyperparameters）" class="headerlink" title="4.6 参数 VS 超参数（Parameters vs Hyperparameters）"></a>4.6 参数 VS 超参数（Parameters vs Hyperparameters）</h2><p>神经网络中的参数是<script type="math/tex">W^{[l]}</script>和<script type="math/tex">b^{[l]}</script></p><p><strong>超参数</strong>则是例如学习速率<script type="math/tex">\alpha</script>，训练迭代次数<script type="math/tex">N</script>，神经网络层数<script type="math/tex">L</script>，各层神经元个数<script type="math/tex">n^{[l]}</script>，激活函数<script type="math/tex">g(z)</script>等</p><p>叫做超参数的原因是它们决定了参数<script type="math/tex">W^{[l]}</script>和<script type="math/tex">b^{[l]}</script>的值</p><p>如何设置最优的超参数：</p><p>通常的做法是选择超参数一定范围内的值，分别代入神经网络进行训练，测试<strong>cost function</strong>随着迭代次数增加的变化，根据结果选择<strong>cost function</strong>最小时对应的超参数值</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;4-1-深层神经网络（Deep-L-layer-neural-network）&quot;&gt;&lt;a href=&quot;#4-1-深层神经网络（Deep-L-layer-neural-network）&quot; class=&quot;headerlink&quot; title=&quot;4.1 深层神经网络（Deep L-layer neural network）&quot;&gt;&lt;/a&gt;4.1 深层神经网络（Deep L-layer neural network）&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/pasted-27.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第一周 机器学习策略（1）（ML strategy（1））(Course 3)</title>
    <link href="https://baozouai.com/2019/02/27/%E7%AC%AC%E4%B8%80%E5%91%A8-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%881%EF%BC%89%EF%BC%88ML-strategy%EF%BC%881%EF%BC%89%EF%BC%89-Course-3/"/>
    <id>https://baozouai.com/2019/02/27/第一周-机器学习（ML）策略（1）（ML-strategy（1））-Course-3/</id>
    <published>2019-02-27T12:49:53.000Z</published>
    <updated>2019-02-27T05:40:17.069Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-1-为什么是-ML-策略？（Why-ML-Strategy-）"><a href="#1-1-为什么是-ML-策略？（Why-ML-Strategy-）" class="headerlink" title="1.1 为什么是 ML 策略？（Why ML Strategy?）"></a>1.1 为什么是 ML 策略？（Why ML Strategy?）</h2><p>当最初得到一个深度神经网络模型时，希望从很多方面来对它进行优化，例如：</p><ul><li><p><strong>Collect more data</strong></p></li><li><p><strong>Collect more diverse training set</strong></p></li><li><p><strong>Train algorithm longer with gradient descent</strong></p></li><li><p><strong>Try Adam instead of gradient descent</strong></p><a id="more"></a></li><li><p><strong>Try bigger network</strong></p></li><li><p><strong>Try smaller network</strong></p></li><li><p><strong>Try dropout</strong></p></li><li><p><strong>Add L2 regularization</strong></p></li><li><p><strong>Network architecture: Activation functions, #hidden units…</strong></p></li></ul><p>可选择的方法很多、很复杂、繁琐。盲目选择、尝试不仅耗费时间而且可能收效甚微。因此，使用快速、有效的策略来优化机器学习模型是非常必要的。</p><h2 id="1-2-正交化（Orthogonalization）"><a href="#1-2-正交化（Orthogonalization）" class="headerlink" title="1.2 正交化（Orthogonalization）"></a>1.2 正交化（Orthogonalization）</h2><p>每次只调试一个参数，保持其它参数不变，使得到的模型某一性能改变是一种最常用的调参策略，称之为正交化方法（Orthogonalization）</p><p>Orthogonalization的核心在于每次调试一个参数只会影响模型的某一个性能</p><p>机器学习监督式学习模型大致分成四个独立的“功能”：</p><ul><li><p><strong>Fit training set well on cost function ，</strong>优化训练集可以通过使用更复杂NN，使用Adam等优化算法来实现</p></li><li><p><strong>Fit dev set well on cost function，</strong>优化验证集可以通过正则化，采用更多训练样本来实现</p></li><li><p><strong>Fit test set well on cost function，</strong>优化测试集可以通过使用更多的验证集样本来实现</p></li><li><p><strong>Performs well in real world，</strong>提升实际应用模型可以通过更换验证集，使用新的cost function来实现</p></li></ul><p>每一种“功能”对应不同的调节方法，是正交的</p><p>early stopping在模型功能调试中并不推荐使用。因为early stopping在提升验证集性能的同时降低了训练集的性能。即early stopping同时影响两个“功能”，不具有独立性、正交性</p><p><img src="/images/pasted-90.png" alt="upload successful"></p><h2 id="1-3-单一数字评估指标（Single-number-evaluation-metric）"><a href="#1-3-单一数字评估指标（Single-number-evaluation-metric）" class="headerlink" title="1.3 单一数字评估指标（Single number evaluation metric）"></a>1.3 单一数字评估指标（Single number evaluation metric）</h2><p>A和B模型的准确率（Precision）和召回率（Recall）分别如下：</p><p><img src="/images/pasted-91.png" alt="upload successful"></p><p>使用单值评价指标F1 Score来评价模型的好坏。F1 Score综合了Precision和Recall的大小：</p><script type="math/tex; mode=display">F1=\frac{2\cdot P\cdot R}{P+R}</script><p><img src="/images/pasted-92.png" alt="upload successful"></p><p>还可以使用平均值作为单值评价指标：</p><p><img src="/images/pasted-93.png" alt="upload successful"></p><blockquote><p>不同国家样本的错误率，计算平均性能，选择平均错误率最小的模型（C模型）</p></blockquote><p><img src="/images/pasted-94.png" alt="upload successful"></p><p><img src="/images/pasted-95.png" alt="upload successful"></p><h2 id="1-4-满足和优化指标（Satisficing-and-optimizing-metrics）"><a href="#1-4-满足和优化指标（Satisficing-and-optimizing-metrics）" class="headerlink" title="1.4 满足和优化指标（Satisficing and optimizing metrics）"></a>1.4 满足和优化指标（Satisficing and optimizing metrics）</h2><p>当把所有的性能指标都综合在一起，构成单值评价指标比较困难时：可以把某些性能作为优化指标（Optimizing metic），寻求最优化值；而某些性能作为满意指标（Satisficing metic），只要满足阈值就行</p><p><img src="/images/pasted-96.png" alt="upload successful"></p><p>Accuracy和Running time这两个性能不太合适综合成单值评价指标。可以将Accuracy作为优化指标（Optimizing metic），Running time作为满意指标（Satisficing metic）。给Running time设定一个阈值，在其满足阈值的情况下，选择Accuracy最大的模型。如果设定Running time必须在100ms以内，模型C不满足阈值条件，剔除；模型B相比较模型A而言，Accuracy更高，性能更好</p><p>如果要考虑N个指标，则选择一个指标为优化指标，其他N-1个指标都是满足指标：</p><script type="math/tex; mode=display">N_{metric}:\left\{ \begin{array}{l}1\qquad \qquad \qquad Optimizing\ metric\\N_{metric}-1\qquad Satisificing\ metric\end{array} \right.</script><p>性能指标（Optimizing metic）需要优化，越优越好；满意指标（Satisficing metic）只要满足设定的阈值</p><p><img src="/images/pasted-97.png" alt="upload successful"></p><h2 id="1-5-训练-开发-测试集划分（Train-dev-test-distributions）"><a href="#1-5-训练-开发-测试集划分（Train-dev-test-distributions）" class="headerlink" title="1.5 训练/开发/测试集划分（Train/dev/test distributions）"></a>1.5 训练/开发/测试集划分（Train/dev/test distributions）</h2><p>训练、开发、测试集选择设置的一些规则和意见：</p><ul><li>训练、开发、测试集的设置会对产品带来非常大的影响；</li><li>在选择<strong>开发集</strong>和<strong>测试集</strong>时要使二者来自同一分布，且从所有数据中随机选取；</li><li>所选择的开发集和测试集中的数据，要与未来想要或者能够得到的数据类似，即模型数据和未来数据要具有相似性；</li><li>设置的测试集只要足够大，使其能够在过拟合的系统中给出高方差的结果就可以，也许10000左右的数目足够；</li><li>设置开发集只要足够使其能够检测不同算法、不同模型之间的优劣差异就可以，百万大数据中1%的大小就足够；</li></ul><p>尽量保证dev sets和test sets来源于同一分布且都反映了实际样本的情况。如果dev sets和test sets不来自同一分布，从dev sets上选择的“最佳”模型往往不能够在test sets上表现得很好。好比在dev sets上找到最接近一个靶的靶心的箭，但是test sets提供的靶心却远远偏离dev sets上的靶心，结果肯定无法射中test sets上的靶心位置</p><p><img src="/images/pasted-98.png" alt="upload successful"></p><p><img src="/images/pasted-99.png" alt="upload successful"></p><h2 id="1-6-开发集和测试集的大小（Size-of-dev-and-test-sets）"><a href="#1-6-开发集和测试集的大小（Size-of-dev-and-test-sets）" class="headerlink" title="1.6 开发集和测试集的大小（Size of dev and test sets）"></a>1.6 开发集和测试集的大小（Size of dev and test sets）</h2><ul><li>样本数量不多（小于一万）的时候，通常将Train/dev/test sets的比例设为60%/20%/20%</li><li>没有dev sets的情况下，Train/test sets的比例设为70%/30%</li><li>样本数量很大（百万级别）的时候，通常将相应的比例设为98%/1%/1%或者99%/1%</li></ul><p>dev sets数量的设置，遵循的准则是通过dev sets能够检测不同算法或模型的区别，以便选择出更好的模型</p><p>test sets数量的设置，遵循的准则是通过test sets能够反映出模型在实际中的表现</p><p>实际应用中，可能只有train/dev sets，而没有test sets。这种情况也是允许的，只要算法模型没有对dev sets过拟合。但条件允许的话，最好有test sets，实现无偏估计</p><p><img src="/images/pasted-100.png" alt="upload successful"></p><p><img src="/images/pasted-101.png" alt="upload successful"></p><h2 id="1-7-什么时候该改变开发-测试集和指标？（When-to-change-dev-test-sets-and-metrics）"><a href="#1-7-什么时候该改变开发-测试集和指标？（When-to-change-dev-test-sets-and-metrics）" class="headerlink" title="1.7 什么时候该改变开发/测试集和指标？（When to change dev/test sets and metrics）"></a>1.7 什么时候该改变开发/测试集和指标？（When to change dev/test sets and metrics）</h2><p>算法模型的评价标准有时候需要根据实际情况进行动态调整，目的是让算法模型在实际应用中有更好的效果</p><h3 id="example1"><a href="#example1" class="headerlink" title="example1"></a>example1</h3><p>假设有两个猫的图片的分类器：</p><ul><li>评估指标：分类错误率</li><li>算法A：3%错误率</li><li>算法B：5%错误率</li></ul><p>初始的评价标准是错误率，A更好一些。实际使用时发现算法A会通过一些色情图片，但是B没有。从用户的角度来说，更倾向选择B模型，虽然B的错误率高一些。这时候需要改变之前只使用错误率作为评价标准，考虑新的情况进行改变。如增加色情图片的权重，增加其代价</p><p>假设开始的评估指标如下：</p><script type="math/tex; mode=display">Error = \dfrac{1}{m_{dev}}\sum\limits_{i=1}^{m_{dev}}I\{y^{(i)}_{pred}\neq y^{(i)}\}</script><p>该评估指标对色情图片和非色情图片一视同仁</p><p>修改的方法，在其中加入权重<script type="math/tex">w^{(i)}</script>：</p><script type="math/tex; mode=display">Error = \dfrac{1}{\sum w^{(i)}}\sum\limits_{i=1}^{m_{dev}} w^{(i)}I\{y^{(i)}_{pred}\neq y^{(i)}\}</script><script type="math/tex; mode=display">w^{(i)}=\begin{cases}1, & x^{(i)}\ is\ non-porn\\10 \ or\ 100, & x^{(i)}\ is\ porn\end{cases}</script><p>通过设置权重，当算法将色情图片分类为猫时，误差项会快速变大</p><p>概括来说，机器学习可分为两个过程：</p><ul><li><p><strong>Define a metric to evaluate classifiers</strong></p></li><li><p><strong>How to do well on this metric</strong></p></li></ul><p>第一步是找靶心，第二步是通过训练，射中靶心。但是在训练的过程中可能会根据实际情况改变算法模型的评价标准，进行动态调整,如果评估指标无法正确评估算法的排名，则需要重新定义一个新的评估指标</p><h3 id="example2"><a href="#example2" class="headerlink" title="example2"></a>example2</h3><p>对example1中的两个不同的猫图片的分类器A和B：</p><p><img src="/images/pasted-102.png" alt="upload successful"></p><p>实际情况是一直使用网上下载的高质量的图片进行训练；当部署到手机上时，由于图片的清晰度及拍照水平的原因，当实际测试算法时，会发现算法B的表现其实更好</p><p>如果在训练开发测试的过程中得到的模型效果比较好，但是在实际应用中所真正关心的问题效果却不好的时候，就需要改变开发、测试集或者评估指标</p><p><strong>Guideline：</strong></p><ol><li>定义正确的评估指标来更好的给分类器的好坏进行排序</li><li>优化评估指标</li></ol><p><img src="/images/pasted-103.png" alt="upload successful"></p><p><img src="/images/pasted-104.png" alt="upload successful"></p><h2 id="1-8-为什么是人的表现？（-Why-human-level-performance-）"><a href="#1-8-为什么是人的表现？（-Why-human-level-performance-）" class="headerlink" title="1.8 为什么是人的表现？（ Why human-level performance?）"></a>1.8 为什么是人的表现？（ Why human-level performance?）</h2><p>机器学习模型的表现通常会跟人类水平表现作比较：</p><p><img src="/images/pasted-105.png" alt="upload successful"></p><p>当开始往人类水平努力时，进展很快，机器学习模型经过训练会不断接近human-level performance甚至超过它。超过之后，准确性会上升得比较缓慢，当继续训练算法时，可能模型越来越大，数据越来越多，但是性能无法超过某个理论上限，这就是所谓的贝叶斯最优错误率（<strong>Bayes optimal error</strong>）。理论上任何模型都不能超过它，即没有任何办法设计出一个<script type="math/tex">x</script>到<script type="math/tex">y</script>的函数，让它能够超过一定的准确度，bayes optimal error代表了<strong>最佳</strong>表现</p><p>对于语音识别来说，如果<script type="math/tex">x</script>是音频片段，有些音频很嘈杂，基本不可能知道说的是什么，所以完美的准确率可能不是100%。对于猫图识别来说，也许一些图像非常模糊，不管是人类还是机器，都无法判断该图片中是否有猫。所以完美的准确度可能不是100</p><p>贝叶斯最优错误率有时写作<strong>Bayesian</strong>，即<strong>省略optimal</strong>，就是从<script type="math/tex">x</script>到<script type="math/tex">y</script>映射的理论最优函数，永远不会被超越。，无论在一个问题上工作多少年，紫色线永远不会超越贝叶斯错误率，贝叶斯最佳错误率</p><p><img src="/images/pasted-106.png" alt="upload successful"></p><p>机器学习的进展直到超越人类的表现之前一直很快，当超越时，有时进展会变慢。有两个原因：</p><ul><li><p>人类水平在很多任务中离贝叶斯最优错误率已经不远</p></li><li><p>只要表现比人类的表现更差，可以使用某些工具来提高性能。一旦超越了人类的表现，这些工具就没那么好用</p></li></ul><p>只要人类的表现比任何其他算法都要好，就可以让人类看看算法处理的例子，知道错误出在哪里，并尝试了解为什么人能做对，算法做错</p><p><img src="/images/pasted-107.png" alt="upload successful"></p><p><img src="/images/pasted-108.png" alt="upload successful"></p><h2 id="1-9-可避免偏差（Avoidable-bias）"><a href="#1-9-可避免偏差（Avoidable-bias）" class="headerlink" title="1.9 可避免偏差（Avoidable bias）"></a>1.9 可避免偏差（Avoidable bias）</h2><p>猫分类器:</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/bbeeddabb1800e91b1460deade38e756.png" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/bbeeddabb1800e91b1460deade38e756.png" alt></a></p><p>人类具有近乎完美的准确度，人类水平的错误是1%,如果学习算法达到8%的训练错误率和10%的开发错误率，算法在训练集上的表现和人类水平的表现有很大差距，说明算法对训练集的拟合并不好。从减少偏差和方差这个角度看，把重点放在减少偏差上。比如训练更大的神经网络，跑久一点梯度下降，试试能不能在训练集上做得更好</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/e94444af122172eecf5df8bdca435d1d.png" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/e94444af122172eecf5df8bdca435d1d.png" alt></a></p><p>同样的训练错误率和开发错误率，假设人类水平错误实际上是7.5%，系统在训练集上的表现还好，只比人类的表现差一点。在第二个例子中，应专注减少学习算法的方差，可以试试正则化，让开发错误率更接近训练错误率</p><p>用人类水平的错误率估计或代替贝叶斯错误率或贝叶斯最优错误率，对于计算机视觉任务而言，这样替代相当合理，因为人类非常擅长计算机视觉任务，人类能做到的水平和贝叶斯错误率相差不远</p><p><a href="https://github.com/fengdu78/deeplearning_ai_books/blob/master/images/ac8eb51425d5dbf663d050398f7e8af8.png" target="_blank" rel="noopener"><br><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ac8eb51425d5dbf663d050398f7e8af8.png" alt></a></p><p>左边的例子8%的训练错误率真的很高，可以把它降到1%，减少偏差的手段可能有效。右边的例子中，如果认为贝叶斯错误率是7.5%，这里使用人类水平错误率来替代贝叶斯错误率，就知道没有太多改善的空间了，不能继续减少训练错误率，训练误差和开发误差之间有更多的改进空间，可以将这个2%的差距缩小一点，使用减少方差的手段，比如正则化，或者收集更多的训练数据</p><p>贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为<strong>可避免偏差</strong></p><p>理论上是不可能超过贝叶斯错误率的，除非过拟合</p><p>训练错误率和开发错误率之前的差值，说明算法在方差问题上还有多少改善空间</p><p><img src="/images/pasted-109.png" alt="upload successful"></p><p><img src="/images/pasted-110.png" alt="upload successful"></p><h2 id="1-10-理解人的表现（Understanding-human-level-performance）"><a href="#1-10-理解人的表现（Understanding-human-level-performance）" class="headerlink" title="1.10 理解人的表现（Understanding human-level performance）"></a>1.10 理解人的表现（Understanding human-level performance）</h2><p>医学图像识别的例子：</p><p><img src="/images/pasted-111.png" alt="upload successful"></p><p>在减小误诊率的背景下，人类水平误差在这种情形下应定义为：0.5% error。但是实际应用中，不同人可能选择的human-level performance基准是不同的，这会带来一些影响</p><p>如果在为了部署系统或者做研究分析的背景下，也许超过一名普通医生即可，即人类水平误差在这种情形下应定义为：1% error</p><p>假如该模型training error为0.7%，dev error为0.8。如果选择Team of experienced doctors，即human-level error为0.5%，则bias比variance更加突出。如果选择Experienced doctor，即human-level error为0.7%，则variance更加突出。选择什么样的human-level error，有时候会影响bias和variance值的相对变化。当然这种情况一般只会在模型表现很好，接近bayes optimal error的时候出现。越接近bayes optimal error，模型越难继续优化，因为这时候的human-level performance可能是比较模糊难以准确定义的</p><p><img src="/images/pasted-112.png" alt="upload successful"></p><p><img src="/images/pasted-113.png" alt="upload successful"></p><p><img src="/images/pasted-114.png" alt="upload successful"></p><h2 id="1-11-超过人的表现（Surpassing-human-level-performance）"><a href="#1-11-超过人的表现（Surpassing-human-level-performance）" class="headerlink" title="1.11 超过人的表现（Surpassing human- level performance）"></a>1.11 超过人的表现（Surpassing human- level performance）</h2><p>对于自然感知类问题，例如视觉、听觉等，机器学习的表现不及人类。但是在很多其它方面，机器学习模型的表现已经超过人类了，包括：</p><ul><li><p><strong>Online advertising</strong></p></li><li><p><strong>Product recommendations</strong></p></li></ul><ul><li><p><strong>Logistics(predicting transit time)</strong></p></li><li><p><strong>Loan approvals</strong></p></li></ul><p>机器学习模型超过human-level performance是比较困难的。但是只要提供足够多的样本数据，训练复杂的神经网络，模型预测准确性会大大提高，很有可能接近甚至超过human-level performance。值得一提的是当算法模型的表现超过human-level performance时，很难再通过人的直觉来解决如何继续提高算法模型性能的问题</p><p><img src="/images/pasted-115.png" alt="upload successful"></p><p><img src="/images/pasted-116.png" alt="upload successful"></p><h2 id="1-12-改善你的模型的表现（Improving-your-model-performance）"><a href="#1-12-改善你的模型的表现（Improving-your-model-performance）" class="headerlink" title="1.12 改善你的模型的表现（Improving your model performance）"></a>1.12 改善你的模型的表现（Improving your model performance）</h2><p>提高机器学习模型性能主要要解决两个问题：avoidable bias和variance。training error与human-level error之间的差值反映的是avoidable bias，dev error与training error之间的差值反映的是variance</p><p><strong>基本假设：</strong></p><ul><li>模型在训练集上有很好的表现；</li><li>模型推广到开发和测试集啥也有很好的表现</li></ul><p><strong>减少可避免偏差</strong></p><ul><li>训练更大的模型</li><li>训练更长时间、训练更好的优化算法（Momentum、RMSprop、Adam）</li><li>寻找更好的网络架构（RNN、CNN）、寻找更好的超参数</li></ul><p><strong>减少方差</strong></p><ul><li>收集更多的数据</li><li>正则化（L2、dropout、数据增强）</li><li>寻找更好的网络架构（RNN、CNN）、寻找更好的超参数</li></ul><p><img src="/images/pasted-117.png" alt="upload successful"></p><p><img src="/images/pasted-118.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-1-为什么是-ML-策略？（Why-ML-Strategy-）&quot;&gt;&lt;a href=&quot;#1-1-为什么是-ML-策略？（Why-ML-Strategy-）&quot; class=&quot;headerlink&quot; title=&quot;1.1 为什么是 ML 策略？（Why ML Strategy?）&quot;&gt;&lt;/a&gt;1.1 为什么是 ML 策略？（Why ML Strategy?）&lt;/h2&gt;&lt;p&gt;当最初得到一个深度神经网络模型时，希望从很多方面来对它进行优化，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Collect more data&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Collect more diverse training set&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Train algorithm longer with gradient descent&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Try Adam instead of gradient descent&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第二周：优化算法 (Optimization algorithms)(Course 2)</title>
    <link href="https://baozouai.com/2019/02/27/%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9A%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-Optimization-algorithms-Course-2/"/>
    <id>https://baozouai.com/2019/02/27/第二周：优化算法-Optimization-algorithms-Course-2/</id>
    <published>2019-02-27T11:20:37.000Z</published>
    <updated>2019-02-27T05:39:24.809Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-1-Mini-batch-梯度下降（Mini-batch-gradient-descent）"><a href="#2-1-Mini-batch-梯度下降（Mini-batch-gradient-descent）" class="headerlink" title="2.1 Mini-batch 梯度下降（Mini-batch gradient descent）"></a>2.1 Mini-batch 梯度下降（Mini-batch gradient descent）</h2><p>神经网络训练过程是同时对所有m个样本（称为batch）通过向量化计算方式进行的。如果m很大，训练速度会很慢，因为每次迭代都要对所有样本进进行求和运算和矩阵运算。这种梯度下降算法称为Batch Gradient Descent<br><a id="more"></a><br>解决：</p><p>把m个训练样本分成若干个子集，称为mini-batches，然后每次在单一子集上进行神经网络训练，这种梯度下降算法叫做Mini-batch Gradient Descent</p><p>假设总的训练样本个数<script type="math/tex">m=5000000</script>，其维度为<script type="math/tex">(n_x,m)</script>。将其分成5000个子集，每个mini-batch含有1000个样本。将每个mini-batch记为<script type="math/tex">X^{\{t\}}</script>，其维度为<script type="math/tex">(n_x,1000)</script>。相应的每个mini-batch的输出记为<script type="math/tex">Y^{\{t\}}</script>，其维度为(1,1000)，且<script type="math/tex">t=1,2,\cdots,5000</script></p><ul><li><script type="math/tex">X^{(i)}</script><strong>：第i个样本</strong></li><li><script type="math/tex">Z^{[l]}</script>：<strong>神经网络第</strong><script type="math/tex">l</script><strong>层网络的线性输出</strong></li><li><script type="math/tex">X^{\{t\}},Y^{\{t\}}</script><strong>：第t组mini-batch</strong></li></ul><p>Mini-batches Gradient Descent是先将总的训练样本分成T个子集（mini-batches），然后对每个mini-batch进行神经网络训练，包括Forward Propagation，Compute Cost Function，Backward Propagation，循环至T个mini-batch都训练完毕</p><script type="math/tex; mode=display">for\ \ t=1,\cdots,T\ \ \{</script><script type="math/tex; mode=display">\ \ \ \ Forward\ Propagation</script><script type="math/tex; mode=display">\ \ \ \ Compute\ Cost\ Function</script><script type="math/tex; mode=display">\ \ \ \ Backward\ Propagation</script><script type="math/tex; mode=display">\ \ \ \ W:=W-\alpha\cdot dW</script><script type="math/tex; mode=display">\ \ \ \ b:=b-\alpha\cdot db</script><script type="math/tex; mode=display">\}</script><p>经过T次循环之后，所有m个训练样本都进行了梯度下降计算。这个过程称之为经历了一个epoch。对于Batch Gradient Descent而言，一个epoch只进行一次梯度下降算法；而Mini-Batches Gradient Descent，一个epoch会进行T次梯度下降算法</p><p>对于Mini-Batches Gradient Descent，可以进行多次epoch训练。每次epoch，最好是将总体训练数据打乱、重新分成T组mini-batches，这样有利于训练出最佳的神经网络模型</p><h2 id="2-2-理解-mini-batch-梯度下降法（Understanding-mini-batch-gradient-descent）"><a href="#2-2-理解-mini-batch-梯度下降法（Understanding-mini-batch-gradient-descent）" class="headerlink" title="2.2 理解 mini-batch 梯度下降法（Understanding mini-batch gradient descent）"></a>2.2 理解 mini-batch 梯度下降法（Understanding mini-batch gradient descent）</h2><p>Batch gradient descent和Mini-batch gradient descent的cost曲线：</p><p><img src="/images/pasted-51.png" alt="upload successful"><br>对于一般的神经网络模型，使用Batch gradient descent，随着迭代次数增加，cost是不断减小的。而使用Mini-batch gradient descent，随着在不同的mini-batch上迭代训练，其cost不是单调下降，而是受类似noise的影响，出现振荡。但整体的趋势是下降的，最终也能得到较低的cost值</p><p>出现细微振荡的原因是不同的mini-batch之间是有差异的。可能第一个子集<script type="math/tex">(X^{\{1\}},Y^{\{1\}})</script>是好的子集，而第二个子集<script type="math/tex">(X^{\{2\}},Y^{\{2\}})</script>包含了一些噪声noise。出现细微振荡是正常的</p><p>如果mini-batch size=m，即为Batch gradient descent，只包含一个子集为<script type="math/tex">(X^{\{1\}},Y^{\{1\}})=(X,Y)</script>；</p><p>如果mini-batch size=1，即为Stachastic gradient descent，每个样本就是一个子集<script type="math/tex">(X^{\{1\}},Y^{\{1\}})=(x^{(i)},y^{(i)})</script>，共有m个子集</p><p>蓝色的线代表Batch gradient descent，紫色的线代表Stachastic gradient descent。Batch gradient descent会比较平稳地接近全局最小值，但因为使用了所有m个样本，每次前进的速度有些慢。Stachastic gradient descent每次前进速度很快，但路线曲折，有较大的振荡，最终会在最小值附近来回波动，难达到最小值。而且在数值处理上不能使用向量化的方法来提高运算速度</p><p><img src="/images/pasted-52.png" alt="upload successful"></p><p><img src="/images/pasted-53.png" alt="upload successful"></p><p>mini-batch size不能设置得太大（Batch gradient descent），也不能设置得太小（Stachastic gradient descent）。相当于结合了Batch gradient descent和Stachastic gradient descent各自的优点，既能使用向量化优化算法，又能较快速地找到最小值。mini-batch gradient descent的梯度下降曲线如下图绿色所示，每次前进速度较快，且振荡较小，基本能接近全局最小值。</p><p><img src="/images/pasted-54.png" alt="upload successful"></p><p><img src="/images/pasted-55.png" alt="upload successful"></p><ul><li>总体样本数量m不太大时，例如<script type="math/tex">m\leq2000</script>，建议直接使用Batch gradient descent</li><li>总体样本数量m很大时，建议将样本分成许多mini-batches。推荐常用的mini-batch size为64,128,256,512。都是2的幂。原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度</li><li><strong> </strong>mini-batch 中确保 <script type="math/tex">X{\{t\}}</script> 和<script type="math/tex">Y{\{t\}}</script>要符合 CPU/GPU 内存，取决于应用方向以及训练集的大小。如果处理的 mini-batch 和 CPU/GPU 内存不相符，不管用什么方法处理数据，算法的表现都急转直下变得惨不忍睹</li></ul><h3 id="从训练集（X，Y）中构建小批量"><a href="#从训练集（X，Y）中构建小批量" class="headerlink" title="从训练集（X，Y）中构建小批量"></a>从训练集（X，Y）中构建小批量</h3><ul><li>随机洗牌（<strong>Shuffle</strong>）：创建训练集（X，Y）的混洗版本，X和Y的每一列代表一个训练示例。随机混洗是在X和Y之间同步完成的。这样在混洗之后第<script type="math/tex">i</script>列的X对应的例子就是Y第<script type="math/tex">i</script>列中的标签。混洗步骤可确保将示例随机分成不同的小批次</li></ul><p><img src="/images/pasted-57.png" alt="upload successful"></p><ul><li>分区（<strong>Partition</strong>）：将混洗（X，Y）分区为小批量mini_batch_size（此处为64）。训练示例的数量并非总是可以被mini_batch_size整除。最后一个小批量可能会更小</li></ul><p><img src="/images/pasted-58.png" alt="upload successful"></p><h2 id="2-3-指数加权平均数（Exponentially-weighted-averages）"><a href="#2-3-指数加权平均数（Exponentially-weighted-averages）" class="headerlink" title="2.3 指数加权平均数（Exponentially weighted averages）"></a>2.3 指数加权平均数（Exponentially weighted averages）</h2><p>半年内伦敦市的气温变化：</p><p><img src="/images/pasted-59.png" alt="upload successful"></p><blockquote><p>温度数据有noise，抖动较大</p></blockquote><p>如果希望看到半年内气温的整体变化趋势，可以通过移动平均（moving average）的方法来对每天气温进行平滑处理</p><p>设<script type="math/tex">V_0=0</script>，当成第0天的气温值</p><p>第一天的气温与第0天的气温有关：</p><script type="math/tex; mode=display">V_1=0.9V_0+0.1\theta_1</script><p>第二天的气温与第一天的气温有关：</p><script type="math/tex; mode=display">\begin{aligned}V_2=&0.9V_1+0.1\theta_2\\=&0.9(0.9V_0+0.1\theta_1)+0.1\theta_2\\=&0.9^2V_0+0.9\cdot0.1\theta_1+0.1\theta_2\end{aligned}</script><p>第三天的气温与第二天的气温有关：</p><script type="math/tex; mode=display">\begin{aligned}V_3=&0.9V_2+0.1\theta_3\\=&0.9(0.9^2V_0+0.9\cdot0.1\theta_1+0.1\theta_2)+0.1\theta_3\\=&0.9^3V_0+0.9^2\cdot 0.1\theta_1+0.9\cdot 0.1\theta_2+0.1\theta_3\end{aligned}</script><p>第<script type="math/tex">t</script>天与第<script type="math/tex">t-1</script>天的气温迭代关系为：</p><script type="math/tex; mode=display">\begin{aligned}V_t=&0.9V_{t-1}+0.1\theta_t\\=&0.9^tV_0+0.9^{t-1}\cdot0.1\theta_1+0.9^{t-2}\cdot 0.1\theta_2+\cdots+0.9\cdot0.1\theta_{t-1}+0.1\theta_t\end{aligned}</script><p>经过移动平均处理得到的气温如下图红色曲线所示：</p><p><img src="/images/pasted-60.png" alt="upload successful"><br>这种滑动平均算法称为指数加权平均（exponentially weighted average）。一般形式为：</p><script type="math/tex; mode=display">V_t=\beta V_{t-1}+(1-\beta)\theta_t</script><p>$\beta$值决定了指数加权平均的天数，近似表示为：</p><script type="math/tex; mode=display">\frac{1}{1-\beta}</script><p>当<script type="math/tex">\beta=0.9</script>，则<script type="math/tex">\frac{1}{1-\beta}=10</script>，表示将前10天进行指数加权平均。当<script type="math/tex">\beta=0.98</script>，则<script type="math/tex">\frac{1}{1-\beta}=50</script>，表示将前50天进行指数加权平均。<script type="math/tex">\beta</script>值越大，则指数加权平均的天数越多，平均后的趋势线就越平缓，但是同时也会向右平移</p><p>绿色曲线和黄色曲线分别表示了<script type="math/tex">\beta=0.98</script>和<script type="math/tex">\beta=0.5</script>时，指数加权平均的结果</p><p><img src="/images/pasted-61.png" alt="upload successful"></p><h2 id="2-4-理解指数加权平均数（Understanding-exponentially-weighted-averages-）"><a href="#2-4-理解指数加权平均数（Understanding-exponentially-weighted-averages-）" class="headerlink" title="2.4 理解指数加权平均数（Understanding exponentially weighted averages ）"></a>2.4 理解指数加权平均数（Understanding exponentially weighted averages ）</h2><p>指数加权平均公式的一般形式：</p><script type="math/tex; mode=display">\begin{aligned}V_t=&\beta V_{t-1}+(1-\beta)\theta_t\\=&(1-\beta)\theta_t+(1-\beta)\cdot\beta\cdot\theta_{t-1}+(1-\beta)\cdot \beta^2\cdot\theta_{t-2}+\cdots+(1-\beta)\cdot \beta^{t-1}\cdot \theta_1+\beta^t\cdot V_0\end{aligned}</script><p>$\theta_t,\theta_{t-1},\theta_{t-2},\cdots,\theta_1$是原始数据值，<script type="math/tex">(1-\beta),(1-\beta)\beta,(1-\beta)\beta^2,\cdots,(1-\beta)\beta^{t-1}</script>是类似指数曲线，从右向左，呈指数下降的。<script type="math/tex">V_t</script> 的值是这两个子式的点乘，将原始数据值与衰减指数点乘，相当于做了指数衰减，离得越近，影响越大，离得越远，影响越小，衰减越厉害</p><p><img src="/images/pasted-62.png" alt="upload successful"></p><p>为了减少内存的使用，使用这样的语句来实现指数加权平均算法：</p><script type="math/tex; mode=display">V_{\theta}=0</script><script type="math/tex; mode=display">Repeat\ \{</script><script type="math/tex; mode=display">\ \ \ \ Get\ next\ \theta_t</script><script type="math/tex; mode=display">\ \ \ \ V_{\theta}:=\beta V_{\theta}+(1-\beta)\theta_t</script><script type="math/tex; mode=display">\}</script><h2 id="2-5-指-数-加-权-平-均-的-偏-差-修-正-（-Bias-correction-inexponentially-weighted-averages-）"><a href="#2-5-指-数-加-权-平-均-的-偏-差-修-正-（-Bias-correction-inexponentially-weighted-averages-）" class="headerlink" title="2.5 指 数 加 权 平 均 的 偏 差 修 正 （ Bias correction inexponentially weighted averages ）"></a>2.5 指 数 加 权 平 均 的 偏 差 修 正 （ Bias correction inexponentially weighted averages ）</h2><p>当<script type="math/tex">\beta=0.98</script>时，指数加权平均结果如绿色曲线。但实际上真实曲线如紫色曲线</p><p><img src="/images/pasted-63.png" alt="upload successful"></p><p>紫色曲线与绿色曲线的区别是，紫色曲线开始的时候相对较低一些。因为开始时设置<script type="math/tex">V_0=0</script>，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常</p><p>修正这种问题的方法是进行<strong>偏移校正（bias correction）</strong>，即在每次计算完<script type="math/tex">V_t</script>后，对<script type="math/tex">V_t</script>进行下式处理：</p><script type="math/tex; mode=display">\frac{V_t}{1-\beta^t}</script><p>刚开始的时候，<script type="math/tex">t</script>比较小，<script type="math/tex">(1-\beta^t)<1</script>,<script type="math/tex">V_t</script>被修正得更大一些，效果是把紫色曲线开始部分向上提升一些，与绿色曲线接近重合。随着<script type="math/tex">t</script>增大，<script type="math/tex">(1-\beta^t)\approx1</script>，<script type="math/tex">V_t</script>基本不变，紫色曲线与绿色曲线依然重合。实现了简单的偏移校正，得到希望的绿色曲线</p><p>机器学习中，偏移校正并不是必须的。因为，在迭代一次次数后（<script type="math/tex">t</script>较大），<script type="math/tex">V_t</script>受初始值影响微乎其微，紫色曲线与绿色曲线基本重合。一般可以忽略初始迭代过程，等到一定迭代之后再取值就不需要进行偏移校正</p><h2 id="2-6-动量梯度下降法（Gradient-descent-with-Momentum-）"><a href="#2-6-动量梯度下降法（Gradient-descent-with-Momentum-）" class="headerlink" title="2.6 动量梯度下降法（Gradient descent with Momentum ）"></a>2.6 动量梯度下降法（Gradient descent with Momentum ）</h2><p>动量梯度下降算法速度比传统的梯度下降算法快很多。做法是在每次训练时，对梯度进行指数加权平均处理，然后用得到的梯度值更新权重<script type="math/tex">W</script>和常数项<script type="math/tex">b</script></p><p><img src="/images/pasted-64.png" alt="upload successful"></p><p>原始的梯度下降算法如上图蓝色折线所示。在梯度下降过程中，梯度下降的振荡较大，尤其对于<script type="math/tex">W</script>、<script type="math/tex">b</script>之间数值范围差别较大的情况。此时每一点处的梯度只与当前方向有关，产生类似折线的效果，前进缓慢。而如果对梯度进行指数加权平均，使当前梯度不仅与当前方向有关，还与之前的方向有关，在纵轴方向，<br>平均过程中，正负数相互抵消，所以平均值接近于零。但在横轴方向，所<br>有的微分都指向横轴方向，因此横轴方向的平均值仍然较大，用算法几次迭代后，最终纵轴方向的摆动变小了，横轴方向运动更快，因此算法走了一<br>条更加直接的路径，在抵达最小值的路上减少了摆动，这样处理让梯度前进方向更加平滑，减少振荡，能够更快地到达最小值处</p><p>权重<script type="math/tex">W</script>和常数项<script type="math/tex">b</script>的指数加权平均表达式如下：</p><script type="math/tex; mode=display">V_{dW}=\beta\cdot V_{dW}+(1-\beta)\cdot dW</script><script type="math/tex; mode=display">V_{db}=\beta\cdot V_{db}+(1-\beta)\cdot db</script><p>动量的角度来看，以权重<script type="math/tex">W</script>为例，<script type="math/tex">V_{dW}</script>可以理解成速度<script type="math/tex">V</script>，<script type="math/tex">dW</script>可以看成是加速度<script type="math/tex">a</script>。指数加权平均实际上是计算当前的速度，当前速度由之前的速度和现在的加速度共同影响。而<script type="math/tex">\beta<1</script>又能限制速度<script type="math/tex">V_{dW}</script>过大。即当前的速度是渐变的，而不是瞬变的，是动量的过程。保证了梯度下降的平稳性和准确性，减少振荡，较快地达到最小值处</p><p>动量梯度下降算法的过程如下：</p><script type="math/tex; mode=display">On\ iteration\ t:</script><script type="math/tex; mode=display">\ \ \ \ Compute\ dW,\ db\ on\ the\ current\ mini-batch</script><script type="math/tex; mode=display">\ \ \ \ V_{dW}=\beta V_{dW}+(1-\beta)dW</script><script type="math/tex; mode=display">\ \ \ \ V_{db}=\beta V_{db}+(1-\beta)db</script><script type="math/tex; mode=display">\ \ \ \ W=W-\alpha V_{dW},\ b=b-\alpha V_{db}</script><p>初始时，令<script type="math/tex">V_{dW}=0,V_{db}=0</script>。一般设置<script type="math/tex">\beta=0.9</script>，即指数加权平均前10次的数据，实际应用效果较好。</p><p>偏移校正可以不使用。因为经过10次迭代后，随着滑动平均的过程，偏移情况会逐渐消失</p><h2 id="2-7-RMSprop-root-mean-square-prop"><a href="#2-7-RMSprop-root-mean-square-prop" class="headerlink" title="2.7 RMSprop(root mean square prop)"></a>2.7 RMSprop(root mean square prop)</h2><p>RMSprop是另外一种优化梯度下降速度的算法。每次迭代训练过程中，其权重<script type="math/tex">W</script>和常数项<script type="math/tex">b</script>的更新表达式为：</p><script type="math/tex; mode=display">S_{dW}=\beta S_{dW}+(1-\beta)dW^2</script><script type="math/tex; mode=display">S_{db}=\beta S_{db}+(1-\beta)db^2</script><script type="math/tex; mode=display">W:=W-\alpha \frac{dW}{\sqrt{S_{dW}}},\ b:=b-\alpha \frac{db}{\sqrt{S_{db}}}</script><h3 id="RMSprop算法的原理解释"><a href="#RMSprop算法的原理解释" class="headerlink" title="RMSprop算法的原理解释"></a>RMSprop算法的原理解释</h3><p>令水平方向为<script type="math/tex">W</script>的方向，垂直方向为<script type="math/tex">b</script>的方向</p><p><img src="/images/pasted-65.png" alt="upload successful"></p><p>梯度下降（蓝色折线）在垂直方向（<script type="math/tex">b</script>）上振荡较大，在水平方向（<script type="math/tex">W</script>）上振荡较小，表示在<script type="math/tex">b</script>方向上梯度较大，即<script type="math/tex">db</script>较大，而在<script type="math/tex">W</script>方向上梯度较小，即<script type="math/tex">dW</script>较小。因此，上述表达式中<script type="math/tex">S_{db}</script>较大，而<script type="math/tex">S_{dW}</script>较小。在更新<script type="math/tex">W</script>和<script type="math/tex">b</script>的表达式中，变化值<script type="math/tex">\frac{dW}{\sqrt{S_{dW}}}</script>较大，而<script type="math/tex">\frac{db}{\sqrt{S_{db}}}</script>较小。也就使得<script type="math/tex">W</script>变化得多一些，<script type="math/tex">b</script>变化得少一些。即加快了<script type="math/tex">W</script>方向的速度，减小了<script type="math/tex">b</script>方向的速度，减小振荡，实现快速梯度下降算法，其梯度下降过程如绿色折线所示。总的来说，就是如果哪个方向振荡大，就减小该方向的更新速度，从而减小振荡</p><p>为了避免RMSprop算法中分母为零，通常可以在分母增加一个极小的常数<script type="math/tex">\varepsilon</script>：</p><script type="math/tex; mode=display">W:=W-\alpha \frac{dW}{\sqrt{S_{dW}}+\varepsilon},\ b:=b-\alpha \frac{db}{\sqrt{S_{db}}+\varepsilon}</script><p>$\varepsilon=10^{-8}$，或者其它较小值</p><h2 id="2-8-Adam-优化算法-Adam-optimization-algorithm"><a href="#2-8-Adam-优化算法-Adam-optimization-algorithm" class="headerlink" title="2.8 Adam 优化算法(Adam optimization algorithm)"></a>2.8 Adam 优化算法(Adam optimization algorithm)</h2><p>Adam（Adaptive Moment Estimation）算法结合了动量梯度下降算法和RMSprop算法。其算法流程为：</p><p>$V_{dW}=0, S_{dW}, V_{db}=0, S_{db}=0$</p><p>$On iteration t:$</p><script type="math/tex; mode=display">\ \ \ \ Cimpute\ dW,\ db</script><script type="math/tex; mode=display">\ \ \ \ V_{dW}=\beta_1V_{dW}+(1-\beta_1)dW,\ V_{db}=\beta_1V_{db}+(1-\beta_1)db</script><script type="math/tex; mode=display">\ \ \ \ S_{dW}=\beta_2S_{dW}+(1-\beta_2)dW^2,\ S_{db}=\beta_2S_{db}+(1-\beta_2)db^2</script><script type="math/tex; mode=display">\ \ \ \ V_{dW}^{corrected}=\frac{V_{dW}}{1-\beta_1^t},\ V_{db}^{corrected}=\frac{V_{db}}{1-\beta_1^t}</script><script type="math/tex; mode=display">\ \ \ \ S_{dW}^{corrected}=\frac{S_{dW}}{1-\beta_2^t},\ S_{db}^{corrected}=\frac{S_{db}}{1-\beta_2^t}</script><script type="math/tex; mode=display">\ \ \ \ W:=W-\alpha\frac{V_{dW}^{corrected}}{\sqrt{S_{dW}^{corrected}}+\varepsilon},\ b:=b-\alpha\frac{V_{db}^{corrected}}{\sqrt{S_{db}^{corrected}}+\varepsilon}</script><p>Adam算法包含了几个超参数，分别是：<script type="math/tex">\alpha,\beta_1,\beta_2,\varepsilon</script>,<script type="math/tex">\beta_1</script>通常设置为0.9，<script type="math/tex">\beta_2</script>通常设置为0.999，<script type="math/tex">\varepsilon</script>通常设置为<script type="math/tex">10^{-8}</script>。一般只需要对<script type="math/tex">\beta_1</script>和<script type="math/tex">\beta_2</script>进行调试</p><p>Adam算法结合了动量梯度下降和RMSprop各自的优点，使得神经网络训练速度大大提高</p><h2 id="2-9-学习率衰减-Learning-rate-decay"><a href="#2-9-学习率衰减-Learning-rate-decay" class="headerlink" title="2.9 学习率衰减(Learning rate decay)"></a>2.9 学习率衰减(Learning rate decay)</h2><p>减小学习因子<script type="math/tex">\alpha</script>也能有效提高神经网络训练速度，这种方法被称为learning rate decay, Learning rate decay就是随着迭代次数增加，学习因子<script type="math/tex">\alpha</script>逐渐减小</p><p>下图中，蓝色折线表示使用恒定的学习因子<script type="math/tex">\alpha</script>，由于每次训练<script type="math/tex">\alpha</script>相同，步进长度不变，在接近最优值处的振荡也大，在最优值附近较大范围内振荡，与最优值距离就比较远。绿色折线表示使用不断减小的<script type="math/tex">\alpha</script>，随着训练次数增加，<script type="math/tex">\alpha</script>逐渐减小，步进长度减小，使得能够在最优值处较小范围内微弱振荡，不断逼近最优值。相比较恒定的<script type="math/tex">\alpha</script>来说，learning rate decay更接近最优值</p><p><img src="/images/pasted-66.png" alt="upload successful"></p><p>Learning rate decay中对<script type="math/tex">\alpha</script>的公式：</p><script type="math/tex; mode=display">\alpha=\frac{1}{1+decay\_rate*epoch}\alpha_0</script><p>deacy_rate是参数（可调），epoch是迭代次数。随着epoch增加，<script type="math/tex">\alpha</script>会不断变小</p><p>其它计算公式：</p><script type="math/tex; mode=display">\alpha=0.95^{epoch}\cdot \alpha_0</script><script type="math/tex; mode=display">\alpha=\frac{k}{\sqrt{epoch}}\cdot \alpha_0\ \ \ \ or\ \ \ \ \frac{k}{\sqrt{t}}\cdot \alpha_0</script><p>$k$为可调参数，<script type="math/tex">t</script>为mini-bach number</p><p>还可以设置<script type="math/tex">\alpha</script>为关于<script type="math/tex">t</script>的离散值，随着<script type="math/tex">t</script>增加，<script type="math/tex">\alpha</script>呈阶梯式减小。也可以根据训练情况灵活调整当前的<script type="math/tex">\alpha</script>值，但会比较耗时间</p><h2 id="2-10-局部最优的问题-The-problem-of-local-optima"><a href="#2-10-局部最优的问题-The-problem-of-local-optima" class="headerlink" title="2.10 局部最优的问题(The problem of local optima)"></a>2.10 局部最优的问题(The problem of local optima)</h2><p>以前对局部最优解的理解是形如碗状的凹槽，如下图左边所示。但是在神经网络中，local optima的概念发生了变化。大部分梯度为零的“最优点”并不是这些凹槽处，而是形如右边所示的马鞍状，称为saddle point（鞍点）。即梯度为零并不能保证都是convex（极小值），也有可能是concave（极大值）。特别是在神经网络中参数很多的情况下，所有参数梯度为零的点很可能都是右边所示的马鞍状的saddle point，而不是左边那样的local optimum</p><p><img src="/images/pasted-67.png" alt="upload successful"></p><p>类似马鞍状的plateaus（平稳端）会降低神经网络学习速度。Plateaus是梯度接近于零的平缓区域，在plateaus上梯度很小，前进缓慢，到达saddle point需要很长时间。到达saddle point后，由于随机扰动，梯度一般能够沿着图中绿色箭头，离开saddle point，继续前进，只是在plateaus上花费了太多时间</p><p><img src="/images/pasted-68.png" alt="upload successful"></p><p>local optima的两点总结：</p><ul><li><p><strong>只要选择合理的强大的神经网络，一般不太可能陷入local optima</strong></p></li><li><p><strong>Plateaus可能会使梯度下降变慢，降低学习速度</strong></p></li></ul><p>动量梯度下降，RMSprop，Adam算法都能有效解决plateaus下降过慢的问题，大大提高神经网络的学习速度</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2-1-Mini-batch-梯度下降（Mini-batch-gradient-descent）&quot;&gt;&lt;a href=&quot;#2-1-Mini-batch-梯度下降（Mini-batch-gradient-descent）&quot; class=&quot;headerlink&quot; title=&quot;2.1 Mini-batch 梯度下降（Mini-batch gradient descent）&quot;&gt;&lt;/a&gt;2.1 Mini-batch 梯度下降（Mini-batch gradient descent）&lt;/h2&gt;&lt;p&gt;神经网络训练过程是同时对所有m个样本（称为batch）通过向量化计算方式进行的。如果m很大，训练速度会很慢，因为每次迭代都要对所有样本进进行求和运算和矩阵运算。这种梯度下降算法称为Batch Gradient Descent&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第一周：深度学习的实用层面(Practical aspects of Deep Learning)(Course 2)</title>
    <link href="https://baozouai.com/2019/02/27/%E7%AC%AC%E4%B8%80%E5%91%A8%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2-Practical-aspects-of-Deep-Learning-Course-2/"/>
    <id>https://baozouai.com/2019/02/27/第一周：深度学习的实用层面-Practical-aspects-of-Deep-Learning-Course-2/</id>
    <published>2019-02-27T11:20:37.000Z</published>
    <updated>2019-02-27T05:37:39.868Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-1-训练，验证，测试集（Train-Dev-Test-sets）"><a href="#1-1-训练，验证，测试集（Train-Dev-Test-sets）" class="headerlink" title="1.1 训练，验证，测试集（Train / Dev / Test sets）"></a>1.1 训练，验证，测试集（Train / Dev / Test sets）</h2><p>在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助创建高效的神经网络。训练神经网络时，需要做出很多决策，例如：</p><ol><li>神经网络分多少层</li><li>每层含有多少个隐藏单元</li><li>学习速率是多少</li><li><p>各层采用哪些激活函数</p><a id="more"></a><p>循环迭代的过程是这样的：</p></li><li><p>先有个想法Idea，先选择初始的参数值，构建神经网络模型结构</p></li><li>然后通过代码Code的形式，实现这个神经网络；</li><li>通过实验Experiment验证这些参数对应的神经网络的表现性能。</li><li>根据验证结果，对参数进行适当的调整优化，再进行下一次的Idea-&gt;Code-&gt;Experiment循环。通过很多次的循环，不断调整参数，选定最佳的参数值，从而让神经网络性能最优化</li></ol><p><img src="/images/pasted-42.png" alt="upload successful"><br>在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是的70%训练集，30%测试集，如果没有明确设置验证集，也可以按照60%训练，20%验证和20%测试集来划分</p><p><img src="/images/pasted-43.png" alt="upload successful"></p><p>在大数据时代，数据量可能是百万级别，验证集和测试集占数据总量的比例会趋向于变得更小。因为验证集的目的就是验证不同的算法，检验哪种算法更有效，因此，验证集要足够大才能评估，比如2个甚至10个不同算法，并迅速判断出哪种算法更有效。可能不需要拿出20%的数据作为验证集</p><p>数据量过百万的应用，训练集可以占到99.5%，验证和测试集各占0.25%，或者验证集占0.4%，测试集占0.1%</p><p><img src="/images/pasted-44.png" alt="upload successful"><br>确保验证集和测试集的数据来自同一分布</p><p><img src="/images/pasted-45.png" alt="upload successful"><br>没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，要做的就是在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估</p><p><img src="/images/pasted-46.png" alt="upload successful"></p><p>搭建训练验证集和测试集能够加速神经网络的集成，也可以更有效地衡量算法的偏差和方差，从而更高效地选择合适方法来优化算法</p><h2 id="1-2-偏差，方差（Bias-Variance）"><a href="#1-2-偏差，方差（Bias-Variance）" class="headerlink" title="1.2 偏差，方差（Bias /Variance）"></a>1.2 偏差，方差（Bias /Variance）</h2><p>在一个只有<script type="math/tex">x_1</script>和<script type="math/tex">x_2</script>两个特征的二维数据集中，可以绘制数据，将偏差和方差可视化。</p><p><img src="http://www.ai-start.com/dl2017/images/05ac08b96177b5d0aaae7b7bfea64f3a.png" alt></p><p>在多维空间数据中，绘制数据和可视化分割边界无法实现，但可以通过几个指标，来研究偏差和方差</p><p><img src="http://www.ai-start.com/dl2017/images/2efd9728b5f07f914903dde309167a5d.png" alt></p><p>理解偏差和方差的两个关键数据是<strong>训练集误差（Train set error）</strong>和<strong>验证集误差（Dev set error）</strong></p><p>假定训练集误差是1%，验证集误差是11%，可以看出训练集设置得非常好，而验证集设置相对较差，可能过度拟合了训练集，验证集并没有充分利用交叉验证集的作用，这种情况称之为“高方差”。</p><p>假设训练集误差是15%，验证集误差是16%，该案例中人的错误率几乎为0%，算法并没有在训练集中得到很好训练，如果训练数据的拟合度不高，就是数据欠拟合，这种算法偏差比较高。对于验证集产生的结果却是合理的，验证集中的错误率只比训练集的多了1%，这种算法偏差高，因为它甚至不能拟合训练集</p><p>训练集误差是15%，偏差相当高，验证集的评估结果更糟糕，错误率达到30%，这种算法偏差高，因为它在训练集上结果不理想，而且方差也很高，这是方差偏差都很糟糕的情况</p><p>训练集误差是0.5%，验证集误差是1%，猫咪分类器只有1%的错误率，偏差和方差都很低</p><p>以上分析都是基于假设预测的，训练集和验证集数据来自相同分布，假设人眼辨别的错误率接近0%，一般来说，<strong>最优误差</strong>也被称为<strong>贝叶斯误差</strong>，最优误差接近0%，如果最优误差或贝叶斯误差非常高，比如15%。再看看这个分类器（训练误差15%，验证误差16%），15%的错误率对训练集来说也是非常合理的，偏差不高，方差也非常低</p><p><img src="http://www.ai-start.com/dl2017/images/c61d149beecddb96f0f93944320cf639.png" alt></p><p>偏差和方差都高：</p><p><img src="http://www.ai-start.com/dl2017/images/6e86aa7d9b21b1a49bf4a084c7503527.png" alt></p><blockquote><p>这条曲线中间部分灵活性非常高，却过度拟合了这两个样本，这类分类器偏差很高，因为它几乎是线性的</p></blockquote><p>采用曲线函数或二次元函数会产生高方差，因为曲线灵活性太高以致拟合了这两个错误样本和中间这些活跃数据。但对于高维数据，有些数据区域偏差高，有些数据区域方差高，所以在高维数据中采用这种分类器看起来就不会那么牵强</p><h2 id="1-3-机器学习基础（Basic-Recipe-for-Machine-Learning）"><a href="#1-3-机器学习基础（Basic-Recipe-for-Machine-Learning）" class="headerlink" title="1.3 机器学习基础（Basic Recipe for Machine Learning）"></a>1.3 机器学习基础（Basic Recipe for Machine Learning）</h2><p>初始模型训练完成后，首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，要做的就是增加神经网络的隐藏层个数、神经元个数，训练时间延长，选择其它更复杂的NN模型等</p><p>如果网络足够大，通常可以很好的拟合训练集，一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方差，要查看验证集性能，从一个性能理想的训练集推断出验证集的性能是否也理想，如果方差高，最好的解决办法就是增加训练样本数据，进行正则化Regularization，选择其他更复杂的NN模型</p><p>两点需要注意：</p><p>第一点，高偏差和高方差是两种不同的情况，通常用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。如果算法存在高偏差问题，准备更多训练数据没什么用处</p><p>第二点，在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要正则适度，通常构建一个更大的网络便可以在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。</p><p>这两步实际要做的工作是：使用更复杂的神经网络和海量的训练样本，一般能够同时有效减小Bias和Variance</p><h2 id="1-4-正则化（Regularization）"><a href="#1-4-正则化（Regularization）" class="headerlink" title="1.4 正则化（Regularization）"></a>1.4 正则化（Regularization）</h2><p>深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据</p><p>$\frac{\lambda}{2m}$乘以<script type="math/tex">w</script>范数的平方，欧几里德范数的平方等于<script type="math/tex">w_j</script>（ <script type="math/tex">j</script>值从1到<script type="math/tex">n_x</script>）平方的和，也可表示为<script type="math/tex">ww^T</script>，也就是向量参数<script type="math/tex">w</script>的欧几里德范数（2范数）的平方，此方法称为<script type="math/tex">L2</script>正则化。因为这里用了欧几里德法线，被称为向量参数<script type="math/tex">w</script>的<script type="math/tex">L2</script>范数。</p><script type="math/tex; mode=display">J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||_2^2</script><script type="math/tex; mode=display">||w||_2^2=\sum_{j=1}^{n_x}w_j^2=w^Tw</script><p>为什么不再加上参数<script type="math/tex">b</script>呢？因为通常<script type="math/tex">w</script>是一个高维参数矢量，几乎涵盖所有参数，已经可以表达高偏差问题，所以参数很大程度上由<script type="math/tex">w</script>决定，而<script type="math/tex">b</script>只是众多参数中的一个，改变<script type="math/tex">b</script>值对整体模型影响较小,所以通常省略不计,如果加了参数<script type="math/tex">b</script>，也没太大影响</p><p><img src="http://www.ai-start.com/dl2017/images/84c4e19130a91a09120087dd704bbaa4.png" alt></p><p>$L2$正则化是最常见的正则化类型，<script type="math/tex">L1</script>正则化是正则项<script type="math/tex">\frac{\lambda}{m}</script>乘以<script type="math/tex">\sum_{j=1}^{n^x}|w|</script>，<script type="math/tex">\sum_{j=1}^{n^x}|w|</script>也被称为参数向量<script type="math/tex">w</script>的<script type="math/tex">L1</script>范数无论分母是，<script type="math/tex">m</script>还是<script type="math/tex">2m</script>，它都是一个比例常量</p><script type="math/tex; mode=display">J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||_1</script><script type="math/tex; mode=display">||w||_1=\sum_{j=1}^{n_x}|w_j|</script><p>如果用的是<script type="math/tex">L1</script>正则化，<script type="math/tex">w</script>最终会是稀疏的，也就是说<script type="math/tex">w</script>向量中有很多0，虽然<script type="math/tex">L1</script>正则化使模型变得稀疏，却没有降低太多存储内存,实际上L1 regularization在解决high variance方面比L2 regularization并不更具优势。而且，L1的在微分求导方面比较复杂</p><p>$\lambda$是正则化参数，可以设置<script type="math/tex">\lambda</script>为不同的值，在Dev set中进行验证，选择最佳的<script type="math/tex">\lambda</script>,通常使用验证集或交叉验证集来配置这个参数</p><p>在深度学习模型中，L2 regularization的表达式为：</p><script type="math/tex; mode=display">J(w^{[1]},b^{[1]},\cdots,w^{[L]},b^{[L]})=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^L||w^{[l]}||^2</script><script type="math/tex; mode=display">||w^{[l]}||^2=\sum_{i=1}^{n^{[l]}}\sum_{j=1}^{n^{[l-1]}}(w_{ij}^{[l]})^2</script><p>$||w^{[l]}||^2$称为Frobenius范数，记为<script type="math/tex">||w^{[l]}||_F^2</script>。一个矩阵的Frobenius范数就是计算所有元素平方和再开方，如下所示：</p><script type="math/tex; mode=display">||A||_F=\sqrt {\sum_{i=1}^m\sum_{j=1}^n|a_{ij}|^2}</script><p>由于加入了正则化项，梯度下降算法中的<script type="math/tex">dw^{[l]}</script>计算表达式需要做如下修改：</p><script type="math/tex; mode=display">dw^{[l]}=dw^{[l]}_{before}+\frac{\lambda}{m}w^{[l]}</script><script type="math/tex; mode=display">w^{[l]}:=w^{[l]}-\alpha\cdot dw^{[l]}</script><p>L2 regularization也被称做weight decay。这是因为，由于加上了正则项，<script type="math/tex">dw^{[l]}</script>有个增量，在更新<script type="math/tex">w^{[l]}</script>的时候，会多减去这个增量，使得<script type="math/tex">w^{[l]}</script>比没有正则项的值要小一些。不断迭代更新，不断地减小</p><script type="math/tex; mode=display">\begin{aligned}w^{[l]}&:=w^{[l]}-\alpha\cdot dw^{[l]}\\&=w^{[l]}-\alpha\cdot(dw^{[l]}_{before}+\frac{\lambda}{m}w^{[l]})\\&=(1-\alpha\frac{\lambda}{m})w^{[l]}-\alpha\cdot dw^{[l]}_{before}\end{aligned}</script><p>其中，<script type="math/tex">(1-\alpha\frac{\lambda}{m})<1</script></p><h2 id="1-5-为什么正则化有利于预防过拟合呢？（Why-regularization-reduces-overfitting-）"><a href="#1-5-为什么正则化有利于预防过拟合呢？（Why-regularization-reduces-overfitting-）" class="headerlink" title="1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?）"></a>1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?）</h2><p>如果正则化<script type="math/tex">\lambda</script>设置得足够大，权重矩阵<script type="math/tex">W</script>被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。但是<script type="math/tex">\lambda</script>会存在一个中间值，于是会有一个接近“<strong>Just Right</strong>”的中间状态。</p><p><img src="http://www.ai-start.com/dl2017/images/2aafa244c3f184cc271b26d1d95d70c9.png" alt></p><p>正则化为什么可以预防过拟合:</p><p>假设激活函数是<script type="math/tex">tanh</script>函数。<script type="math/tex">tanh</script>函数的特点是在<script type="math/tex">z</script>接近零的区域，函数近似是线性的，而当<script type="math/tex">|z|</script>很大的时候，函数非线性且变化缓慢。当使用正则化，<script type="math/tex">\lambda</script>较大，即对权重<script type="math/tex">w^{[l]}</script>的惩罚较大，<script type="math/tex">w^{[l]}</script>减小。因为<script type="math/tex">z^{[l]}=w^{[l]}a^{[l]}+b^{[l]}</script>。当<script type="math/tex">w^{[l]}</script>减小的时候，<script type="math/tex">z^{[l]}</script>也会减小。则此时的<script type="math/tex">z^{[l]}</script>分布在<script type="math/tex">tanh</script>函数的近似线性区域。那么这个神经元起的作用就相当于是linear regression。如果每个神经元对应的权重<script type="math/tex">w^{[l]}</script>都比较小，那么整个神经网络模型相当于是多个linear regression的组合，即可看成一个linear network。得到的分类超平面就会比较简单，不会出现过拟合现象</p><p><img src="http://www.ai-start.com/dl2017/images/8248be8e83121535b73969a4599fbb08.png" alt></p><h2 id="1-6-dropout-正则化（Dropout-Regularization）"><a href="#1-6-dropout-正则化（Dropout-Regularization）" class="headerlink" title="1.6 dropout 正则化（Dropout Regularization）"></a>1.6 dropout 正则化（Dropout Regularization）</h2><p>Dropout是指在深度学习网络的训练过程中，对于每层的神经元，按照一定的概率将其暂时从网络中丢弃。即每次训练时，每一层都有部分神经元不工作，起到简化复杂网络模型的效果，从而避免发生过拟合</p><p><img src="/images/pasted-34.png" alt="upload successful"></p><h3 id="Inverted-dropout（反向随机失活）"><a href="#Inverted-dropout（反向随机失活）" class="headerlink" title="Inverted dropout（反向随机失活）"></a>Inverted dropout（反向随机失活）</h3><p>假设对于第<script type="math/tex">l</script>层神经元，设定保留神经元比例概率keep_prob=0.8，即该层有20%的神经元停止工作。<script type="math/tex">dl</script>为dropout向量，设置<script type="math/tex">dl</script>为随机vector，其中80%的元素为1，20%的元素为0。</p><p>生成dropout vector：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dl = np.random.rand(al.shape[<span class="number">0</span>],al.shape[<span class="number">1</span>])&lt;keep_prob</span><br></pre></td></tr></table></figure><p>第<script type="math/tex">l</script>层经过dropout，随机删减20%的神经元，只保留80%的神经元，其输出为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">al = np.multiply(al,dl)</span><br></pre></td></tr></table></figure><p>最后，对<script type="math/tex">al</script>进行scale up处理，即：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">al /= keep_prob</span><br></pre></td></tr></table></figure><p>对<script type="math/tex">al</script>进行scale up是为了保证在经过dropout后，<script type="math/tex">al</script>作为下一层神经元的输入值尽量保持不变,尽可能保持<script type="math/tex">al</script>的期望值相比之前没有大的变化</p><p>Inverted dropout的另外一个好处就是在对该dropout后的神经网络进行测试时能够减少scaling问题。因为在训练时，使用scale up保证<script type="math/tex">al</script>的期望值没有大的变化，测试时就不需要再对样本数据进行类似的尺度伸缩操作</p><p>对于<script type="math/tex">m</script>个样本，单次迭代训练时，随机删除掉隐藏层一定数量的神经元；然后，在删除后的剩下的神经元上正向和反向更新权重<script type="math/tex">w</script>和常数项<script type="math/tex">b</script>；接着，下一次迭代中，再恢复之前删除的神经元，重新随机删除一定数量的神经元，进行正向和反向更新<script type="math/tex">w</script>和<script type="math/tex">b</script>。不断重复上述过程，直至迭代训练完成</p><p>使用dropout训练结束后，在测试和实际应用模型时，不需要进行dropout和随机删减神经元，所有的神经元都在工作</p><h2 id="1-7-理解-dropout（Understanding-Dropout）"><a href="#1-7-理解-dropout（Understanding-Dropout）" class="headerlink" title="1.7 理解 dropout（Understanding Dropout）"></a>1.7 理解 dropout（Understanding Dropout）</h2><p>Dropout通过每次迭代训练时，随机选择不同的神经元，相当于每次都在不同的神经网络上进行训练，能够防止过拟合</p><p>对于某个神经元来说，某次训练时，它的某些输入在dropout的作用下被过滤了。而在下一次训练时，又有不同的某些输入被过滤。经过多次训练后，某些输入被过滤，某些输入被保留。这样，该神经元就不会受某个输入非常大的影响而被均匀化了。即对应的权重w不会很大。从效果上来说与L2 regularization是类似的，都是对权重w进行“惩罚”，减小了w的值。</p><p><img src="/images/pasted-35.png" alt="upload successful"></p><p>对于同一组训练数据，利用不同的神经网络训练之后，求其输出的平均值可以减少overfitting</p><p>Dropout就是利用这个原理，每次丢掉一定数量的隐藏层神经元，相当于在不同的神经网络上进行训练，这样就减少了神经元之间的依赖性，即每个神经元不能依赖于某几个其他的神经元（指层与层之间相连接的神经元），使神经网络更加能学习到与其他神经元之间的更加健壮的特征</p><p>在使用dropout的时候，有几点需要注意。：</p><ul><li>不同隐藏层的dropout系数keep_prob可以不同。</li><li>一般来说，神经元越多的隐藏层，keep_out可以设置得小一些.，例如0.5；神经元越少的隐藏层，keep_out可以设置的大一些，例如0.8</li><li>实际应用中，不建议对输入层进行dropout，如果输入层维度很大，例如图片，那么可以设置dropout，但keep_out应设置的大一些，例如0.8，0.9。</li><li>越容易出现overfitting的隐藏层，其keep_prob就设置的相对小一些</li><li>如果担心某些层比其它层更容易发生过拟合，可以把某些层的<strong>keep-prob</strong>值设置得比其它层更低，缺点是为了使用交叉验证，要搜索更多的超级参数</li></ul><p>使用dropout的时候，先将所有层的keep_prob全设置为1，再绘制cost function，即涵盖所有神经元，看J是否单调下降。下一次迭代训练时，再将keep_prob设置为其它值</p><h2 id="1-8-其他正则化方法（Other-regularization-methods）"><a href="#1-8-其他正则化方法（Other-regularization-methods）" class="headerlink" title="1.8 其他正则化方法（Other regularization methods）"></a>1.8 其他正则化方法（Other regularization methods）</h2><p>除了L2 regularization和dropout regularization之外，其它减少过拟合的方法：</p><ul><li>增加训练样本数量。但是通常成本较高，难以获得额外的训练样本。但是可以对已有的训练样本进行一些处理来“制造”出更多的样本，称为data augmentation（数据扩增）。例如图片识别问题中，可以对已有的图片进行水平翻转、垂直翻转、任意角度旋转、缩放或扩大等</li></ul><p><img src="/images/pasted-36.png" alt="upload successful"></p><p>在数字识别中，也可以将原有的数字图片进行任意旋转或者扭曲，或者增加一些noise，如下图所示：</p><p><img src="/images/pasted-37.png" alt="upload successful"></p><ul><li>early stopping。一个神经网络模型随着迭代训练次数增加，train set error一般是单调减小的，而dev set error 先减小，之后又增大。即训练次数过多时，模型会对训练样本拟合的越来越好，但是对验证集拟合效果逐渐变差，发生了过拟合。可以通过train set error和dev set error随着迭代次数的变化趋势，选择合适的迭代次数，即early stopping。</li></ul><p><img src="/images/pasted-38.png" alt="upload successful"></p><p>当还未在神经网络上运行太多迭代过程的时候，参数<script type="math/tex">w</script>接近0，因为随机初始化<script type="math/tex">w</script>值时，它的值可能都是较小的随机值，但在迭代过程和训练过程中<script type="math/tex">w</script>的值会变得越来越大，所以early stopping要做就是在中间点停止迭代过程</p><p>机器学习训练模型有两个目标：一是优化cost function，尽量减小J；二是防止过拟合。这两个目标彼此对立的，即减小J的同时可能会造成过拟合，反之亦然。二者之间的关系称为正交化orthogonalization</p><ul><li><p>Early stopping的做法通过减少迭代训练次数来防止过拟合，这样J就不会足够小。即early stopping将上述两个目标融合在一起，同时优化，但可能没有“分而治之”的效果好。</p></li><li><p>与early stopping相比，L2 regularization可以实现“分而治之”的效果：迭代训练足够多，减小J，而且也能有效防止过拟合。而L2 regularization的缺点之一是最优的正则化参数<script type="math/tex">\lambda</script>的选择比较复杂。而early stopping比较简单。</p></li><li><p>总的来说，L2 regularization更加常用一些</p></li></ul><h2 id="1-9-归一化输入（Normalizing-inputs）"><a href="#1-9-归一化输入（Normalizing-inputs）" class="headerlink" title="1.9 归一化输入（Normalizing inputs）"></a>1.9 归一化输入（Normalizing inputs）</h2><p>在训练神经网络时，标准化输入可以提高训练的速度</p><script type="math/tex; mode=display">\mu=\frac1m\sum_{i=1}^mX^{(i)}</script><script type="math/tex; mode=display">\sigma^2=\frac1m\sum_{i=1}^m(X^{(i)})^2</script><script type="math/tex; mode=display">X:=\frac{X-\mu}{\sigma^2}</script><p><img src="/images/pasted-39.png" alt="upload successful"></p><p>由于训练集进行了标准化处理，测试集或在实际应用时，应该使用同样的<script type="math/tex">\mu</script>和<script type="math/tex">\sigma^2</script>对其进行标准化处理。保证训练集和测试集的标准化操作一致</p><p>对输入进行标准化操作，是为了让所有输入归一化在同样的尺度上，方便进行梯度下降算法时能够更快更准确地找到全局最优解。假如输入特征是二维的，且<script type="math/tex">x_1</script>的范围是[1,1000]，<script type="math/tex">x_2</script>的范围是[0,1]。如果不进行标准化处理，<script type="math/tex">x_1</script>与<script type="math/tex">x_2</script>之间分布极不平衡，训练得到的<script type="math/tex">w_1</script>和<script type="math/tex">w_2</script>也会在数量级上差别很大。这样导致的结果是costfunction与<script type="math/tex">w</script>和<script type="math/tex">b</script>的关系可能是一个非常细长的椭圆形碗。对其进行梯度下降算法时，由于<script type="math/tex">w_1</script>和<script type="math/tex">w_2</script>数值差异很大，只能选择很小的学习因子<script type="math/tex">\alpha</script>，来避免J发生振荡。一旦<script type="math/tex">\alpha</script>较大，必然发生振荡，<script type="math/tex">J</script>不再单调下降。如果进行了标准化操作，<script type="math/tex">x_1</script>与<script type="math/tex">x_2</script>分布均匀，<script type="math/tex">w_1</script>和<script type="math/tex">w_2</script>数值差别不大，得到的cost function与<script type="math/tex">w</script>和<script type="math/tex">b</script>的关系是类似圆形碗。对其进行梯度下降算法时，<script type="math/tex">\alpha</script>可以选择相对大一些，且<script type="math/tex">J</script>一般不会发生振荡，保证了<script type="math/tex">J</script>是单调下降</p><p><img src="/images/pasted-40.png" alt="upload successful"></p><p>如果输入特征之间的范围比较接近，不进行标准化操作没有太大影响</p><h2 id="1-10-梯度消失-梯度爆炸（Vanishing-Exploding-gradients）"><a href="#1-10-梯度消失-梯度爆炸（Vanishing-Exploding-gradients）" class="headerlink" title="1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients）"></a>1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients）</h2><p>当训练一个层数非常多的神经网络时，计算得到的梯度可能非常小或非常大，甚至是指数级别的减小或增大</p><p><img src="/images/pasted-47.png" alt="upload successful"><br>令各层的激活函数为线性函数，即<script type="math/tex">g(Z)=Z</script>。且忽略各层常数项b的影响，令b全部为零。该网络的预测输出<script type="math/tex">\hat Y</script>为：</p><script type="math/tex; mode=display">\hat Y=W^{[L]}W^{[L-1]}W^{[L-2]}\cdots W^{[3]}W^{[2]}W^{[1]}X</script><p>如果各层权重<script type="math/tex">W[l]</script>的元素都稍大于1，例如1.5，则预测输出<script type="math/tex">\hat Y</script>将正比于<script type="math/tex">1.5^L</script>。L越大，<script type="math/tex">\hat Y</script>越大，且呈指数型增长。称之为<strong>梯度爆炸</strong>。</p><p>如果各层权重<script type="math/tex">W[l]</script>的元素都稍小于1，例如0.5，则预测输出<script type="math/tex">\hat Y</script>将正比于<script type="math/tex">0.5^L</script>。网络层数L越多，<script type="math/tex">\hat Y</script>呈指数型减小。称之为<strong>梯度消失</strong></p><h2 id="1-11-神经网络的权重初始化（Weight-Initialization-for-Deep-Networks）"><a href="#1-11-神经网络的权重初始化（Weight-Initialization-for-Deep-Networks）" class="headerlink" title="1.11 神经网络的权重初始化（Weight Initialization for Deep Networks）"></a>1.11 神经网络的权重初始化（Weight Initialization for Deep Networks）</h2><p>深度神经网络模型中，以单个神经元为例，该层（<script type="math/tex">l</script>）的输入个数为<script type="math/tex">n</script>，其输出为：</p><script type="math/tex; mode=display">z=w_1x_1+w_2x_2+\cdots+w_nx_n</script><script type="math/tex; mode=display">a=g(z)</script><p><img src="/images/pasted-48.png" alt="upload successful"></p><blockquote><p>忽略了常数项b</p></blockquote><p>为了让<script type="math/tex">z</script>不会过大或者过小，<script type="math/tex">w</script>应该越小才好。方法是在初始化<script type="math/tex">w</script>时，令其方差为<script type="math/tex">\frac{1}{n}</script></p><p>激活函数是<script type="math/tex">tanh</script>相应的python伪代码为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w[l] = np.random.randn(n[l],n[l<span class="number">-1</span>])*np.sqrt(<span class="number">1</span>/n[l<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><p>如果激活函数是<script type="math/tex">ReLU</script>，权重<script type="math/tex">w</script>的初始化一般令其方差为<script type="math/tex">\frac{2}{n}</script>：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w[l] = np.random.randn(n[l],n[l<span class="number">-1</span>])*np.sqrt(<span class="number">2</span>/n[l<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><p>另外一种初始化<script type="math/tex">w</script>的方法，令其方差为<script type="math/tex">\frac{2}{n^{[l-1]}+n^{[l]}}</script>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w[l] = np.random.randn(n[l],n[l<span class="number">-1</span>])*np.<span class="built_in">sqrt</span>(<span class="number">2</span>/(n[l<span class="number">-1</span>] + n[l]))</span><br></pre></td></tr></table></figure><h2 id="1-12-梯度的数值逼近（Numerical-approximation-of-gradients）"><a href="#1-12-梯度的数值逼近（Numerical-approximation-of-gradients）" class="headerlink" title="1.12 梯度的数值逼近（Numerical approximation of gradients）"></a>1.12 梯度的数值逼近（Numerical approximation of gradients）</h2><p>Back Propagation神经网络有一项重要的测试是梯度检验（gradient checking）。其目的是检查验证反向传播过程中梯度下降算法是否正确。</p><p><img src="/images/pasted-49.png" alt="upload successful"></p><p>对于一个非零的<script type="math/tex">\varepsilon</script>，它的逼近误差可以写成<script type="math/tex">O(\varepsilon^2)</script>，<script type="math/tex">\varepsilon</script>值非常小，大写符号<script type="math/tex">O</script>的含义是指<strong>逼近误差</strong></p><p>函数<script type="math/tex">f</script>在点<script type="math/tex">\theta</script>处的梯度可以表示成：</p><script type="math/tex; mode=display">g(\theta)=\frac{f(\theta+\varepsilon)-f(\theta-\varepsilon)}{2\varepsilon}</script><p>$\varepsilon&gt;0$，且足够小</p><h2 id="1-13-梯度检验（Gradient-checking）"><a href="#1-13-梯度检验（Gradient-checking）" class="headerlink" title="1.13 梯度检验（Gradient checking）"></a>1.13 梯度检验（Gradient checking）</h2><ul><li>梯度检查要做的是将<script type="math/tex">W^{[1]},b^{[1]},\cdots,W^{[L]},b^{[L]}</script>这些矩阵构造成一维向量，然后将这些一维向量组合起来构成一个更大的一维向量<script type="math/tex">\theta</script>。这样的cost function<script type="math/tex">J(W^{[1]},b^{[1]},\cdots,W^{[L]},b^{[L]})</script>可以表示成<script type="math/tex">J(\theta)</script></li></ul><p><img src="/images/pasted-50.png" alt="upload successful"></p><ul><li><p>然后将反向传播过程通过梯度下降算法得到的$dW^{[1]},db^{[1]},\cdots,dW^{[L]},db^{[L]}$按照一样的顺序构造成一个一维向量<script type="math/tex">d\theta</script>。<script type="math/tex">d\theta</script>的维度与<script type="math/tex">\theta</script>一致</p></li><li><p>接着利用<script type="math/tex">J(\theta)</script>对每个<script type="math/tex">\theta_i</script>算近似梯度，其值与反向传播算法得到的<script type="math/tex">d\theta_i</script>相比较，检查是否一致。例如，对于第<script type="math/tex">i</script>个元素，近似梯度为：</p></li></ul><script type="math/tex; mode=display">d\theta_{approx}[i]=\frac{J(\theta_1,\theta_2,\cdots,\theta_i+\varepsilon,\cdots)-J(\theta_1,\theta_2,\cdots,\theta_i-\varepsilon,\cdots)}{2\varepsilon}</script><ul><li>计算完所有<script type="math/tex">\theta_i</script>的近似梯度后，可以计算<script type="math/tex">d\theta_{approx}</script>与<script type="math/tex">d\theta</script>的欧氏（Euclidean）距离来比较二者的相似度。公式如下：</li></ul><script type="math/tex; mode=display">\frac{||d\theta_{approx}-d\theta||_2}{||d\theta_{approx}||_2+||d\theta||_2}</script><ul><li>如果欧氏距离越小，例如<script type="math/tex">10^{-7}</script>，甚至更小，则表明<script type="math/tex">d\theta_{approx}</script>与<script type="math/tex">d\theta</script>越接近，即反向梯度计算是正确的，没有bugs。如果欧氏距离较大，例如<script type="math/tex">10^{-5}</script>，则表明梯度计算可能出现问题，需要再次检查是否有bugs存在。如果欧氏距离很大，例如<script type="math/tex">10^{-3}</script>，甚至更大，则表明<script type="math/tex">d\theta_{approx}</script>与<script type="math/tex">d\theta</script>差别很大，梯度下降计算过程有bugs，需要仔细检查</li></ul><h2 id="1-14-梯度检验应用的注意事项（Gradient-Checking-Implementation-Notes）"><a href="#1-14-梯度检验应用的注意事项（Gradient-Checking-Implementation-Notes）" class="headerlink" title="1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes）"></a>1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes）</h2><p>在进行梯度检验的过程中有几点需要注意的地方：</p><ul><li><p>不要在训练中使用梯度检验而仅仅在调试时使用。计算所有<script type="math/tex">i</script>值的<script type="math/tex">d\theta_{approx}[i]</script>是一个非常漫长的计算过程，为了实施梯度下降，必须使用<script type="math/tex">W</script>和<script type="math/tex">b</script><strong> </strong>backprop来计算<script type="math/tex">d\theta</script><strong>，</strong>并使用backprop来计算导数，所以只有调试的时候才会计算它，来确认数值是否接近<script type="math/tex">d\theta</script>。完成后要关闭梯度检验。别在每一次进行梯度下降迭代的时候都运行梯度检验，因为太慢了</p></li><li><p>如果<script type="math/tex">d\theta_{approx}</script>与<script type="math/tex">d\theta</script>差距很大, 应检查不同的<script type="math/tex">i</script>值,看看哪些<script type="math/tex">d\theta_{approx}</script>的值与<script type="math/tex">d\theta</script>的值差距最大</p></li><li><p>进行梯度检验时,如果使用了正则化,注意不要忽略正则化项，计算近似梯度的时候要包括进去</p></li><li><p>梯度检验不能与随机失活(dropout) 一起使用,因为在每一次的迭代中,随机失活(dropout)将随机消除隐藏层单元的不同子集,在使用随机失活(dropout) 进行梯度下降的过程中并不存在一个容易计算的代价函数<script type="math/tex">J</script>,随机失活(dropout)可以被视为对代价函数的优化, 但是这个代价函数的定义是在每一次迭代中对所有非常大的可消除节点集进行求和,所以这个代价函数是很难计算的,只需要对代价函数进行抽样,在那些使用随机失活(dropout)的集合中每次消除不同的随机集合,所以使用梯度检验来检查包含了随机失活(dropout)的运算是很困难的,可以把keep-prob和dropout设为1.0,然后打开dropout。梯度检查时关闭dropout，检查完毕后再打开dropout。关掉随机失活(dropout) 使用梯度检验来检查算法，在没有dropout的情况下至少是正确的 然后再打开dropout</p></li><li><p>在随机初始化的时候运行梯度检验,然后训练网络一段时间,<script type="math/tex">w</script>和<script type="math/tex">b</script> 将会在0附近摇摆一段时间,即很小的随机初始值,在进行几次训练的迭代后再运行梯度检验。<strong>（不常用）</strong></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-1-训练，验证，测试集（Train-Dev-Test-sets）&quot;&gt;&lt;a href=&quot;#1-1-训练，验证，测试集（Train-Dev-Test-sets）&quot; class=&quot;headerlink&quot; title=&quot;1.1 训练，验证，测试集（Train / Dev / Test sets）&quot;&gt;&lt;/a&gt;1.1 训练，验证，测试集（Train / Dev / Test sets）&lt;/h2&gt;&lt;p&gt;在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助创建高效的神经网络。训练神经网络时，需要做出很多决策，例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;神经网络分多少层&lt;/li&gt;
&lt;li&gt;每层含有多少个隐藏单元&lt;/li&gt;
&lt;li&gt;学习速率是多少&lt;/li&gt;
&lt;li&gt;&lt;p&gt;各层采用哪些激活函数&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第三周：浅层神经网络(Shallow neural networks)(Course 1)</title>
    <link href="https://baozouai.com/2019/02/27/%E7%AC%AC%E4%B8%89%E5%91%A8%EF%BC%9A%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Shallow-neural-networks/"/>
    <id>https://baozouai.com/2019/02/27/第三周：浅层神经网络-Shallow-neural-networks/</id>
    <published>2019-02-27T08:54:10.000Z</published>
    <updated>2019-02-27T05:38:57.095Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3-1-神经网络概述（Neural-Network-Overview）"><a href="#3-1-神经网络概述（Neural-Network-Overview）" class="headerlink" title="3.1 神经网络概述（Neural Network Overview）"></a>3.1 神经网络概述（Neural Network Overview）</h2><p><img src="/images/pasted-16.png" alt="upload successful"></p><a id="more"></a><h2 id="3-2-神经网络的表示（Neural-Network-Representation-）"><a href="#3-2-神经网络的表示（Neural-Network-Representation-）" class="headerlink" title="3.2 神经网络的表示（Neural Network Representation ）"></a>3.2 神经网络的表示（Neural Network Representation ）</h2><p>单隐藏层神经网络就是典型的<strong>浅层（shallow）神经网络</strong></p><p><img src="/images/pasted-17.png" alt="upload successful"></p><p>单隐藏层神经网络也被称为两层神经网络（2 layer NN）</p><p>第<script type="math/tex">l</script>层的权重<script type="math/tex">W^{[l]}</script>维度的行等于<script type="math/tex">l</script>层神经元的个数，列等于<script type="math/tex">l-1</script>层神经元的个数；第<script type="math/tex">i</script>层常数项<script type="math/tex">b^{[l]}</script>维度的行等于<script type="math/tex">l</script>层神经元的个数，列始终为1</p><h2 id="3-3-计算一个神经网络的输出（Computing-a-Neural-Network’s-output-）"><a href="#3-3-计算一个神经网络的输出（Computing-a-Neural-Network’s-output-）" class="headerlink" title="3.3 计算一个神经网络的输出（Computing a Neural Network’s output ）"></a>3.3 计算一个神经网络的输出（Computing a Neural Network’s output ）</h2><p>两层神经网络可以看成是逻辑回归再重复计算一次</p><p>逻辑回归的正向计算可以分解成计算z和a的两部分：</p><script type="math/tex; mode=display">z=w^Tx+b</script><script type="math/tex; mode=display">a=\sigma(z)</script><p><img src="/images/pasted-18.png" alt="upload successful"></p><p>两层神经网络，从输入层到隐藏层对应一次逻辑回归运算；从隐藏层到输出层对应一次逻辑回归运算</p><script type="math/tex; mode=display">z^{[1]}=W^{[1]}x+b^{[1]}</script><script type="math/tex; mode=display">a^{[1]}=\sigma(z^{[1]})</script><script type="math/tex; mode=display">z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}</script><script type="math/tex; mode=display">a^{[2]}=\sigma(z^{[2]})</script><p><img src="/images/pasted-19.png" alt="upload successful"></p><h2 id="3-4-多样本向量化（Vectorizing-across-multiple-examples-）"><a href="#3-4-多样本向量化（Vectorizing-across-multiple-examples-）" class="headerlink" title="3.4 多样本向量化（Vectorizing across multiple examples ）"></a>3.4 多样本向量化（Vectorizing across multiple examples ）</h2><p>for循环来求解其正向输出：</p><p>for i = 1 to m:</p><script type="math/tex; mode=display">\begin{aligned}&z^{[1](i)}=W^{[1]}x^{(i)}+b^{[1]}\\&a^{[1](i)}=\sigma(z^{[1](i)})\\&z^{[2](i)}=W^{[2]}a^{[1](i)}+b^{[2]} \\&a^{[2](i)}=\sigma(z^{[2](i)})\end{aligned}</script><p>矩阵运算的形式：</p><script type="math/tex; mode=display">Z^{[1]}=W^{[1]}X+b^{[1]}</script><script type="math/tex; mode=display">A^{[1]}=\sigma(Z^{[1]})</script><script type="math/tex; mode=display">Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}</script><script type="math/tex; mode=display">A^{[2]}=\sigma(Z^{[2]})</script><p>行表示神经元个数，列表示样本数目<script type="math/tex">m</script></p><h2 id="3-5-激活函数（Activation-functions）"><a href="#3-5-激活函数（Activation-functions）" class="headerlink" title="3.5 激活函数（Activation functions）"></a>3.5 激活函数（Activation functions）</h2><ul><li>sigmoid函数</li></ul><p><img src="/images/pasted-20.png" alt="upload successful"></p><ul><li>tanh函数</li></ul><p><img src="/images/pasted-21.png" alt="upload successful"></p><ul><li>ReLU函数</li></ul><p><img src="/images/pasted-22.png" alt="upload successful"></p><ul><li>Leaky ReLU函数</li></ul><p><img src="/images/pasted-23.png" alt="upload successful"></p><p>对于隐藏层的激活函数，<script type="math/tex">tanh</script>函数要比<script type="math/tex">sigmoid</script>函数表现更好一些。因为<script type="math/tex">tanh</script>函数的取值范围在<script type="math/tex">[-1,+1]</script>之间，隐藏层的输出被限定在[<script type="math/tex">-1,+1]</script>之间，可以看成是在<script type="math/tex">0</script>值附近分布，均值为<script type="math/tex">0</script>。这样从隐藏层到输出层，数据起到了归一化（均值为<script type="math/tex">0</script>）的效果</p><p>对于输出层的激活函数，因为二分类问题的输出取值为<script type="math/tex">\{0,+1\}</script>，所以一般会选择<script type="math/tex">sigmoid</script>作为激活函数</p><p>选择<script type="math/tex">ReLU</script>作为激活函数能够保证<script type="math/tex">z</script>大于零时梯度始终为<script type="math/tex">1</script>，从而提高神经网络梯度下降算法运算速度。但当<script type="math/tex">z</script>小于零时，存在梯度为<script type="math/tex">0</script>的缺点</p><script type="math/tex; mode=display">Leaky$$ $$ReLU$$激活函数，能够保证$$z$$小于零时梯度不为$$0</script><h2 id="3-6-为什么需要（-非线性激活函数？（why-need-a-nonlinear-activation-function-）"><a href="#3-6-为什么需要（-非线性激活函数？（why-need-a-nonlinear-activation-function-）" class="headerlink" title="3.6 为什么需要（ 非线性激活函数？（why need a nonlinear activation function?）"></a>3.6 为什么需要（ 非线性激活函数？（why need a nonlinear activation function?）</h2><p>假设所有的激活函数都是线性的，直接令激活函数<script type="math/tex">g(z)=z</script>，即<script type="math/tex">a=z</script></p><script type="math/tex; mode=display">z^{[1]}=W^{[1]}x+b^{[1]}</script><script type="math/tex; mode=display">a^{[1]}=z^{[1]}</script><script type="math/tex; mode=display">z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}</script><script type="math/tex; mode=display">a^{[2]}=z^{[2]}</script><script type="math/tex; mode=display">a^{[2]}=z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}=W^{[2]}(W^{[1]}x+b^{[1]})+b^{[2]}=(W^{[2]}W^{[1]})x+(W^{[2]}b^{[1]}+b^{[2]})=W'x+b'</script><p>多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入<script type="math/tex">x</script>的线性模型。这样的话神经网络就没有任何作用了。因此，隐藏层的激活函数必须要是非线性的</p><p>如果是预测问题而不是分类问题，输出<script type="math/tex">y</script>是连续的情况下，输出层的激活函数可以使用线性函数。如果输出<script type="math/tex">y</script>恒为正值，则也可以使用<script type="math/tex">ReLU</script>激活函数</p><h2 id="3-7-激活函数的导数（Derivatives-of-activation-functions-）"><a href="#3-7-激活函数的导数（Derivatives-of-activation-functions-）" class="headerlink" title="3.7 激活函数的导数（Derivatives of activation functions ）"></a>3.7 激活函数的导数（Derivatives of activation functions ）</h2><p>$sigmoid$函数的导数：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{(-z)}}</script><script type="math/tex; mode=display">g'(z)=\frac{d}{dz}g(z)=g(z)(1-g(z))=a(1-a)</script><p>$tanh$函数的导数：</p><script type="math/tex; mode=display">g(z)=\frac{e^{(z)}-e^{(-z)}}{e^{(z)}+e^{(-z)}}</script><script type="math/tex; mode=display">g'(z)=\frac{d}{dz}g(z)=1-(g(z))^2=1-a^2</script><p>$ReLU$函数的导数：</p><script type="math/tex; mode=display">g(z)=max(0,z)</script><script type="math/tex; mode=display">x = \begin{cases}0 &\text{if } z < 0 \\1 &\text{if } z \geq 0\end{cases}</script><p>$Leaky ReLU$函数：</p><script type="math/tex; mode=display">g(z)=max(0.01z,z)</script><script type="math/tex; mode=display">g'(z) = \begin{cases}0.01 &\text{if } z < 0 \\1 &\text{if } z \geq 0\end{cases}</script><h2 id="3-8-神经网络的梯度下降（Gradient-descent-for-neural-networks）"><a href="#3-8-神经网络的梯度下降（Gradient-descent-for-neural-networks）" class="headerlink" title="3.8 神经网络的梯度下降（Gradient descent for neural networks）"></a>3.8 神经网络的梯度下降（Gradient descent for neural networks）</h2><script type="math/tex; mode=display">dZ^{[2]}=A^{[2]}-Y</script><script type="math/tex; mode=display">dW^{[2]}=\frac1mdZ^{[2]}A^{[1]T}</script><script type="math/tex; mode=display">db^{[2]}=\frac1mnp.sum(dZ^{[2]},axis=1,keepdim=True)</script><script type="math/tex; mode=display">dZ^{[1]}=W^{[2]T}dZ^{[2]}\ast g'(Z^{[1]})</script><script type="math/tex; mode=display">dW^{[1]}=\frac1mdZ^{[1]}X^T</script><script type="math/tex; mode=display">db^{[1]}=\frac1mnp.sum(dZ^{[1]},axis=1,keepdim=True)</script><h2 id="3-9-（选修）直观理解反向传播（Backpropagation-intuition-）"><a href="#3-9-（选修）直观理解反向传播（Backpropagation-intuition-）" class="headerlink" title="3.9 （选修）直观理解反向传播（Backpropagation intuition ）"></a>3.9 （选修）直观理解反向传播（Backpropagation intuition ）</h2><p>单个训练样本反向过程可以根据梯度计算方法逐一推导：</p><script type="math/tex; mode=display">dz^{[2]}=a^{[2]}-y</script><script type="math/tex; mode=display">dW^{[2]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial W^{[2]}}=dz^{[2]}a^{[1]T}</script><script type="math/tex; mode=display">db^{[2]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial b^{[2]}}=dz^{[2]}\cdot 1=dz^{[2]}</script><script type="math/tex; mode=display">dz^{[1]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial a^{[1]}}\cdot \frac{\partial a^{[1]}}{\partial z^{[1]}}=W^{[2]T}dz^{[2]}\ast g^{[1]'}(z^{[1]})</script><script type="math/tex; mode=display">dW^{[1]}=dz^{[1]}\cdot \frac{\partial z^{[1]}}{\partial W^{[1]}}=dz^{[1]}x^T</script><script type="math/tex; mode=display">db^{[1]}=dz^{[1]}\cdot \frac{\partial z^{[1]}}{\partial b^{[1]}}=dz^{[1]}\cdot 1=dz^{[1]}</script><p><img src="/images/pasted-24.png" alt="upload successful"></p><p>浅层神经网络（包含一个隐藏层），<script type="math/tex">m</script>个训练样本的正向传播过程和反向传播过程分别包含了<script type="math/tex">6</script>个表达式，其向量化矩阵形式如下图所示：</p><p><img src="/images/pasted-25.png" alt="upload successful"></p><h2 id="3-10-随机初始化（Random-Initialization）"><a href="#3-10-随机初始化（Random-Initialization）" class="headerlink" title="3.10 随机初始化（Random Initialization）"></a>3.10 随机初始化（Random Initialization）</h2><p>神经网络模型中的参数权重<script type="math/tex">W</script>不能全部初始化为零</p><p><img src="/images/pasted-26.png" alt="upload successful"></p><p>如果权重<script type="math/tex">W^{[1]}</script>和<script type="math/tex">W^{[2]}</script>都初始化为零，即：</p><script type="math/tex; mode=display">W^{[1]}= \left[ \begin{matrix} 0 & 0 \\ 0 & 0 \end{matrix} \right]</script><script type="math/tex; mode=display">W^{[2]}= \left[ \begin{matrix} 0 & 0 \end{matrix} \right]</script><p>这样使得隐藏层第一个神经元的输出等于第二个神经元的输出，即<script type="math/tex">a_1^{[1]}=a_2^{[1]}</script>。经过推导得到<script type="math/tex">dz_1^{[1]}=dz_2^{[1]}</script>，<script type="math/tex">dW_1^{[1]}=dW_2^{[1]}</script>，这样的结果是隐藏层两个神经元对应的权重行向量<script type="math/tex">W_1^{[1]}</script>和<script type="math/tex">W_2^{[1]}</script>每次迭代更新都会得到完全相同的结果，<script type="math/tex">W_1^{[1]}</script>始终等于<script type="math/tex">W_2^{[1]}</script>，完全对称。这样隐藏层设置多个神经元就没有任何意义</p><p>权重<script type="math/tex">W</script>全部初始化为零带来的问题称为<strong>symmetry breaking problem</strong></p><p>随机初始化：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W_1 = np.random.randn((<span class="number">2</span>,<span class="number">2</span>))*<span class="number">0.01</span></span><br><span class="line">b_1 = np.zero((<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">W_2 = np.random.randn((<span class="number">1</span>,<span class="number">2</span>))*<span class="number">0.01</span></span><br><span class="line">b_2 = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>让<script type="math/tex">W</script>比较小，是因为如果使用<script type="math/tex">sigmoid</script>函数或者<script type="math/tex">tanh</script>函数作为激活函数的话，<script type="math/tex">W</script>比较小，得到的<script type="math/tex">|z|</script>也比较小（靠近零点），而零点区域的梯度比较大，这样能大大提高梯度下降算法的更新速度，尽快找到全局最优解</p><p>如果<script type="math/tex">W</script>较大，得到的<script type="math/tex">|z|</script>也比较大，附近曲线平缓，梯度较小，训练过程会慢很多</p><p>如果激活函数是<script type="math/tex">ReLU</script>或者<script type="math/tex">Leaky</script> <script type="math/tex">ReLU</script>函数，则不需要考虑这个问题</p><p>如果输出层是<script type="math/tex">sigmoid</script>函数，则对应的权重<script type="math/tex">W</script>最好初始化到比较小的值</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;3-1-神经网络概述（Neural-Network-Overview）&quot;&gt;&lt;a href=&quot;#3-1-神经网络概述（Neural-Network-Overview）&quot; class=&quot;headerlink&quot; title=&quot;3.1 神经网络概述（Neural Network Overview）&quot;&gt;&lt;/a&gt;3.1 神经网络概述（Neural Network Overview）&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/pasted-16.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>DeepLearning.ai深度学习课程笔记</title>
    <link href="https://baozouai.com/2019/02/27/DeepLearning-ai%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    <id>https://baozouai.com/2019/02/27/DeepLearning-ai深度学习课程笔记/</id>
    <published>2019-02-27T06:11:00.000Z</published>
    <updated>2019-02-26T15:31:18.831Z</updated>
    
    <content type="html"><![CDATA[<p>笔记中没有涵盖所有的视频内容，主要是我不懂或者觉得比较重要的内容，学生我水平有限，如笔记中有知识点、公式、代码错误，还烦请指出</p><p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/%E6%8D%95%E8%8E%B7_%E5%89%AF%E6%9C%AC11.png" alt><br><a id="more"></a><br><strong>Andrew Ng（吴恩达）的公开信：</strong></p><p>朋友们，</p><p>我在做三个全新的<strong>AI</strong>项目。现在，我十分兴奋地宣布其中的第一个：<strong>deeplearning.ai</strong>，一个立志于扩散<strong>AI</strong>知识的项目。该项目在<strong>Coursera</strong>上发布了一系列深度学习课程，这些课程将帮助你掌握深度学习、对它高效地应用，并打造属于你自己的<strong>AI</strong>事业。</p><p><strong>AI是新一轮电力革命</strong></p><p>就像一百年前电力改造了每个主流行业，当今的<strong>AI</strong>技术在做着相同的事。好几个大型科技公司都设立了<strong>AI</strong>部门，用<strong>AI</strong>革新他们的业务。接下来的几年里，各个行业、规模大小各不相同的公司也都会意识到——-在由<strong>AI</strong>驱动的未来，他们必须成为其中的一份子。</p><p><strong>创建由AI驱动的社会</strong></p><p>我希望，我们可以建立一个由<strong>AI</strong>驱动的社会：让每个人看得起病，给每个孩子个性化的教育，让所有人都能坐上价格亲民的自动驾驶汽车，并向男人和女人提供有意义的工作。总而言之，是一个让每个人的生活变得更好的社会。</p><p>但是，任何一个公司都不可能单独完成这些任务。就像现在每一个计算机专业的毕业生都知道怎么用云，将来，每个程序员也必须懂得怎么用<strong>AI</strong>。用深度学习改善人类生活的方法有数百万种，社会也需要数百万个人——即来自世界各国的你们，来创造出了不起的<strong>AI</strong>系统。不管你是加州的一个软件工程师，一名中国的研究员，还是印度的<strong>ML</strong>工程师，我希望都能用深度学习来解决世界上的各种挑战。</p><p><strong>你会学到什么</strong></p><p>任何一个掌握了机器学习基础知识的人，都可以学习这五门系列课程，它们组成了<strong>Coursera</strong>的全新深度学习专业。</p><p>你会学到深度学习的基础，理解如何创建神经网络，学习怎么成功地领导机器学习项目。你会学习卷积神经网络、<strong>RNNs</strong>、<strong>LSTM</strong>、<strong>Adam</strong>、<strong>Dropout</strong>、<strong>BatchNorm</strong>、<strong>Xavier/He initialization</strong>以及更多。学习过程中，你会接触到医疗、自动驾驶、读手语、音乐生成、自然语言处理的案例。</p><p>你不仅会掌握深度学习理论，还会看到它是怎样在行业应用落地的。你会在<strong>Python</strong>和<strong>TensorFlow</strong>里试验这些想法，你还会听到各位深度学习领袖人物的意见，他们会分享各自的学习经历，并提供职业规划建议。</p><p>当你拿到<strong>Coursera</strong>的深度学习专业证书，就可以自信得把“深度学习”四个字写进你的简历。</p><p><strong>加入我，建立一个由AI驱动的社会</strong></p><p>从2011年到现在，已经有180万人加入了我的机器学习课程。当时，我和四名斯坦福的学生发布了这门课程，它随即成为了<strong>Coursera</strong>的第一门公开课。那之后，我受到你们之中许多人的启发——当我看到你们是如何努力地理解机器学习，开发优秀的<strong>AI</strong>系统，并开启令人惊艳的事业。</p><p>我希望深度学习专业能帮助你们实现更了不起的事，让你们为社<br>会贡献更多，在职业道路上走得更远。</p><p>我希望大家和我一道，建立一个由<strong>AI</strong>驱动的社会。</p><p>我会通知大家另外两个项目的进展，并不断探索，为全世界<strong>AI</strong>社区的每一个人提供更多支持的途径。</p><p>Sincerely，</p><p>吴恩达</p><p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/343rsrimport.png" alt></p><blockquote><p>吴恩达与<strong>deeplearning.ai</strong>团队</p></blockquote><p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/0001.jpg" alt></p><p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/0002.jpg" alt></p><p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/Structuring%20Machine%20Learning%20Projects-1.jpg" alt></p><p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/Convolutional%20Neural%20Networks-1.jpg" alt></p><p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/Sequence%20Models-1.jpg" alt></p><p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/Deep%20Learning.ai-1.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;笔记中没有涵盖所有的视频内容，主要是我不懂或者觉得比较重要的内容，学生我水平有限，如笔记中有知识点、公式、代码错误，还烦请指出&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/%E6%8D%95%E8%8E%B7_%E5%89%AF%E6%9C%AC11.png&quot; alt&gt;&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第二周：神经网络的编程基础(Basics of Neural Network programming)(Course 1)</title>
    <link href="https://baozouai.com/2019/02/27/%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80-Basics-of-Neural-Network-programming/"/>
    <id>https://baozouai.com/2019/02/27/第二周：神经网络的编程基础-Basics-of-Neural-Network-programming/</id>
    <published>2019-02-26T23:39:42.000Z</published>
    <updated>2019-02-27T05:38:39.187Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-1-二分类-Binary-Classification"><a href="#2-1-二分类-Binary-Classification" class="headerlink" title="2.1 二分类(Binary Classification)"></a>2.1 二分类(Binary Classification)</h2><p><strong>逻辑回归</strong>模型一般用来解决<strong>二分类（Binary Classification）</strong>问题</p><p>二分类就是输出y只有{0,1}两个离散值（也有{-1,1}的情况）<br><a id="more"></a><br><img src="/images/pasted-8.png" alt="upload successful"></p><p>彩色图片包含RGB三个通道。例如该cat图片的尺寸为（64，64，3）</p><p>在神经网络模型中，首先要将图片输入x（维度是（64，64，3））转化为一维的<strong>特征向量（featurevector）</strong>。方法是每个通道一行一行取，再连接起来。则转化后的输入特征向量维度为（12288，1）。此特征向量x是列向量，维度一般记为<script type="math/tex">n_x</script></p><p>如果训练样本共有m张图片，那么整个训练样本X组成了矩阵，维度是（<script type="math/tex">n_x</script>,m),  <script type="math/tex">n_x</script>代表了每个样本<script type="math/tex">X^{(i)}</script>特征个数，列m代表了样本个数,输出Y组成了一维的行向量，维度是（1，m）</p><p><img src="/images/pasted-9.png" alt="upload successful">)</p><p><img src="/images/pasted-10.png" alt="upload successful"></p><h2 id="2-2-逻辑回归-Logistic-Regression"><a href="#2-2-逻辑回归-Logistic-Regression" class="headerlink" title="2.2 逻辑回归(Logistic Regression)"></a>2.2 逻辑回归(Logistic Regression)</h2><p>逻辑回归中，预测值<script type="math/tex">\hat y=P(y=1 | x)</script>表示为1的概率，取值范围在[0,1]之间</p><p>使用线性模型，引入参数w和b。权重w的维度是（<script type="math/tex">n_x</script>，1），b是一个常数项</p><p>逻辑回归的预测输出可以完整写成：</p><script type="math/tex; mode=display">\hat y = Sigmoid(w^Tx+b)=\sigma(w^Tx+b)</script><p>Sigmoid函数的一阶导数可以用其自身表示：</p><script type="math/tex; mode=display">\sigma'(z)=\sigma(z)(1-\sigma(z))</script><p><img src="/images/pasted-11.png" alt="upload successful"></p><p><img src="/images/pasted-12.png" alt="upload successful"></p><h2 id="2-3-逻辑回归的代价函数（Logistic-Regression-Cost-Function）"><a href="#2-3-逻辑回归的代价函数（Logistic-Regression-Cost-Function）" class="headerlink" title="2.3 逻辑回归的代价函数（Logistic Regression Cost Function）"></a>2.3 逻辑回归的代价函数（Logistic Regression Cost Function）</h2><p>单个样本的<strong>cost function</strong>用<strong>Loss function</strong>来表示，使用<strong>平方误差（squared error）</strong>：</p><script type="math/tex; mode=display">L(\hat y,y)=\frac12(\hat y-y)^2</script><p>逻辑回归一般不使用平方误差来作为Loss function。原因是这种Loss function一般是non-convex的。</p><p>non-convex函数在使用梯度下降算法时，容易得到局部最小值（localminimum），即局部最优化。而最优化的目标是计算得到全局最优化（Global optimization），因此一般选择的Loss function应该是convex的</p><p>构建另外一种Loss function(针对单个样本)，且是convex的：</p><script type="math/tex; mode=display">L(\hat y,y)=-(ylog\ \hat y+(1-y)log\ (1-\hat y))</script><p>当y=1时，<script type="math/tex">L(\hat y,y)=-\log \hat y</script>，如果<script type="math/tex">\hat y</script>越接近1，<script type="math/tex">L(\hat y,y)\approx 0</script>，表示预测效果越好；如果<script type="math/tex">\hat y</script>越接近0，<script type="math/tex">L(\hat y,y)\approx +\infty</script>，表示预测效果越差</p><p>当y=0时，<script type="math/tex">L(\hat y,y)=-\log(1- \hat y)</script>，如果<script type="math/tex">\hat y</script>越接近0，<script type="math/tex">L(\hat y,y)\approx 0</script>，表示预测效果越好；如果<script type="math/tex">\hat y</script>越接近1，<script type="math/tex">L(\hat y,y)\approx +\infty</script>，表示预测效果越差</p><p><strong>Cost function</strong>是m个样本的<strong>Loss function</strong>的平均值，反映了m个样本的预测输出<script type="math/tex">\hat y</script>与真实样本输出y的平均接近程度:</p><script type="math/tex; mode=display">J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac1m\sum_{i=1}^m[y^{(i)}log\ \hat y^{(i)}+(1-y^{(i)})log\ (1-\hat y^{(i)})]</script><p><img src="/images/pasted-13.png" alt="upload successful"></p><h2 id="2-4-逻辑回归的梯度下降（Logistic-Regression-Gradient-Descent）"><a href="#2-4-逻辑回归的梯度下降（Logistic-Regression-Gradient-Descent）" class="headerlink" title="2.4 逻辑回归的梯度下降（Logistic Regression Gradient Descent）"></a>2.4 逻辑回归的梯度下降（Logistic Regression Gradient Descent）</h2><p>对单个样本而言，<strong>逻辑回归Loss function</strong>表达式如下：</p><script type="math/tex; mode=display">z=w^Tx+b</script><script type="math/tex; mode=display">\hat y=a=\sigma(z)</script><script type="math/tex; mode=display">L(a,y)=-(y\log(a)+(1-y)\log(1-a))</script><p><img src="/images/pasted-14.png" alt="upload successful"></p><p>计算该逻辑回归的反向传播过程:</p><script type="math/tex; mode=display">da=\frac{\partial L}{\partial a}=-\frac ya+\frac{1-y}{1-a}</script><script type="math/tex; mode=display">dz=\frac{\partial L}{\partial z}=\frac{\partial L}{\partial a}\cdot \frac{\partial a}{\partial z}=(-\frac ya+\frac{1-y}{1-a})\cdot a(1-a)=a-y</script><script type="math/tex; mode=display">dw_1=\frac{\partial L}{\partial w_1}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial w_1}=x_1\cdot dz=x_1(a-y)</script><script type="math/tex; mode=display">dw_2=\frac{\partial L}{\partial w_2}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial w_2}=x_2\cdot dz=x_2(a-y)</script><script type="math/tex; mode=display">db=\frac{\partial L}{\partial b}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial b}=1\cdot dz=a-y</script><p>则梯度下降算法可表示为：</p><script type="math/tex; mode=display">w_1:=w_1-\alpha\ dw_1</script><script type="math/tex; mode=display">w_2:=w_2-\alpha\ dw_2</script><script type="math/tex; mode=display">b:=b-\alpha\ db</script><p><img src="/images/pasted-15.png" alt="upload successful"></p><h2 id="2-5-梯度下降的例子-Gradient-Descent-on-m-Examples"><a href="#2-5-梯度下降的例子-Gradient-Descent-on-m-Examples" class="headerlink" title="2.5 梯度下降的例子(Gradient Descent on m Examples)"></a>2.5 梯度下降的例子(Gradient Descent on m Examples)</h2><p>m个样本的<strong>Cost function</strong>表达式如下：</p><script type="math/tex; mode=display">z^{(i)}=w^Tx^{(i)}+b</script><script type="math/tex; mode=display">\hat y^{(i)}=a^{(i)}=\sigma(z^{(i)})</script><script type="math/tex; mode=display">J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac1m\sum_{i=1}^m[y^{(i)}log\ \hat y^{(i)}+(1-y^{(i)})log\ (1-\hat y^{(i)})]</script><p><strong>Cost function</strong>关于w和b的偏导数可以写成和平均的形式：</p><script type="math/tex; mode=display">dw_1=\frac1m\sum_{i=1}^mx_1^{(i)}(a^{(i)}-y^{(i)})</script><script type="math/tex; mode=display">dw_2=\frac1m\sum_{i=1}^mx_2^{(i)}(a^{(i)}-y^{(i)})</script><script type="math/tex; mode=display">dw_m=\frac1m\sum_{i=1}^mx_m^{(i)}(a^{(i)}-y^{(i)})</script><script type="math/tex; mode=display">db=\frac1m\sum_{i=1}^m(a^{(i)}-y^{(i)})</script><p>算法流程如下所示：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">J=<span class="number">0</span>; dw1=<span class="number">0</span>; dw2=<span class="number">0</span>; db=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span> to m</span><br><span class="line">z(i) = wx(i)+b;</span><br><span class="line">a(i) = sigmoid(z(i));</span><br><span class="line">J += -[y(i)log(a(i))+(<span class="number">1</span>-y(i)）log(<span class="number">1</span>-a(i));</span><br><span class="line">dz(i) = a(i)-y(i);</span><br><span class="line">dw1 += x1(i)dz(i);</span><br><span class="line">dw2 += x2(i)dz(i);</span><br><span class="line">db += dz(i);</span><br><span class="line">J /= m;</span><br><span class="line">dw1 /= m;</span><br><span class="line">dw2 /= m;</span><br><span class="line">db /= m;</span><br></pre></td></tr></table></figure><p>经过每次迭代后，根据梯度下降算法，w和b都进行更新：</p><script type="math/tex; mode=display">w_1:=w_1-\alpha\ dw_1</script><script type="math/tex; mode=display">w_2:=w_2-\alpha\ dw_2</script><script type="math/tex; mode=display">w_m:=w_m-\alpha\ dw_m</script><script type="math/tex; mode=display">b:=b-\alpha\ db</script><p>在深度学习中，样本数量m通常很大，使用for循环会让神经网络程序运行得很慢。应该尽量避免使用for循环操作，而使用矩阵运算，能够大大提高程序运行速度</p><h2 id="2-6-向量化-logistic-回归的梯度输出（Vectorizing-Logistic-Regression’s-Gradient-Output）"><a href="#2-6-向量化-logistic-回归的梯度输出（Vectorizing-Logistic-Regression’s-Gradient-Output）" class="headerlink" title="2.6 向量化 logistic 回归的梯度输出（Vectorizing Logistic Regression’s Gradient Output）"></a>2.6 向量化 logistic 回归的梯度输出（Vectorizing Logistic Regression’s Gradient Output）</h2><p>db可表示为：</p><script type="math/tex; mode=display">db=\frac1m \sum_{i=1}^mdz^{(i)}</script><p>dw可表示为：</p><script type="math/tex; mode=display">dw=\frac1m X\cdot dZ^T</script><p>单次迭代，梯度下降算法流程如下所示：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Z = np.dot(w.T,X) + b</span><br><span class="line">A = sigmoid(Z)</span><br><span class="line">dZ = A-Y</span><br><span class="line">dw = <span class="number">1</span>/m*np.dot(X,dZ.T)</span><br><span class="line">db = <span class="number">1</span>/m*np.sum(dZ)</span><br><span class="line"></span><br><span class="line">w = w - alpha*dw</span><br><span class="line">b = b - alpha*db</span><br></pre></td></tr></table></figure><h2 id="2-7-（选修）logistic-损失函数的解释（Explanation-of-logistic-regression-cost-function-）"><a href="#2-7-（选修）logistic-损失函数的解释（Explanation-of-logistic-regression-cost-function-）" class="headerlink" title="2.7 （选修）logistic 损失函数的解释（Explanation of logistic regression cost function ）"></a>2.7 （选修）logistic 损失函数的解释（Explanation of logistic regression cost function ）</h2><p>$\hat y$可以看成是预测输出为正类（+1）的概率：</p><script type="math/tex; mode=display">\hat y=P(y=1|x)</script><p>当y=1时：</p><script type="math/tex; mode=display">p(y|x)=\hat y</script><p>当y=0时：</p><script type="math/tex; mode=display">p(y|x)=1-\hat y</script><p>整合到一个式子:</p><script type="math/tex; mode=display">P(y|x)=\hat y^y(1-\hat y)^{(1-y)}</script><p>进行log处理：</p><script type="math/tex; mode=display">log\ P(y|x)=log\ \hat y^y(1-\hat y)^{(1-y)}=y\ log\ \hat y+(1-y)log(1-\hat y)</script><p>上述概率P(y|x)越大越好，加上负号，则转化成了单个样本的<strong>Loss function</strong>，越小越好:</p><script type="math/tex; mode=display">L=-(y\ log\ \hat y+(1-y)log(1-\hat y))</script><p>对于所有m个训练样本，假设样本之间是独立同分布的，总的概率越大越好：</p><script type="math/tex; mode=display">max\ \prod_{i=1}^m\ P(y^{(i)}|x^{(i)})</script><p>引入log函数，加上负号，将上式转化为<strong>Cost function</strong>：</p><script type="math/tex; mode=display">J(w,b)=-\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac 1m\sum_{i=1}^m[y^{(i)}\ log\ \hat y^{(i)}+(1-y^{(i)})log(1-\hat y^{(i)})]</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2-1-二分类-Binary-Classification&quot;&gt;&lt;a href=&quot;#2-1-二分类-Binary-Classification&quot; class=&quot;headerlink&quot; title=&quot;2.1 二分类(Binary Classification)&quot;&gt;&lt;/a&gt;2.1 二分类(Binary Classification)&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;逻辑回归&lt;/strong&gt;模型一般用来解决&lt;strong&gt;二分类（Binary Classification）&lt;/strong&gt;问题&lt;/p&gt;
&lt;p&gt;二分类就是输出y只有{0,1}两个离散值（也有{-1,1}的情况）&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第一周：深度学习引言(Introduction to Deep Learning)(Course 1)</title>
    <link href="https://baozouai.com/2019/02/27/%E7%AC%AC%E4%B8%80%E9%97%A8%E8%AF%BE-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Neural-Networks-and-Deep-Learning/"/>
    <id>https://baozouai.com/2019/02/27/第一门课-神经网络和深度学习-Neural-Networks-and-Deep-Learning/</id>
    <published>2019-02-26T23:32:07.000Z</published>
    <updated>2019-02-27T05:38:12.327Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-1-神经网络的监督学习-Supervised-Learning-with-Neural-Networks"><a href="#1-1-神经网络的监督学习-Supervised-Learning-with-Neural-Networks" class="headerlink" title="1.1 神经网络的监督学习(Supervised Learning with Neural Networks)"></a>1.1 神经网络的监督学习(Supervised Learning with Neural Networks)</h2><p><img src="/images/pasted-0.png" alt="upload successful"></p><p>一般的<strong>监督式学习</strong>（房价预测和线上广告问题），只要使用标准的神经网络模型就可以<br><a id="more"></a><br>图像识别处理问题，则要使用<strong>卷积神经网络（Convolution Neural Network）</strong>，即<strong>CNN</strong></p><p>处理类似语音这样的序列信号时，则要<strong>使用循环神经网络（Recurrent Neural Network）</strong>，即<strong>RNN</strong></p><p>自动驾驶这样的复杂问题则需要更加复杂的<strong>混合神经网络模型</strong></p><p><img src="/images/pasted-1.png" alt="upload successful"></p><p><strong>CNN</strong>一般处理图像问题，<strong>RNN</strong>一般处理语音信号</p><p>数据类型一般分为两种：<strong>Structured Data</strong>和<strong>Unstructured Data</strong></p><p><img src="/images/pasted-2.png" alt="upload successful"></p><p><strong>Structured Data</strong>通常指的是有实际意义的数据，例如房价预测中的size，#bedrooms，price等；例如在线广告中的User Age，Ad ID等</p><p><strong>Unstructured Data</strong>通常指的是比较抽象的数据，例如Audio，Image或者Text</p><p><img src="/images/pasted-3.png" alt="upload successful"></p><p><img src="/images/pasted-4.png" alt="upload successful"></p><h2 id="1-2Why-is-Deep-Learning-taking-off？"><a href="#1-2Why-is-Deep-Learning-taking-off？" class="headerlink" title="1.2Why is Deep Learning taking off？"></a>1.2Why is Deep Learning taking off？</h2><p><img src="/images/pasted-5.png" alt="upload successful"></p><p>红色曲线代表了传统机器学习算法的表现，例如是SVM，logistic regression，decision tree等。当数据量比较小的时候，传统学习模型的表现是比较好的。当数据量很大的时候，其性能基本趋于水平</p><p>构建一个深度学习的流程是首先产生Idea，然后将Idea转化为Code，最后进行Experiment。接着根据结果修改Idea，继续这种Idea-&gt;Code-&gt;Experiment的循环，直到最终训练得到表现不错的深度学习网络模型</p><p><img src="/images/pasted-6.png" alt="upload successful">![]<br><img src="/images/pasted-7.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-1-神经网络的监督学习-Supervised-Learning-with-Neural-Networks&quot;&gt;&lt;a href=&quot;#1-1-神经网络的监督学习-Supervised-Learning-with-Neural-Networks&quot; class=&quot;headerlink&quot; title=&quot;1.1 神经网络的监督学习(Supervised Learning with Neural Networks)&quot;&gt;&lt;/a&gt;1.1 神经网络的监督学习(Supervised Learning with Neural Networks)&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/pasted-0.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
&lt;p&gt;一般的&lt;strong&gt;监督式学习&lt;/strong&gt;（房价预测和线上广告问题），只要使用标准的神经网络模型就可以&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning</title>
    <link href="https://baozouai.com/2019/02/23/machine%20learning/"/>
    <id>https://baozouai.com/2019/02/23/machine learning/</id>
    <published>2019-02-23T13:06:11.566Z</published>
    <updated>2019-02-26T15:07:17.058Z</updated>
    
    <content type="html"><![CDATA[<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E<br><a id="more"></a><br>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://baozouai.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://baozouai.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://baozouai.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Python/"/>
    
    
      <category term="深度学习" scheme="https://baozouai.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://baozouai.com/tags/Python/"/>
    
      <category term="机器学习" scheme="https://baozouai.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
