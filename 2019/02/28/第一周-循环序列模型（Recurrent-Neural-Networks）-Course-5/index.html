<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<script src="/js/src/photoswipe.min.js?v=6.0.0"></script>
<script src="/js/src/photoswipe-ui-default.min.js?v=6.0.0"></script>


<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  



  
  
    
  
  <link href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.css" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.0.0" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/favicon128.ico?v=6.0.0">







  <meta name="keywords" content="深度学习,">





  <link rel="alternate" href="/atom.xml" title="暴走的技术博客" type="application/atom+xml">






<meta name="description" content="1.1 为什么选择序列模型？（Why Sequence Models?）语音识别：给定一个输入音频片段 X，要求输出对应的文字记录 Y。输入和输出数据都是序列模型，因为 X是一个按时播放的音频片段，输出 Y是一系列单词">
<meta name="keywords" content="深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="第一周 循环序列模型（Recurrent Neural Networks）(Course 5)">
<meta property="og:url" content="https://www.baozouai.com/2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/index.html">
<meta property="og:site_name" content="暴走的技术博客">
<meta property="og:description" content="1.1 为什么选择序列模型？（Why Sequence Models?）语音识别：给定一个输入音频片段 X，要求输出对应的文字记录 Y。输入和输出数据都是序列模型，因为 X是一个按时播放的音频片段，输出 Y是一系列单词">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ae2970d80a119cd341ef31c684bfac49.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/cccbc03192af67a089b53d7940659505.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8deca8a84f06466155d2d8d53d26e05d.png">
<meta property="og:image" content="http://pnlb0i3oh.bkt.clouddn.com/pasted-156.png">
<meta property="og:image" content="http://pnlb0i3oh.bkt.clouddn.com/pasted-157.png">
<meta property="og:image" content="http://pnlb0i3oh.bkt.clouddn.com/pasted-158.png">
<meta property="og:image" content="http://pnlb0i3oh.bkt.clouddn.com/pasted-159.png">
<meta property="og:image" content="http://pnlb0i3oh.bkt.clouddn.com/pasted-160.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/998c7af4f90cd0de0c88f138b61f0168.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/rnn_cell_backprop.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1daa38085604dd04e91ebc5e609d1179.png">
<meta property="og:image" content="http://pnlb0i3oh.bkt.clouddn.com/pasted-161.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8b901fc8fcab9e16b1fe26b92f4ec546.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1d31771da8ced333968541fbbf67e6f1.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8fb1c4afe30b7a0ede26522b355068ba.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ac5d647140997ba713c376fb097ea0e2.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1521560729.png">
<meta property="og:image" content="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/501import.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c1df3f793dcb1ec681db6757b4974cee.png">
<meta property="og:image" content="http://pnlb0i3oh.bkt.clouddn.com/pasted-164.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/94e871edbd87337937ce374e71d56e42.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/LSTM.png">
<meta property="og:image" content="http://pnlb0i3oh.bkt.clouddn.com/pasted-165.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/48c787912f7f8daee638dd311583d6cf.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/053831ff43d039bd5e734df96d8794cb.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8378c2bfe73e1ac9f85d6aa79b71b5eb.png">
<meta property="og:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/455863a3c8c2dfaa0e5474bfa2c6824d.png">
<meta property="og:updated_time" content="2019-03-02T08:31:14.199Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第一周 循环序列模型（Recurrent Neural Networks）(Course 5)">
<meta name="twitter:description" content="1.1 为什么选择序列模型？（Why Sequence Models?）语音识别：给定一个输入音频片段 X，要求输出对应的文字记录 Y。输入和输出数据都是序列模型，因为 X是一个按时播放的音频片段，输出 Y是一系列单词">
<meta name="twitter:image" content="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ae2970d80a119cd341ef31c684bfac49.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.baozouai.com/2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/">





  <title>第一周 循环序列模型（Recurrent Neural Networks）(Course 5) | 暴走的技术博客</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?8a46909e912a122ce69d3b5e9a8dc661";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>
<!--动态标题-->
<script type="text/javascript" src="/js/src/dytitle.js"></script>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
  


  
  
  
    
  



  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
<a href="https://github.com/baozouai" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">暴走的技术博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">The people who are crazy enough to change the world are the ones who do！</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-photos">
          <a href="/photos" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-camera-retro"></i> <br>
            
            相册
          </a>
        </li>
      
        
        <li class="menu-item menu-item-books">
          <a href="/books" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br>
            
            书单
          </a>
        </li>
      
        
        <li class="menu-item menu-item-movies">
          <a href="/movies" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-film"></i> <br>
            
            电影
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>
    
    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">第一周 循环序列模型（Recurrent Neural Networks）(Course 5)</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-28T06:17:00+08:00">
                2019-02-27
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-02T16:31:14+08:00">
                2019-03-02
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/" class="leancloud_visitors" data-flag-title="第一周 循环序列模型（Recurrent Neural Networks）(Course 5)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  19
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        <h2 id="1-1-为什么选择序列模型？（Why-Sequence-Models-）"><a href="#1-1-为什么选择序列模型？（Why-Sequence-Models-）" class="headerlink" title="1.1 为什么选择序列模型？（Why Sequence Models?）"></a>1.1 为什么选择序列模型？（Why Sequence Models?）</h2><p>语音识别：给定一个输入音频片段 <script type="math/tex">X</script>，要求输出对应的文字记录 <script type="math/tex">Y</script>。输入和输出数据都是序列模型，因为 <script type="math/tex">X</script>是一个按时播放的音频片段，输出 <script type="math/tex">Y</script>是一系列单词<br><a id="more"></a><br>音乐生成问题：只有输出数据 <script type="math/tex">Y</script>是序列，而输入数据可以是空集，也可以是个单一的整数，这个数可能指代想要生成的音乐风格，或者想要生成的那首曲子的头几个音符</p>
<p>处理情感分类：输入数据 <script type="math/tex">X</script>是序列，会得到类似这样的输入：“<strong>There is nothing to like in this movie.</strong>”，你认为这句评论对应几星？</p>
<p><strong>DNA</strong>序列分析：<strong>DNA</strong>用<strong>A</strong>、<strong>C</strong>、<strong>G</strong>、<strong>T</strong>四个字母来表示。给定一段<strong>DNA</strong>序列，能够标记出哪部分是匹配某种蛋白质？</p>
<p>机器翻译：输入句：“<strong>Voulez-vou chante avecmoi?</strong>”（法语：要和我一起唱么？），要求输出另一种语言的翻译结果</p>
<p>视频行为识别：得到一系列视频帧，要求识别其中的行为</p>
<p>命名实体识别：给定一个句子，要求识别出句中的人名</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ae2970d80a119cd341ef31c684bfac49.png" alt></p>
<p>这些问题都可以被称作使用标签数据 <script type="math/tex">(X,Y)</script>作为训练集的监督学习。但序列问题有很多不同类型。有些问题里，输入数据 <script type="math/tex">X</script>和输出数据<script type="math/tex">Y</script>都是序列，但就算在那种情况下，<script type="math/tex">X</script>和<script type="math/tex">Y</script>有时也会不一样长。或者像上图编号1和编号2所示的<script type="math/tex">X</script>和<script type="math/tex">Y</script>有相同的数据长度。在另一些问题里，只有 <script type="math/tex">X</script>或者只有<script type="math/tex">Y</script>是序列</p>
<h2 id="1-2-数学符号（Notation）"><a href="#1-2-数学符号（Notation）" class="headerlink" title="1.2 数学符号（Notation）"></a>1.2 数学符号（Notation）</h2><p>序列模型的输入语句是：“<strong>Harry Potter and Herminoe Granger invented a new spell.</strong>”。假如想要建立一个能够自动识别句中人名位置的序列模型，那么这就是一个命名实体识别问题</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/cccbc03192af67a089b53d7940659505.png" alt></p>
<p>该句话包含9个单词，输出y即为1 x 9向量，每位表征对应单词是否为人名的一部分，对应的输出y表示为：</p>
<script type="math/tex; mode=display">
y=[1\ \ 1\ \ 0\ \ 1\ \ 1\ \ 0\ \ 0\ \ 0\ \ 0]^T</script><p>$y^{&lt; t&gt;}$表示序列对应位置的输出，<script type="math/tex">T_y</script>表示输出序列长度，<script type="math/tex">1\leq t\leq T_y</script></p>
<p>对于输入<script type="math/tex">x</script>，表示为：</p>
<script type="math/tex; mode=display">
[x^{<1>}\ \ x^{<2>}\ \ x^{<3>}\ \ x^{<4>}\ \ x^{<5>}\ \ x^{<6>}\ \ x^{<7>}\ \ x^{<8>}\ \ x^{<9>}]</script><p>$x^{&lt; t&gt;}$表示序列对应位置的输入，<script type="math/tex">T_x</script>表示输入序列长度。此例中<script type="math/tex">T_x=T_y</script>，但是也存在<script type="math/tex">T_x\neq T_y</script></p>
<p>如何表示每个<script type="math/tex">x^{<t>}</script>：</p>
<p>建立一个词汇库vocabulary，尽可能包含更多的词汇。例如一个包含10000个词汇的词汇库为：</p>
<script type="math/tex; mode=display">
\left[
\begin{matrix}
a \\
and \\
\cdot \\
\cdot \\
\cdot \\
harry \\
\cdot \\
\cdot \\
\cdot \\
potter \\
\cdot \\
\cdot \\
\cdot \\
zulu
\end{matrix}
\right]</script><p>然后使用one-hot编码，词汇表中与<script type="math/tex">x^{<t>}</script>对应的位置为1，其它位置为0。如果出现词汇表之外的单词，可以使用UNK或其他字符串来表示</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8deca8a84f06466155d2d8d53d26e05d.png" alt></p>
<p>对于多样本：对应的命名规则可表示为：<script type="math/tex">X^{(i)<t>}</script>，<script type="math/tex">Y^{(i)<t>}</script>，<script type="math/tex">T_x^{(i)}</script>，<script type="math/tex">T_y^{(i)}</script>，<script type="math/tex">i</script>表示第<script type="math/tex">i</script>个样本。不同样本的<script type="math/tex">T_x^{(i)}</script>或<script type="math/tex">T_y^{(i)}</script>都有可能不同</p>
<h2 id="1-3-循环神经网络模型（Recurrent-Neural-Network-Model）"><a href="#1-3-循环神经网络模型（Recurrent-Neural-Network-Model）" class="headerlink" title="1.3 循环神经网络模型（Recurrent Neural Network Model）"></a>1.3 循环神经网络模型（Recurrent Neural Network Model）</h2><p>序列模型从左到右，依次传递，此例中，<script type="math/tex">T_x=T_y</script>。<script type="math/tex">x^{<t>}</script>到<script type="math/tex">\hat y^{<t>}</script>之间是隐藏神经元。<script type="math/tex">a^{<t>}</script>会传入到第<script type="math/tex">t+1</script>元素中，作为输入。其中，<script type="math/tex">a^{<0>}</script>一般为零向量</p>
<p><img src="http://pnlb0i3oh.bkt.clouddn.com/pasted-156.png" alt></p>
<p>循环神经网络是从左向右扫描数据，同时每个时间步的参数也是共享的，用<script type="math/tex">W_{\text{ax}}</script>来表示管理着从<script type="math/tex">x^{<1>}</script>到隐藏层的连接的一系列参数，每个时间步使用的都是相同的参数<script type="math/tex">W_{\text{ax}}</script>。而激活值是由参数<script type="math/tex">W_{aa}</script>决定，同时每一个时间步都使用相同的参数<script type="math/tex">W_{aa}</script>，同样的输出结果由<script type="math/tex">W_{\text{ya}}</script>决定：</p>
<p><img src="http://pnlb0i3oh.bkt.clouddn.com/pasted-157.png" alt="upload successful"></p>
<p>预测<script type="math/tex">{\hat{y}}^{< 3 >}</script>时，不仅要使用<script type="math/tex">x^{<3>}</script>的信息，还要使用来自<script type="math/tex">x^{<1>}</script>和<script type="math/tex">x^{<2>}</script>的信息，而这个循环神经网络的一个缺点是只使用了这个序列中之前的信息来做出预测，因为如果给定了这个句子，“<strong>Teddy Roosevelt was a great President.</strong>”，为了判断<strong>Teddy</strong>是否是人名的一部分，仅仅知道句中前两个词是完全不够的，还需要知道句中后部分的信息，因为句子也可能是这样的，“<strong>Teddy bears are on sale!</strong>”。因此如果只给定前三个单词，是不可能确切地知道<strong>Teddy</strong>是否是人名的一部分，第一个例子是人名，第二个例子就不是，所以不可能只看前三个单词就能分辨出其中的区别</p>
<p>所以这样特定的神经网络结构的一个限制是它在某一时刻的预测仅使用了从序列之前的输入信息，并没有使用序列中后部分的信息</p>
<p>RNN的正向传播（Forward Propagation）过程为：</p>
<script type="math/tex; mode=display">
a^{<t>}=g(W_{aa}\cdot a^{<t-1>}+W_{ax}\cdot x^{<t>}+b_a)</script><script type="math/tex; mode=display">
\hat y^{<t>}=g(W_{ya}\cdot a^{<t>}+b_y)</script><p><img src="http://pnlb0i3oh.bkt.clouddn.com/pasted-158.png" alt="upload successful"></p>
<p>为了简化表达式，可以对<script type="math/tex">a^{<t>}</script>项进行整合：</p>
<script type="math/tex; mode=display">
W_{aa}\cdot a^{<t-1>}+W_{ax}\cdot x^{<t>}=[W_{aa}\ \ W_{ax}]\left[
\begin{matrix}
a^{<t-1>} \\
x^{<t>}
\end{matrix}
\right]\rightarrow W_a[a^{<t-1>},x^{<t>}]</script><p>则正向传播可表示为：</p>
<script type="math/tex; mode=display">
a^{<t>}=g(W_a[a^{<t-1>},x^{<t>}]+b_a)</script><script type="math/tex; mode=display">
\hat y^{<t>}=g(W_{y}\cdot a^{<t>}+b_y)</script><p><img src="http://pnlb0i3oh.bkt.clouddn.com/pasted-159.png" alt="upload successful">)</p>
<p><strong>RNN</strong>前向传播示意图：</p>
<p><img src="http://pnlb0i3oh.bkt.clouddn.com/pasted-160.png" alt="upload successful"></p>
<h2 id="1-4-通过时间的反向传播（Backpropagation-through-time）"><a href="#1-4-通过时间的反向传播（Backpropagation-through-time）" class="headerlink" title="1.4 通过时间的反向传播（Backpropagation through time）"></a>1.4 通过时间的反向传播（Backpropagation through time）</h2><p>反向传播计算方向与前向传播基本上是相反：</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/998c7af4f90cd0de0c88f138b61f0168.png" alt></p>
<p>识别人名的例子，经过RNN正向传播，单个元素的Loss function为：</p>
<script type="math/tex; mode=display">
L^{<t>}(\hat y^{<t>},y^{<t>})=-y^{<t>}log\ \hat y^{<t>}-(1-y^{<t>})log\ (1-\hat y^{<t>})</script><blockquote>
<p>这是 binary classification 的 Loss Function，注意与1.6 的softmax Loss Function区别</p>
</blockquote>
<p>该样本所有元素的Loss function为：</p>
<script type="math/tex; mode=display">
L(\hat y,y)=\sum_{t=1}^{T_y}L^{<t>}(\hat y^{<t>},y^{<t>})</script><p>反向传播（Backpropagation）过程就是从右到左分别计算<script type="math/tex">L(\hat y,y)</script>对参数<script type="math/tex">W_{a}</script>，<script type="math/tex">W_{y}</script>，<script type="math/tex">b_a</script>，<script type="math/tex">b_y</script>的偏导数，这种从右到左的求导过程被称为Backpropagation through time</p>
<p><strong>RNN</strong>反向传播示意图：</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/rnn_cell_backprop.png" alt></p>
<h2 id="1-5-不同类型的循环神经网络（Different-types-of-RNNs）"><a href="#1-5-不同类型的循环神经网络（Different-types-of-RNNs）" class="headerlink" title="1.5 不同类型的循环神经网络（Different types of RNNs）"></a>1.5 不同类型的循环神经网络（Different types of RNNs）</h2><p>RNN模型包含以下几个类型：</p>
<ul>
<li><strong>一对一，</strong>当去掉<script type="math/tex">a^{<0>}</script>时它就是一种标准类型的神经网络</li>
<li><strong>一对多</strong>，比如音乐生成或者序列生成</li>
<li><strong>多对一</strong>，如是情感分类的例子，首先读取输入，一个电影评论的文本，然后判断他们是否喜欢电影还是不喜欢</li>
<li><strong>多对多</strong>，如命名实体识别，<script type="math/tex">T_{x}=T_{y}</script></li>
<li><strong>多对多，</strong>如机器翻译，<script type="math/tex">T_x\neq T_y</script></li>
</ul>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1daa38085604dd04e91ebc5e609d1179.png" alt></p>
<h2 id="1-6-语言模型和序列生成（Language-model-and-sequence-generation）"><a href="#1-6-语言模型和序列生成（Language-model-and-sequence-generation）" class="headerlink" title="1.6 语言模型和序列生成（Language model and sequence generation）"></a>1.6 语言模型和序列生成（Language model and sequence generation）</h2><p>在语音识别中，某句语音有两种翻译：</p>
<ul>
<li><strong>the apple and pair salad</strong></li>
<li><strong>the apple and pear salad</strong></li>
</ul>
<p>语言模型会计算出这两句话各自的出现概率：</p>
<ul>
<li><script type="math/tex; mode=display">P( \text{The apple and pair salad}) = 3.2 \times 10^{-13}</script></li>
<li><script type="math/tex; mode=display">P\left(\text{The apple and pear salad} \right) = 5.7 \times 10^{-10}</script></li>
</ul>
<p>选择概率最大的语句作为正确的翻译</p>
<p>概率计算的表达式为：</p>
<script type="math/tex; mode=display">
P(y^{<1>},y^{<2>},\cdots,y^{<T_y>})</script><p>如何使用RNN构建语言模型：</p>
<p>首先需要一个足够大的训练集，训练集由大量的单词语句语料库（corpus）构成。然后，对corpus的每句话进行切分词（tokenize），建立vocabulary，对每个单词进行one-hot编码。例如下面这句话：</p>
<p><strong>The Egyptian Mau is a bread of cat.</strong></p>
<p>每句话结束末尾，需要加上<strong>&lt; EOS &gt;</strong>作为语句结束符。若语句中有词汇表中没有的单词，用<strong>&lt; UNK &gt;</strong>表示。假设单词“Mau”不在词汇表中，则上面这句话可表示为：</p>
<p><strong>The Egyptian &lt; UNK &gt; is a bread of cat. &lt; EOS &gt;</strong></p>
<p>准备好训练集并对语料库进行切分词等处理之后，接下来构建相应的RNN模型：</p>
<p><img src="http://pnlb0i3oh.bkt.clouddn.com/pasted-161.png" alt="upload successful"><br>$x^{<1>}$和<script type="math/tex">a^{<0>}</script>均为零向量。Softmax输出层<script type="math/tex">\hat y^{<1>}</script>表示出现该语句第一个单词的概率，softmax输出层<script type="math/tex">\hat y^{<2>}</script>表示在第一个单词基础上出现第二个单词的概率，即条件概率，以此类推，最后是出现<strong>&lt; EOS &gt;</strong>的条件概率</1></p>
<p>单个元素的softmax loss function为：</p>
<script type="math/tex; mode=display">
L^{<t>}(\hat y^{<t>},y^{<t>})=-\sum_iy_i^{<t>}log\ \hat y_i^{<t>}</script><blockquote>
<p>这是softmax Loss Function ，注意与1.4 binary classification 的 Loss Function区别</p>
</blockquote>
<p>该样本所有元素的Loss function为：</p>
<script type="math/tex; mode=display">
L(\hat y,y)=\sum_tL^{<t>}(\hat y^{<t>},y^{<t>})</script><p>对语料库的每条语句进行RNN模型训练，最终得到的模型可以根据给出语句的前几个单词预测其余部分，将语句补充完整。例如给出<strong>“Cats average 15”</strong>，RNN模型可能预测完整的语句是<strong>“Cats average 15 hours of sleep a day.”</strong></p>
<p>整个语句出现的概率等于语句中所有元素出现的条件概率乘积。例如某个语句包含<script type="math/tex">y^{<1>},y^{<2>},y^{<3>}</script>，则整个语句出现的概率为：</p>
<script type="math/tex; mode=display">
P(y^{<1>},y^{<2>},y^{<3>})=P(y^{<1>})\cdot P(y^{<2>}|y^{<1>})\cdot P(y^{<3>}|y^{<1>},y^{<2>})</script><h2 id="1-7-对新序列采样（Sampling-novel-sequences）"><a href="#1-7-对新序列采样（Sampling-novel-sequences）" class="headerlink" title="1.7 对新序列采样（Sampling novel sequences）"></a>1.7 对新序列采样（Sampling novel sequences）</h2><h3 id="基于词汇的RNN模型"><a href="#基于词汇的RNN模型" class="headerlink" title="基于词汇的RNN模型"></a>基于词汇的RNN模型</h3><p>序列模型模拟了任意特定单词序列的概率，要做的是对这些概率分布进行采样来生成一个新的单词序列。编号1所示的网络已经被上方所展示的结构训练过，编号2是进行采样</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8b901fc8fcab9e16b1fe26b92f4ec546.png" alt></p>
<p>第一步要做的是对想要模型生成的第一个词进行采样，输入<script type="math/tex">x^{<1>} =0</script>，<script type="math/tex">a^{<0>} =0</script>，第一个时间步得到的是所有可能的输出，是经过<strong>softmax</strong>层后得到的概率，然后根据这个<strong>softmax</strong>的分布进行随机采样。对这个向量使用<code>np.random.choice</code>，来根据向量中这些概率的分布进行采样，就能对第一个词进行采样</p>
<p>然后继续下一个时间步，<script type="math/tex">\hat y^{<1>}</script>作为输入（编号4），然后<strong>softmax</strong>层就会预测<script type="math/tex">\hat y^{<2>}</script>是什么。假如第一个词进行抽样后得到的是<strong>The</strong>，现在要计算出在第一词是<strong>The</strong>的情况下，第二个词应该是什么（编号5），然后再用采样函数来对<script type="math/tex">\hat y^{<2>}</script>进行采样</p>
<p>即无论得到什么样的用<strong>one-hot</strong>码表示的选择结果，都把它传递到下一个时间步，然后进行采样，直到最后一个时间步</p>
<p>怎样知道一个句子结束：</p>
<ul>
<li>如果代表句子结尾的标识在字典中，可以一直进行采样直到得到<strong>EOS</strong>标识（编号6），代表着已经抵达结尾，可以停止采样</li>
<li>如果字典中没有这个词，可以决定从20个或100个或其他个单词进行采样，然后一直将采样进行下去直到达到所设定的时间步。不过这种过程有时候会产生一些未知标识（编号7），如果要确保算法不会输出这种标识，要做的是拒绝采样过程中产生任何未知的标识，一旦出现就继续在剩下的词中进行重采样，直到得到一个不是未知标识的词</li>
</ul>
<p>这就是如何从<strong>RNN</strong>语言模型中生成一个随机选择的句子。以上所建立的是基于词汇的<strong>RNN</strong>模型，意思就是字典中的词都是英语单词（下图编号1）</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1d31771da8ced333968541fbbf67e6f1.png" alt></p>
<h3 id="基于字符的RNN结构"><a href="#基于字符的RNN结构" class="headerlink" title="基于字符的RNN结构"></a>基于字符的<strong>RNN</strong>结构</h3><p>用以上字符组成字典（上图编号2所示）</p>
<p>序列<script type="math/tex">\hat y^{<1>}</script>，<script type="math/tex">\hat y^{<2>}</script>，<script type="math/tex">\hat y^{<3>}</script>在训练数据中是单独的字符，对于“<strong>Cats average 15 hours of sleep a day.</strong>”，<strong>C</strong>是<script type="math/tex">\hat y^{<1>}</script>，<strong>a</strong>就是<script type="math/tex">\hat y^{<2>}</script>，<strong>t</strong>就是<script type="math/tex">\hat y^{<3>}</script>等等</p>
<p>优点：</p>
<p>不必担心会出现未知的标识，基于字符的语言模型会将<strong>Mau</strong>这样的序列也视为可能性非零的序列。而基于词汇的语言模型，如果<strong>Mau</strong>不在字典中，只能当作未知标识<strong>UNK</strong></p>
<p>缺点：</p>
<p>最后会得到太多太长的序列，基于字符的语言模型在捕捉句子中的依赖关系也就是句子较前部分如何影响较后部分不如基于词汇的语言模型那样可以捕捉长范围的关系，并且基于字符的语言模型训练起来计算成本比较高</p>
<h2 id="1-8-循环神经网络的梯度消失（Vanishing-gradients-withRNNs）"><a href="#1-8-循环神经网络的梯度消失（Vanishing-gradients-withRNNs）" class="headerlink" title="1.8 循环神经网络的梯度消失（Vanishing gradients withRNNs）"></a>1.8 循环神经网络的梯度消失（Vanishing gradients withRNNs）</h2><p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8fb1c4afe30b7a0ede26522b355068ba.png" alt></p>
<p>编号1<strong>cat</strong>是单数，应该用<strong>was，</strong>编号2 <strong>cats</strong>是复数，用<strong>were</strong></p>
<p>这个例子中的句子有长期的依赖，最前面的单词对句子后面的单词有影响。但基本的<strong>RNN</strong>模型（编号3）不擅长捕获长期依赖效应</p>
<p><strong>RNN</strong>反向传播很困难，会有梯度消失的问题，后面层的输出误差（编号6）很难影响前面层（编号7）的计算。即很难让一个神经网络能够意识到它要记住看到的是单数名词还是复数名词，然后在序列后面生成依赖单复数形式的<strong>was</strong>或者<strong>were</strong>。且在英语里面中间的内容（编号8）可以任意长，所以基本的<strong>RNN</strong>模型会有很多局部影响，输出<script type="math/tex">\hat y^{<3>}</script>主要受附近的值（编号10）的影响，编号6所示的输出很难受到序列靠前的输入（编号10）的影响，因为不管输出是什么，对的还是错的，这个区域都很难反向传播到序列的前面部分，也因此网络很难调整序列前面的计算</p>
<p>在反向传播的时候，随着层数的增多，梯度不仅可能指数型的下降，也可能指数型的上升。梯度消失在训练<strong>RNN</strong>时是首要的问题，不过梯度爆炸也会出现，但是梯度爆炸很明显，因为指数级大的梯度会让参数变得极其大，以至于网络参数崩溃。参数大到崩溃会看到很多<strong>NaN</strong>，或者不是数字的情况，这意味着网络计算出现了数值溢出</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/ac5d647140997ba713c376fb097ea0e2.png" alt></p>
<p>解决方法：用<strong>梯度修剪</strong>。梯度向量如果大于某个阈值，缩放梯度向量，保证不会太大</p>
<h2 id="1-9-GRU单元（Gated-Recurrent-Unit（GRU））"><a href="#1-9-GRU单元（Gated-Recurrent-Unit（GRU））" class="headerlink" title="1.9 GRU单元（Gated Recurrent Unit（GRU））"></a>1.9 GRU单元（Gated Recurrent Unit（GRU））</h2><p>门控循环单元：改变了<strong>RNN</strong>的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题</p>
<h3 id="简化的GRU模型"><a href="#简化的GRU模型" class="headerlink" title="简化的GRU模型"></a>简化的GRU模型</h3><p><strong>RNN</strong>隐藏层的单元的可视化：</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/1521560729.png" alt></p>
<p>$a^{&lt; t&gt;}$表达式为：</p>
<script type="math/tex; mode=display">
a^{<t>}=tanh(W_a[a^{<t-1>},x^{<t>}]+b_a)</script><p>为了解决梯度消失问题，对上述单元进行修改，添加了记忆单元，构建GRU，如下图所示：</p>
<p><img src="https://baozou.gitbooks.io/neural-networks-and-deep-learning/content/assets/501import.png" alt></p>
<p>表达式为：</p>
<script type="math/tex; mode=display">
\tilde c^{<t>}=tanh(W_c[c^{<t-1>},x^{<t>}]+b_c)</script><script type="math/tex; mode=display">
\Gamma_u=\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)</script><script type="math/tex; mode=display">
c^{<t>}=\Gamma_u*\tilde c^{<t>}+(1-\Gamma_u)*c^{<t-1>}</script><p>$c^{<t-1>}=a^{<t-1>}$，<script type="math/tex">c^{<t>}=a^{<t>}</script>。符号<script type="math/tex">c</script>表示记忆细胞的值，<script type="math/tex">a</script>表示输出的激活值，<script type="math/tex">\tilde c^{<t>}</script>是个候选值，替代了c的值，<script type="math/tex">\Gamma_u</script>（0到1）意为gate，<strong>u</strong>表示“<strong>update</strong>”，当<script type="math/tex">\Gamma_u=1</script>时，代表更新；当<script type="math/tex">\Gamma_u=0</script>时，代表记忆，保留之前的模块输出。<script type="math/tex">\Gamma_u</script>能够保证RNN模型中跨度很大的依赖关系不受影响，消除梯度消失问题</t-1></t-1></p>
<h3 id="完整的GRU"><a href="#完整的GRU" class="headerlink" title="完整的GRU"></a>完整的GRU</h3><p>完整的GRU添加了另外一个gate，即<script type="math/tex">\Gamma_r</script>，表达式如下：</p>
<script type="math/tex; mode=display">
\tilde c^{<t>}=tanh(W_c[\Gamma_r*c^{<t-1>},x^{<t>}]+b_c)</script><script type="math/tex; mode=display">
\Gamma_u=\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)</script><script type="math/tex; mode=display">
\Gamma_r=\sigma(W_r[c^{<t-1>},x^{<t>}]+b_r)</script><script type="math/tex; mode=display">
c^{<t>}=\Gamma_u*\tilde c^{<t>}+(1-\Gamma_u)*c^{<t-1>}</script><script type="math/tex; mode=display">
a^{<t>}=c^{<t>}</script><p>$\Gamma_{r}$门：计算出的下一个<script type="math/tex">c^{<t>}</script>的候选值<script type="math/tex">{\tilde{c}}^{<t>}</script>跟<script type="math/tex">c^{<t-1>}</script>有多大的相关性</p>
<p>$c^{&lt; t&gt;}$可以是一个向量（编号1），如果有100维的隐藏的激活值，那么<script type="math/tex">c^{<t>}</script>、<script type="math/tex">{\tilde{c}}^{<t>}</script>、<script type="math/tex">\Gamma_{u}</script>还有画在框中的其他值也是100维</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/c1df3f793dcb1ec681db6757b4974cee.png" alt></p>
<p>$*$实际上就是元素对应的乘积（<script type="math/tex">c^{< t>}=\Gamma_u*\tilde c^{< t>}+(1-\Gamma_u)*c^{<t-1>}</script>），若<script type="math/tex">\Gamma_{u}</script>（<script type="math/tex">\Gamma_u=\sigma(W_u[c^{<t-1>},x^{< t>}]+b_u)</script>）是一个100维的向量，而里面的值<strong>几乎</strong>都是0或者1，则这100维的记忆细胞<script type="math/tex">c^{< t>}</script>（<script type="math/tex">c^{< t>}=a^{< t>}</script>，编号1）就是要更新的比特</p>
<h2 id="1-10-长短期记忆（LSTM（long-short-term-memory）unit）"><a href="#1-10-长短期记忆（LSTM（long-short-term-memory）unit）" class="headerlink" title="1.10 长短期记忆（LSTM（long short term memory）unit）"></a>1.10 长短期记忆（LSTM（long short term memory）unit）</h2><p>LSTM是另一种更强大的解决梯度消失问题的方法。它对应的RNN隐藏层单元结构如下图所示：</p>
<p><img src="http://pnlb0i3oh.bkt.clouddn.com/pasted-164.png" alt="upload successful"></p>
<p>相应的表达式为：</p>
<script type="math/tex; mode=display">
\tilde c^{<t>}=tanh(W_c[a^{<t-1>},x^{<t>}]+b_c)</script><script type="math/tex; mode=display">
\Gamma_u=\sigma(W_u[a^{<t-1>},x^{< t>}]+b_u)</script><script type="math/tex; mode=display">
\Gamma_f=\sigma(W_f[a^{<t-1>},x^{< t>}]+b_f)</script><script type="math/tex; mode=display">
\Gamma_o=\sigma(W_o[a^{<t-1>},x^{< t>}]+b_o)</script><script type="math/tex; mode=display">
c^{< t>}=\Gamma_u*\tilde c^{< t>}+\Gamma_f*c^{<t-1>}</script><script type="math/tex; mode=display">
a^{< t>}=\Gamma_o*c^{< t>}</script><p>LSTM包含三个gates：<script type="math/tex">\Gamma_u,\Gamma_f,\Gamma_o</script>，分别对应update gate，forget gate和output gate</p>
<p>在<strong>LSTM</strong>中不再有<script type="math/tex">a^{< t>} = c^{< t>}</script>的情况</p>
<p>红线显示了只要正确地设置了遗忘门和更新门，<strong>LSTM</strong>很容易把<script type="math/tex">c^{<0>}</script>的值一直往下传递到右边，比如<script type="math/tex">c^{<3>} = c^{<0>}</script>。这就是为什么<strong>LSTM</strong>和<strong>GRU</strong>非常擅长于长时间记忆某个值</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/94e871edbd87337937ce374e71d56e42.png" alt></p>
<p>“<strong>窥视孔连接</strong>”（<strong>peephole connection</strong>）:门值不仅取决于<script type="math/tex">a^{<t-1>}</script>和<script type="math/tex">x^{< t>}</script>，也取决于上一个记忆细胞的值（<script type="math/tex">c^{<t-1>}</script>），即<script type="math/tex">c^{<t-1>}</script>也能影响门值</p>
<p>如果考虑<script type="math/tex">c^{<t-1>}</script>对<script type="math/tex">\Gamma_u,\Gamma_f,\Gamma_o</script>的影响，可加入“窥视孔连接”，对LSTM的表达式进行修改：</p>
<script type="math/tex; mode=display">
\tilde c^{< t>}=tanh(W_c[a^{<t-1>},x^{< t>}]+b_c)</script><script type="math/tex; mode=display">
\Gamma_u=\sigma(W_u[a^{<t-1>},x^{< t>},c^{<t-1>}]+b_u)</script><script type="math/tex; mode=display">
\Gamma_f=\sigma(W_f[a^{<t-1>},x^{< t>},c^{<t-1>}]+b_f)</script><script type="math/tex; mode=display">
\Gamma_o=\sigma(W_o[a^{<t-1>},x^{< t>},c^{<t-1>}]+b_o)</script><script type="math/tex; mode=display">
c^{< t>}=\Gamma_u*\tilde c^{< t>}+\Gamma_f*c^{<t-1>}</script><script type="math/tex; mode=display">
a^{< t>}=\Gamma_o*c^{<t>}</script><p><strong>LSTM</strong>主要的区别：比如（上图编号13）有一个100维的隐藏记忆细胞单元，第<script type="math/tex">i</script>个<script type="math/tex">c^{<t-1>}</script>的元素只会影响第<script type="math/tex">i</script>个元素对应的那个门，所以关系是一对一的，并不是任意这100维的<script type="math/tex">c^{<t-1>}</script>可以影响所有的门元素</p>
<p><strong>LSTM</strong>前向传播图：</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/LSTM.png" alt></p>
<p><img src="http://pnlb0i3oh.bkt.clouddn.com/pasted-165.png" alt="upload successful"><br><strong>GRU</strong>：模型简单，更容易创建一个更大的网络，只有两个门，在计算上运行得更快，且可以扩大模型的规模</p>
<p><strong>LSTM：</strong>更加强大和灵活，因为它有三个门而不是两个</p>
<h2 id="1-11-双向循环神经网络（Bidirectional-RNN）"><a href="#1-11-双向循环神经网络（Bidirectional-RNN）" class="headerlink" title="1.11 双向循环神经网络（Bidirectional RNN）"></a>1.11 双向循环神经网络（Bidirectional RNN）</h2><p>双向<strong>RNN</strong>模型在序列的某点处不仅可以获取之前的信息，还可以获取未来的信息</p>
<p>用只有4个单词的句子，<script type="math/tex">x^{<1>}</script>到<script type="math/tex">x^{<4>}</script>。这个网络有一个前向的循环单元<script type="math/tex">a^{\rightarrow <1>}</script>，<script type="math/tex">a^{\rightarrow <2>}</script>，<script type="math/tex">a^{\rightarrow <3>}</script>，<script type="math/tex">a^{\rightarrow <4>}</script>，这四个循环单元都有一个当前输入<script type="math/tex">x</script>输入进去，得到预测的<script type="math/tex">\hat y^{<1>}</script>，<script type="math/tex">\hat y^{<2>}</script>，<script type="math/tex">\hat y^{<3>}</script>和<script type="math/tex">\hat y^{<4>}</script></p>
<p>再增加一个反向循环层：<script type="math/tex">a^{\leftarrow <1>}</script>，<script type="math/tex">a^{\leftarrow <2>}</script>，<script type="math/tex">a^{\leftarrow <3>}</script>，<script type="math/tex">a^{\leftarrow <4>}</script></p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/48c787912f7f8daee638dd311583d6cf.png" alt></p>
<p>给定一个输入序列<script type="math/tex">x^{<1>}</script>到<script type="math/tex">x^{<4>}</script>，这个序列先后计算前向的<script type="math/tex">a^{\rightarrow <1>}</script>，<script type="math/tex">a^{\rightarrow <2>}</script>，<script type="math/tex">a^{\rightarrow <3>}</script>，<script type="math/tex">a^{\rightarrow <4>}</script>，而反向序列从<script type="math/tex">a^{\leftarrow <4>}</script>开始，计算完了反向的<script type="math/tex">a^{\leftarrow <4>}</script>，可以用这些激活值计算反向<script type="math/tex">a^{\leftarrow <3>},a^{\leftarrow <2>},a^{\leftarrow <1>}</script></p>
<p>值得注意的是计算的是网络激活值，这不是反向传播而是前向的传播，图中前向传播一部分计算是从左到右，一部分计算是从右到左。把所有激活值都计算完了就可以计算预测结果</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/053831ff43d039bd5e734df96d8794cb.png" alt></p>
<p>预测结果：</p>
<script type="math/tex; mode=display">
\hat y^{} =g(W_{g}\left\lbrack a^{\rightarrow <t>},a^{\leftarrow <t>} \right\rbrack +b_{y})</script><p>这些基本单元不仅仅是标准<strong>RNN</strong>单元，也可以是<strong>GRU</strong>单元或者<strong>LSTM</strong>单元</p>
<p>双向<strong>RNN</strong>网络模型的缺点是需要完整的数据的序列才能预测任意位置。比如要构建一个语音识别系统，双向<strong>RNN</strong>模型需要等待整个语音说完，获取整个语音表达才能处理这段语音，并进一步做语音识别</p>
<h2 id="1-12-深层循环神经网络（Deep-RNNs）"><a href="#1-12-深层循环神经网络（Deep-RNNs）" class="headerlink" title="1.12 深层循环神经网络（Deep RNNs）"></a>1.12 深层循环神经网络（Deep RNNs）</h2><p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/8378c2bfe73e1ac9f85d6aa79b71b5eb.png" alt></p>
<p>$a^{\lbrack l\rbrack }$表示第<script type="math/tex">l</script>层的激活值，&lt;t&gt;表示第<script type="math/tex">t</script>个时间点</p>
<p>激活值<script type="math/tex">a^{[l]< t>}</script>有两个输入:</p>
<script type="math/tex; mode=display">
a^{[l]< t>}=g(W_a^{[l]}[a^{[l]<t-1>},a^{[l-1]< t>}]+b_a^{[l]})</script><p>对于<strong>RNN</strong>来说，有三层就已经不少了。由于时间的维度，<strong>RNN</strong>网络会变得相当大，即使只有很少的几层</p>
<p>另外一种Deep RNNs结构是每个输出层上还有一些垂直单元：</p>
<p><img src="https://github.com/fengdu78/deeplearning_ai_books/raw/master/images/455863a3c8c2dfaa0e5474bfa2c6824d.png" alt><br>即把输出去掉（编号1），在每一个上面堆叠循环层，然后换成一些深的层，这些层并不水平连接，只是一个深层的网络，然后用来预测<script type="math/tex">y^{< t>}</script></p>
<p>这些单元（编号3）没必要是标准的<strong>RNN</strong>，也可以是<strong>GRU</strong>单元或者<strong>LSTM</strong>单元，也可以构建深层的双向<strong>RNN</strong>网络，但深层的<strong>RNN</strong>训练需要很多计算资源，需要很长的时间</p>

      
    </div>
    
    
    

    

    <div>
     
       <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
     
  </div>


    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>有钱能使鬼写作 л̵ʱªʱªʱª (ᕑᗢᓫา∗)˒</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.png" alt="暴走 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpeg" alt="暴走 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i>

 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/28/第四周-特殊应用：人脸识别和神经风格转换（Special-applications-Face-recognition-Neural-style-transfer）-Course-4/" rel="next" title="第四周 特殊应用：人脸识别和神经风格转换（Special applications: Face recognition & Neural style transfer)(Course 4)">
                <i class="fa fa-chevron-left"></i> 第四周 特殊应用：人脸识别和神经风格转换（Special applications: Face recognition & Neural style transfer)(Course 4)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/28/第二周-自然语言处理与词嵌入（Natural-Language-Processing-and-Word-Embeddings）-Course-5/" rel="prev" title="第二周 自然语言处理与词嵌入（Natural Language Processing and Word Embeddings）(Course 5)">
                第二周 自然语言处理与词嵌入（Natural Language Processing and Word Embeddings）(Course 5) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        
  <div class="bdsharebuttonbox">
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
    <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
    <a href="#" class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
    <a href="#" class="bds_tieba" data-cmd="tieba" title="分享到百度贴吧"></a>
    <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
    <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
    <a href="#" class="bds_more" data-cmd="more"></a>
    <a class="bds_count" data-cmd="count"></a>
  </div>
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "2",
        "bdMiniList": false,
        "bdPic": ""
      },
      "share": {
        "bdSize": "16",
        "bdStyle": "0"
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div class="ds-thread" data-thread-key="2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/" data-title="第一周 循环序列模型（Recurrent Neural Networks）(Course 5)" data-url="https://www.baozouai.com/2019/02/28/第一周-循环序列模型（Recurrent-Neural-Networks）-Course-5/">
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>



  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">


            
              <img class="site-author-image" itemprop="image" src="/img/avatar.png" alt="暴走">
            


              <p class="site-author-name" itemprop="name">暴走</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>
<script type="text/javascript" src="https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@1.2/dist/Meting.min.js"></script>
<div class="aplayer" data-id="D89A1236EF4D99ED641FFD846F1A23AF" data-server="kugou " data-type="song" data-autoplay="false" data-mode="single"></div>
<br>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/baozouai" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:baozouai@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-为什么选择序列模型？（Why-Sequence-Models-）"><span class="nav-number">1.</span> <span class="nav-text">1.1 为什么选择序列模型？（Why Sequence Models?）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-数学符号（Notation）"><span class="nav-number">2.</span> <span class="nav-text">1.2 数学符号（Notation）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-循环神经网络模型（Recurrent-Neural-Network-Model）"><span class="nav-number">3.</span> <span class="nav-text">1.3 循环神经网络模型（Recurrent Neural Network Model）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-通过时间的反向传播（Backpropagation-through-time）"><span class="nav-number">4.</span> <span class="nav-text">1.4 通过时间的反向传播（Backpropagation through time）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-5-不同类型的循环神经网络（Different-types-of-RNNs）"><span class="nav-number">5.</span> <span class="nav-text">1.5 不同类型的循环神经网络（Different types of RNNs）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-6-语言模型和序列生成（Language-model-and-sequence-generation）"><span class="nav-number">6.</span> <span class="nav-text">1.6 语言模型和序列生成（Language model and sequence generation）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-7-对新序列采样（Sampling-novel-sequences）"><span class="nav-number">7.</span> <span class="nav-text">1.7 对新序列采样（Sampling novel sequences）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基于词汇的RNN模型"><span class="nav-number">7.1.</span> <span class="nav-text">基于词汇的RNN模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于字符的RNN结构"><span class="nav-number">7.2.</span> <span class="nav-text">基于字符的RNN结构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-8-循环神经网络的梯度消失（Vanishing-gradients-withRNNs）"><span class="nav-number">8.</span> <span class="nav-text">1.8 循环神经网络的梯度消失（Vanishing gradients withRNNs）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-9-GRU单元（Gated-Recurrent-Unit（GRU））"><span class="nav-number">9.</span> <span class="nav-text">1.9 GRU单元（Gated Recurrent Unit（GRU））</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简化的GRU模型"><span class="nav-number">9.1.</span> <span class="nav-text">简化的GRU模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#完整的GRU"><span class="nav-number">9.2.</span> <span class="nav-text">完整的GRU</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-10-长短期记忆（LSTM（long-short-term-memory）unit）"><span class="nav-number">10.</span> <span class="nav-text">1.10 长短期记忆（LSTM（long short term memory）unit）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-11-双向循环神经网络（Bidirectional-RNN）"><span class="nav-number">11.</span> <span class="nav-text">1.11 双向循环神经网络（Bidirectional RNN）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-12-深层循环神经网络（Deep-RNNs）"><span class="nav-number">12.</span> <span class="nav-text">1.12 深层循环神经网络（Deep RNNs）</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>
    
    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart" aria-hidden="true"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">暴走</span>

  
</div>



  <span class="post-meta-divider">|</span>






<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共64.3k字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
</div>








        
      </div>
    </footer>
    
    
    
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  
  <script type="text/javascript" color="255,0,0" opacity="0.5" zindex="-2" count="100" src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script>












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazyload@2.0.0-beta.2/lazyload.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.0"></script>
<script type="text/javascript" src="/js/src/photoswipe.min.js?v=6.0.0"></script>
<script type="text/javascript" src="/js/src/photoswipe-ui-default.min.js?v=6.0.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"notes-iissnan"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  


















  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("S5fCBBMaimjEzLztiJKSBnbL-gzGzoHsz", "m3rlGieJoVqNqhc9YbnO52cM");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=6.0.0"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=6.0.0"></script>


  

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":80,"height":80},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
