<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）(Course 4)]]></title>
    <url>%2F2019%2F02%2F28%2F%E7%AC%AC%E4%BA%8C%E5%91%A8-%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6%EF%BC%88Deep-convolutional-models-case-studies%EF%BC%89-Course-4%2F</url>
    <content type="text"><![CDATA[2.1 经典网络（Classic networks）LeNet-5LeNet-5可以识别图中的手写数字，是针对灰度图片训练的，所以图片的大小只有32×32×1。该LeNet模型总共包含了大约6万个参数，典型的LeNet-5结构包含CONV layer，POOL layer和FC layer，顺序一般是CONV layer-&gt;POOL layer-&gt;CONV layer-&gt;POOL layer-&gt;FC layer-&gt;FC layer-&gt;OUTPUT layer，即\hat y： 随着网络越来越深，图像的高度和宽度在缩小，从最初的32×32缩小到28×28，再到14×14、10×10，最后只有5×5，通道数量一直在增加，从1增加到6个，再到16个 这个神经网络中还有一种模式就是一个或多个卷积层后面跟着一个池化层，然后又是若干个卷积层再接一个池化层，然后是全连接层，最后是输出 AlexNetAlexNet包含约6000万个参数。当用于训练图像和数据集时，AlexNet能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，AlexNet比LeNet表现更为出色的另一个原因是它使用了ReLu激活函数 VGG-16VGG，也叫作VGG-16网络。VGG-16网络没有那么多超参数，是一种只需要专注于构建卷积层的简单网络。首先用3×3，步幅为1的过滤器构建卷积层，padding参数为same卷积中的参数。然后用一个2×2，步幅为2的过滤器构建最大池化层。VGG网络的一大优点是简化了神经网络结构 假设要识别这个图像，在最开始的两层用64个3×3的过滤器对输入图像进行卷积，输出结果是224×224×64，因为使用了same卷积，通道数量也一样 接下来创建一个池化层，池化层将输入图像进行压缩，减少到112×112×64。然后又是若干个卷积层，使用128个过滤器，以及一些same卷积，输出112×112×128。然后进行池化，池化后的结果是56×56×128。再用256个相同的过滤器进行三次卷积操作，然后再池化，然后再卷积三次，再池化。如此进行几轮操作后，将最后得到的7×7×512的特征图进行全连接操作，得到4096个单元，然后进行softmax激活，输出从1000个对象中识别的结果 VGG-16的数字16指在这个网络中有13个卷积层和3个全链接层 总共包含约1.38亿个参数，这种网络结构很规整，都是几个卷积层后面跟着可以压缩图像大小的池化层，池化层缩小图像的高度和宽度。同时，卷积层的过滤器数量变化存在一定的规律，由64翻倍变成128，再到256和512。主要缺点是需要训练的特征数量非常巨大 随着网络的加深，图像的高度和宽度都在以一定的规律不断缩小，每次池化后刚好缩小一半，而通道数量在不断增加，而且刚好也是在每组卷积操作后增加一倍。即图像缩小的比例和通道数增加的比例是有规律的 2.2 残差网络（Residual Networks (ResNets)）人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系，这种神经网络被称为Residual Networks(ResNets) Residual Networks由许多隔层相连的神经元子模块组成，称之为Residual block（残差块）。单个Residual block的结构如下图所示： 紫色线是skip connection（跳跃连接），直接建立a^{[l]}与a^{[l+2]}之间的隔层联系。相应的表达式如下： z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]} a^{[l+1]}=g(z^{[l+1]}) z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]} a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$a^{[l]}$直接隔层与下一层的线性输出相连，a^{[l]}插入的时机是在线性激活之后，ReLU激活之前，与z^{[l+2]}共同通过激活函数（ReLU）输出a^{[l+2]} 这种模型结构对于训练非常深的神经网络效果很好。非Residual Networks称为Plain Network Residual Network的结构 Plain Network 与Plain Network相比，Residual Network能够训练更深层的神经网络，有效避免发生发生梯度消失和梯度爆炸 随着神经网络层数增加，Plain Network实际性能会变差，training error甚至会变大 Residual Network的训练效果却很好，training error一直呈下降趋势 2.3 残差网络为什么有用？（Why ResNets work?） 输入X 经过一个大型神经网络输出激活值a^{[l]}，再给这个网络额外添加两层作为一个ResNets块，输出a^{\left\lbrack l + 2 \right\rbrack}： a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})假设在整个网络中使用ReLU激活函数，所以激活值都大于等于0，包括输入X的非零异常值。因为ReLU激活函数输出的数字要么是0，要么是正数 如果使用L2正则化或权重衰减，会压缩W^{\left\lbrack l + 2\right\rbrack}的值。W是关键项，如果W^{\left\lbrack l + 2 \right\rbrack} = 0，方便起见，假设b^{\left\lbrack l + 2 \right\rbrack} = 0，假定使用ReLU激活函数，并且所有激活值都是非负的，g\left(a^{[l]} \right)是应用于非负数的ReLU函数，所以a^{[l+2]} =a^{[l]} 可以看出，即使发生了梯度消失，W^{[l+2]}\approx0，b^{[l+2]}\approx0，也能直接建立a^{[l+2]}与a^{[l]}的线性关系，且a^{[l+2]}=a^{[l]}，这就是identity function（恒等函数）。a^{[l]}直接连到a^{[l+2]}，相当于直接忽略了a^{[l]}之后的这两层神经层。这样看似很深的神经网络，由于许多Residual blocks的存在，弱化削减了某些神经层之间的联系，实现隔层线性传递，而不是一味追求非线性关系，模型本身也就能“容忍”更深层的神经网络了。从性能上来说，这两层额外的Residual blocks也不会降低Big NN的性能，所以给大型神经网络增加两层，不论是把残差块添加到神经网络的中间还是末端位置，都不会影响网络的表现 如果Residual blocks确实能训练得到非线性关系，那么也会忽略short cut，跟Plain Network起到同样的效果 如果Residual blocks中a^{[l+2]}与a^{[l]}的维度不同，可以引入矩阵W_s与a^{[l]}相乘，使得W_s*a^{[l]}的维度与a^{[l+2]}一致 参数矩阵W_s有来两种方法得到： 将W_s作为学习参数，通过模型训练得到 固定W_s值（类似单位矩阵），不需要训练，W_s与a^{[l]}的乘积仅使得a^{[l]}截断或者补零 CNN中ResNets的结构： ResNets同类型层之间，例如CONV layers，大多使用same类型，这也解释了添加项z^{[l+2]}+a^{[l]}（维度相同所以能够相加）。如果是不同类型层之间的连接，例如CONV layer与POOL layer之间，如果维度不同，则引入矩阵W_s 2.4 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）如果是一张6×6×32的图片，使用1×1过滤器进行卷积效果更好。1×1卷积所实现的功能是遍历这36个单元格，计算左图中32个数字和过滤器中32个数字的元素积之和，然后应用ReLU非线性函数 1×1×32过滤器中的32个数字可以理解为一个神经元的输入是32个数字，这32个数字具有不同通道，乘以32个权重（将过滤器中的32个数理解为权重），然后应用ReLU非线性函数，输出相应的结果 如果过滤器是多个，就好像有多个输入单元，其输入内容为一个切片上所有数字，输出结果是6×6×#filters 1×1卷积可以从根本上理解为对这32个不同的位置都应用一个全连接层，全连接层的作用是输入32个数字（过滤器数量标记为n\_{C}^{\left\lbrack l + 1\right\rbrack}，在这36个单元上重复此过程）,输出结果是6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（non-trivial）计算 这种方法通常称为1×1卷积，也被称为Network in Network 假设一个28×28×192的输入层，如果通道数量很大，可以用32个大小为1×1×192的过滤器，使输出层为28×28×32，这就是压缩通道数（n_{C}）的方法 如果想保持通道数192不变，也是可行的，1×1卷积只是添加了非线性函数，也可以让网络学习更复杂的函数 1×1卷积层给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，也可以增加通道数量 2.5 谷歌 Inception 网络简介（Inception network motivation）Inception网络或Inception层的作用是代替人工来确定卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层 基本思想是Inception网络在单层网络上可以使用多个不同尺寸的filters，进行same convolutions，把各filter下得到的输出拼接起来。还可以将CONV layer与POOL layer混合，同时实现各种效果，但是要注意使用same pool。Inception Network不需要人为决定使用哪个过滤器或者是否需要池化，它使用不同尺寸的filters并将CONV和POOL混合起来，将所有功能输出组合拼接，再由神经网络本身去学习参数并选择最好的模块 Inception Network在提升性能的同时，会带来计算量大的问题： 乘法运算的总次数为每个输出值所需要执行的乘法运算次数（5×5×192）乘以输出值个数（28×28×32），结果等于1.2亿。 为此，引入1x1 Convolutions来减少计算量，对于输入层，使用1×1卷积把输入值从192个通道减少到16个通道。然后对这个较小层运行5×5卷积，得到最终输出 把该1x1 Convolution称为“瓶颈层”（bottleneck layer），瓶颈层是网络中最小的部分，即先缩小网络，然后再扩大 引入bottleneck layer之后，第一个卷积层计算成本：1×1×192×输出28×28×16，相乘结果约等于240万，第二个卷积层的计算成本是：28×28×32×5×5×16，计算结果为1000万，总次数是1204万，计算成本从1.2亿下降到了原来的十分之一 总结： 如果在构建神经网络层的时候，不想决定池化层是使用1×1，3×3还是5×5的过滤器，Inception模块是最好的选择。可以应用各种类型的过滤器，只需要把输出连接起来 计算成本问题，通过使用1×1卷积来构建瓶颈层，大大降低计算成本 只要合理构建瓶颈层，既可以显著缩小表示层规模，又不会降低网络性能，从而节省了计算 Inception 网络（Inception network）引入1x1 Convolution后的Inception module如下图所示： Inception模块会将之前层的激活或者输出作为它的输入，为了能在最后将这些输出都连接起来，会使用same类型的padding来池化，使得输出的高和宽依然是28×28，这样才能将它与其他输出连接起来。如果进行了最大池化，即便用了same padding，3×3的过滤器，stride为1，其输出将会是28×28×192，其通道数与输入（通道数）相同。要做的是再加上一个1×1的卷积层，将通道的数量缩小到28×28×32，避免了最后输出时，池化层占据所有的通道 最后把得到的各个层的通道都加起来，得到一个28×28×256的输出。这就是一个Inception模块 Inception网络只是很多在不同的位置重复组成的网络： 中间隐藏层也可以作为输出层Softmax，确保了即便是隐藏单元和中间层也参与了特征计算，也能预测图片的分类，起到一种调整的效果，有利于防止发生过拟合 2.7迁移学习（Transfer Learning） 训练集很小的情况： 建议：从网上下载一些神经网络开源的实现，不仅把代码下载下来，也把权重下载下来。然后去掉Softmax层，创建自己的Softmax单元，用来输出Tigger、Misty和neither三个类别。把所有的层看作是冻结的，冻结网络中所有层的参数，只需要训练和Softmax层有关的参数。这个Softmax层有三种可能的输出，Tigger、Misty或者Neither。 通过使用其他人预训练的权重，很可能得到很好的性能，即使只有一个小的数据集。大多数深度学习框架会有trainableParameter=0的参数，对于前面的层，可以设置这个参数。为了不训练这些权重，会有freeze=1的参数。只需要训练softmax层的权重，把前面这些层的权重都冻结 由于前面的层都冻结了，相当于一个固定的函数，因此不需要改变和训练它，取输入图像X，然后把它映射到softmax前一层的激活函数。能加速训练的技巧是如果先计算这一层（紫色箭头标记），计算特征或者激活值，然后把它们存到硬盘里。所做的就是用这个固定的函数，在这个神经网络的前半部分（softmax层之前的所有层视为一个固定映射），取任意输入图像X，然后计算它的某个特征向量，这样训练的就是一个很浅的softmax模型，用这个特征向量来做预测。对计算有用的一步就是对训练集中所有样本的这一层的激活值进行预计算，然后存储到硬盘里，在此之上训练softmax分类器。存储到硬盘或者说预计算方法的优点是不需要每次遍历训练集再重新计算这个激活值 更大的训练集：应该冻结更少的层，然后训练后面的层。如果输出层的类别不同，那么需要构建自己的输出单元，Tigger、Misty或者Neither三个类别。可以取后面几层的权重，用作初始化，然后从这里开始梯度下降 也可以直接去掉这几层，换成自己的隐藏单元和softmax输出层，如果有越来越多的数据，那么需要冻结的层数就越少，能够训练的层数就越多。如果有一个更大的数据集，那么不要单单训练一个softmax单元，而是考虑训练中等大小的网络，包含最终要用的网络的后面几层 如果有大量数据：应该做的就是用开源的网络和它的权重，把所有的权重当作初始化，然后训练整个网络 如果有越多的标定的数据，可以训练越多的层。极端情况下，可以用下载的权重只作为初始化，用它们来代替随机初始化，接着用梯度下降训练，更新网络所有层的所有权重 2.8 数据扩充（Data augmentation）当下计算机视觉的主要问题是没有办法得到充足的数据 最简单的数据扩充方法就是垂直镜像对称 另一个经常使用的技巧是随机裁剪，给定一个数据集，然后开始随机裁剪，得到不同的图片放在数据集中，随机裁剪并不是一个完美的数据扩充的方法，如果随机裁剪的那一部分（红色方框标记部分，编号4）看起来不像猫。但在实践中，这个方法还是很实用的，随机裁剪构成了很大一部分的真实图片 也可以使用旋转，剪切（仅水平或垂直坐标发生变化）图像，扭曲变形，引入很多形式的局部弯曲等等，但在实践中太复杂所以使用的很少 彩色转换：给R、G和B三个通道上加上不同的失真值 实践中对R、G和B的变化是基于某些分布，改变可能很小，R、G和B的值是根据某种概率分布来决定，这样会使得学习算法对照片的颜色更改更具鲁棒性 对R、G和B有不同的采样方式，其中一种影响颜色失真的算法是PCA，即主成分分析，PCA颜色增强的大概含义是，如果图片呈现紫色，即主要含有红色和蓝色，绿色很少，然后PCA颜色增强算法就会对红色和蓝色增减很多，绿色变化相对少一点，所以使总体的颜色保持一致 如果有特别大的训练数据，可以使用CPU线程，不停的从硬盘中读取数据，用CPU线程来实现失真变形，可以是随机裁剪、颜色变化，或者是镜像 同时CPU线程持续加载数据，然后实现任意失真变形，从而构成批数据或者最小批数据，这些数据持续的传输给其他线程或者其他的进程，然后开始训练，可以在CPU或者GPU上实现一个大型网络的训练 常用的实现数据扩充的方法是使用一个线程或者是多线程来加载数据，实现变形失真，然后传给其他的线程或者其他进程，来训练编号2和这个编号1，可以并行实现 在数据扩充过程中也有一些超参数，比如说颜色变化了多少，以及随机裁剪的时候使用的参数 2.9 计算机视觉现状（The state of computer vision） 大部分机器学习问题是介于少量数据和大量数据范围之间的。 语音识别有很大数量的数据 虽然现在图像识别或图像分类方面有相当大的数据集，但因为图像识别是一个复杂的问题，通过分析像素并识别出它是什么，即使在线数据集非常大，如超过一百万张图片，仍然希望能有更多的数据 物体检测拥有的数据更少 图像识别是如何看图片的问题，并且告诉你这张图是不是猫，而对象检测则是看一幅图，画一个框，告诉你图片里的物体，比如汽车等等。因为获取边框的成本比标记对象的成本更高，所以进行对象检测的数据往往比图像识别数据要少 当有很多数据时，倾向于使用更简单的算法和更少的手工工程，只要有一个大型的神经网络，甚至一个更简单的架构，就可以去学习它想学习的东西 当没有那么多的数据时，更多的是手工工程 对机器学习应用时，通常学习算法有两种知识来源： 一个来源是被标记的数据，像(x,y)应用在监督学习 第二个来源是手工工程，有很多方法去建立一个手工工程系统，它可以是源于精心设计的特征，手工精心设计的网络体系结构或者是系统的其他组件。当没有太多标签数据时，只需要更多地考虑手工工程 在基准研究和比赛中，下面的tips可能会有较好的表现： 集成，意味着想好了要的神经网络之后，可以独立训练几个神经网络，并平均它们的输出。比如说随机初始化三个、五个或者七个神经网络，然后训练所有这些网络，对输出\hat y进行平均计算，而不要平均权重，可能会在基准上提高1%，2%或者更好。但因为集成意味着要对每张图片进行测试，可能需要在从3到15个不同的网络中运行一个图像，会让运行时间变慢 Multi-crop at test time，Multi-crop是一种将数据扩充应用到测试图像中的一种形式，在测试图片的多种版本上运行分类器，输出平均结果 如把猫的图片复制四遍，包括两个镜像版本。如取中心的crop，然后取四个角落的crop，通过分类器来运行它 编号1和编号3是中心crop，编号2和编号4是四个角落的crop。把这些加起来会有10种不同的图像的crop，命名为10-crop。通过分类器来运行这十张图片，然后对结果进行平均 集成的一个大问题是需要保持所有这些不同的神经网络，占用了更多的计算机内存。multi-crop，只保留一个网络，不会占用太多的内存，但仍然会让运行时间变慢]]></content>
      <categories>
        <category>深度学习Z</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一周 卷积神经网络（Foundations of Convolutional Neural Networks）(Course 4)]]></title>
    <url>%2F2019%2F02%2F28%2F%E7%AC%AC%E4%B8%80%E5%91%A8-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88Foundations-of-Convolutional-Neural-Networks%EF%BC%89-Course-4%2F</url>
    <content type="text"><![CDATA[1.1 计算机视觉（Computer vision）图片分类，或图片识别： 目标检测： 神经网络实现图片风格迁移： 使用传统神经网络处理机器视觉的一个主要问题是输入层维度很大。例如一张64x64x3的图片，神经网络输入层的维度为12288。如果图片尺寸较大，例如一张1000x1000x3的图片，神经网络输入层的维度将达到3百万，使得网络权重W非常庞大。这样会造成两个后果，一是神经网络结构复杂，数据量相对不够，容易出现过拟合；二是所需内存、计算量较大。解决这一问题的方法就是使用卷积神经网络（CNN）。 1.2边缘检测示例（Edge detection example）对于CV问题，神经网络由浅层到深层，分别可以检测出图片的边缘特征 、局部特征（例如眼睛、鼻子等）、整体面部轮廓 图片的边缘检测最常检测的图片边缘有两类：一是垂直边缘（vertical edges），二是水平边缘（horizontal edges） 图片的边缘检测可以通过与相应滤波器进行卷积来实现。以垂直边缘检测为例，原始图片尺寸为6x6，滤波器filter尺寸为3x3，卷积后的图片尺寸为4x4，得到结果如下： ∗表示卷积操作。python中，卷积用conv_forward()表示；tensorflow中，卷积用tf.nn.conv2d()表示；keras中，卷积用Conv2D()表示 垂直边缘是一个3×3的区域，左边是明亮的像素，中间的并不需要考虑，右边是深色像素。在这个6×6图像的中间部分，明亮的像素在左边，深色的像素在右边，就被视为一个垂直边缘 1.3 更多边缘检测内容（More edge detection）图片边缘有两种渐变方式，一种是由明变暗，另一种是由暗变明。实际应用中，这两种渐变方式并不影响边缘检测结果，可以对输出图片取绝对值操作，得到同样的结果 由亮向暗 由暗向亮 下图的垂直边缘过滤器是一个3×3的区域，左边相对较亮，右边相对较暗。右图的水平边缘过滤器也是一个3×3的区域，上边相对较亮，而下方相对较暗 30（右边矩阵中绿色方框标记元素）代表了左边这块3×3的区域（左边矩阵绿色方框标记部分），这块区域是上边比较亮，下边比较暗，所以它在这里发现了一条正边缘。而-30（右边矩阵中紫色方框标记元素）代表了左边另一块区域（左边矩阵紫色方框标记部分），这块区域是底部比较亮，而上边则比较暗，所以在这里它是一条负边 10（右边矩阵中黄色方框标记元素）代表的是左边这块区域（左边6×6矩阵中黄色方框标记的部分）。这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这是一个非常大的1000×1000大图，就不会出现亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小 对于这个3×3的过滤器来说，使用了其中的一种数字组合： 还可以使用这种： \begin{bmatrix}1 & 0 & - 1 \\ 2 & 0 & - 2 \\ 1 & 0 & - 1 \end{bmatrix}叫做Sobel过滤器，优点在于增加了中间一行元素的权重，使得结果的鲁棒性会更高一些 或者： \begin{bmatrix} 3& 0 & - 3 \\ 10 & 0 & - 10 \\ 3 & 0 & - 3 \end{bmatrix}叫做Scharr过滤器，也是一种垂直边缘检测，如果将其翻转90度，就能得到对应水平边缘检测 随着深度学习的发展，如果想检测图片的各种边缘特征，而不仅限于垂直边缘和水平边缘，那么filter的数值一般需要通过模型训练得到，将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，类似于标准神经网络中的权重W一样由梯度下降算法反复迭代求得，会发现神经网络可以学习一些低级的特征，例如这些边缘的特征。CNN的主要目的就是计算出这些filter的数值，确定得到了这些filter后，CNN浅层网络也就实现了对图片所有边缘特征的检测 1.4 Padding 如果有一个n\times n的图像，用f\times f的过滤器做卷积，输出的维度就是(n-f+1)\times (n-f+1) 这样的话会有两个缺点: 每次做卷积操作，输出图片尺寸缩小 原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息 角落边缘的像素（绿色阴影标记）只被一个输出所触碰或者使用，中间的像素点（红色方框标记）会有许多3×3的区域与之重叠。角落或者边缘区域的像素点在输出中采用较少，丢掉了图像边缘位置的许多信息 可以在卷积操作之前填充这幅图像。沿着图像边缘再填充一层像素,6×6的图像填充成8×8的图像。就得到了一个尺寸和原始图像6×6的图像。习惯上，可以用0去填充，如果p是填充的数量，输出也就变成了(n+2p-f+1)\times (n+2p-f+1)。涂绿的像素点（左边矩阵）影响了输出中的这些格子（右边矩阵）。这样角落或图像边缘的信息发挥的作用较小的这一缺点就被削弱了 选择填充多少像素，通常有两个选择，分别叫做Valid卷积和Same卷积 Valid卷积意味着不填充，如果有一个n\times n的图像，用一个f\times f的过滤器卷积，会给一个(n-f+1)\times (n-f+1)维的输出 另一个叫做Same卷积，填充后输出大小和输入大小是一样的。由n-f+1，当填充p个像素点，n就变成了n+2p，公式变为： n+2p-f+1即： p=\frac{f-1}{2}当f是一个奇数，只要选择相应的填充尺寸就能确保得到和输入相同尺寸的输出 计算机视觉中，f通常是奇数，有两个原因： 如果f是偶数，只能使用一些不对称填充 当有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点，便于指出过滤器的位置 1.5 卷积步长（Strided convolutions）Stride表示filter在原图片中水平方向和垂直方向每次的步进长度。之前默认stride=1。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次 用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为： \lfloor\frac{n+2p-f}{s}+1\rfloor\ \times\ \lfloor\frac{n+2p-f}{s}+1\rfloor真正的卷积运算会先将filter绕其中心旋转180度，然后再将旋转后的filter在原始图片上进行滑动计算。filter旋转如下所示： 相关系数的计算过程则不会对filter进行旋转，而是直接在原始图片上进行滑动计算 目前为止介绍的CNN卷积实际上计算的是相关系数，而不是数学意义上的卷积。为了简化计算，一般把CNN中的这种“相关系数”就称作卷积运算。之所以可以这么等效，是因为滤波器算子一般是水平或垂直对称的，180度旋转影响不大；而且最终滤波器算子需要通过CNN网络梯度下降算法计算得到，旋转部分可以看作是包含在CNN模型算法中。忽略旋转运算可以大大提高CNN网络运算速度，而且不影响模型性能。 卷积运算服从分配律： (A*B)*C=A*(B*C)1.6三维卷积（Convolutions over volumes）3通道的RGB图片对应的滤波器算子也是3通道的。例如一个图片是6 x 6 x 3，分别表示图片的高度（height）、宽度（weight）和通道（#channel） 3通道图片的卷积运算与单通道图片的卷积运算基本一致。过程是将每个单通道（R，G，B）与对应的filter进行卷积运算求和，然后再将3通道的和相加，得到输出图片的一个像素值 不同通道的滤波算子可以不相同。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。做完卷积，然后把这两个4×4的输出堆叠在一起，第一个放到前面，第二个放到后面，就得到一个4×4×2的输出立方体 不同滤波器组卷积得到不同的输出，个数由滤波器组决定 若输入图片的尺寸为n x n xn_c，filter尺寸为f x f x n_c，则卷积后的图片尺寸为(n-f+1) x (n-f+1) x {n}'_c(默认padding为1）。n_c为图片通道数目，{n}'_c为滤波器组个数 1.7单层卷积网络（One layer of a convolutional network）卷积神经网络的单层结构如下所示： 相比之前的卷积过程，CNN的单层结构多了激活函数ReLU和偏移量b。整个过程与标准的神经网络单层结构非常类似： Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]} A^{[l]}=g^{[l]}(Z^{[l]})卷积运算对应着上式中的乘积运算，滤波器组数值对应着权重W^{[l]}，所选的激活函数为ReLU 每个滤波器组有3x3x3=27个参数，还有1个偏移量b，则每个滤波器组有27+1=28个参数，两个滤波器组总共包含28x2=56个参数。选定滤波器组后，参数数目与输入图片尺寸无关。所以不存在由于图片尺寸过大，造成参数过多的情况，这就是卷积神经网络的一个特征，叫作“避免过拟合”。例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，参数数目只由滤波器组决定，数目相对来说要少得多，这是CNN的优势之一 设层数为l，CNN单层结构的所有标记符号： f^{[l]}= filter size p^{[l]}= padding s^{[l]}= stride n_c^{[l]}= number of filters 输入维度为：n_H^{[l-1]}\times n_W^{[l-1]}\times n_c^{[l-1]}，因为是上一层的激活值每个滤波器组维度为：f^{[l]}\times f^{[l]}\times n_c^{[l-1]} 权重维度为：f^{[l]}\times f^{[l]}\times n_c^{[l-1]}\times n_c^{[l]} 偏置维度为：1 \times 1\times 1 \times n_c^{[l]} 输出维度为：n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]} 其中： n_H^{[l]}=\lfloor \frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor n_W^{[l]}=\lfloor \frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor如果有m个样本，进行向量化运算，相应的输出维度为： m \times n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}1.8 简单卷积网络示例（A simple convolution network example）简单的CNN网络模型： a^{[3]}$$的维度是7 x 7 x 40，将$$a^{[3]}$$排列成1列，维度为1960 x 1，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出$$\hat y随着CNN层数增加，n_H^{[l]}和n_W^{[l]}一般逐渐减小，而n_c^{[l]}一般逐渐增大 CNN有三种类型的layer： Convolution层（CONV） Pooling层（POOL） Fully connected层（FC） CONV最为常见也最重要 1.9 池化层（Pooling layers）Pooling layers是CNN中用来减小尺寸，提高运算速度的，同样能减小noise影响，让各特征更具有健壮性 Pooling layers没有卷积运算，仅在滤波器算子滑动区域内取最大值，即max pooling，这是最常用的做法。超参数p很少在pooling layers中使用 Max pooling的好处是只保留区域内的最大值（特征），数字大意味着可能探测到了某些特定的特征，忽略了其它值，降低了noise影响，提高了模型健壮性。max pooling需要的超参数仅为滤波器尺寸f和滤波器步进长度s，没有其他参数需要模型训练得到，计算量很小 如果是多个通道，每个通道单独进行max pooling操作： average pooling是在滤波器算子滑动区域计算平均值： 实际应用中，max pooling比average pooling更为常用，也有例外，深度很深的神经网络可以用平均池化来分解规模为7×7×1000的网络的表示层，在整个空间内求平均值，得到1×1×1000 总结： 池化的超级参数包括过滤器大小f和步幅s，常用的参数值为f=2，s=2，应用频率非常高，其效果相当于高度和宽度缩减一半。最大池化时，往往很少用到超参数padding，p最常用的值是0，即p=0。最大池化的输入就是： n_{H} \times n_{W} \times n_{c}假设没有padding，则输出： \lfloor\frac{n_{H} - f}{s} +1\rfloor \times \lfloor\frac{n_{w} - f}{s} + 1\rfloor \times n_{c}输入通道与输出通道个数相同，因为对每个通道都做了池化。最大池化只是计算神经网络某一层的静态属性，池化过程中没有需要学习的参数。执行反向传播时，反向传播没有参数适用于最大池化 1.10 卷积神经网络示例（Convolutional neural network example）简单的数字识别CNN例子： CONV层后面紧接一个POOL层，CONV1和POOL1构成第一层，CONV2和POOL2构成第二层。FC3和FC4为全连接层FC，跟标准的神经网络结构一致。最后的输出层（softmax）由10个神经元构成 整个网络各层的尺寸和参数如下表格所示： 池化层和最大池化层没有参数；卷积层的参数相对较少，许多参数都存在于神经网络的全连接层。随着神经网络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能 尽量不要自己设置超参数，而是查看文献中别人采用了哪些超参数，选一个在别人任务中效果很好的架构，也可能适用于自己的应用程序 在神经网络中，另一种常见模式就是一个或多个卷积后面跟随一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个softmax 1.11 为什么使用卷积？（Why convolutions?）和只用全连接层相比，卷积层的两个主要优势在于参数共享和稀疏连接 如果这是一张1000×1000的图片，权重矩阵会变得非常大。而卷积层的参数数量：每个过滤器都是5×5，一个过滤器有25个参数，再加上偏差参数，那么每个过滤器就有26个参数，一共有6个过滤器，所以参数共计156个，参数数量很少 卷积网络映射这么少参数有两个原因： 参数共享：一个特征检测器（例如垂直边缘检测）对图片某块区域有用，同时也可能作用在图片其它区域。 特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。如果用一个3×3的过滤器检测垂直边缘，那么图片的左上角区域，以及旁边的各个区域（左边矩阵中蓝色方框标记的部分）都可以使用这个3×3的过滤器。每个特征检测器以及输出都可以在输入图片的不同区域中使用同样的参数，以便提取垂直边缘或其它特征。它不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征，例如提取脸上的眼睛，猫或者其他特征对象。即使减少参数个数，这9个参数同样能计算出16个输出。直观感觉是，一个特征检测器，如垂直边缘检测器用于检测图片左上角区域的特征，这个特征很可能也适用于图片的右下角区域。因此在计算图片左上角和右下角区域时，不需要添加其它特征检测器 连接的稀疏性：因为滤波器算子尺寸限制，每一层的每个输出只与输入部分区域内有关 右边输出单元（元素0）仅与36个输入特征中9个相连接。其它像素值都不会对输出产生任何影响，输出（右边矩阵中红色标记的元素 30）仅仅依赖于这9个特征（左边矩阵红色方框标记的区域），只有这9个输入特征与输出相连接，其它像素对输出没有任何影响 神经网络可以通过这两种机制减少参数，以便用更小的训练集来训练它，从而预防过拟合。CNN比较擅长捕捉区域位置偏移，也就是说CNN进行物体检测时，不太受物体所处图片位置的影响，增加检测的准确性和系统的健壮性。通过观察可以发现，向右移动两个像素，图片中的猫依然清晰可见，因为神经网络的卷积结构使得即使移动几个像素，这张图片依然具有非常相似的特征，应该属于同样的输出标记 最后，把这些层整合起来，比如要构建一个猫咪检测器，x表示一张图片，\hat{y}是二进制标记或某个重要标记。选定一个卷积神经网络，输入图片，增加卷积层和池化层，然后添加全连接层，并随机初始化参数w和b，最后输出一个softmax，即\hat{y}，代价函数J等于神经网络对整个训练集的预测的损失总和再除以m（即\text{Cost} J = \frac{1}{m}\sum_{i = 1}^{m}{L(\hat{y}^{(i)},y^{(i)})}）。所以训练神经网络，要做的就是使用梯度下降法，或其它算法，例如Momentum梯度下降法，含RMSProp或其它因子的梯度下降来优化神经网络中所有参数，以减少代价函数J的值]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二周：机器学习策略（2）(ML Strategy (2))(Course 3)]]></title>
    <url>%2F2019%2F02%2F28%2F%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%EF%BC%882%EF%BC%89-ML-Strategy-2-Course-2%2F</url>
    <content type="text"><![CDATA[2.1 进行误差分析（Carrying out error analysis）如果希望让学习算法能够胜任人类能做的任务，但学习算法还没有达到人类的表现，那么人工检查一下算法犯的错误可以了解接下来应该做什么，这个过程称为错误分析假设正在调试猫分类器，取得了90%准确率，相当于10%错误，注意到算法将一些狗分类为猫，需要对模型的一些部分做相应调整，才能更好地提升分类的精度 收集错误样例： 在开发集（测试集）中，获取大约100个错误标记的例子，然后手动检查，一次只看一个，看看开发集里有多少错误标记的样本是狗 100个数据中有5个样例是狗，如果对数据集的错误标记做努力去改进模型的精度，可以提升的上限是5%，仅可以达到9.5%的错误率，称为性能上限（ceiling on performance）。这种情况下，这样耗时的努力方向不是很值得的事 100个数据中，有50多个样例是狗，改进数据集的错误标记是一个值得的改进方向，可以将模型的精确度提升至95 并行分析： 修改那些被分类成猫的狗狗图片标签 修改那些被错误分类的大型猫科动物，如：狮子，豹子等 提升模糊图片的质量 为了并行的分析，可以建立表格来进行。在最左边，人工过一遍想分析的图像集，电子表格的每一列对应要评估的想法，如狗的问题，猫科动物的问题，模糊图像的问题，最后一列写评论 在这个步骤做到一半时，可能会发现其他错误类型，比如可能发现有Instagram滤镜，那些花哨的图像滤镜，干扰了分类器。在这种情况下可以在错误分析途中，增加一列多色滤镜 Instagram滤镜和Snapchat滤镜，再过一遍，并确定新的错误类型百分比，这个分析步骤的结果可以给出一个估计，是否值得去处理每个不同的错误类型 可以把团队可以分成两个团队，其中一个改善大猫的识别，另一个改善模糊图片的识别 总结： 进行错误分析，应该找一组错误样本，可能在开发集或者测试集，观察错误标记的样本，看看假阳性（false positives）和假阴性（false negatives），统计属于不同错误类型的错误数量。在这个过程中，可能会得到启发，归纳出新的错误类型，通过统计不同错误标记类型的百分比，可以发现哪些问题需要优先解决 2.2 清楚标注错误的数据（Cleaning up Incorrectly labeled data）监督学习问题的数据由输入x和输出标签y 构成，如果发现有些输出标签 y 是错的，是否值得花时间去修正这些标签？ 倒数第二不是猫，是标记错误的样本。“标记错误的样本”表示学习算法输出了错误的 y 值，如果数据有一些标记错误的样本，该怎么办？ 训练集：深度学习算法对于训练集中的随机错误是相当健壮的（robust）。只要这些错误样本离随机错误不太远，有时可能做标记的人没有注意或者不小心，按错键了，如果错误足够随机，放着这些错误不管可能也没问题，而不要花太多时间修复它们，只要总数据集足够大，实际错误率可能不会太高 深度学习算法对随机误差很健壮，但对系统性的错误没那么健壮。如果做标记的人一直把白色的狗标记成猫，那就成问题。因为分类器学习之后，会把所有白色的狗都分类为猫。但随机错误或近似随机错误，对于大多数深度学习算法来说不成问题 开发集和测试集有标记出错的样本：在错误分析时，添加一个额外的列，统计标签 y=1错误的样本数。统计因为标签错误所占的百分比，解释为什么学习算法做出和数据集的标记不一样的预测1 是否值得修正6%标记出错的样本： 如果标记错误严重影响了在开发集上评估算法的能力，应该去花时间修正错误的标签 如果没有严重影响到用开发集评估成本偏差的能力，不应该花时间去处理 看3个数字来确定是否值得去人工修正标记出错的数据： 看整体的开发集错误率，系统达到了90%整体准确度，10%错误率，应该看错误标记引起的错误的数量或者百分比。6％的错误来自标记出错，10%的6%是0.6%，剩下的占9.4%，是其他原因导致的，比如把狗误认为猫，大猫图片。即有9.4%错误率需要集中精力修正，而标记出错导致的错误是总体错误的一小部分而已，应该看其他原因导致的错误 错误率降到了2％，但总体错误中的0.6%还是标记出错导致的。修正开发集里的错误标签更有价值 开发集的主要目的是从两个分类器A和B中选择一个。当测试两个分类器A和B时，在开发集上一个有2.1%错误率，另一个有1.9%错误率，但是不能再信任开发集，因为它无法告诉你这个分类器是否比这个好，因为0.6%的错误率是标记出错导致的。现在就有很好的理由去修正开发集里的错误标签，因为右边这个样本标记出错对算法错误的整体评估标准有严重的影响，而左边相对较小 如果决定要去修正开发集数据，手动重新检查标签，并尝试修正一些标签，这里还有一些额外的方针和原则需要考虑： 不管用什么修正手段，都要同时作用到开发集和测试集上，开发和测试集必须来自相同的分布。开发集确定了目标，当击中目标后，希望算法能够推广到测试集上，这样能够更高效的在来自同一分布的开发集和测试集上迭代 如果打算修正开发集上的部分数据，最好也对测试集做同样的修正以确保它们继续来自相同的分布。可以让一个人来仔细检查这些标签，但必须同时检查开发集和测试集 要同时检验算法判断正确和判断错误的样本，如果只修正算法出错的样本，算法的偏差估计可能会变大，会让算法有一点不公平的优势 修正训练集中的标签相对没那么重要，如果训练集来自稍微不同的分布，对于这种情况学习算法其实相当健壮，通常是一件很合理的事情 几个建议： 构造实际系统时，需要更多的人工错误分析，更多的人类见解来架构这些系统 搭建机器学习系统时，花时间亲自检查数据非常值得，可以帮你找到需要优先处理的任务，然后确定应该优先尝试哪些想法，或者哪些方向 2.3 快速搭建你的第一个系统，并进行迭代（Build your first system quickly, then iterate）如果正在开发全新的机器学习应用，应该尽快建立第一个系统原型，然后快速迭代 改进语音识别系统特定的技术: 对于几乎所有的机器学习程序可能会有50个不同的方向可以前进，并且每个方向都是相对合理的可以改善系统。但挑战在于如何选择一个方向集中精力处理。如果想搭建全新的机器学习程序，就是快速搭好第一个系统，然后开始迭代。首先快速设立开发集和测试集还有指标，决定目标所在，如果目标定错，之后改也可以。但一定要设立某个目标，然后马上搭好一个机器学习系统原型，找到训练集训练一下，看算法表现如何，在开发集测试集，评估指标表现如何。当建立第一个系统后，就可以马上用到偏差方差分析和错误分析，来确定下一步优先做什么。如果错误分析到大部分的错误来源是说话人远离麦克风，就有很好的理由去集中精力研究这些技术，所谓远场语音识别的技术，就是处理说话人离麦克风很远的情况 建立初始系统所有意义：是一个快速和粗糙的实现（quick and dirty implementation），有一个学习过的系统，有一个训练过的系统，确定偏差方差的范围，知道下一步应该优先做什么，能够进行错误分析，观察一些错误，然后想出所有能走的方向，哪些是实际上最有希望的方向 当这个领域有很多可以借鉴的学术文献，处理的问题和要解决的几乎完全相同，比如人脸识别有很多学术文献，如果搭建一个人脸识别设备，可以从现有大量学术文献为基础出发，一开始就搭建比较复杂的系统。但如果第一次处理某个新问题，还是构建一些快速而粗糙的实现，然后用来找到改善系统要优先处理的方向 2.4 在不同的划分上进行训练并测试（Training and testing on different distributions）猫咪识别假设只收集到10,000张用户上传的照片和超过20万张网上下载的高清猫图： 做法一：将两组数据合并在一起，把这21万张照片随机分配到训练、开发和测试集中。假设已经确定开发集和测试集各包含2500个样本，训练集有205000个样本。 好处：训练集、开发集和测试集都来自同一分布 坏处：开发集的2500个样本中很多图片都来自网页下载的图片，并不是真正关心的数据分布，因为真正要处理的是来自手机的图片 2500个样本有2500\times \frac{200k}{210k} =2381张图来自网页下载，平均只有119张图来自手机上传。设立开发集的目的是告诉团队去瞄准的目标，而瞄准目标的大部分精力却都用在优化来自网页下载的图片 建议：开发集和测试集都是2500张来自应用的图片，训练集包含来自网页的20万张图片还有5000张来自应用的图片，现在瞄准的目标就是想要处理的目标，才是真正关心的图片分布 语音激活后视镜假设有很多不是来自语音激活后视镜的数据 分配： 训练集500k段语音，开发集和测试集各包含10k段语音（从实际的语音激活后视镜收集） 也可以拿一半放训练集里，训练集51万段语音，开发集和测试集各5000 2.5 不匹配数据划分的偏差和方差（Bias and Variance with mismatched data distributions）当训练集和开发集、测试集不同分布时，分析偏差和方差的方式： 分析的问题在于，当看训练误差，再看开发误差，有两件事变了，很难确认这增加的9%误差率有多少是因为： 算法只见过训练集数据，没见过开发集数据（方差） 开发集数据来自不同的分布 为了弄清楚哪个因素影响更大，定义一组新的数据，称之为训练-开发集，是一个新的数据子集。从训练集的分布里分出来，但不会用来训练网络 随机打散训练集，分出一部分训练集作为训练-开发集（training-dev），训练集、训练-开发集来自同一分布 只在训练集训练神经网络，不让神经网络在训练-开发集上跑后向传播。为了进行误差分析，应该看分类器在训练集上的误差、训练-开发集上的误差、开发集上的误差 假设训练误差是1%，训练-开发集上的误差是9%，开发集误差是10%，存在方差，因为训练-开发集的错误率是在和训练集来自同一分布的数据中测得的，尽管神经网络在训练集中表现良好，但无法泛化到来自相同分布的训练-开发集 假设训练误差为1%，训练-开发误差为1.5%，开发集错误率10%。方差很小，当转到开发集时错误率大大上升，是数据不匹配的问题 如果训练集误差是10%，训练-开发误差是11%，开发误差为12%，人类水平对贝叶斯错误率的估计大概是0%，存在可避免偏差问题 如果训练集误差是10%，训练-开发误差是11%，开发误差是20%，有两个问题 可避免偏差问题 数据不匹配问题 如果加入测试集错误率，而开发集表现和测试集表现有很大差距，可能对开发集过拟合，需要一个更大的开发集 如果人类的表现是4%，训练错误率是7%，训练-开发错误率是10%。开发集是6%。可能开发测试集分布比实际处理的数据容易得多，错误率可能会下降 Human level 4%和Training error 7%衡量了可避免偏差大小，Training error 7%和Training-dev error 10%衡量了方差大小，Training-dev error 10%和Dev/Test dev 6%衡量了数据不匹配问题的大小 rearview mirror speech data 6%和Error on examples trained on 6%：获得这个数字的方式是让一些人标记他们的后视镜语音识别数据，看看人类在这个任务里能做多好，然后收集一些后视镜语音识别数据，放在训练集中，让神经网络去学习，测量那个数据子集上的错误率，如果得到rearview mirror speech data 6%和Error on examples trained on 6%，说明在后视镜语音数据上达到人类水平 General speech recognition Human level 4%和rearview mirror speech data 6%：说明后视镜的语音数据比一般语音识别更难，因为人类都有6%的错误，而不是4%的错误 总结： 开发集、测试集不同分布： 可以提供更多训练数据，有助于提高学习算法的性能 潜在问题不只是偏差和方差问题，还有数据不匹配 2.6 定位数据不匹配（Addressing data mismatch）解决train set与dev/test set样本分布不一致的两条建议： 为了让训练数据更接近开发集，可以人工合成数据（artificial data synthesis）。例如说话人识别问题，实际应用场合（dev/test set）是包含背景噪声的，而训练样本train set很可能没有背景噪声。为了让train set与dev/test set分布一致，可以在train set上人工添加背景噪声，合成类似实际场景的声音。这样会让模型训练的效果更准确。但是不能给每段语音都增加同一段背景噪声，会出现对背景噪音过拟合，这就是人工数据合成需要注意的地方 研发无人驾驶汽车，用计算机合成图像 如果只合成这些车中很小的子集，学习算法可能会对合成的这一个小子集过拟合 2.7 迁移学习（Transfer learning）将已经训练好的模型的一部分知识（网络结构）直接应用到另一个类似模型中去。比如已经训练好一个猫类识别的神经网络模型，直接把该模型中的一部分网络结构应用到使用X光片预测疾病的模型中去，这种学习方法被称为迁移学习（Transfer Learning） 如果已经有一个训练好的神经网络用来做图像识别。想要构建另一个X光片进行诊断的模型。迁移学习的做法是无需重新构建新的模型，而是利用之前的神经网络模型，只改变样本输入、输出以及输出层的权重系数W^{[L]},\ b^{[L]}，即对新的样本(X,Y)，重新训练输出层权重系数W^{[L]},\ b^{[L]}，其它层所有的权重系数W^{[L]},\ b^{[L]}保持不变 如果需要构建新模型的样本数量较少，可以只训练输出层的权重系数W^{[L]},\ b^{[L]}，保持其它层所有的权重系数W^{[l]},\ b^{[l]}不变 如果样本数量足够多，可以只保留网络结构，重新训练所有层的权重系数。这种做法使得模型更加精确，因为样本对模型的影响最大 择哪种方法通常由数据量决定 如果重新训练所有权重系数，初始W^{[l]},\ b^{[l]}由之前的模型训练得到，这一过程称为pre-training。之后，不断调试、优化W^{[l]},\ b^{[l]}的过程称为fine-tuning。pre-training和fine-tuning分别对应上图中的黑色箭头和红色箭头 迁移学习能这么做的原因是神经网络浅层部分能够检测出许多图片固有特征，例如图像边缘、曲线等。使用之前训练好的神经网络部分结果有助于更快更准确地提取X光片特征。二者处理的都是图片，而图片处理是有相同的地方，第一个训练好的神经网络已经实现如何提取图片有用特征。即便是即将训练的第二个神经网络样本数目少，仍然可以根据第一个神经网络结构和权重系数得到健壮性好的模型 迁移学习可以保留原神经网络的一部分，再添加新的网络层，可以去掉输出层后再增加额外一些神经层 迁移学习的应用场合主要包括三点： Task A and B have the same input x. You have a lot more data for Task A than Task B. Low level features from A could be helpful for learning B. 2.8 多任务学习（Multi-task learning）在迁移学习中，步骤是串行的，从任务A里学习然后只是迁移到任务B。在多任务学习中是同时开始学习的，试图让单个神经网络同时做几件事情，希望每个任务都能帮到其他所有任务 假设无人驾驶需要同时检测行人、车辆、停车标志，还有交通灯各种其他东西 如果输入图像x^{(i)}，那么 y^{(i)}不再是一个标签，而是有4个标签。在这个例子中，没有行人，有一辆车，有一个停车标志，没有交通灯。所以 y^{(i)}是个4×1向量。将训练集的标签水平堆叠起来，从y^{(1)}一直到y^{(m)}： \begin{bmatrix} \vdots & \vdots & \vdots & \vdots & \vdots\\ y^{(1)} & y^{(2)} & y^{(3)} & \cdots & y^{(m)}\\ \vdots & \vdots & \vdots & \vdots & \vdots \end{bmatrix}矩阵Y变成4\times m矩阵 输出四个节点，第一个节点是预测图中有没有行人，第二个预测有没有车，第三预测有没有停车标志，第四预测有没有交通灯，所以\hat y是四维 整个训练集的平均损失： \frac{1}{m}\sum_{i = 1}^{m}{\sum_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}}$\sum_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}$是单个预测的损失，所以这是对四个分量的求和，行人、车、停车标志、交通灯，标志L指的是logistic损失： L(\hat y_{j}^{(i)},y_{j}^{(i)}) = - y_{j}^{(i)}\log\hat y_{j}^{(i)} - (1 - y_{j}^{(i)})log(1 - \hat y_{j}^{(i)})Multi-task learning与Softmax regression的区别在于： Multi-task learning是multiple labels的，即输出向量y可以有多个元素为1 Softmax regression是single label的，即输出向量y只有一个元素为1 神经网络一些早期特征，在识别不同物体时都会用到，训练一个神经网络做四件事情会比训练四个完全独立的神经网络分别做四件事性能要更好 多任务学习也可以处理图像只有部分物体被标记的情况。比如没有标记是否有停车标志，或者是否有交通灯。也许有些样本都有标记，有些样本只标记了有没有车，然后还有一些是问号 即使是这样的数据集，也可以在上面训练算法，同时做四个任务，即使一些图像只有一小部分标签，其他是问号。训练算法的方式是对j从1到4只对带0和1标签的j值求和，当有问号就在求和时忽略那个项 多任务学习当三件事为真时有意义的： 训练的一组任务，可以共用低层次特征。对于无人驾驶的例子，同时识别交通灯、汽车和行人是有道理的，这些物体有相似的特征 如果每个任务的数据量很接近，这个准则没那么绝对，不一定对 想要从多任务学习得到很大性能提升，其他任务加起来必须要有比单个任务大得多的数据量 多任务学习会降低性能的唯一情况是神经网络还不够大。但如果可以训练一个足够大的神经网络，多任务学习肯定不会或者很少会降低性能 在实践中，多任务学习的使用频率要低于迁移学习。因为很难找到那么多相似且数据量对等的任务可以用单一神经网络训练。不过在计算机视觉领域，物体检测这个例子是最显著的例外情况 2.9 什么是端到端的深度学习？（What is end-to-end deep learning?）以前有一些数据处理系统或者学习系统需要多个阶段的处理。端到端深度学习就是忽略所有这些不同的阶段，用单个神经网络代替它 语音识别目标是输入x，比如说一段音频，然后把它映射到一个输出y，就是这段音频的听写文本: 传统上语音识别需要很多阶段的处理。首先提取一些特征，一些手工设计的音频特征，比如MFCC，这种算法是用来从音频中提取一组特定的人工设计的特征。在提取出一些低层次特征之后，应用机器学习算法在音频片段中找到音位（声音的基本单位），比如“Cat”这个词是三个音节构成的，Cu-、Ah-和Tu-，算法把这三个音位提取出来，然后将音位串在一起构成独立的词，然后将词串起来构成音频片段的听写文本 ) 端到端深度学习是训练一个巨大的神经网络，输入一段音频，输出直接是听写文本。只需要把训练集拿过来，直接学到了x和y之间的函数映射，绕过了其中很多步骤 端到端深度学习的挑战之一是需要大量数据才能让系统表现良好，比如只有3000小时数据去训练语音识别系统，那传统的流水线效果很好。但当有非常大的数据集时，比如10,000小时数据或者100,000小时数据，端到端方法突然开始很厉害。所以当数据集较小时，传统流水线方法效果更好。如果数据量适中，也可以用中间件方法，如输入还是音频，然后绕过特征提取，直接尝试从神经网络输出音位 门禁识别系统 最好的方法是一个多步方法，首先运行一个软件来检测人脸，然后放大图像并裁剪图像，使人脸居中显示，然后红线框起来的照片再喂到神经网络里，让网络去学习，或估计那人的身份 比起一步到位，一步学习，把这个问题分解成两个更简单的步骤更好： 首先弄清楚脸在哪里 第二步是看着脸，弄清楚这是谁 这种方法让两个学习算法分别解决两个更简单的任务，并在整体上得到更好的表现 训练第二步的方式：输入两张图片，网络将两张图比较一下，判断是否是同一个人。比如记录了10,000个员工ID，可以把红色框起来的图像快速比较，看看红线内的照片是不是那10000个员工之一，判断是否应该允许其进入 为什么两步法更好： 解决的两个问题，每个问题实际上要简单得多 两个子任务的训练数据都很多 机器翻译 传统上机器翻译系统也有一个很复杂的流水线，比如英语机翻得到文本，然后做文本分析，基本上要从文本中提取一些特征之类的，经过很多步骤，最后会将英文文本翻译成法文。因为对于机器翻译来说有很多(英文,法文)的数据对，端到端深度学习在机器翻译领域非常好用 2.10 是否要使用端到端的深度学习？（Whether to use end-to-end learning?）端到端学习的优点 端到端学习只是让数据说话。如果有足够多的(x,y)数据，不管从x到y最适合的函数映射是什么，如果训练一个足够大的神经网络，希望这个神经网络能自己搞清楚。使用纯机器学习方法，直接从x到y输入去训练神经网络，可能更能够捕获数据中的任何统计信息，而不是被迫引入人类的成见。例如在语音识别领域，早期的识别系统有这个音位概念，如果让学习算法学习它想学习的任意表示方式，而不是强迫使用音位作为表示方式，其整体表现可能会更好 所需手工设计的组件更少，能够简化设计工作流程，不需要花太多时间去手工设计功能，手工设计中间表示方式 端到端学习的缺点 直接学到x到y的映射，需要大量(x,y)数据 排除了可能有用的手工设计组件。当有大量数据时，手工设计不太重要，当没有太多的数据时，构造一个精心设计的系统，可以将人类对这个问题的很多认识直接注入到问题里，对算法很有帮助 端到端深度学习的弊端之一是它把可能有用的人工设计的组件排除在外，精心设计的人工组件可能非常有用，但也可能真的影响算法表现。例如，强制算法以音位为单位思考，也许让算法自己找到更好的表示方法更好。但往往好处更多，手工设计的组件往往在训练集更小的时候帮助更大 决定是否使用端到端深度学习，关键的问题是是否有足够的数据能够直接学到从x映射到y足够复杂的函数。识别图中骨头位置是相对简单的问题，系统不需要那么多数据。但把手的X射线照片直接映射到孩子的年龄，直接去找这种函数，就是更为复杂的问题。如果用纯端到端方法，需要很多数据去学习]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第 三 周 超 参 数 调 试 、 Batch 正 则 化 和 程 序 框 架 （Hyperparameter tuning）(Course 2)]]></title>
    <url>%2F2019%2F02%2F28%2F%E7%AC%AC-%E4%B8%89-%E5%91%A8-%E8%B6%85-%E5%8F%82-%E6%95%B0-%E8%B0%83-%E8%AF%95-%E3%80%81-Batch-%E6%AD%A3-%E5%88%99-%E5%8C%96-%E5%92%8C-%E7%A8%8B-%E5%BA%8F-%E6%A1%86-%E6%9E%B6-%EF%BC%88Hyperparameter-tuning%EF%BC%89-Course-2%2F</url>
    <content type="text"><![CDATA[3.1 调试处理（Tuning process）深度神经网络需要调试的超参数（Hyperparameters）包括： \alpha：学习因子 \beta：动量梯度下降因子 \beta_1,\beta_2,\varepsilon：Adam算法参数 #layers：神经网络层数 #hidden units：各隐藏层神经元个数 learning rate decay：学习因子下降参数 mini-batch size：批量训练样本包含的样本个数 学习因子\alpha是最重要的超参数，也是需要重点调试的超参数。动量梯度下降因子\beta、各隐藏层神经元个数#hidden units和mini-batch size的重要性仅次于,然后就是神经网络层数#layers和学习因子下降参数learning rate decay。最后，Adam算法的三个参数\beta_1,\beta_2,\varepsilon一般常设置为0.9，0.999和10^{-8} 传统的机器学习中，对每个参数等距离选取任意个数的点，分别使用不同点对应的参数组合进行训练，最后根据验证集上的表现好坏来选定最佳的参数。例如有两个待调试的参数，分别在每个参数上选取5个点，这样构成了5x5=25中参数组合： 这种做法在参数比较少的时候效果较好 深度神经网络模型中是使用随机选择。随机选择25个点，作为待调试的超参数： ) 随机化选择参数是为了尽可能地得到更多种参数组合。如果使用均匀采样，每个参数只有5种情况；而使用随机采样的话，每个参数有25种可能的情况，更可能得到最佳的参数组合 另外一个好处是对重要性不同的参数之间的选择效果更好。假设hyperparameter1为\alpha，hyperparameter2为\varepsilon，显然二者的重要性是不一样的。如果使用第一种均匀采样的方法，\varepsilon的影响很小，相当于只选择了5个\alpha值。而如果使用第二种随机采样的方法，\varepsilon和\alpha都有可能选择25种不同值。这大大增加了\alpha调试的个数，更有可能选择到最优值 在实际应用中完全不知道哪个参数更加重要的情况下，随机采样的方式能有效解决这一问题，但是均匀采样做不到这点 随机采样之后，可能得到某些区域模型的表现较好。为了得到更精确的最佳参数，继续对选定的区域进行由粗到细的采样（coarse to fine sampling scheme）。就是放大表现较好的区域，对此区域做更密集的随机采样 如对下图中右下角的方形区域再做25点的随机采样，以获得最佳参数： 3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数 对于超参数#layers和#hidden units，都是正整数，是可以进行均匀随机采样的，即超参数每次变化的尺度都是一致 对于某些超参数，可能需要非均匀随机采样（即非均匀刻度尺）。例如超参数\alpha，待调范围是[0.0001, 1]。如果使用均匀随机采样，90%的采样点分布在[0.1, 1]之间，只有10%分布在[0.0001, 0.1]之间。而最佳的\alpha值可能主要分布在[0.0001, 0.1]之间，因此更应在区间[0.0001, 0.1]内细分更多刻度 通常的做法是将linear scale转换为log scale，将均匀尺度转化为非均匀尺度，然后再在log scale下进行均匀采样。这样，[0.0001, 0.001]，[0.001, 0.01]，[0.01, 0.1]，[0.1, 1]各个区间内随机采样的超参数个数基本一致，扩大了之前[0.0001, 0.1]区间内采样值个数 如果线性区间为[a, b]，令m=log(a)，n=log(b)，则对应的log区间为[m,n]。对log区间的[m,n]进行随机均匀采样，得到的采样值r，最后反推到线性区间，即10^r.10^r是最终采样的超参数。代码为： 12345m = np.log10(a)n = np.log10(b)r = np.random.rand()r = m + (n-m)*rr = np.power(10,r) 动量梯度因子\beta在超参数调试也需要进行非均匀采样。一般\beta的取值范围在[0.9, 0.999]之间，1−\beta的取值范围在[0.001, 0.1]。那么直接对1−\beta在[0.001, 0.1]区间内进行log变换 为什么\beta也需要向\alpha那样做非均匀采样： 假设\beta从0.9000变化为0.9005，那么\frac{1}{1-\beta}基本没有变化。但假设β从0.9990变化为0.9995，那么\frac{1}{1-\beta}前后差别1000。\beta越接近1，指数加权平均的个数越多，变化越大。所以对\beta接近1的区间，应该采集得更密集一些 3.3 超参数训练的实践： Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）经过调试选择完最佳的超参数不是一成不变的，一段时间之后（例如一个月），需要根据新的数据和实际情况，再次调试超参数，以获得实时的最佳模型 在训练深度神经网络时，一种情况是有庞大的数据组，但没有许多计算资源或足够的 CPU 和GPU 的前提下，只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳的表现。称之为Babysitting one model。另外一种情况是可以对多个模型同时进行训练，每个模型上调试不同的超参数，根据表现情况，选择最佳的模型。称之为Training many models in parallel 第一种情况只使用一个模型，类比做Panda approach；第二种情况同时训练多个模型，类比做Caviar approach。使用哪种模型是由计算资源、计算能力所决定的。一般来说，对于非常复杂或者数据量很大的模型，使用Panda approach更多一些 3.4 归一化网络的激活函数（ Normalizing activations in a network）在神经网络中，第l层隐藏层的输入就是第l-1层隐藏层的输出A^{[l-1]}。对A^{[l-1]}进行标准化处理，从原理上来说可以提高W^{[l]}和b^{[l]}的训练速度和准确度。这种对各隐藏层的标准化处理就是Batch Normalization。一般是对Z^{[l-1]}进行标准化处理而不是A^{[l-1]} Batch Normalization对第l层隐藏层的输入Z^{[l-1]}做如下标准化处理，忽略上标[l-1]： \mu=\frac1m\sum_iz^{(i)} \sigma^2=\frac1m\sum_i(z_i-\mu)^2 z^{(i)}_{norm}=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\varepsilon}}m是单个mini-batch包含样本个数，ε是为了防止分母为零，可取值10^{-8}。使得该隐藏层的所有输入z^{(i)}均值为0，方差为1 大部分情况下并不希望所有的z^{(i)}均值都为0，方差都为1，也不太合理。通常需要对z^{(i)}进行进一步处理： \tilde z^{(i)}=\gamma\cdot z^{(i)}_{norm}+\beta$\gamma$和\beta是learnable parameters，可以通过梯度下降等算法求得。\gamma和\beta是让\tilde z^{(i)}的均值和方差为任意值，只需调整其值。如： \gamma=\sqrt{\sigma^2+\varepsilon},\ \ \beta=u则\tilde z^{(i)}=z^{(i)}，即identity function。设置\gamma和\beta为不同的值，可以得到任意的均值和方差 通过Batch Normalization，对隐藏层的各个z^{[l](i)}进行标准化处理，得到\tilde z^{[l](i)}，替代z^{[l](i)} 输入的标准化处理Normalizing inputs和隐藏层的标准化处理Batch Normalization是有区别的。Normalizing inputs使所有输入的均值为0，方差为1。而Batch Normalization可使各隐藏层输入的均值和方差为任意值。从激活函数的角度来说，如果各隐藏层的输入均值在靠近0的区域即处于激活函数的线性区域，这样不利于训练好的非线性神经网络，得到的模型效果也不会太好 3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）前向传播的计算流程： 实现梯度下降： for t = 1 … num （这里num 为Mini Batch 的数量）： 在每一个X^t 上进行前向传播（forward prop）的计算： 在每个隐藏层都用 Batch Norm 将z^{[l]}替换为 \widetilde{z}^{[l]} 使用反向传播（Back prop）计算各个参数的梯度：dw^{[l]},d\gamma^{[l]},d\beta^{[l]} 更新参数： w^{[l]}:=w^{[l]}-\alpha dw^{[l]} \gamma^{[l]}:=\gamma^{[l]}-\alpha d\gamma^{[l]} \beta^{[l]}:=\beta^{[l]}-\alpha d\beta^{[l]} 经过Batch Norm的作用，整体流程如下： ) Batch Norm对各隐藏层Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}有去均值的操作，Batch Norm 要做的就是将z^{[l]}归一化，结果成为均值为0，标准差为1的分布，再由\beta 和\gamma 进行重新的分布缩放，意味着无论b^{[l]} 值为多少，在这个过程中都会被减去，不会再起作用。所以常数项b^{[l]}可以消去，其数值效果完全可以由\widetilde{z}^{[l]}中的\beta来实现。在使用Batch Norm的时候，可以忽略各隐藏层的常数项b^{[l]}。在使用梯度下降算法时，分别对W^{[l]},\beta^{[l]}和\gamma^{[l]}进行迭代更新 除了传统的梯度下降算法之外，还可以使用动量梯度下降、RMSprop或者Adam等优化算法 3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）Batch Norm 可以加速神经网络训练的原因： 和输入层的输入特征进行归一化，从而改变Cost function的形状，使得每一次梯度下降都可以更快的接近函数的最小值点，从而加速模型训练过程的原理有相同的道理，只是Batch Norm是将各个隐藏层的激活函数的激活值进行的归一化，并调整到另外的分布 Batch Norm 可以使权重比网络更滞后或者更深层 判别是否是猫的分类问题：假设第一训练样本的集合中的猫均是黑猫，而第二个训练样本集合中的猫是各种颜色的猫。如果将第二个训练样本直接输入到用第一个训练样本集合训练出的模型进行分类判别，在很大程度上无法保证能够得到很好的判别结果 因为训练样本不具有一般性（即不是所有的猫都是黑猫），第一个训练集合中均是黑猫，而第二个训练集合中各色猫均有，虽然都是猫，但是很大程度上样本的分布情况是不同的，无法保证模型可以仅仅通过黑色猫的样本就可以完美的找到完整的决策边界 这种训练样本（黑猫）和测试样本（猫）分布的变化称之为covariate shift。如下图所示： 深度神经网络中，covariate shift会导致模型预测效果变差，重新训练的模型各隐藏层的W^{[l]}和B^{[l]}均产生偏移、变化。而Batch Norm的作用恰恰是减小covariate shift的影响，让模型变得更加健壮，鲁棒性更强 使用深层神经网络，使用Batch Norm，该模型对花猫的识别能力应该也是不错 Batch Norm 解决Covariate shift的问题) 网络的目的是通过不断的训练，最后输出一个更加接近于真实值的\hat y，以第2个隐藏层为输入来看： 对于后面的神经网络，是以第二层隐层的输出值a^{[2]}作为输入特征的，通过前向传播得到最终的\hat y，但是网络还有前面两层，由于训练过程，参数w^{[1]},w^{[2]}是不断变化的，对于后面的网络，a^{[2]}的值也是处于不断变化之中，所以就有了Covariate shift的问题 如果对z^{[2]}使用了Batch Norm，即使其值不断的变化，其均值和方差却会保持。Batch Norm的作用是限制前层的参数更新导致对后面网络数值分布程度的影响，使得输入后层的数值变得更加稳定。Batch Norm减少了各层W^{[l]},B^{[l]}之间的耦合性，让各层更加独立，实现自我训练学习的效果。如果输入发生covariate shift，Batch Norm的作用是对个隐藏层输出Z^{[l]}进行均值和方差的归一化处理，让W^{[l]},B^{[l]}更加稳定，使得原来的模型也有不错的表现 Batch Norm 削弱了前层参数与后层参数之间的联系，使得网络的每层都可以自己进行学习，相对其他层有一定的独立性，有助于加速整个网络的学习 Batch Norm 正则化效果 使用Mini-batch梯度下降，每次计算均值和偏差都是在一个Mini-batch上进行计算，而不是在整个数据样集上。这样在均值和偏差上带来一些比较小的噪声。那么用均值和偏差计算得到的\widetilde{z}^{[l]}也将会加入一定的噪声 和Dropout相似，其在每个隐藏层的激活值上加入了一些噪声，（Dropout以一定的概率给神经元乘上0或者1）。Batch Norm 也有轻微的正则化效果 如果使用Batch Norm ，使用大的Mini-batch如256，相比使用小的Mini-batch如64，会引入更少的噪声，会减少正则化的效果 Batch Norm的正则化效果比较微弱，正则化不是Batch Norm的主要功能 3.7 测试时的 Batch Norm（Batch Norm at test time）训练过程中Batch Norm的主要过程： \mu=\frac1m\sum_iz^{(i)} \sigma^2=\frac1m\sum_i(z^{(i)}-\mu)^2 z_{norm}^{(i)}=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\varepsilon}} \tilde z^{(i)}=\gamma\cdot z^{(i)}_{norm}+\beta$\mu$和\sigma^2是对单个mini-batch中所有m个样本求得的。在测试过程中，如果只有一个样本，求其均值和方差是没有意义的，就需要对\mu和\sigma^2进行估计。实际应用是使用指数加权平均（exponentially weighted average）的方法来预测测试过程单个样本的\mu和\sigma^2 对于第l层隐藏层，在训练的过程中, ，对于训练集的Mini-batch，考虑所有mini-batch在该隐藏层下的\mu^{[l]}和{\sigma^{2}}^{[l]}，使用指数加权平均，当训练结束的时候，得到指数加权平均后当前单个样本的\mu^{[l]}和{\sigma^{2}}^{[l]},这些值直接用于Batch Norm公式的计算，用以对测试样本进行预测，再利用训练过程得到的\gamma和\beta计算出各层的\tilde z^{(i)}值 3.8 Softmax 回归（Softmax regression）Softmax 回归，能在识别多种分类中的一个时做出预测，对于多分类问题，用C表示种类个数，神经网络中输出层就有C个神经元，即n^{[L]}=C，每个神经元的输出依次对应属于该类的概率，即P(y=c|x)，处理多分类问题一般使用Softmax回归模型 把猫做类 1，狗为类 2，小鸡 是类 3， 如果不属于以上任何一类， 就分到“其它”或者“以上均不符合”这一类，叫 做类 0 用大写C表示输入会被分入的类别总个数,当有 4 个分类时，指示类别的数字，就是从 0 到C − 1( 0、 1、 2、 3) Softmax回归模型输出层的激活函数： z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]} a^{[L]}_i=\frac{e^{z^{[L]}_i}}{\sum_{i=1}^Ce^{z^{[L]}_i}}输出层每个神经元的输出a^{[L]}_i对应属于该类的概率，满足： \sum_{i=1}^Ca^{[L]}_i=1所有的a^{[L]}_i，即\hat y，维度为(C, 1) 在没有隐藏隐藏层的时候，直接对Softmax层输入样本的特点，则在不同数量的类别下，Sotfmax层的作用： 图中的颜色显示了 Softmax 分类器的输出的阈值，输入的着色是基于三种输出中概率最高的那种，任何两个分类之间的决策边界都是线性的 如果使用神经网络，特别是深层神经网络，可以得到更复杂、更精确的非线性模型 3.9 训练一个 Softmax 分类器（Training a Softmax classifier）C=4，某个样本的预测输出\hat y和真实输出y： \hat y=\left[ \begin{matrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \end{matrix} \right] y=\left[ \begin{matrix} 0 \\ 1 \\ 0 \\ 0 \end{matrix} \right]从\hat y值来看，P(y=4|x)=0.4，概率最大，而真实样本属于第2类，该预测效果不佳 定义softmax classifier的loss function为： L(\hat y,y)=-\sum_{j=1}^4y_j\cdot log\ \hat y_j$L(\hat y,y)$简化为： L(\hat y,y)=-y_2\cdot log\ \hat y_2=-log\ \hat y_2让L(\hat y,y)更小，就应该让\hat y_2越大越好。\hat y_2反映的是概率 m个样本的cost function为： J=\frac{1}{m}\sum_{i=1}^mL(\hat y,y)预测输出向量A^{[L]}即\hat Y的维度为(4, m) softmax classifier的反向传播过程: 先推导dZ^{[L]}： da^{[L]}=-\frac{1}{a^{[L]}} \frac{\partial a^{[L]}}{\partial z^{[L]}}=\frac{\partial}{\partial z^{[L]}}\cdot (\frac{e^{z^{[L]}_i}}{\sum_{i=1}^Ce^{z^{[L]}_i}})=a^{[L]}\cdot (1-a^{[L]}) 所有m个训练样本： dZ^{[L]}=A^{[L]}-Y]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第四周：深层神经网络(Deep Neural Networks)(Course 1)]]></title>
    <url>%2F2019%2F02%2F28%2F%E7%AC%AC%E5%9B%9B%E5%91%A8%EF%BC%9A%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Deep-Neural-Networks%2F</url>
    <content type="text"><![CDATA[4.1 深层神经网络（Deep L-layer neural network） $L-layer\quad NN$，则包含了L-1个隐藏层，最后的L层是输出层 $a^{[l]}$和W^{[l]}中的上标l都是从1开始的，l=1,\cdots,L 输入x记为a^{[0]}​​，把输出层\hat y记为a^{[L]} $X$：(12288, 209)(with m=209 examples) Shape of W Shape of b Activation Shape of Activation Layer 1 (n^{[1]},12288) (n^{[1]},1) Z^{[1]} = W^{[1]} X + b^{[1]} (n^{[1]},209) Layer 2 (n^{[2]}, n^{[1]}) (n^{[2]},1) Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]} (n^{[2]},209) \vdots \vdots \vdots \vdots \vdots Layer L-1 (n^{[L-1]}, n^{[L-2]}) (n^{[L-1]}, 1) Z^{[L-1]} = W^{[L-1]} A^{[L-2]} + b^{[L-1]} (n^{[L-1]}, 209) Layer L (n^{[L]}, n^{[L-1]}) (n^{[L]}, 1) Z^{[L]} = W^{[L]} A^{[L-1]} + b^{[L]} (n^{[L]}, 209) 4.2 前向传播和反向传播（Forward and backward propagation）正向传播过程 z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]} a^{[l]}=g^{[l]}(z^{[l]})$m$个训练样本，向量化形式为： Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]} A^{[l]}=g^{[l]}(Z^{[l]})反向传播过程 dz^{[l]}=da^{[l]}\ast g^{[l]'}(z^{[l]}) dW^{[l]}=dz^{[l]}\cdot {a^{[l-1]}}^T db^{[l]}=dz^{[l]} da^{[l-1]}=W^{[l]T}\cdot dz^{[l]}得到： dz^{[l]}=W^{[l+1]T}\cdot dz^{[l+1]}\ast g^{[l]'}(z^{[l]})$m$个训练样本，向量化形式为： dZ^{[l]}=dA^{[l]}\ast g^{[l]'}(Z^{[l]}) dW^{[l]}=\frac1mdZ^{[l]}\cdot A^{[l-1]T} db^{[l]}=\frac1mnp.sum(dZ^{[l]},axis=1,keepdim=True) dA^{[l-1]}=W^{[l]T}\cdot dZ^{[l]} dZ^{[l]}=W^{[l+1]T}\cdot dZ^{[l+1]}\ast g^{[l]'}(Z^{[l]}) 4.3 深层网络中的前向传播（Forward propagation in a Deep Network ）对于第l层，其正向传播过程的Z^{[l]}和A^{[l]}可以表示为： Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]} A^{[l]}=g^{[l]}(Z^{[l]})其中l=1,\cdots,L 4.4 为什么使用深层表示？（Why deep representations?）人脸识别经过训练，神经网络第一层所做的事就是从原始图片中提取出人脸的轮廓与边缘，即边缘检测。这样每个神经元得到的是一些边缘信息。神经网络第二层所做的事情就是将前一层的边缘进行组合，组合成人脸一些局部特征，比如眼睛、鼻子、嘴巴等。再往后面，就将这些局部特征组合起来，融合成人脸的模样。 随着层数由浅到深，神经网络提取的特征也是从边缘到局部特征到整体，由简单到复杂。如果隐藏层足够多，那么能够提取的特征就越丰富、越复杂，模型的准确率就会越高。 语音识别模型浅层的神经元能够检测一些简单的音调，较深的神经元能够检测出基本的音素，更深的神经元就能够检测出单词信息。如果网络够深，还能对短语、句子进行检测。 神经网络从左到右，神经元提取的特征从简单到复杂。特征复杂度与神经网络层数成正相关。特征越来越复杂，功能也越来越强大 深层网络另外一个优点:减少神经元个数，从而减少计算量 使用电路理论，计算逻辑输出： y=x_1\oplus x_2\oplus x_3\oplus\cdots\oplus x_n对于这个逻辑运算，深度网络的结构是每层将前一层的两两单元进行异或，最后得到一个输出 整个深度网络的层数是log_2(n)，不包含输入层。总共使用的神经元个数为： 1+2+\cdots+2^{log_2(n)-1}=1\cdot\frac{1-2^{log_2(n)}}{1-2}=2^{log_2(n)}-1=n-1输入个数是n，这种深层网络所需的神经元个数仅仅是n-1个 如果不用深层网络，使用单个隐藏层，需要的神经元个数将是指数级别那么大。由于包含了所有的逻辑位（0和1），则需要2^{n-1}个神经元 处理同一逻辑问题，深层网络所需的神经元个数比浅层网络要少很多 4.5 搭建神经网络块（Building blocks of deep neural networks）第l层的流程块图 对于神经网络所有层，整体的流程块图正向传播过程和反向传播过程如下所示： 4.6 参数 VS 超参数（Parameters vs Hyperparameters）神经网络中的参数是W^{[l]}和b^{[l]} 超参数则是例如学习速率\alpha，训练迭代次数N，神经网络层数L，各层神经元个数n^{[l]}，激活函数g(z)等 叫做超参数的原因是它们决定了参数W^{[l]}和b^{[l]}的值 如何设置最优的超参数： 通常的做法是选择超参数一定范围内的值，分别代入神经网络进行训练，测试cost function随着迭代次数增加的变化，根据结果选择cost function最小时对应的超参数值]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三周 目标检测（Object detection)(Course 4)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%B8%89%E5%91%A8-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88Object-detection-Course-4%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[第一周 机器学习策略（1）（ML strategy（1））(Course 3)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%B8%80%E5%91%A8-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5%EF%BC%881%EF%BC%89%EF%BC%88ML-strategy%EF%BC%881%EF%BC%89%EF%BC%89-Course-3%2F</url>
    <content type="text"><![CDATA[1.1 为什么是 ML 策略？（Why ML Strategy?）当最初得到一个深度神经网络模型时，希望从很多方面来对它进行优化，例如： Collect more data Collect more diverse training set Train algorithm longer with gradient descent Try Adam instead of gradient descent Try bigger network Try smaller network Try dropout Add L2 regularization Network architecture: Activation functions, #hidden units… 可选择的方法很多、很复杂、繁琐。盲目选择、尝试不仅耗费时间而且可能收效甚微。因此，使用快速、有效的策略来优化机器学习模型是非常必要的。 1.2 正交化（Orthogonalization）每次只调试一个参数，保持其它参数不变，使得到的模型某一性能改变是一种最常用的调参策略，称之为正交化方法（Orthogonalization） Orthogonalization的核心在于每次调试一个参数只会影响模型的某一个性能 机器学习监督式学习模型大致分成四个独立的“功能”： Fit training set well on cost function ，优化训练集可以通过使用更复杂NN，使用Adam等优化算法来实现 Fit dev set well on cost function，优化验证集可以通过正则化，采用更多训练样本来实现 Fit test set well on cost function，优化测试集可以通过使用更多的验证集样本来实现 Performs well in real world，提升实际应用模型可以通过更换验证集，使用新的cost function来实现 每一种“功能”对应不同的调节方法，是正交的 early stopping在模型功能调试中并不推荐使用。因为early stopping在提升验证集性能的同时降低了训练集的性能。即early stopping同时影响两个“功能”，不具有独立性、正交性 1.3 单一数字评估指标（Single number evaluation metric）A和B模型的准确率（Precision）和召回率（Recall）分别如下： 使用单值评价指标F1 Score来评价模型的好坏。F1 Score综合了Precision和Recall的大小： F1=\frac{2\cdot P\cdot R}{P+R} 还可以使用平均值作为单值评价指标： 不同国家样本的错误率，计算平均性能，选择平均错误率最小的模型（C模型） 1.4 满足和优化指标（Satisficing and optimizing metrics）当把所有的性能指标都综合在一起，构成单值评价指标比较困难时：可以把某些性能作为优化指标（Optimizing metic），寻求最优化值；而某些性能作为满意指标（Satisficing metic），只要满足阈值就行 Accuracy和Running time这两个性能不太合适综合成单值评价指标。可以将Accuracy作为优化指标（Optimizing metic），Running time作为满意指标（Satisficing metic）。给Running time设定一个阈值，在其满足阈值的情况下，选择Accuracy最大的模型。如果设定Running time必须在100ms以内，模型C不满足阈值条件，剔除；模型B相比较模型A而言，Accuracy更高，性能更好 如果要考虑N个指标，则选择一个指标为优化指标，其他N-1个指标都是满足指标： N_{metric}:\left\{ \begin{array}{l} 1\qquad \qquad \qquad Optimizing\ metric\\ N_{metric}-1\qquad Satisificing\ metric \end{array} \right.性能指标（Optimizing metic）需要优化，越优越好；满意指标（Satisficing metic）只要满足设定的阈值 1.5 训练/开发/测试集划分（Train/dev/test distributions）训练、开发、测试集选择设置的一些规则和意见： 训练、开发、测试集的设置会对产品带来非常大的影响； 在选择开发集和测试集时要使二者来自同一分布，且从所有数据中随机选取； 所选择的开发集和测试集中的数据，要与未来想要或者能够得到的数据类似，即模型数据和未来数据要具有相似性； 设置的测试集只要足够大，使其能够在过拟合的系统中给出高方差的结果就可以，也许10000左右的数目足够； 设置开发集只要足够使其能够检测不同算法、不同模型之间的优劣差异就可以，百万大数据中1%的大小就足够； 尽量保证dev sets和test sets来源于同一分布且都反映了实际样本的情况。如果dev sets和test sets不来自同一分布，从dev sets上选择的“最佳”模型往往不能够在test sets上表现得很好。好比在dev sets上找到最接近一个靶的靶心的箭，但是test sets提供的靶心却远远偏离dev sets上的靶心，结果肯定无法射中test sets上的靶心位置 1.6 开发集和测试集的大小（Size of dev and test sets） 样本数量不多（小于一万）的时候，通常将Train/dev/test sets的比例设为60%/20%/20% 没有dev sets的情况下，Train/test sets的比例设为70%/30% 样本数量很大（百万级别）的时候，通常将相应的比例设为98%/1%/1%或者99%/1% dev sets数量的设置，遵循的准则是通过dev sets能够检测不同算法或模型的区别，以便选择出更好的模型 test sets数量的设置，遵循的准则是通过test sets能够反映出模型在实际中的表现 实际应用中，可能只有train/dev sets，而没有test sets。这种情况也是允许的，只要算法模型没有对dev sets过拟合。但条件允许的话，最好有test sets，实现无偏估计 1.7 什么时候该改变开发/测试集和指标？（When to change dev/test sets and metrics）算法模型的评价标准有时候需要根据实际情况进行动态调整，目的是让算法模型在实际应用中有更好的效果 example1假设有两个猫的图片的分类器： 评估指标：分类错误率 算法A：3%错误率 算法B：5%错误率 初始的评价标准是错误率，A更好一些。实际使用时发现算法A会通过一些色情图片，但是B没有。从用户的角度来说，更倾向选择B模型，虽然B的错误率高一些。这时候需要改变之前只使用错误率作为评价标准，考虑新的情况进行改变。如增加色情图片的权重，增加其代价 假设开始的评估指标如下： Error = \dfrac{1}{m_{dev}}\sum\limits_{i=1}^{m_{dev}}I\{y^{(i)}_{pred}\neq y^{(i)}\}该评估指标对色情图片和非色情图片一视同仁 修改的方法，在其中加入权重w^{(i)}： Error = \dfrac{1}{\sum w^{(i)}}\sum\limits_{i=1}^{m_{dev}} w^{(i)}I\{y^{(i)}_{pred}\neq y^{(i)}\} w^{(i)}=\begin{cases} 1, & x^{(i)}\ is\ non-porn\\ 10 \ or\ 100, & x^{(i)}\ is\ porn \end{cases}通过设置权重，当算法将色情图片分类为猫时，误差项会快速变大 概括来说，机器学习可分为两个过程： Define a metric to evaluate classifiers How to do well on this metric 第一步是找靶心，第二步是通过训练，射中靶心。但是在训练的过程中可能会根据实际情况改变算法模型的评价标准，进行动态调整,如果评估指标无法正确评估算法的排名，则需要重新定义一个新的评估指标 example2对example1中的两个不同的猫图片的分类器A和B： 实际情况是一直使用网上下载的高质量的图片进行训练；当部署到手机上时，由于图片的清晰度及拍照水平的原因，当实际测试算法时，会发现算法B的表现其实更好 如果在训练开发测试的过程中得到的模型效果比较好，但是在实际应用中所真正关心的问题效果却不好的时候，就需要改变开发、测试集或者评估指标 Guideline： 定义正确的评估指标来更好的给分类器的好坏进行排序 优化评估指标 1.8 为什么是人的表现？（ Why human-level performance?）机器学习模型的表现通常会跟人类水平表现作比较： 当开始往人类水平努力时，进展很快，机器学习模型经过训练会不断接近human-level performance甚至超过它。超过之后，准确性会上升得比较缓慢，当继续训练算法时，可能模型越来越大，数据越来越多，但是性能无法超过某个理论上限，这就是所谓的贝叶斯最优错误率（Bayes optimal error）。理论上任何模型都不能超过它，即没有任何办法设计出一个x到y的函数，让它能够超过一定的准确度，bayes optimal error代表了最佳表现 对于语音识别来说，如果x是音频片段，有些音频很嘈杂，基本不可能知道说的是什么，所以完美的准确率可能不是100%。对于猫图识别来说，也许一些图像非常模糊，不管是人类还是机器，都无法判断该图片中是否有猫。所以完美的准确度可能不是100 贝叶斯最优错误率有时写作Bayesian，即省略optimal，就是从x到y映射的理论最优函数，永远不会被超越。，无论在一个问题上工作多少年，紫色线永远不会超越贝叶斯错误率，贝叶斯最佳错误率 机器学习的进展直到超越人类的表现之前一直很快，当超越时，有时进展会变慢。有两个原因： 人类水平在很多任务中离贝叶斯最优错误率已经不远 只要表现比人类的表现更差，可以使用某些工具来提高性能。一旦超越了人类的表现，这些工具就没那么好用 只要人类的表现比任何其他算法都要好，就可以让人类看看算法处理的例子，知道错误出在哪里，并尝试了解为什么人能做对，算法做错 1.9 可避免偏差（Avoidable bias）猫分类器: 人类具有近乎完美的准确度，人类水平的错误是1%,如果学习算法达到8%的训练错误率和10%的开发错误率，算法在训练集上的表现和人类水平的表现有很大差距，说明算法对训练集的拟合并不好。从减少偏差和方差这个角度看，把重点放在减少偏差上。比如训练更大的神经网络，跑久一点梯度下降，试试能不能在训练集上做得更好 同样的训练错误率和开发错误率，假设人类水平错误实际上是7.5%，系统在训练集上的表现还好，只比人类的表现差一点。在第二个例子中，应专注减少学习算法的方差，可以试试正则化，让开发错误率更接近训练错误率 用人类水平的错误率估计或代替贝叶斯错误率或贝叶斯最优错误率，对于计算机视觉任务而言，这样替代相当合理，因为人类非常擅长计算机视觉任务，人类能做到的水平和贝叶斯错误率相差不远 左边的例子8%的训练错误率真的很高，可以把它降到1%，减少偏差的手段可能有效。右边的例子中，如果认为贝叶斯错误率是7.5%，这里使用人类水平错误率来替代贝叶斯错误率，就知道没有太多改善的空间了，不能继续减少训练错误率，训练误差和开发误差之间有更多的改进空间，可以将这个2%的差距缩小一点，使用减少方差的手段，比如正则化，或者收集更多的训练数据 贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差 理论上是不可能超过贝叶斯错误率的，除非过拟合 训练错误率和开发错误率之前的差值，说明算法在方差问题上还有多少改善空间 1.10 理解人的表现（Understanding human-level performance）医学图像识别的例子： 在减小误诊率的背景下，人类水平误差在这种情形下应定义为：0.5% error。但是实际应用中，不同人可能选择的human-level performance基准是不同的，这会带来一些影响 如果在为了部署系统或者做研究分析的背景下，也许超过一名普通医生即可，即人类水平误差在这种情形下应定义为：1% error 假如该模型training error为0.7%，dev error为0.8。如果选择Team of experienced doctors，即human-level error为0.5%，则bias比variance更加突出。如果选择Experienced doctor，即human-level error为0.7%，则variance更加突出。选择什么样的human-level error，有时候会影响bias和variance值的相对变化。当然这种情况一般只会在模型表现很好，接近bayes optimal error的时候出现。越接近bayes optimal error，模型越难继续优化，因为这时候的human-level performance可能是比较模糊难以准确定义的 1.11 超过人的表现（Surpassing human- level performance）对于自然感知类问题，例如视觉、听觉等，机器学习的表现不及人类。但是在很多其它方面，机器学习模型的表现已经超过人类了，包括： Online advertising Product recommendations Logistics(predicting transit time) Loan approvals 机器学习模型超过human-level performance是比较困难的。但是只要提供足够多的样本数据，训练复杂的神经网络，模型预测准确性会大大提高，很有可能接近甚至超过human-level performance。值得一提的是当算法模型的表现超过human-level performance时，很难再通过人的直觉来解决如何继续提高算法模型性能的问题 1.12 改善你的模型的表现（Improving your model performance）提高机器学习模型性能主要要解决两个问题：avoidable bias和variance。training error与human-level error之间的差值反映的是avoidable bias，dev error与training error之间的差值反映的是variance 基本假设： 模型在训练集上有很好的表现； 模型推广到开发和测试集啥也有很好的表现 减少可避免偏差 训练更大的模型 训练更长时间、训练更好的优化算法（Momentum、RMSprop、Adam） 寻找更好的网络架构（RNN、CNN）、寻找更好的超参数 减少方差 收集更多的数据 正则化（L2、dropout、数据增强） 寻找更好的网络架构（RNN、CNN）、寻找更好的超参数]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二周：优化算法 (Optimization algorithms)(Course 2)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9A%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-Optimization-algorithms-Course-2%2F</url>
    <content type="text"><![CDATA[2.1 Mini-batch 梯度下降（Mini-batch gradient descent）神经网络训练过程是同时对所有m个样本（称为batch）通过向量化计算方式进行的。如果m很大，训练速度会很慢，因为每次迭代都要对所有样本进进行求和运算和矩阵运算。这种梯度下降算法称为Batch Gradient Descent解决： 把m个训练样本分成若干个子集，称为mini-batches，然后每次在单一子集上进行神经网络训练，这种梯度下降算法叫做Mini-batch Gradient Descent 假设总的训练样本个数m=5000000，其维度为(n_x,m)。将其分成5000个子集，每个mini-batch含有1000个样本。将每个mini-batch记为X^{\{t\}}，其维度为(n_x,1000)。相应的每个mini-batch的输出记为Y^{\{t\}}，其维度为(1,1000)，且t=1,2,\cdots,5000 X^{(i)}：第i个样本 Z^{[l]}：神经网络第l层网络的线性输出 X^{\{t\}},Y^{\{t\}}：第t组mini-batch Mini-batches Gradient Descent是先将总的训练样本分成T个子集（mini-batches），然后对每个mini-batch进行神经网络训练，包括Forward Propagation，Compute Cost Function，Backward Propagation，循环至T个mini-batch都训练完毕 for\ \ t=1,\cdots,T\ \ \{ \ \ \ \ Forward\ Propagation \ \ \ \ Compute\ Cost\ Function \ \ \ \ Backward\ Propagation \ \ \ \ W:=W-\alpha\cdot dW \ \ \ \ b:=b-\alpha\cdot db \}经过T次循环之后，所有m个训练样本都进行了梯度下降计算。这个过程称之为经历了一个epoch。对于Batch Gradient Descent而言，一个epoch只进行一次梯度下降算法；而Mini-Batches Gradient Descent，一个epoch会进行T次梯度下降算法 对于Mini-Batches Gradient Descent，可以进行多次epoch训练。每次epoch，最好是将总体训练数据打乱、重新分成T组mini-batches，这样有利于训练出最佳的神经网络模型 2.2 理解 mini-batch 梯度下降法（Understanding mini-batch gradient descent）Batch gradient descent和Mini-batch gradient descent的cost曲线： 对于一般的神经网络模型，使用Batch gradient descent，随着迭代次数增加，cost是不断减小的。而使用Mini-batch gradient descent，随着在不同的mini-batch上迭代训练，其cost不是单调下降，而是受类似noise的影响，出现振荡。但整体的趋势是下降的，最终也能得到较低的cost值 出现细微振荡的原因是不同的mini-batch之间是有差异的。可能第一个子集(X^{\{1\}},Y^{\{1\}})是好的子集，而第二个子集(X^{\{2\}},Y^{\{2\}})包含了一些噪声noise。出现细微振荡是正常的 如果mini-batch size=m，即为Batch gradient descent，只包含一个子集为(X^{\{1\}},Y^{\{1\}})=(X,Y)； 如果mini-batch size=1，即为Stachastic gradient descent，每个样本就是一个子集(X^{\{1\}},Y^{\{1\}})=(x^{(i)},y^{(i)})，共有m个子集 蓝色的线代表Batch gradient descent，紫色的线代表Stachastic gradient descent。Batch gradient descent会比较平稳地接近全局最小值，但因为使用了所有m个样本，每次前进的速度有些慢。Stachastic gradient descent每次前进速度很快，但路线曲折，有较大的振荡，最终会在最小值附近来回波动，难达到最小值。而且在数值处理上不能使用向量化的方法来提高运算速度 mini-batch size不能设置得太大（Batch gradient descent），也不能设置得太小（Stachastic gradient descent）。相当于结合了Batch gradient descent和Stachastic gradient descent各自的优点，既能使用向量化优化算法，又能较快速地找到最小值。mini-batch gradient descent的梯度下降曲线如下图绿色所示，每次前进速度较快，且振荡较小，基本能接近全局最小值。 总体样本数量m不太大时，例如m\leq2000，建议直接使用Batch gradient descent 总体样本数量m很大时，建议将样本分成许多mini-batches。推荐常用的mini-batch size为64,128,256,512。都是2的幂。原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度 mini-batch 中确保 X{\{t\}} 和Y{\{t\}}要符合 CPU/GPU 内存，取决于应用方向以及训练集的大小。如果处理的 mini-batch 和 CPU/GPU 内存不相符，不管用什么方法处理数据，算法的表现都急转直下变得惨不忍睹 从训练集（X，Y）中构建小批量 随机洗牌（Shuffle）：创建训练集（X，Y）的混洗版本，X和Y的每一列代表一个训练示例。随机混洗是在X和Y之间同步完成的。这样在混洗之后第i列的X对应的例子就是Y第i列中的标签。混洗步骤可确保将示例随机分成不同的小批次 分区（Partition）：将混洗（X，Y）分区为小批量mini_batch_size（此处为64）。训练示例的数量并非总是可以被mini_batch_size整除。最后一个小批量可能会更小 2.3 指数加权平均数（Exponentially weighted averages）半年内伦敦市的气温变化： 温度数据有noise，抖动较大 如果希望看到半年内气温的整体变化趋势，可以通过移动平均（moving average）的方法来对每天气温进行平滑处理 设V_0=0，当成第0天的气温值 第一天的气温与第0天的气温有关： V_1=0.9V_0+0.1\theta_1第二天的气温与第一天的气温有关： \begin{aligned}V_2 =&0.9V_1+0.1\theta_2\\ =&0.9(0.9V_0+0.1\theta_1)+0.1\theta_2\\ =&0.9^2V_0+0.9\cdot0.1\theta_1+0.1\theta_2 \end{aligned}第三天的气温与第二天的气温有关： \begin{aligned}V_3 =&0.9V_2+0.1\theta_3\\ =&0.9(0.9^2V_0+0.9\cdot0.1\theta_1+0.1\theta_2)+0.1\theta_3\\ =&0.9^3V_0+0.9^2\cdot 0.1\theta_1+0.9\cdot 0.1\theta_2+0.1\theta_3 \end{aligned}第t天与第t-1天的气温迭代关系为： \begin{aligned}V_t =&0.9V_{t-1}+0.1\theta_t\\ =&0.9^tV_0+0.9^{t-1}\cdot0.1\theta_1+0.9^{t-2}\cdot 0.1\theta_2+\cdots+0.9\cdot0.1\theta_{t-1}+0.1\theta_t \end{aligned}经过移动平均处理得到的气温如下图红色曲线所示： 这种滑动平均算法称为指数加权平均（exponentially weighted average）。一般形式为： V_t=\beta V_{t-1}+(1-\beta)\theta_t$\beta$值决定了指数加权平均的天数，近似表示为： \frac{1}{1-\beta}当\beta=0.9，则\frac{1}{1-\beta}=10，表示将前10天进行指数加权平均。当\beta=0.98，则\frac{1}{1-\beta}=50，表示将前50天进行指数加权平均。\beta值越大，则指数加权平均的天数越多，平均后的趋势线就越平缓，但是同时也会向右平移 绿色曲线和黄色曲线分别表示了\beta=0.98和\beta=0.5时，指数加权平均的结果 2.4 理解指数加权平均数（Understanding exponentially weighted averages ）指数加权平均公式的一般形式： \begin{aligned}V_t =&\beta V_{t-1}+(1-\beta)\theta_t\\ =&(1-\beta)\theta_t+(1-\beta)\cdot\beta\cdot\theta_{t-1}+(1-\beta)\cdot \beta^2\cdot\theta_{t-2}+\cdots +(1-\beta)\cdot \beta^{t-1}\cdot \theta_1+\beta^t\cdot V_0 \end{aligned}$\theta_t,\theta_{t-1},\theta_{t-2},\cdots,\theta_1$是原始数据值，(1-\beta),(1-\beta)\beta,(1-\beta)\beta^2,\cdots,(1-\beta)\beta^{t-1}是类似指数曲线，从右向左，呈指数下降的。V_t 的值是这两个子式的点乘，将原始数据值与衰减指数点乘，相当于做了指数衰减，离得越近，影响越大，离得越远，影响越小，衰减越厉害 为了减少内存的使用，使用这样的语句来实现指数加权平均算法： V_{\theta}=0 Repeat\ \{ \ \ \ \ Get\ next\ \theta_t \ \ \ \ V_{\theta}:=\beta V_{\theta}+(1-\beta)\theta_t \}2.5 指 数 加 权 平 均 的 偏 差 修 正 （ Bias correction inexponentially weighted averages ）当\beta=0.98时，指数加权平均结果如绿色曲线。但实际上真实曲线如紫色曲线 紫色曲线与绿色曲线的区别是，紫色曲线开始的时候相对较低一些。因为开始时设置V_0=0，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常 修正这种问题的方法是进行偏移校正（bias correction），即在每次计算完V_t后，对V_t进行下式处理： \frac{V_t}{1-\beta^t}刚开始的时候，t比较小，(1-\beta^t)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一周：深度学习的实用层面(Practical aspects of Deep Learning)(Course 2)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%B8%80%E5%91%A8%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2-Practical-aspects-of-Deep-Learning-Course-2%2F</url>
    <content type="text"><![CDATA[1.1 训练，验证，测试集（Train / Dev / Test sets）在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助创建高效的神经网络。训练神经网络时，需要做出很多决策，例如： 神经网络分多少层 每层含有多少个隐藏单元 学习速率是多少 各层采用哪些激活函数 循环迭代的过程是这样的： 先有个想法Idea，先选择初始的参数值，构建神经网络模型结构 然后通过代码Code的形式，实现这个神经网络； 通过实验Experiment验证这些参数对应的神经网络的表现性能。 根据验证结果，对参数进行适当的调整优化，再进行下一次的Idea-&gt;Code-&gt;Experiment循环。通过很多次的循环，不断调整参数，选定最佳的参数值，从而让神经网络性能最优化 在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是的70%训练集，30%测试集，如果没有明确设置验证集，也可以按照60%训练，20%验证和20%测试集来划分 在大数据时代，数据量可能是百万级别，验证集和测试集占数据总量的比例会趋向于变得更小。因为验证集的目的就是验证不同的算法，检验哪种算法更有效，因此，验证集要足够大才能评估，比如2个甚至10个不同算法，并迅速判断出哪种算法更有效。可能不需要拿出20%的数据作为验证集 数据量过百万的应用，训练集可以占到99.5%，验证和测试集各占0.25%，或者验证集占0.4%，测试集占0.1% 确保验证集和测试集的数据来自同一分布 没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，要做的就是在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估 搭建训练验证集和测试集能够加速神经网络的集成，也可以更有效地衡量算法的偏差和方差，从而更高效地选择合适方法来优化算法 1.2 偏差，方差（Bias /Variance）在一个只有x_1和x_2两个特征的二维数据集中，可以绘制数据，将偏差和方差可视化。 在多维空间数据中，绘制数据和可视化分割边界无法实现，但可以通过几个指标，来研究偏差和方差 理解偏差和方差的两个关键数据是训练集误差（Train set error）和验证集误差（Dev set error） 假定训练集误差是1%，验证集误差是11%，可以看出训练集设置得非常好，而验证集设置相对较差，可能过度拟合了训练集，验证集并没有充分利用交叉验证集的作用，这种情况称之为“高方差”。 假设训练集误差是15%，验证集误差是16%，该案例中人的错误率几乎为0%，算法并没有在训练集中得到很好训练，如果训练数据的拟合度不高，就是数据欠拟合，这种算法偏差比较高。对于验证集产生的结果却是合理的，验证集中的错误率只比训练集的多了1%，这种算法偏差高，因为它甚至不能拟合训练集 训练集误差是15%，偏差相当高，验证集的评估结果更糟糕，错误率达到30%，这种算法偏差高，因为它在训练集上结果不理想，而且方差也很高，这是方差偏差都很糟糕的情况 训练集误差是0.5%，验证集误差是1%，猫咪分类器只有1%的错误率，偏差和方差都很低 以上分析都是基于假设预测的，训练集和验证集数据来自相同分布，假设人眼辨别的错误率接近0%，一般来说，最优误差也被称为贝叶斯误差，最优误差接近0%，如果最优误差或贝叶斯误差非常高，比如15%。再看看这个分类器（训练误差15%，验证误差16%），15%的错误率对训练集来说也是非常合理的，偏差不高，方差也非常低 偏差和方差都高： 这条曲线中间部分灵活性非常高，却过度拟合了这两个样本，这类分类器偏差很高，因为它几乎是线性的 采用曲线函数或二次元函数会产生高方差，因为曲线灵活性太高以致拟合了这两个错误样本和中间这些活跃数据。但对于高维数据，有些数据区域偏差高，有些数据区域方差高，所以在高维数据中采用这种分类器看起来就不会那么牵强 1.3 机器学习基础（Basic Recipe for Machine Learning）初始模型训练完成后，首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，要做的就是增加神经网络的隐藏层个数、神经元个数，训练时间延长，选择其它更复杂的NN模型等 如果网络足够大，通常可以很好的拟合训练集，一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方差，要查看验证集性能，从一个性能理想的训练集推断出验证集的性能是否也理想，如果方差高，最好的解决办法就是增加训练样本数据，进行正则化Regularization，选择其他更复杂的NN模型 两点需要注意： 第一点，高偏差和高方差是两种不同的情况，通常用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。如果算法存在高偏差问题，准备更多训练数据没什么用处 第二点，在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要正则适度，通常构建一个更大的网络便可以在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。 这两步实际要做的工作是：使用更复杂的神经网络和海量的训练样本，一般能够同时有效减小Bias和Variance 1.4 正则化（Regularization）深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据 $\frac{\lambda}{2m}$乘以w范数的平方，欧几里德范数的平方等于w_j（ j值从1到n_x）平方的和，也可表示为ww^T，也就是向量参数w的欧几里德范数（2范数）的平方，此方法称为L2正则化。因为这里用了欧几里德法线，被称为向量参数w的L2范数。 J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||_2^2 ||w||_2^2=\sum_{j=1}^{n_x}w_j^2=w^Tw为什么不再加上参数b呢？因为通常w是一个高维参数矢量，几乎涵盖所有参数，已经可以表达高偏差问题，所以参数很大程度上由w决定，而b只是众多参数中的一个，改变b值对整体模型影响较小,所以通常省略不计,如果加了参数b，也没太大影响 $L2$正则化是最常见的正则化类型，L1正则化是正则项\frac{\lambda}{m}乘以\sum_{j=1}^{n^x}|w|，\sum_{j=1}^{n^x}|w|也被称为参数向量w的L1范数无论分母是，m还是2m，它都是一个比例常量 J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||_1 ||w||_1=\sum_{j=1}^{n_x}|w_j|如果用的是L1正则化，w最终会是稀疏的，也就是说w向量中有很多0，虽然L1正则化使模型变得稀疏，却没有降低太多存储内存,实际上L1 regularization在解决high variance方面比L2 regularization并不更具优势。而且，L1的在微分求导方面比较复杂 $\lambda$是正则化参数，可以设置\lambda为不同的值，在Dev set中进行验证，选择最佳的\lambda,通常使用验证集或交叉验证集来配置这个参数 在深度学习模型中，L2 regularization的表达式为： J(w^{[1]},b^{[1]},\cdots,w^{[L]},b^{[L]})=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^L||w^{[l]}||^2 ||w^{[l]}||^2=\sum_{i=1}^{n^{[l]}}\sum_{j=1}^{n^{[l-1]}}(w_{ij}^{[l]})^2$||w^{[l]}||^2$称为Frobenius范数，记为||w^{[l]}||_F^2。一个矩阵的Frobenius范数就是计算所有元素平方和再开方，如下所示： ||A||_F=\sqrt {\sum_{i=1}^m\sum_{j=1}^n|a_{ij}|^2}由于加入了正则化项，梯度下降算法中的dw^{[l]}计算表达式需要做如下修改： dw^{[l]}=dw^{[l]}_{before}+\frac{\lambda}{m}w^{[l]} w^{[l]}:=w^{[l]}-\alpha\cdot dw^{[l]}L2 regularization也被称做weight decay。这是因为，由于加上了正则项，dw^{[l]}有个增量，在更新w^{[l]}的时候，会多减去这个增量，使得w^{[l]}比没有正则项的值要小一些。不断迭代更新，不断地减小 \begin{aligned}w^{[l]} &:=w^{[l]}-\alpha\cdot dw^{[l]}\\ &=w^{[l]}-\alpha\cdot(dw^{[l]}_{before}+\frac{\lambda}{m}w^{[l]})\\ &=(1-\alpha\frac{\lambda}{m})w^{[l]}-\alpha\cdot dw^{[l]}_{before} \end{aligned}其中，(1-\alpha\frac{\lambda}{m})]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三周：浅层神经网络(Shallow neural networks)(Course 1)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%B8%89%E5%91%A8%EF%BC%9A%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Shallow-neural-networks%2F</url>
    <content type="text"><![CDATA[3.1 神经网络概述（Neural Network Overview） 3.2 神经网络的表示（Neural Network Representation ）单隐藏层神经网络就是典型的浅层（shallow）神经网络 单隐藏层神经网络也被称为两层神经网络（2 layer NN） 第l层的权重W^{[l]}维度的行等于l层神经元的个数，列等于l-1层神经元的个数；第i层常数项b^{[l]}维度的行等于l层神经元的个数，列始终为1 3.3 计算一个神经网络的输出（Computing a Neural Network’s output ）两层神经网络可以看成是逻辑回归再重复计算一次 逻辑回归的正向计算可以分解成计算z和a的两部分： z=w^Tx+b a=\sigma(z) 两层神经网络，从输入层到隐藏层对应一次逻辑回归运算；从隐藏层到输出层对应一次逻辑回归运算 z^{[1]}=W^{[1]}x+b^{[1]} a^{[1]}=\sigma(z^{[1]}) z^{[2]}=W^{[2]}a^{[1]}+b^{[2]} a^{[2]}=\sigma(z^{[2]}) 3.4 多样本向量化（Vectorizing across multiple examples ）for循环来求解其正向输出： for i = 1 to m: \begin{aligned}&z^{[1](i)}=W^{[1]}x^{(i)}+b^{[1]}\\&a^{[1](i)}=\sigma(z^{[1](i)})\\&z^{[2](i)}=W^{[2]}a^{[1](i)}+b^{[2]} \\&a^{[2](i)}=\sigma(z^{[2](i)})\end{aligned}矩阵运算的形式： Z^{[1]}=W^{[1]}X+b^{[1]} A^{[1]}=\sigma(Z^{[1]}) Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]} A^{[2]}=\sigma(Z^{[2]})行表示神经元个数，列表示样本数目m 3.5 激活函数（Activation functions） sigmoid函数 tanh函数 ReLU函数 Leaky ReLU函数 对于隐藏层的激活函数，tanh函数要比sigmoid函数表现更好一些。因为tanh函数的取值范围在[-1,+1]之间，隐藏层的输出被限定在[-1,+1]之间，可以看成是在0值附近分布，均值为0。这样从隐藏层到输出层，数据起到了归一化（均值为0）的效果 对于输出层的激活函数，因为二分类问题的输出取值为\{0,+1\}，所以一般会选择sigmoid作为激活函数 选择ReLU作为激活函数能够保证z大于零时梯度始终为1，从而提高神经网络梯度下降算法运算速度。但当z小于零时，存在梯度为0的缺点 Leaky$$ $$ReLU$$激活函数，能够保证$$z$$小于零时梯度不为$$03.6 为什么需要（ 非线性激活函数？（why need a nonlinear activation function?）假设所有的激活函数都是线性的，直接令激活函数g(z)=z，即a=z z^{[1]}=W^{[1]}x+b^{[1]} a^{[1]}=z^{[1]} z^{[2]}=W^{[2]}a^{[1]}+b^{[2]} a^{[2]}=z^{[2]} a^{[2]}=z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}=W^{[2]}(W^{[1]}x+b^{[1]})+b^{[2]}=(W^{[2]}W^{[1]})x+(W^{[2]}b^{[1]}+b^{[2]})=W'x+b'多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入x的线性模型。这样的话神经网络就没有任何作用了。因此，隐藏层的激活函数必须要是非线性的 如果是预测问题而不是分类问题，输出y是连续的情况下，输出层的激活函数可以使用线性函数。如果输出y恒为正值，则也可以使用ReLU激活函数 3.7 激活函数的导数（Derivatives of activation functions ）$sigmoid$函数的导数： g(z)=\frac{1}{1+e^{(-z)}} g'(z)=\frac{d}{dz}g(z)=g(z)(1-g(z))=a(1-a)$tanh$函数的导数： g(z)=\frac{e^{(z)}-e^{(-z)}}{e^{(z)}+e^{(-z)}} g'(z)=\frac{d}{dz}g(z)=1-(g(z))^2=1-a^2$ReLU$函数的导数： g(z)=max(0,z) x = \begin{cases} 0 &\text{if } z < 0 \\ 1 &\text{if } z \geq 0 \end{cases}$Leaky ReLU$函数： g(z)=max(0.01z,z) g'(z) = \begin{cases} 0.01 &\text{if } z < 0 \\ 1 &\text{if } z \geq 0 \end{cases}3.8 神经网络的梯度下降（Gradient descent for neural networks） dZ^{[2]}=A^{[2]}-Y dW^{[2]}=\frac1mdZ^{[2]}A^{[1]T} db^{[2]}=\frac1mnp.sum(dZ^{[2]},axis=1,keepdim=True) dZ^{[1]}=W^{[2]T}dZ^{[2]}\ast g'(Z^{[1]}) dW^{[1]}=\frac1mdZ^{[1]}X^T db^{[1]}=\frac1mnp.sum(dZ^{[1]},axis=1,keepdim=True)3.9 （选修）直观理解反向传播（Backpropagation intuition ）单个训练样本反向过程可以根据梯度计算方法逐一推导： dz^{[2]}=a^{[2]}-y dW^{[2]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial W^{[2]}}=dz^{[2]}a^{[1]T} db^{[2]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial b^{[2]}}=dz^{[2]}\cdot 1=dz^{[2]} dz^{[1]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial a^{[1]}}\cdot \frac{\partial a^{[1]}}{\partial z^{[1]}}=W^{[2]T}dz^{[2]}\ast g^{[1]'}(z^{[1]}) dW^{[1]}=dz^{[1]}\cdot \frac{\partial z^{[1]}}{\partial W^{[1]}}=dz^{[1]}x^T db^{[1]}=dz^{[1]}\cdot \frac{\partial z^{[1]}}{\partial b^{[1]}}=dz^{[1]}\cdot 1=dz^{[1]} 浅层神经网络（包含一个隐藏层），m个训练样本的正向传播过程和反向传播过程分别包含了6个表达式，其向量化矩阵形式如下图所示： 3.10 随机初始化（Random Initialization）神经网络模型中的参数权重W不能全部初始化为零 如果权重W^{[1]}和W^{[2]}都初始化为零，即： W^{[1]}= \left[ \begin{matrix} 0 & 0 \\ 0 & 0 \end{matrix} \right] W^{[2]}= \left[ \begin{matrix} 0 & 0 \end{matrix} \right]这样使得隐藏层第一个神经元的输出等于第二个神经元的输出，即a_1^{[1]}=a_2^{[1]}。经过推导得到dz_1^{[1]}=dz_2^{[1]}，dW_1^{[1]}=dW_2^{[1]}，这样的结果是隐藏层两个神经元对应的权重行向量W_1^{[1]}和W_2^{[1]}每次迭代更新都会得到完全相同的结果，W_1^{[1]}始终等于W_2^{[1]}，完全对称。这样隐藏层设置多个神经元就没有任何意义 权重W全部初始化为零带来的问题称为symmetry breaking problem 随机初始化： 1234W_1 = np.random.randn((2,2))*0.01b_1 = np.zero((2,1))W_2 = np.random.randn((1,2))*0.01b_2 = 0 让W比较小，是因为如果使用sigmoid函数或者tanh函数作为激活函数的话，W比较小，得到的|z|也比较小（靠近零点），而零点区域的梯度比较大，这样能大大提高梯度下降算法的更新速度，尽快找到全局最优解 如果W较大，得到的|z|也比较大，附近曲线平缓，梯度较小，训练过程会慢很多 如果激活函数是ReLU或者Leaky ReLU函数，则不需要考虑这个问题 如果输出层是sigmoid函数，则对应的权重W最好初始化到比较小的值]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DeepLearning.ai深度学习课程笔记]]></title>
    <url>%2F2019%2F02%2F27%2FDeepLearning-ai%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[笔记中没有涵盖所有的视频内容，主要是我不懂或者觉得比较重要的内容，学生我水平有限，如笔记中有知识点、公式、代码错误，还烦请指出 Andrew Ng（吴恩达）的公开信： 朋友们， 我在做三个全新的AI项目。现在，我十分兴奋地宣布其中的第一个：deeplearning.ai，一个立志于扩散AI知识的项目。该项目在Coursera上发布了一系列深度学习课程，这些课程将帮助你掌握深度学习、对它高效地应用，并打造属于你自己的AI事业。 AI是新一轮电力革命 就像一百年前电力改造了每个主流行业，当今的AI技术在做着相同的事。好几个大型科技公司都设立了AI部门，用AI革新他们的业务。接下来的几年里，各个行业、规模大小各不相同的公司也都会意识到——-在由AI驱动的未来，他们必须成为其中的一份子。 创建由AI驱动的社会 我希望，我们可以建立一个由AI驱动的社会：让每个人看得起病，给每个孩子个性化的教育，让所有人都能坐上价格亲民的自动驾驶汽车，并向男人和女人提供有意义的工作。总而言之，是一个让每个人的生活变得更好的社会。 但是，任何一个公司都不可能单独完成这些任务。就像现在每一个计算机专业的毕业生都知道怎么用云，将来，每个程序员也必须懂得怎么用AI。用深度学习改善人类生活的方法有数百万种，社会也需要数百万个人——即来自世界各国的你们，来创造出了不起的AI系统。不管你是加州的一个软件工程师，一名中国的研究员，还是印度的ML工程师，我希望都能用深度学习来解决世界上的各种挑战。 你会学到什么 任何一个掌握了机器学习基础知识的人，都可以学习这五门系列课程，它们组成了Coursera的全新深度学习专业。 你会学到深度学习的基础，理解如何创建神经网络，学习怎么成功地领导机器学习项目。你会学习卷积神经网络、RNNs、LSTM、Adam、Dropout、BatchNorm、Xavier/He initialization以及更多。学习过程中，你会接触到医疗、自动驾驶、读手语、音乐生成、自然语言处理的案例。 你不仅会掌握深度学习理论，还会看到它是怎样在行业应用落地的。你会在Python和TensorFlow里试验这些想法，你还会听到各位深度学习领袖人物的意见，他们会分享各自的学习经历，并提供职业规划建议。 当你拿到Coursera的深度学习专业证书，就可以自信得把“深度学习”四个字写进你的简历。 加入我，建立一个由AI驱动的社会 从2011年到现在，已经有180万人加入了我的机器学习课程。当时，我和四名斯坦福的学生发布了这门课程，它随即成为了Coursera的第一门公开课。那之后，我受到你们之中许多人的启发——当我看到你们是如何努力地理解机器学习，开发优秀的AI系统，并开启令人惊艳的事业。 我希望深度学习专业能帮助你们实现更了不起的事，让你们为社会贡献更多，在职业道路上走得更远。 我希望大家和我一道，建立一个由AI驱动的社会。 我会通知大家另外两个项目的进展，并不断探索，为全世界AI社区的每一个人提供更多支持的途径。 Sincerely， 吴恩达 吴恩达与deeplearning.ai团队]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二周：神经网络的编程基础(Basics of Neural Network programming)(Course 1)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80-Basics-of-Neural-Network-programming%2F</url>
    <content type="text"><![CDATA[2.1 二分类(Binary Classification)逻辑回归模型一般用来解决二分类（Binary Classification）问题 二分类就是输出y只有{0,1}两个离散值（也有{-1,1}的情况） 彩色图片包含RGB三个通道。例如该cat图片的尺寸为（64，64，3） 在神经网络模型中，首先要将图片输入x（维度是（64，64，3））转化为一维的特征向量（featurevector）。方法是每个通道一行一行取，再连接起来。则转化后的输入特征向量维度为（12288，1）。此特征向量x是列向量，维度一般记为n_x 如果训练样本共有m张图片，那么整个训练样本X组成了矩阵，维度是（n_x,m), n_x代表了每个样本X^{(i)}特征个数，列m代表了样本个数,输出Y组成了一维的行向量，维度是（1，m） ) 2.2 逻辑回归(Logistic Regression)逻辑回归中，预测值\hat y=P(y=1 | x)表示为1的概率，取值范围在[0,1]之间 使用线性模型，引入参数w和b。权重w的维度是（n_x，1），b是一个常数项 逻辑回归的预测输出可以完整写成： \hat y = Sigmoid(w^Tx+b)=\sigma(w^Tx+b)Sigmoid函数的一阶导数可以用其自身表示： \sigma'(z)=\sigma(z)(1-\sigma(z)) 2.3 逻辑回归的代价函数（Logistic Regression Cost Function）单个样本的cost function用Loss function来表示，使用平方误差（squared error）： L(\hat y,y)=\frac12(\hat y-y)^2逻辑回归一般不使用平方误差来作为Loss function。原因是这种Loss function一般是non-convex的。 non-convex函数在使用梯度下降算法时，容易得到局部最小值（localminimum），即局部最优化。而最优化的目标是计算得到全局最优化（Global optimization），因此一般选择的Loss function应该是convex的 构建另外一种Loss function(针对单个样本)，且是convex的： L(\hat y,y)=-(ylog\ \hat y+(1-y)log\ (1-\hat y))当y=1时，L(\hat y,y)=-\log \hat y，如果\hat y越接近1，L(\hat y,y)\approx 0，表示预测效果越好；如果\hat y越接近0，L(\hat y,y)\approx +\infty，表示预测效果越差 当y=0时，L(\hat y,y)=-\log(1- \hat y)，如果\hat y越接近0，L(\hat y,y)\approx 0，表示预测效果越好；如果\hat y越接近1，L(\hat y,y)\approx +\infty，表示预测效果越差 Cost function是m个样本的Loss function的平均值，反映了m个样本的预测输出\hat y与真实样本输出y的平均接近程度: J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac1m\sum_{i=1}^m[y^{(i)}log\ \hat y^{(i)}+(1-y^{(i)})log\ (1-\hat y^{(i)})] 2.4 逻辑回归的梯度下降（Logistic Regression Gradient Descent）对单个样本而言，逻辑回归Loss function表达式如下： z=w^Tx+b \hat y=a=\sigma(z) L(a,y)=-(y\log(a)+(1-y)\log(1-a)) 计算该逻辑回归的反向传播过程: da=\frac{\partial L}{\partial a}=-\frac ya+\frac{1-y}{1-a} dz=\frac{\partial L}{\partial z}=\frac{\partial L}{\partial a}\cdot \frac{\partial a}{\partial z}=(-\frac ya+\frac{1-y}{1-a})\cdot a(1-a)=a-y dw_1=\frac{\partial L}{\partial w_1}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial w_1}=x_1\cdot dz=x_1(a-y) dw_2=\frac{\partial L}{\partial w_2}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial w_2}=x_2\cdot dz=x_2(a-y) db=\frac{\partial L}{\partial b}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial b}=1\cdot dz=a-y则梯度下降算法可表示为： w_1:=w_1-\alpha\ dw_1 w_2:=w_2-\alpha\ dw_2 b:=b-\alpha\ db 2.5 梯度下降的例子(Gradient Descent on m Examples)m个样本的Cost function表达式如下： z^{(i)}=w^Tx^{(i)}+b \hat y^{(i)}=a^{(i)}=\sigma(z^{(i)}) J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac1m\sum_{i=1}^m[y^{(i)}log\ \hat y^{(i)}+(1-y^{(i)})log\ (1-\hat y^{(i)})]Cost function关于w和b的偏导数可以写成和平均的形式： dw_1=\frac1m\sum_{i=1}^mx_1^{(i)}(a^{(i)}-y^{(i)}) dw_2=\frac1m\sum_{i=1}^mx_2^{(i)}(a^{(i)}-y^{(i)}) dw_m=\frac1m\sum_{i=1}^mx_m^{(i)}(a^{(i)}-y^{(i)}) db=\frac1m\sum_{i=1}^m(a^{(i)}-y^{(i)})算法流程如下所示： 12345678910111213J=0; dw1=0; dw2=0; db=0;for i = 1 to mz(i) = wx(i)+b;a(i) = sigmoid(z(i));J += -[y(i)log(a(i))+(1-y(i)）log(1-a(i));dz(i) = a(i)-y(i);dw1 += x1(i)dz(i);dw2 += x2(i)dz(i);db += dz(i);J /= m;dw1 /= m;dw2 /= m;db /= m; 经过每次迭代后，根据梯度下降算法，w和b都进行更新： w_1:=w_1-\alpha\ dw_1 w_2:=w_2-\alpha\ dw_2 w_m:=w_m-\alpha\ dw_m b:=b-\alpha\ db在深度学习中，样本数量m通常很大，使用for循环会让神经网络程序运行得很慢。应该尽量避免使用for循环操作，而使用矩阵运算，能够大大提高程序运行速度 2.6 向量化 logistic 回归的梯度输出（Vectorizing Logistic Regression’s Gradient Output）db可表示为： db=\frac1m \sum_{i=1}^mdz^{(i)}dw可表示为： dw=\frac1m X\cdot dZ^T单次迭代，梯度下降算法流程如下所示： 12345678Z = np.dot(w.T,X) + bA = sigmoid(Z)dZ = A-Ydw = 1/m*np.dot(X,dZ.T)db = 1/m*np.sum(dZ)w = w - alpha*dwb = b - alpha*db 2.7 （选修）logistic 损失函数的解释（Explanation of logistic regression cost function ）$\hat y$可以看成是预测输出为正类（+1）的概率： \hat y=P(y=1|x)当y=1时： p(y|x)=\hat y当y=0时： p(y|x)=1-\hat y整合到一个式子: P(y|x)=\hat y^y(1-\hat y)^{(1-y)}进行log处理： log\ P(y|x)=log\ \hat y^y(1-\hat y)^{(1-y)}=y\ log\ \hat y+(1-y)log(1-\hat y)上述概率P(y|x)越大越好，加上负号，则转化成了单个样本的Loss function，越小越好: L=-(y\ log\ \hat y+(1-y)log(1-\hat y))对于所有m个训练样本，假设样本之间是独立同分布的，总的概率越大越好： max\ \prod_{i=1}^m\ P(y^{(i)}|x^{(i)})引入log函数，加上负号，将上式转化为Cost function： J(w,b)=-\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac 1m\sum_{i=1}^m[y^{(i)}\ log\ \hat y^{(i)}+(1-y^{(i)})log(1-\hat y^{(i)})]]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一周：深度学习引言(Introduction to Deep Learning)(Course 1)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%B8%80%E9%97%A8%E8%AF%BE-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Neural-Networks-and-Deep-Learning%2F</url>
    <content type="text"><![CDATA[1.1 神经网络的监督学习(Supervised Learning with Neural Networks) 一般的监督式学习（房价预测和线上广告问题），只要使用标准的神经网络模型就可以图像识别处理问题，则要使用卷积神经网络（Convolution Neural Network），即CNN 处理类似语音这样的序列信号时，则要使用循环神经网络（Recurrent Neural Network），即RNN 自动驾驶这样的复杂问题则需要更加复杂的混合神经网络模型 CNN一般处理图像问题，RNN一般处理语音信号 数据类型一般分为两种：Structured Data和Unstructured Data Structured Data通常指的是有实际意义的数据，例如房价预测中的size，#bedrooms，price等；例如在线广告中的User Age，Ad ID等 Unstructured Data通常指的是比较抽象的数据，例如Audio，Image或者Text 1.2Why is Deep Learning taking off？ 红色曲线代表了传统机器学习算法的表现，例如是SVM，logistic regression，decision tree等。当数据量比较小的时候，传统学习模型的表现是比较好的。当数据量很大的时候，其性能基本趋于水平 构建一个深度学习的流程是首先产生Idea，然后将Idea转化为Code，最后进行Experiment。接着根据结果修改Idea，继续这种Idea-&gt;Code-&gt;Experiment的循环，直到最终训练得到表现不错的深度学习网络模型 ![]]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning]]></title>
    <url>%2F2019%2F02%2F23%2Fmachine%20learning%2F</url>
    <content type="text"><![CDATA[A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience EA computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
