<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[第四周：深层神经网络(Deep Neural Networks)(Course 1)]]></title>
    <url>%2F2019%2F02%2F28%2F%E7%AC%AC%E5%9B%9B%E5%91%A8%EF%BC%9A%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Deep-Neural-Networks%2F</url>
    <content type="text"><![CDATA[4.1 深层神经网络（Deep L-layer neural network） $L-layer\quad NN$，则包含了L-1个隐藏层，最后的L层是输出层 $a^{[l]}$和W^{[l]}中的上标l都是从1开始的，l=1,\cdots,L 输入x记为a^{[0]}​​，把输出层\hat y记为a^{[L]} $X$：(12288, 209)(with m=209 examples) Shape of W Shape of b Activation Shape of Activation Layer 1 (n^{[1]},12288) (n^{[1]},1) Z^{[1]} = W^{[1]} X + b^{[1]} (n^{[1]},209) Layer 2 (n^{[2]}, n^{[1]}) (n^{[2]},1) Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]} (n^{[2]},209) \vdots \vdots \vdots \vdots \vdots Layer L-1 (n^{[L-1]}, n^{[L-2]}) (n^{[L-1]}, 1) Z^{[L-1]} = W^{[L-1]} A^{[L-2]} + b^{[L-1]} (n^{[L-1]}, 209) Layer L (n^{[L]}, n^{[L-1]}) (n^{[L]}, 1) Z^{[L]} = W^{[L]} A^{[L-1]} + b^{[L]} (n^{[L]}, 209) 4.2 前向传播和反向传播（Forward and backward propagation）正向传播过程 z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]} a^{[l]}=g^{[l]}(z^{[l]})$m$个训练样本，向量化形式为： Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]} A^{[l]}=g^{[l]}(Z^{[l]})反向传播过程 dz^{[l]}=da^{[l]}\ast g^{[l]'}(z^{[l]}) dW^{[l]}=dz^{[l]}\cdot {a^{[l-1]}}^T db^{[l]}=dz^{[l]} da^{[l-1]}=W^{[l]T}\cdot dz^{[l]}得到： dz^{[l]}=W^{[l+1]T}\cdot dz^{[l+1]}\ast g^{[l]'}(z^{[l]})$m$个训练样本，向量化形式为： dZ^{[l]}=dA^{[l]}\ast g^{[l]'}(Z^{[l]}) dW^{[l]}=\frac1mdZ^{[l]}\cdot A^{[l-1]T} db^{[l]}=\frac1mnp.sum(dZ^{[l]},axis=1,keepdim=True) dA^{[l-1]}=W^{[l]T}\cdot dZ^{[l]} dZ^{[l]}=W^{[l+1]T}\cdot dZ^{[l+1]}\ast g^{[l]'}(Z^{[l]}) 4.3 深层网络中的前向传播（Forward propagation in a Deep Network ）对于第l层，其正向传播过程的Z^{[l]}和A^{[l]}可以表示为： Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]} A^{[l]}=g^{[l]}(Z^{[l]})其中l=1,\cdots,L 4.4 为什么使用深层表示？（Why deep representations?）人脸识别经过训练，神经网络第一层所做的事就是从原始图片中提取出人脸的轮廓与边缘，即边缘检测。这样每个神经元得到的是一些边缘信息。神经网络第二层所做的事情就是将前一层的边缘进行组合，组合成人脸一些局部特征，比如眼睛、鼻子、嘴巴等。再往后面，就将这些局部特征组合起来，融合成人脸的模样。 随着层数由浅到深，神经网络提取的特征也是从边缘到局部特征到整体，由简单到复杂。如果隐藏层足够多，那么能够提取的特征就越丰富、越复杂，模型的准确率就会越高。 语音识别模型浅层的神经元能够检测一些简单的音调，较深的神经元能够检测出基本的音素，更深的神经元就能够检测出单词信息。如果网络够深，还能对短语、句子进行检测。 神经网络从左到右，神经元提取的特征从简单到复杂。特征复杂度与神经网络层数成正相关。特征越来越复杂，功能也越来越强大 深层网络另外一个优点:减少神经元个数，从而减少计算量 使用电路理论，计算逻辑输出： y=x_1\oplus x_2\oplus x_3\oplus\cdots\oplus x_n对于这个逻辑运算，深度网络的结构是每层将前一层的两两单元进行异或，最后得到一个输出 整个深度网络的层数是log_2(n)，不包含输入层。总共使用的神经元个数为： 1+2+\cdots+2^{log_2(n)-1}=1\cdot\frac{1-2^{log_2(n)}}{1-2}=2^{log_2(n)}-1=n-1输入个数是n，这种深层网络所需的神经元个数仅仅是n-1个 如果不用深层网络，使用单个隐藏层，需要的神经元个数将是指数级别那么大。由于包含了所有的逻辑位（0和1），则需要2^{n-1}个神经元 处理同一逻辑问题，深层网络所需的神经元个数比浅层网络要少很多 4.5 搭建神经网络块（Building blocks of deep neural networks）第l层的流程块图 对于神经网络所有层，整体的流程块图正向传播过程和反向传播过程如下所示： 4.6 参数 VS 超参数（Parameters vs Hyperparameters）神经网络中的参数是W^{[l]}和b^{[l]} 超参数则是例如学习速率\alpha，训练迭代次数N，神经网络层数L，各层神经元个数n^{[l]}，激活函数g(z)等 叫做超参数的原因是它们决定了参数W^{[l]}和b^{[l]}的值 如何设置最优的超参数： 通常的做法是选择超参数一定范围内的值，分别代入神经网络进行训练，测试cost function随着迭代次数增加的变化，根据结果选择cost function最小时对应的超参数值]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二周：优化算法 (Optimization algorithms)(Course 2)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9A%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95-Optimization-algorithms-Course-2%2F</url>
    <content type="text"><![CDATA[2.1Mini-batch 梯度下降（Mini-batch gradient descent）神经网络训练过程是同时对所有m个样本（称为batch）通过向量化计算方式进行的。如果m很大，训练速度会很慢，因为每次迭代都要对所有样本进进行求和运算和矩阵运算。这种梯度下降算法称为Batch Gradient Descent 解决： 把m个训练样本分成若干个子集，称为mini-batches，然后每次在单一子集上进行神经网络训练，这种梯度下降算法叫做Mini-batch Gradient Descent 假设总的训练样本个数m=5000000，其维度为(n_x,m)。将其分成5000个子集，每个mini-batch含有1000个样本。将每个mini-batch记为X^{\{t\}}，其维度为(n_x,1000)。相应的每个mini-batch的输出记为Y^{\{t\}}，其维度为(1,1000)，且t=1,2,\cdots,5000 X^{(i)}：第i个样本 Z^{[l]}：神经网络第l层网络的线性输出 X^{\{t\}},Y^{\{t\}}：第t组mini-batch Mini-batches Gradient Descent是先将总的训练样本分成T个子集（mini-batches），然后对每个mini-batch进行神经网络训练，包括Forward Propagation，Compute Cost Function，Backward Propagation，循环至T个mini-batch都训练完毕 for\ \ t=1,\cdots,T\ \ \{ \ \ \ \ Forward\ Propagation \ \ \ \ Compute\ Cost\ Function \ \ \ \ Backward\ Propagation \ \ \ \ W:=W-\alpha\cdot dW \ \ \ \ b:=b-\alpha\cdot db \}经过T次循环之后，所有m个训练样本都进行了梯度下降计算。这个过程称之为经历了一个epoch。对于Batch Gradient Descent而言，一个epoch只进行一次梯度下降算法；而Mini-Batches Gradient Descent，一个epoch会进行T次梯度下降算法 对于Mini-Batches Gradient Descent，可以进行多次epoch训练。每次epoch，最好是将总体训练数据打乱、重新分成T组mini-batches，这样有利于训练出最佳的神经网络模型 2.2理解 mini-batch 梯度下降法（Understanding mini-batch gradient descent）Batch gradient descent和Mini-batch gradient descent的cost曲线： 对于一般的神经网络模型，使用Batch gradient descent，随着迭代次数增加，cost是不断减小的。而使用Mini-batch gradient descent，随着在不同的mini-batch上迭代训练，其cost不是单调下降，而是受类似noise的影响，出现振荡。但整体的趋势是下降的，最终也能得到较低的cost值 出现细微振荡的原因是不同的mini-batch之间是有差异的。可能第一个子集(X^{\{1\}},Y^{\{1\}})是好的子集，而第二个子集(X^{\{2\}},Y^{\{2\}})包含了一些噪声noise。出现细微振荡是正常的 如果mini-batch size=m，即为Batch gradient descent，只包含一个子集为(X^{\{1\}},Y^{\{1\}})=(X,Y)； 如果mini-batch size=1，即为Stachastic gradient descent，每个样本就是一个子集(X^{\{1\}},Y^{\{1\}})=(x^{(i)},y^{(i)})，共有m个子集 蓝色的线代表Batch gradient descent，紫色的线代表Stachastic gradient descent。Batch gradient descent会比较平稳地接近全局最小值，但因为使用了所有m个样本，每次前进的速度有些慢。Stachastic gradient descent每次前进速度很快，但路线曲折，有较大的振荡，最终会在最小值附近来回波动，难达到最小值。而且在数值处理上不能使用向量化的方法来提高运算速度 mini-batch size不能设置得太大（Batch gradient descent），也不能设置得太小（Stachastic gradient descent）。相当于结合了Batch gradient descent和Stachastic gradient descent各自的优点，既能使用向量化优化算法，又能较快速地找到最小值。mini-batch gradient descent的梯度下降曲线如下图绿色所示，每次前进速度较快，且振荡较小，基本能接近全局最小值。 总体样本数量m不太大时，例如m\leq2000，建议直接使用Batch gradient descent 总体样本数量m很大时，建议将样本分成许多mini-batches。推荐常用的mini-batch size为64,128,256,512。都是2的幂。原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度 mini-batch 中确保 X{\{t\}} 和Y{\{t\}}要符合 CPU/GPU 内存，取决于应用方向以及训练集的大小。如果处理的 mini-batch 和 CPU/GPU 内存不相符，不管用什么方法处理数据，算法的表现都急转直下变得惨不忍睹 从训练集（X，Y）中构建小批量 随机洗牌（Shuffle）：创建训练集（X，Y）的混洗版本，X和Y的每一列代表一个训练示例。随机混洗是在X和Y之间同步完成的。这样在混洗之后第i列的X对应的例子就是Y第i列中的标签。混洗步骤可确保将示例随机分成不同的小批次 分区（Partition）：将混洗（X，Y）分区为小批量mini_batch_size（此处为64）。训练示例的数量并非总是可以被mini_batch_size整除。最后一个小批量可能会更小 2.3指数加权平均数（Exponentially weighted averages）半年内伦敦市的气温变化： 温度数据有noise，抖动较大 如果希望看到半年内气温的整体变化趋势，可以通过移动平均（moving average）的方法来对每天气温进行平滑处理 设V_0=0，当成第0天的气温值 第一天的气温与第0天的气温有关： V_1=0.9V_0+0.1\theta_1第二天的气温与第一天的气温有关： \begin{aligned}V_2 =&0.9V_1+0.1\theta_2\\ =&0.9(0.9V_0+0.1\theta_1)+0.1\theta_2\\ =&0.9^2V_0+0.9\cdot0.1\theta_1+0.1\theta_2 \end{aligned}第三天的气温与第二天的气温有关： \begin{aligned}V_3 =&0.9V_2+0.1\theta_3\\ =&0.9(0.9^2V_0+0.9\cdot0.1\theta_1+0.1\theta_2)+0.1\theta_3\\ =&0.9^3V_0+0.9^2\cdot 0.1\theta_1+0.9\cdot 0.1\theta_2+0.1\theta_3 \end{aligned}第t天与第t-1天的气温迭代关系为： \begin{aligned}V_t =&0.9V_{t-1}+0.1\theta_t\\ =&0.9^tV_0+0.9^{t-1}\cdot0.1\theta_1+0.9^{t-2}\cdot 0.1\theta_2+\cdots+0.9\cdot0.1\theta_{t-1}+0.1\theta_t \end{aligned}经过移动平均处理得到的气温如下图红色曲线所示： 这种滑动平均算法称为指数加权平均（exponentially weighted average）。一般形式为： V_t=\beta V_{t-1}+(1-\beta)\theta_t$\beta$值决定了指数加权平均的天数，近似表示为： \frac{1}{1-\beta}当\beta=0.9，则\frac{1}{1-\beta}=10，表示将前10天进行指数加权平均。当\beta=0.98，则\frac{1}{1-\beta}=50，表示将前50天进行指数加权平均。\beta值越大，则指数加权平均的天数越多，平均后的趋势线就越平缓，但是同时也会向右平移 绿色曲线和黄色曲线分别表示了\beta=0.98和\beta=0.5时，指数加权平均的结果 2.4理解指数加权平均数（Understanding exponentially weighted averages ）指数加权平均公式的一般形式： \begin{aligned}V_t =&\beta V_{t-1}+(1-\beta)\theta_t\\ =&(1-\beta)\theta_t+(1-\beta)\cdot\beta\cdot\theta_{t-1}+(1-\beta)\cdot \beta^2\cdot\theta_{t-2}+\cdots +(1-\beta)\cdot \beta^{t-1}\cdot \theta_1+\beta^t\cdot V_0 \end{aligned}$\theta_t,\theta_{t-1},\theta_{t-2},\cdots,\theta_1$是原始数据值，(1-\beta),(1-\beta)\beta,(1-\beta)\beta^2,$$$$\cdots,(1-\beta)\beta^{t-1}是类似指数曲线，从右向左，呈指数下降的。V_t 的值是这两个子式的点乘，将原始数据值与衰减指数点乘，相当于做了指数衰减，离得越近，影响越大，离得越远，影响越小，衰减越厉害 为了减少内存的使用，使用这样的语句来实现指数加权平均算法： V_{\theta}=0 Repeat\ \{ \ \ \ \ Get\ next\ \theta_t \ \ \ \ V_{\theta}:=\beta V_{\theta}+(1-\beta)\theta_t \}2.5指 数 加 权 平 均 的 偏 差 修 正 （ Bias correction inexponentially weighted averages ）当\beta=0.98时，指数加权平均结果如绿色曲线。但实际上真实曲线如紫色曲线 紫色曲线与绿色曲线的区别是，紫色曲线开始的时候相对较低一些。因为开始时设置V_0=0，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常 修正这种问题的方法是进行偏移校正（bias correction），即在每次计算完V_t后，对V_t进行下式处理： \frac{V_t}{1-\beta^t}刚开始的时候，t比较小，(1-\beta^t)]]></content>
  </entry>
  <entry>
    <title><![CDATA[第一周：深度学习的实用层面(Practical aspects of Deep Learning)(Course 2)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%B8%80%E5%91%A8%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2-Practical-aspects-of-Deep-Learning-Course-2%2F</url>
    <content type="text"><![CDATA[1.1训练，验证，测试集（Train / Dev / Test sets）在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助创建高效的神经网络。训练神经网络时，需要做出很多决策，例如： 神经网络分多少层 每层含有多少个隐藏单元 学习速率是多少 各层采用哪些激活函数 循环迭代的过程是这样的： 先有个想法Idea，先选择初始的参数值，构建神经网络模型结构 然后通过代码Code的形式，实现这个神经网络； 通过实验Experiment验证这些参数对应的神经网络的表现性能。 根据验证结果，对参数进行适当的调整优化，再进行下一次的Idea-&gt;Code-&gt;Experiment循环。通过很多次的循环，不断调整参数，选定最佳的参数值，从而让神经网络性能最优化 在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是的70%训练集，30%测试集，如果没有明确设置验证集，也可以按照60%训练，20%验证和20%测试集来划分 在大数据时代，数据量可能是百万级别，验证集和测试集占数据总量的比例会趋向于变得更小。因为验证集的目的就是验证不同的算法，检验哪种算法更有效，因此，验证集要足够大才能评估，比如2个甚至10个不同算法，并迅速判断出哪种算法更有效。可能不需要拿出20%的数据作为验证集 数据量过百万的应用，训练集可以占到99.5%，验证和测试集各占0.25%，或者验证集占0.4%，测试集占0.1% 确保验证集和测试集的数据来自同一分布 没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，要做的就是在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估 搭建训练验证集和测试集能够加速神经网络的集成，也可以更有效地衡量算法的偏差和方差，从而更高效地选择合适方法来优化算法 1.2偏差，方差（Bias /Variance）在一个只有x_1和x_2两个特征的二维数据集中，可以绘制数据，将偏差和方差可视化。 在多维空间数据中，绘制数据和可视化分割边界无法实现，但可以通过几个指标，来研究偏差和方差 理解偏差和方差的两个关键数据是训练集误差（Train set error）和验证集误差（Dev set error） 假定训练集误差是1%，验证集误差是11%，可以看出训练集设置得非常好，而验证集设置相对较差，可能过度拟合了训练集，验证集并没有充分利用交叉验证集的作用，这种情况称之为“高方差”。 假设训练集误差是15%，验证集误差是16%，该案例中人的错误率几乎为0%，算法并没有在训练集中得到很好训练，如果训练数据的拟合度不高，就是数据欠拟合，这种算法偏差比较高。对于验证集产生的结果却是合理的，验证集中的错误率只比训练集的多了1%，这种算法偏差高，因为它甚至不能拟合训练集 训练集误差是15%，偏差相当高，验证集的评估结果更糟糕，错误率达到30%，这种算法偏差高，因为它在训练集上结果不理想，而且方差也很高，这是方差偏差都很糟糕的情况 训练集误差是0.5%，验证集误差是1%，猫咪分类器只有1%的错误率，偏差和方差都很低 以上分析都是基于假设预测的，训练集和验证集数据来自相同分布，假设人眼辨别的错误率接近0%，一般来说，最优误差也被称为贝叶斯误差，最优误差接近0%，如果最优误差或贝叶斯误差非常高，比如15%。再看看这个分类器（训练误差15%，验证误差16%），15%的错误率对训练集来说也是非常合理的，偏差不高，方差也非常低 偏差和方差都高： 这条曲线中间部分灵活性非常高，却过度拟合了这两个样本，这类分类器偏差很高，因为它几乎是线性的 采用曲线函数或二次元函数会产生高方差，因为曲线灵活性太高以致拟合了这两个错误样本和中间这些活跃数据。但对于高维数据，有些数据区域偏差高，有些数据区域方差高，所以在高维数据中采用这种分类器看起来就不会那么牵强 1.3 机器学习基础（Basic Recipe for Machine Learning）初始模型训练完成后，首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，要做的就是增加神经网络的隐藏层个数、神经元个数，训练时间延长，选择其它更复杂的NN模型等 如果网络足够大，通常可以很好的拟合训练集，一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方差，要查看验证集性能，从一个性能理想的训练集推断出验证集的性能是否也理想，如果方差高，最好的解决办法就是增加训练样本数据，进行正则化Regularization，选择其他更复杂的NN模型 两点需要注意： 第一点，高偏差和高方差是两种不同的情况，通常用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。如果算法存在高偏差问题，准备更多训练数据没什么用处 第二点，在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要正则适度，通常构建一个更大的网络便可以在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。 这两步实际要做的工作是：使用更复杂的神经网络和海量的训练样本，一般能够同时有效减小Bias和Variance 1.4正则化（Regularization）深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据 $\frac{\lambda}{2m}$乘以w范数的平方，欧几里德范数的平方等于w_j（ j值从1到n_x）平方的和，也可表示为ww^T，也就是向量参数w的欧几里德范数（2范数）的平方，此方法称为L2正则化。因为这里用了欧几里德法线，被称为向量参数w的L2范数。 J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||_2^2 ||w||_2^2=\sum_{j=1}^{n_x}w_j^2=w^Tw为什么不再加上参数b呢？因为通常w是一个高维参数矢量，几乎涵盖所有参数，已经可以表达高偏差问题，所以参数很大程度上由w决定，而b只是众多参数中的一个，改变b值对整体模型影响较小,所以通常省略不计,如果加了参数b，也没太大影响 $L2$正则化是最常见的正则化类型，L1正则化是正则项\frac{\lambda}{m}乘以\sum_{j=1}^{n^x}|w|，\sum_{j=1}^{n^x}|w|也被称为参数向量w的L1范数无论分母是，m还是2m，它都是一个比例常量 J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||_1 ||w||_1=\sum_{j=1}^{n_x}|w_j|如果用的是L1正则化，w最终会是稀疏的，也就是说w向量中有很多0，虽然L1正则化使模型变得稀疏，却没有降低太多存储内存,实际上L1 regularization在解决high variance方面比L2 regularization并不更具优势。而且，L1的在微分求导方面比较复杂 $\lambda$是正则化参数，可以设置\lambda为不同的值，在Dev set中进行验证，选择最佳的\lambda,通常使用验证集或交叉验证集来配置这个参数 在深度学习模型中，L2 regularization的表达式为： J(w^{[1]},b^{[1]},\cdots,w^{[L]},b^{[L]})=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^L||w^{[l]}||^2 ||w^{[l]}||^2=\sum_{i=1}^{n^{[l]}}\sum_{j=1}^{n^{[l-1]}}(w_{ij}^{[l]})^2$||w^{[l]}||^2$称为Frobenius范数，记为||w^{[l]}||_F^2。一个矩阵的Frobenius范数就是计算所有元素平方和再开方，如下所示： ||A||_F=\sqrt {\sum_{i=1}^m\sum_{j=1}^n|a_{ij}|^2}由于加入了正则化项，梯度下降算法中的dw^{[l]}计算表达式需要做如下修改： dw^{[l]}=dw^{[l]}_{before}+\frac{\lambda}{m}w^{[l]} w^{[l]}:=w^{[l]}-\alpha\cdot dw^{[l]}L2 regularization也被称做weight decay。这是因为，由于加上了正则项，dw^{[l]}有个增量，在更新w^{[l]}的时候，会多减去这个增量，使得w^{[l]}比没有正则项的值要小一些。不断迭代更新，不断地减小 \begin{aligned}w^{[l]} &:=w^{[l]}-\alpha\cdot dw^{[l]}\\ &=w^{[l]}-\alpha\cdot(dw^{[l]}_{before}+\frac{\lambda}{m}w^{[l]})\\ &=(1-\alpha\frac{\lambda}{m})w^{[l]}-\alpha\cdot dw^{[l]}_{before} \end{aligned}其中，(1-\alpha\frac{\lambda}{m})]]></content>
  </entry>
  <entry>
    <title><![CDATA[第三周：浅层神经网络(Shallow neural networks)(Course 1)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%B8%89%E5%91%A8%EF%BC%9A%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Shallow-neural-networks%2F</url>
    <content type="text"><![CDATA[3.1 神经网络概述（Neural Network Overview） 3.2 神经网络的表示（Neural Network Representation ）单隐藏层神经网络就是典型的浅层（shallow）神经网络 单隐藏层神经网络也被称为两层神经网络（2 layer NN） 第l层的权重W^{[l]}维度的行等于l层神经元的个数，列等于l-1层神经元的个数；第i层常数项b^{[l]}维度的行等于l层神经元的个数，列始终为1 3.3 计算一个神经网络的输出（Computing a Neural Network’s output ）两层神经网络可以看成是逻辑回归再重复计算一次 逻辑回归的正向计算可以分解成计算z和a的两部分： z=w^Tx+b a=\sigma(z) 两层神经网络，从输入层到隐藏层对应一次逻辑回归运算；从隐藏层到输出层对应一次逻辑回归运算 z^{[1]}=W^{[1]}x+b^{[1]} a^{[1]}=\sigma(z^{[1]}) z^{[2]}=W^{[2]}a^{[1]}+b^{[2]} a^{[2]}=\sigma(z^{[2]}) 3.4 多样本向量化（Vectorizing across multiple examples ）for循环来求解其正向输出： for i = 1 to m: \begin{aligned}&z^{[1](i)}=W^{[1]}x^{(i)}+b^{[1]}\\&a^{[1](i)}=\sigma(z^{[1](i)})\\&z^{[2](i)}=W^{[2]}a^{[1](i)}+b^{[2]} \\&a^{[2](i)}=\sigma(z^{[2](i)})\end{aligned}矩阵运算的形式： Z^{[1]}=W^{[1]}X+b^{[1]} A^{[1]}=\sigma(Z^{[1]}) Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]} A^{[2]}=\sigma(Z^{[2]})行表示神经元个数，列表示样本数目m 3.5 激活函数（Activation functions） sigmoid函数 tanh函数 ReLU函数 Leaky ReLU函数 对于隐藏层的激活函数，tanh函数要比sigmoid函数表现更好一些。因为tanh函数的取值范围在[-1,+1]之间，隐藏层的输出被限定在[-1,+1]之间，可以看成是在0值附近分布，均值为0。这样从隐藏层到输出层，数据起到了归一化（均值为0）的效果 对于输出层的激活函数，因为二分类问题的输出取值为\{0,+1\}，所以一般会选择sigmoid作为激活函数 选择ReLU作为激活函数能够保证z大于零时梯度始终为1，从而提高神经网络梯度下降算法运算速度。但当z小于零时，存在梯度为0的缺点 Leaky$$ $$ReLU$$激活函数，能够保证$$z$$小于零时梯度不为$$03.6 为什么需要（ 非线性激活函数？（why need a nonlinear activation function?）假设所有的激活函数都是线性的，直接令激活函数g(z)=z，即a=z z^{[1]}=W^{[1]}x+b^{[1]} a^{[1]}=z^{[1]} z^{[2]}=W^{[2]}a^{[1]}+b^{[2]} a^{[2]}=z^{[2]} a^{[2]}=z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}=W^{[2]}(W^{[1]}x+b^{[1]})+b^{[2]}=(W^{[2]}W^{[1]})x+(W^{[2]}b^{[1]}+b^{[2]})=W'x+b'多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入x的线性模型。这样的话神经网络就没有任何作用了。因此，隐藏层的激活函数必须要是非线性的 如果是预测问题而不是分类问题，输出y是连续的情况下，输出层的激活函数可以使用线性函数。如果输出y恒为正值，则也可以使用ReLU激活函数 3.7 激活函数的导数（Derivatives of activation functions ）$sigmoid$函数的导数： g(z)=\frac{1}{1+e^{(-z)}} g'(z)=\frac{d}{dz}g(z)=g(z)(1-g(z))=a(1-a)$tanh$函数的导数： g(z)=\frac{e^{(z)}-e^{(-z)}}{e^{(z)}+e^{(-z)}} g'(z)=\frac{d}{dz}g(z)=1-(g(z))^2=1-a^2$ReLU$函数的导数： g(z)=max(0,z) x = \begin{cases} 0 &\text{if } z < 0 \\ 1 &\text{if } z \geq 0 \end{cases}$Leaky ReLU$函数： g(z)=max(0.01z,z) g'(z) = \begin{cases} 0.01 &\text{if } z < 0 \\ 1 &\text{if } z \geq 0 \end{cases}3.8 神经网络的梯度下降（Gradient descent for neural networks） dZ^{[2]}=A^{[2]}-Y dW^{[2]}=\frac1mdZ^{[2]}A^{[1]T} db^{[2]}=\frac1mnp.sum(dZ^{[2]},axis=1,keepdim=True) dZ^{[1]}=W^{[2]T}dZ^{[2]}\ast g'(Z^{[1]}) dW^{[1]}=\frac1mdZ^{[1]}X^T db^{[1]}=\frac1mnp.sum(dZ^{[1]},axis=1,keepdim=True)3.9 （选修）直观理解反向传播（Backpropagation intuition ）单个训练样本反向过程可以根据梯度计算方法逐一推导： dz^{[2]}=a^{[2]}-y dW^{[2]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial W^{[2]}}=dz^{[2]}a^{[1]T} db^{[2]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial b^{[2]}}=dz^{[2]}\cdot 1=dz^{[2]} dz^{[1]}=dz^{[2]}\cdot \frac{\partial z^{[2]}}{\partial a^{[1]}}\cdot \frac{\partial a^{[1]}}{\partial z^{[1]}}=W^{[2]T}dz^{[2]}\ast g^{[1]'}(z^{[1]}) dW^{[1]}=dz^{[1]}\cdot \frac{\partial z^{[1]}}{\partial W^{[1]}}=dz^{[1]}x^T db^{[1]}=dz^{[1]}\cdot \frac{\partial z^{[1]}}{\partial b^{[1]}}=dz^{[1]}\cdot 1=dz^{[1]} 浅层神经网络（包含一个隐藏层），m个训练样本的正向传播过程和反向传播过程分别包含了6个表达式，其向量化矩阵形式如下图所示： 3.10 随机初始化（Random Initialization）神经网络模型中的参数权重W不能全部初始化为零 如果权重W^{[1]}和W^{[2]}都初始化为零，即： W^{[1]}= \left[ \begin{matrix} 0 & 0 \\ 0 & 0 \end{matrix} \right] W^{[2]}= \left[ \begin{matrix} 0 & 0 \end{matrix} \right]这样使得隐藏层第一个神经元的输出等于第二个神经元的输出，即a_1^{[1]}=a_2^{[1]}。经过推导得到dz_1^{[1]}=dz_2^{[1]}，dW_1^{[1]}=dW_2^{[1]}，这样的结果是隐藏层两个神经元对应的权重行向量W_1^{[1]}和W_2^{[1]}每次迭代更新都会得到完全相同的结果，W_1^{[1]}始终等于W_2^{[1]}，完全对称。这样隐藏层设置多个神经元就没有任何意义 权重W全部初始化为零带来的问题称为symmetry breaking problem 随机初始化： 1234W_1 = np.random.randn((2,2))*0.01b_1 = np.zero((2,1))W_2 = np.random.randn((1,2))*0.01b_2 = 0 让W比较小，是因为如果使用sigmoid函数或者tanh函数作为激活函数的话，W比较小，得到的|z|也比较小（靠近零点），而零点区域的梯度比较大，这样能大大提高梯度下降算法的更新速度，尽快找到全局最优解 如果W较大，得到的|z|也比较大，附近曲线平缓，梯度较小，训练过程会慢很多 如果激活函数是ReLU或者Leaky ReLU函数，则不需要考虑这个问题 如果输出层是sigmoid函数，则对应的权重W最好初始化到比较小的值]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DeepLearning.ai深度学习课程笔记]]></title>
    <url>%2F2019%2F02%2F27%2FDeepLearning-ai%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[笔记中没有涵盖所有的视频内容，主要是我不懂或者觉得比较重要的内容，学生我水平有限，如笔记中有知识点、公式、代码错误，还烦请指出 Andrew Ng（吴恩达）的公开信： 朋友们， 我在做三个全新的AI项目。现在，我十分兴奋地宣布其中的第一个：deeplearning.ai，一个立志于扩散AI知识的项目。该项目在Coursera上发布了一系列深度学习课程，这些课程将帮助你掌握深度学习、对它高效地应用，并打造属于你自己的AI事业。 AI是新一轮电力革命 就像一百年前电力改造了每个主流行业，当今的AI技术在做着相同的事。好几个大型科技公司都设立了AI部门，用AI革新他们的业务。接下来的几年里，各个行业、规模大小各不相同的公司也都会意识到——-在由AI驱动的未来，他们必须成为其中的一份子。 创建由AI驱动的社会 我希望，我们可以建立一个由AI驱动的社会：让每个人看得起病，给每个孩子个性化的教育，让所有人都能坐上价格亲民的自动驾驶汽车，并向男人和女人提供有意义的工作。总而言之，是一个让每个人的生活变得更好的社会。 但是，任何一个公司都不可能单独完成这些任务。就像现在每一个计算机专业的毕业生都知道怎么用云，将来，每个程序员也必须懂得怎么用AI。用深度学习改善人类生活的方法有数百万种，社会也需要数百万个人——即来自世界各国的你们，来创造出了不起的AI系统。不管你是加州的一个软件工程师，一名中国的研究员，还是印度的ML工程师，我希望都能用深度学习来解决世界上的各种挑战。 你会学到什么 任何一个掌握了机器学习基础知识的人，都可以学习这五门系列课程，它们组成了Coursera的全新深度学习专业。 你会学到深度学习的基础，理解如何创建神经网络，学习怎么成功地领导机器学习项目。你会学习卷积神经网络、RNNs、LSTM、Adam、Dropout、BatchNorm、Xavier/He initialization以及更多。学习过程中，你会接触到医疗、自动驾驶、读手语、音乐生成、自然语言处理的案例。 你不仅会掌握深度学习理论，还会看到它是怎样在行业应用落地的。你会在Python和TensorFlow里试验这些想法，你还会听到各位深度学习领袖人物的意见，他们会分享各自的学习经历，并提供职业规划建议。 当你拿到Coursera的深度学习专业证书，就可以自信得把“深度学习”四个字写进你的简历。 加入我，建立一个由AI驱动的社会 从2011年到现在，已经有180万人加入了我的机器学习课程。当时，我和四名斯坦福的学生发布了这门课程，它随即成为了Coursera的第一门公开课。那之后，我受到你们之中许多人的启发——当我看到你们是如何努力地理解机器学习，开发优秀的AI系统，并开启令人惊艳的事业。 我希望深度学习专业能帮助你们实现更了不起的事，让你们为社会贡献更多，在职业道路上走得更远。 我希望大家和我一道，建立一个由AI驱动的社会。 我会通知大家另外两个项目的进展，并不断探索，为全世界AI社区的每一个人提供更多支持的途径。 Sincerely， 吴恩达 吴恩达与deeplearning.ai团队]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二周：神经网络的编程基础(Basics of Neural Network programming)(Course 1)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%BA%8C%E5%91%A8%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80-Basics-of-Neural-Network-programming%2F</url>
    <content type="text"><![CDATA[2.1 二分类(Binary Classification)逻辑回归模型一般用来解决二分类（Binary Classification）问题 二分类就是输出y只有{0,1}两个离散值（也有{-1,1}的情况） 彩色图片包含RGB三个通道。例如该cat图片的尺寸为（64，64，3） 在神经网络模型中，首先要将图片输入x（维度是（64，64，3））转化为一维的特征向量（featurevector）。方法是每个通道一行一行取，再连接起来。则转化后的输入特征向量维度为（12288，1）。此特征向量x是列向量，维度一般记为n_x 如果训练样本共有m张图片，那么整个训练样本X组成了矩阵，维度是（n_x,m), n_x代表了每个样本X^{(i)}特征个数，列m代表了样本个数,输出Y组成了一维的行向量，维度是（1，m） ) 2.2 逻辑回归(Logistic Regression)逻辑回归中，预测值\hat y=P(y=1 | x)表示为1的概率，取值范围在[0,1]之间 使用线性模型，引入参数w和b。权重w的维度是（n_x，1），b是一个常数项 逻辑回归的预测输出可以完整写成： \hat y = Sigmoid(w^Tx+b)=\sigma(w^Tx+b)Sigmoid函数的一阶导数可以用其自身表示： \sigma'(z)=\sigma(z)(1-\sigma(z)) 2.3 逻辑回归的代价函数（Logistic Regression Cost Function）单个样本的cost function用Loss function来表示，使用平方误差（squared error）： L(\hat y,y)=\frac12(\hat y-y)^2逻辑回归一般不使用平方误差来作为Loss function。原因是这种Loss function一般是non-convex的。 non-convex函数在使用梯度下降算法时，容易得到局部最小值（localminimum），即局部最优化。而最优化的目标是计算得到全局最优化（Global optimization），因此一般选择的Loss function应该是convex的 构建另外一种Loss function(针对单个样本)，且是convex的： L(\hat y,y)=-(ylog\ \hat y+(1-y)log\ (1-\hat y))当y=1时，L(\hat y,y)=-\log \hat y，如果\hat y越接近1，L(\hat y,y)\approx 0，表示预测效果越好；如果\hat y越接近0，L(\hat y,y)\approx +\infty，表示预测效果越差 当y=0时，L(\hat y,y)=-\log(1- \hat y)，如果\hat y越接近0，L(\hat y,y)\approx 0，表示预测效果越好；如果\hat y越接近1，L(\hat y,y)\approx +\infty，表示预测效果越差 Cost function是m个样本的Loss function的平均值，反映了m个样本的预测输出\hat y与真实样本输出y的平均接近程度: J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac1m\sum_{i=1}^m[y^{(i)}log\ \hat y^{(i)}+(1-y^{(i)})log\ (1-\hat y^{(i)})] 2.4 逻辑回归的梯度下降（Logistic Regression Gradient Descent）对单个样本而言，逻辑回归Loss function表达式如下： z=w^Tx+b \hat y=a=\sigma(z) L(a,y)=-(y\log(a)+(1-y)\log(1-a)) 计算该逻辑回归的反向传播过程: da=\frac{\partial L}{\partial a}=-\frac ya+\frac{1-y}{1-a} dz=\frac{\partial L}{\partial z}=\frac{\partial L}{\partial a}\cdot \frac{\partial a}{\partial z}=(-\frac ya+\frac{1-y}{1-a})\cdot a(1-a)=a-y dw_1=\frac{\partial L}{\partial w_1}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial w_1}=x_1\cdot dz=x_1(a-y) dw_2=\frac{\partial L}{\partial w_2}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial w_2}=x_2\cdot dz=x_2(a-y) db=\frac{\partial L}{\partial b}=\frac{\partial L}{\partial z}\cdot \frac{\partial z}{\partial b}=1\cdot dz=a-y则梯度下降算法可表示为： w_1:=w_1-\alpha\ dw_1 w_2:=w_2-\alpha\ dw_2 b:=b-\alpha\ db 2.5 梯度下降的例子(Gradient Descent on m Examples)m个样本的Cost function表达式如下： z^{(i)}=w^Tx^{(i)}+b \hat y^{(i)}=a^{(i)}=\sigma(z^{(i)}) J(w,b)=\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac1m\sum_{i=1}^m[y^{(i)}log\ \hat y^{(i)}+(1-y^{(i)})log\ (1-\hat y^{(i)})]Cost function关于w和b的偏导数可以写成和平均的形式： dw_1=\frac1m\sum_{i=1}^mx_1^{(i)}(a^{(i)}-y^{(i)}) dw_2=\frac1m\sum_{i=1}^mx_2^{(i)}(a^{(i)}-y^{(i)}) dw_m=\frac1m\sum_{i=1}^mx_m^{(i)}(a^{(i)}-y^{(i)}) db=\frac1m\sum_{i=1}^m(a^{(i)}-y^{(i)})算法流程如下所示： 12345678910111213J=0; dw1=0; dw2=0; db=0;for i = 1 to mz(i) = wx(i)+b;a(i) = sigmoid(z(i));J += -[y(i)log(a(i))+(1-y(i)）log(1-a(i));dz(i) = a(i)-y(i);dw1 += x1(i)dz(i);dw2 += x2(i)dz(i);db += dz(i);J /= m;dw1 /= m;dw2 /= m;db /= m; 经过每次迭代后，根据梯度下降算法，w和b都进行更新： w_1:=w_1-\alpha\ dw_1 w_2:=w_2-\alpha\ dw_2 w_m:=w_m-\alpha\ dw_m b:=b-\alpha\ db在深度学习中，样本数量m通常很大，使用for循环会让神经网络程序运行得很慢。应该尽量避免使用for循环操作，而使用矩阵运算，能够大大提高程序运行速度 2.6 向量化 logistic 回归的梯度输出（Vectorizing Logistic Regression’s Gradient Output）db可表示为： db=\frac1m \sum_{i=1}^mdz^{(i)}dw可表示为： dw=\frac1m X\cdot dZ^T单次迭代，梯度下降算法流程如下所示： 12345678Z = np.dot(w.T,X) + bA = sigmoid(Z)dZ = A-Ydw = 1/m*np.dot(X,dZ.T)db = 1/m*np.sum(dZ)w = w - alpha*dwb = b - alpha*db 2.7 （选修）logistic 损失函数的解释（Explanation of logistic regression cost function ）$\hat y$可以看成是预测输出为正类（+1）的概率： \hat y=P(y=1|x)当y=1时： p(y|x)=\hat y当y=0时： p(y|x)=1-\hat y整合到一个式子: P(y|x)=\hat y^y(1-\hat y)^{(1-y)}进行log处理： log\ P(y|x)=log\ \hat y^y(1-\hat y)^{(1-y)}=y\ log\ \hat y+(1-y)log(1-\hat y)上述概率P(y|x)越大越好，加上负号，则转化成了单个样本的Loss function，越小越好: L=-(y\ log\ \hat y+(1-y)log(1-\hat y))对于所有m个训练样本，假设样本之间是独立同分布的，总的概率越大越好： max\ \prod_{i=1}^m\ P(y^{(i)}|x^{(i)})引入log函数，加上负号，将上式转化为Cost function： J(w,b)=-\frac1m\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})=-\frac 1m\sum_{i=1}^m[y^{(i)}\ log\ \hat y^{(i)}+(1-y^{(i)})log(1-\hat y^{(i)})]]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一周：深度学习引言(Introduction to Deep Learning)(Course 1)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%AC%AC%E4%B8%80%E9%97%A8%E8%AF%BE-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Neural-Networks-and-Deep-Learning%2F</url>
    <content type="text"><![CDATA[1.1 神经网络的监督学习(Supervised Learning with Neural Networks) 一般的监督式学习（房价预测和线上广告问题），只要使用标准的神经网络模型就可以图像识别处理问题，则要使用卷积神经网络（Convolution Neural Network），即CNN 处理类似语音这样的序列信号时，则要使用循环神经网络（Recurrent Neural Network），即RNN 自动驾驶这样的复杂问题则需要更加复杂的混合神经网络模型 CNN一般处理图像问题，RNN一般处理语音信号 数据类型一般分为两种：Structured Data和Unstructured Data Structured Data通常指的是有实际意义的数据，例如房价预测中的size，#bedrooms，price等；例如在线广告中的User Age，Ad ID等 Unstructured Data通常指的是比较抽象的数据，例如Audio，Image或者Text Why is Deep Learning taking off？ 红色曲线代表了传统机器学习算法的表现，例如是SVM，logistic regression，decision tree等。当数据量比较小的时候，传统学习模型的表现是比较好的。当数据量很大的时候，其性能基本趋于水平 构建一个深度学习的流程是首先产生Idea，然后将Idea转化为Code，最后进行Experiment。接着根据结果修改Idea，继续这种Idea-&gt;Code-&gt;Experiment的循环，直到最终训练得到表现不错的深度学习网络模型 ![]]]></content>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning]]></title>
    <url>%2F2019%2F02%2F23%2Fmachine%20learning%2F</url>
    <content type="text"><![CDATA[A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience EA computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
