<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<script src="/js/src/photoswipe.min.js?v=6.0.0"></script>
<script src="/js/src/photoswipe-ui-default.min.js?v=6.0.0"></script>


<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">



  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/c6c3b5e3.js","daovoice")
  daovoice('init', {
      app_id: "c6c3b5e3"
    });
  daovoice('update');
  </script>






<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  



  
  
    
  
  <link href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.css" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.0.0" rel="stylesheet" type="text/css">




  <link rel="icon" type="image/png" sizes="16x16" href="/favicon16.ico?v=6.0.0">






  <meta name="keywords" content="Python, 深度学习, 机器学习, machine learning, deeplearning">





  <link rel="alternate" href="/atom.xml" title="暴走的技术博客" type="application/atom+xml">






<meta name="description" content="你如果不忙着求生， 你就在忙着求死">
<meta name="keywords" content="Machine Learning&#x2F;Deep Learning&#x2F;Python&#x2F;">
<meta property="og:type" content="website">
<meta property="og:title" content="暴走的技术博客">
<meta property="og:url" content="https://www.baozouai.com/index.html">
<meta property="og:site_name" content="暴走的技术博客">
<meta property="og:description" content="你如果不忙着求生， 你就在忙着求死">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="暴走的技术博客">
<meta name="twitter:description" content="你如果不忙着求生， 你就在忙着求死">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.baozouai.com/">





  <title>暴走的技术博客</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?8a46909e912a122ce69d3b5e9a8dc661";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>
<!--动态标题-->
<script type="text/javascript" src="/js/src/dytitle.js"></script>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
  


  
  
  
    
  



  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
<a href="https://github.com/baozouai" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">暴走的技术博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">The people who are crazy enough to change the world are the ones who do！</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-photos">
          <a href="/photos" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-camera-retro"></i> <br>
            
            相册
          </a>
        </li>
      
        
        <li class="menu-item menu-item-books">
          <a href="/books" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br>
            
            书单
          </a>
        </li>
      
        
        <li class="menu-item menu-item-movies">
          <a href="/movies" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-film"></i> <br>
            
            电影
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>
    
    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/05/斯坦福机器学习笔记-Week-7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/05/斯坦福机器学习笔记-Week-7/" itemprop="url">斯坦福机器学习笔记(Week 7)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-05T04:57:00Z">
                2019-03-05
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-04T05:04:55Z">
                2019-03-04
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/05/斯坦福机器学习笔记-Week-7/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/05/斯坦福机器学习笔记-Week-7/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/05/斯坦福机器学习笔记-Week-7/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week 7)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          
            <h2 id="十、支持向量机-Support-Vector-Machines"><a href="#十、支持向量机-Support-Vector-Machines" class="headerlink" title="十、支持向量机( Support Vector Machines)"></a>十、支持向量机( Support Vector Machines)</h2><h3 id="10-1-优化目标"><a href="#10-1-优化目标" class="headerlink" title="10.1 优化目标"></a>10.1 优化目标</h3><h4 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h4><p>在逻辑回归中，预测函数为：</p>
<script type="math/tex; mode=display">
h_{\theta}(x) = \frac{1}{1+e^{-\theta^T x}}</script><p>代价函数为：</p>
<script type="math/tex; mode=display">
cost = -(ylog(h_{\theta}(x))+(1-y)log(1-h_{\theta}(x)))</script><p>当<script type="math/tex">y=1</script>时，代价函数就为：</p>
<script type="math/tex; mode=display">
cost = -log(h_{\theta}(x) )
= -log\frac{1}{1+e^{-z}}, \quad z=\theta^T x</script><p>此时，代价函数随<script type="math/tex">z</script>的变化曲线如下图：</p>
<p><img src="https://yoyoyohamapi.gitbooks.io/mit-ml/content/SVM/attachments/cost1z.png" alt></p>
<p>当<script type="math/tex">y=1</script>时，随着<script type="math/tex">z</script>取值变大，预测代价变小，因此，逻辑回归想要在面对正样本<script type="math/tex">y=1</script>时，获得足够高的预精度，就希望<script type="math/tex">z=\theta^T x \gg 0</script>。而 SVM 则将上图的曲线拉直为下图中的折线，构成了<script type="math/tex">y=1</script>时的代价函数曲线<script type="math/tex">cost_1(z)</script>:</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/12112import.png" alt></p>
<p>当<script type="math/tex">y=1</script>时，为了预测精度足够高，SVM 希望<script type="math/tex">\theta^T x \geq 1</script></p>
<p>在<script type="math/tex">y = 0</script>时，SVM 定义了代价函数<script type="math/tex">cost_0(z)</script>，为了预测精度足够高，SVM 希望<script type="math/tex">\theta^T x \leq -1</script>：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/2312import.png" alt></p>
<h4 id="最小化预测代价"><a href="#最小化预测代价" class="headerlink" title="最小化预测代价"></a>最小化预测代价</h4><p>SVM定义其最小化预测代价的过程为：</p>
<script type="math/tex; mode=display">
\min\limits_{\theta}C[\sum\limits_{i=1}^{m}y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum\limits_{j=1}^{n}\theta_j^2</script><p>而在逻辑回归中，最小化预测代价的过程为：</p>
<script type="math/tex; mode=display">
\min\limits_{\theta}\frac{1}{m}[\sum\limits_{i=1}^{m}y^{(i)}(-logh_\theta(x^{(i)}))+(1-y^{(i)})(-log(1-h_\theta(x^{(i)})))] + \frac{\lambda}{2m}\sum\limits_{j=1}^{n}\theta_j^2</script><p>可以将逻辑回归的代价函数简要描述为：</p>
<script type="math/tex; mode=display">
cost = A+\lambda B</script><p>SVM 的代价函数描述为：</p>
<script type="math/tex; mode=display">
cost = CA+B</script><p>在逻辑回归中，通过正规化参数<script type="math/tex">\lambda</script>调节<script type="math/tex">A</script>、<script type="math/tex">B</script>所占的权重，且<script type="math/tex">A</script>的权重与<script type="math/tex">\lambda</script>取值成<strong>反比。</strong>而在 SVM 中，则通过参数<script type="math/tex">C</script>调节<script type="math/tex">A</script>、<script type="math/tex">B</script>所占的权重，且<script type="math/tex">A</script>权重与<script type="math/tex">C</script>的取值成反比。即参数<script type="math/tex">C</script>可以被认为是扮演了<script type="math/tex">\frac{1}{\lambda}</script>的角色</p>
<h4 id="预测函数"><a href="#预测函数" class="headerlink" title="预测函数"></a>预测函数</h4><p>当训练得到<script type="math/tex">\theta</script>之后，可以代入下面的 SVM 预测函数进行预测：</p>
<script type="math/tex; mode=display">
h_\theta(x) =
\begin{cases}
1,\quad \text{if } \theta^T x {\geq 0} \\
0,\quad \text{otherwise}
\end{cases}</script><h3 id="10-2-大间距分类器"><a href="#10-2-大间距分类器" class="headerlink" title="10.2 大间距分类器"></a>10.2 大间距分类器</h3><p><strong>SVM</strong> 最小化代价函数过程为：</p>
<script type="math/tex; mode=display">
\min\limits_{\theta}C[\sum\limits_{i=1}^{m}y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum\limits_{j=1}^{n}\theta_j^2</script><p>当<script type="math/tex">y^{(i)}=1</script>时，<strong>SVM</strong> 希望<script type="math/tex">\theta^Tx^{(i)} \geq 1</script>；而当<script type="math/tex">y^{(i)}=0</script>时，<strong>SVM</strong> 希望<script type="math/tex">\theta^Tx^{(i)} \leq -1</script></p>
<p>最小化代价函数的过程就可以描述为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
& \min\frac{1}{2}\sum\limits_{j=1}^{n}\theta_j^2 \\
\text{s.t}. \quad &\theta^T x^{(i)} \geq 1 &\text{if } y^{(i)}=1 \\
& \theta^T x^{(i)} \leq -1 &\text{if } y^{(i)}=0
\end{aligned}</script><p><strong>SVM</strong> 最终找出的<strong>决策边界</strong>会是下图中黑色直线所示的<strong>决策边界</strong>，而不是绿色或者紫色的<strong>决策边界</strong>。该<strong>决策边界</strong>保持了与正、负样本都足够大的距离，这个距离叫做支持向量机的<strong>间距</strong>。因此，<strong>SVM</strong> 是典型的<strong>大间距分类器（Large margin classifier）</strong></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/2351import.png" alt></p>
<p>回顾 <script type="math/tex">C=1/\lambda</script>：</p>
<p>$C$ 较大时，相当于 <script type="math/tex">\lambda</script> 较小，可能会导致过拟合，高方差。</p>
<p>$C$ 较小时，相当于 <script type="math/tex">\lambda</script> 较大，可能会导致欠拟合，高偏差。</p>
<h4 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h4><p>假定有两个 2 维向量：</p>
<script type="math/tex; mode=display">
u=\left(\begin{matrix}u_1 \\ u_2\end{matrix}\right),v=\left(\begin{matrix}v_1 \\ v_2\end{matrix}\right)</script><p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1212import.png" alt></p>
<p>内积为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
u^Tv &= p \cdot ||u|| \\
&= u_1v_1+u_2v_2
\end{aligned}</script><p>$||u||$为<script type="math/tex">u</script>的范数，也是<script type="math/tex">u</script>的长度</p>
<p>假定<script type="math/tex">\theta=\left(\begin{matrix}\theta_1 \\ \theta_2\end{matrix}\right)</script>，且令<script type="math/tex">\theta_0 = 0</script>，以使得向量<script type="math/tex">\theta</script>过原点，则：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\min\limits_\theta\frac{1}{2}\sum\limits_{j=1}^{2}\theta_j^2 &=\min\limits_\theta\frac{1}{2}(\theta_1^2+\theta_2^2) \\
&=\min\limits_\theta\frac{1}{2}(\sqrt{\theta_1^2+\theta_2^2})^2 \\
&=\min\limits_\theta\frac{1}{2}||\theta||^2
\end{aligned}</script><p>由向量内积公式可得：</p>
<script type="math/tex; mode=display">
\theta^T x^{(i)} = p^{(i)}\cdot||\theta||</script><p>$p^{(i)}$为特征向量<script type="math/tex">x^{(i)}</script>在<script type="math/tex">\theta</script>上的投影：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/321import.png" alt></p>
<p>当<script type="math/tex">y^{(i)}=1</script>时，希望<script type="math/tex">\theta^T x^{(i)} \geq 1</script>，亦即希望<script type="math/tex">p^{(i)}\cdot||\theta|| \geq 1</script>，此时考虑两种情况：</p>
<p>1.<script type="math/tex">p^{(i)}</script>很小，则需要<script type="math/tex">||\theta||</script>很大，这与<script type="math/tex">\min\limits_\theta\frac{1}{2}||\theta||^2</script>矛盾</p>
<p>2.<script type="math/tex">p^{(i)}</script>很大，如下图所示，即样本与决策边界的距离足够大，才能在既要<script type="math/tex">||\theta||</script>足够小的情况下，又能有</p>
<p>$\theta^Tx^{(i)} \geq 1$，保证预测精度够高。这解释了为什么 <strong>SVM</strong> 的模型会具有<strong>大间距分类器</strong>的性质</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/432import.png" alt></p>
<h3 id="10-3-核函数"><a href="#10-3-核函数" class="headerlink" title="10.3 核函数"></a>10.3 核函数</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/456import.png" alt></p>
<p>在逻辑回归中，会通过多项式扩展来处理<strong>非线性</strong>分类问题：</p>
<script type="math/tex; mode=display">
h_\theta(x) = \theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1x_2+\theta_4x_1^2+\theta_5x_2^2+\cdots</script><p>假设令：</p>
<script type="math/tex; mode=display">
f_1=x_1,f_2=x_2,f_3=x_1x_2,f_4=x_1^2,f_5=x_2^2</script><p>则预测函数为：</p>
<script type="math/tex; mode=display">
h_\theta(x) = \theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+\cdots</script><p>但多项式回归所带来的高阶项不一定作用明显，针对这一问题，SVM不会引入高阶项来作为新的特征，而是会选择一些<strong>标记点（landmark）</strong>，并将样本<script type="math/tex">x</script>与标记点<script type="math/tex">l^{(i)}</script>的<strong>相似程度</strong>作为新的训练特征<script type="math/tex">f_i</script>：</p>
<script type="math/tex; mode=display">
f_i = similarity(x, l^{(i)})</script><p><img src="https://yoyoyohamapi.gitbooks.io/mit-ml/content/SVM/attachments/landmarks.jpg" alt></p>
<p>距离度量的方式就称之为<strong>核函数（Kernel）</strong>，最常见的核函数是<strong>高斯核函数（Gaussian Kernel）</strong>：</p>
<script type="math/tex; mode=display">
f_i = exp(-\frac{||x-l^{(i)}||^2}{2\sigma ^2})</script><p>其中：</p>
<script type="math/tex; mode=display">
||x-l^{(i)}||^2 = \sum_{j=1}^{n}(x_j-l_j^{(i)})^2</script><p>为实例 <script type="math/tex">x</script>中所有特征与地标<script type="math/tex">l^{(i)}</script>之间的距离的和</p>
<p><strong>注：这个函数与正态分布没什么实际上的关系，只是看上去像而已</strong></p>
<p>在高斯核中，注意到：</p>
<ul>
<li>如果样本与标记点足够接近，即<script type="math/tex">x \approx l^{(i)}</script>，则：</li>
</ul>
<script type="math/tex; mode=display">
f \approx exp(-\frac{0^2}{2\sigma ^2}) \approx 1</script><ul>
<li>如果样本远离标记点，则：</li>
</ul>
<script type="math/tex; mode=display">
f \approx exp(-\frac{(\text{large number})^2}{2\sigma ^2}) \approx 0</script><p>假设训练实例含有两个特征<script type="math/tex">[x_1\quad x_2 ]</script>,给定地标<script type="math/tex">l^{(1)}</script>与不同的<script type="math/tex">\sigma</script>值，见下图：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/130import.png" alt></p>
<blockquote>
<p><strong>在使用高斯核函数前，需要做特征缩放（feature scaling），以使 SVM 同等程度地关注到不同的特征</strong></p>
</blockquote>
<p>水平面的坐标为 <script type="math/tex">x_1</script> ，<script type="math/tex">x_2</script> ,而垂直坐标轴代表 <script type="math/tex">f</script>。只有当 <script type="math/tex">x</script> 与 <script type="math/tex">l^{ (1)}</script> 重合时<script type="math/tex">f</script>才具有最大值。随着<script type="math/tex">x</script>的改变<script type="math/tex">f</script>值改变的速率受到<script type="math/tex">\sigma ^2</script>的控制</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/129import.png" alt></p>
<p>图中红色的封闭曲线所表示的范围，是依据一个单一的训练实例和选取的地标所得出的判定边界，在预测时，采用的特征不是训练实例本身的特征，而是通过核函数计算出的新特征<script type="math/tex">f _1 ,f_ 2 ,f _3</script></p>
<h4 id="标记点选取"><a href="#标记点选取" class="headerlink" title="标记点选取"></a>标记点选取</h4><p>假定有如下的数据集：</p>
<script type="math/tex; mode=display">
(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),(x^{(3)},y^{(3)}) \cdots (x^{(m)},y^{(m)})</script><p>将每个样本作为一个标记点：</p>
<script type="math/tex; mode=display">
l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},l^{(3)}=x^{(3)} \cdots l^{(m)}=x^{(m)}</script><p>对于样本<script type="math/tex">(x^{(i)}, y^{(i)})</script>，计算其与各个标记点的距离：</p>
<script type="math/tex; mode=display">
f_1^{(i)}=sim(x^{(i)},l^{(1)})</script><script type="math/tex; mode=display">
f_2^{(i)}=sim(x^{(i)},l^{(2)})</script><script type="math/tex; mode=display">
\vdots</script><script type="math/tex; mode=display">
f_i^{(i)}=sim(x^{(i)},l^{(i)})=exp(-\frac{0^2}{2\sigma ^2})=1</script><script type="math/tex; mode=display">
\vdots</script><script type="math/tex; mode=display">
f_m^{(i)}=sim(x^{(i)},l^{(m)})</script><p>得到新的特征向量：<script type="math/tex">f \in R^{m+1}</script></p>
<script type="math/tex; mode=display">
f=\left(\begin{matrix}f_0 \\ f_1 \\ f_2 \\ \vdots \\ f_m \end{matrix}\right) \quad \text{其中} f_0=1</script><p>将核函数运用到支持向量机中，修改支持向量机假设为：</p>
<p>给定<script type="math/tex">x</script>，计算新特征<script type="math/tex">f</script>，当<script type="math/tex">\theta ^T f>=0</script>时，预测<script type="math/tex">y=1</script>，否则反之。 相应地修改代价函数为：</p>
<script type="math/tex; mode=display">
\min\limits_{\theta}C\big[\sum\limits_{i=1}^{m}(y^{(i)}cost_1(\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\theta^Tf^{(i)}))\big]+\frac{1}{2}\sum\limits_{j=1}^{n=m}\theta_j^2</script><p>在计算<script type="math/tex">\sum\limits_{j=1}^{n=m}\theta_j^2=\theta^T\theta</script>时，用<script type="math/tex">\theta^T M\theta</script>代替<script type="math/tex">\theta ^T \theta</script>，其中<script type="math/tex">M</script>是根据选择的核函数而不同的一个矩阵。这样做的原因是为了简化计算。理论上讲，也可以在逻辑回归中使用核函数，但是上面使用<script type="math/tex">M</script>来简化计算的方法不适用于逻辑回归，因为计算将非常耗费时间</p>
<p>支持向量机也可以不使用核函数，不使用核函数又称为<strong>线性核函数（linear kernel）</strong>，当不采用非常复杂的函数，或者训练集特征非常多而实例非常少的时候，可以采用这种不带核函数的支持向量机</p>
<p>支持向量机的两个参数<script type="math/tex">C</script>和<script type="math/tex">\sigma</script>的影响：</p>
<p>$C=1/\lambda$</p>
<ul>
<li><p>C 较大时，相当于<script type="math/tex">\lambda</script>较小，可能会导致过拟合，高方差</p>
</li>
<li><p>C 较小时，相当于<script type="math/tex">\lambda</script>较大，可能会导致欠拟合，高偏差</p>
</li>
<li><p><script type="math/tex">\sigma</script>较大时，可能会导致低方差，高偏差</p>
</li>
<li><p><script type="math/tex">\sigma</script>较小时，可能会导致低偏差，高方差</p>
</li>
</ul>
<h3 id="10-4-使用支持向量机"><a href="#10-4-使用支持向量机" class="headerlink" title="10.4 使用支持向量机"></a>10.4 使用支持向量机</h3><p>选择支持向量机的原因主要在于它的代价函数是<strong>凸函数</strong>，不存在<strong>局部最小值</strong></p>
<h4 id="使用流行库"><a href="#使用流行库" class="headerlink" title="使用流行库"></a>使用流行库</h4><p>作为当今最为流行的分类算法之一，SVM 已经拥有了不少优秀的实现库，如<strong>libsvm</strong>等，因此，不需要自己手动实现 SVM（一个能用于生产环境的 SVM 模型并非课程中介绍的那么简单）</p>
<p>在使用这些库时，通常需要声明 SVM 的两个关键部分：</p>
<ul>
<li>参数<script type="math/tex">C</script>的选择</li>
<li>选择内核参数或想要使用的相似函数，其中一个选择是：选择不需要任何内核参数，没有内核参数的理念，也叫<strong>线性核函数</strong>。</li>
</ul>
<p>核函数的选择：</p>
<ul>
<li><p>当特征维度<script type="math/tex">n</script>较高，而样本规模<script type="math/tex">m</script>较小时，<strong>不宜使用核函数</strong>，否则容易引起过拟合</p>
</li>
<li><p>当特征维度<script type="math/tex">n</script>较低，而样本规模<script type="math/tex">m</script>足够大时，考虑使用<strong>高斯核函数</strong>。不过在使用高斯核函数前，需要进行<strong>特征缩放（feature scaling）</strong>。另外，当核函数的参数<script type="math/tex">\sigma</script><strong>较大</strong>时，特征<script type="math/tex">f_i</script>较为平缓，即各个样本的特征差异变小，此时会造成<strong>欠拟合（高偏差，低方差）</strong>：</p>
</li>
</ul>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/876import.png" alt></p>
<p>当<script type="math/tex">\sigma</script><strong>较小</strong>时，特征<script type="math/tex">f_i</script>曲线变化剧烈，即各个样本的特征差异变大，此时会造成<strong>过拟合（低偏差，高方差）</strong>：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/987import.png" alt></p>
<blockquote>
<p>不是所有的相似度评估手段都能被用作SVM核函数，他们需要满足Mercer 理论</p>
</blockquote>
<h4 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h4><p>流行的SVM库已经内置了多分类相关的 api，如果其不支持多分类，则与逻辑回归一样，使用 One-vs-All策略来进行多分类：</p>
<ol>
<li><p>轮流选中某一类型<script type="math/tex">i</script>，将其视为正样本，即 “1” 分类，剩下样本都看做是负样本，即 “0” 分类</p>
</li>
<li><p>训练 SVM 得到参数<script type="math/tex">\theta^{(1)}, \theta^{(2)}, ..., \theta^{(K)}</script>，即总共获得了<script type="math/tex">K-1</script>个决策边界</p>
</li>
</ol>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/999import.png" alt></p>
<h2 id="分类模型的选择"><a href="#分类模型的选择" class="headerlink" title="分类模型的选择"></a>分类模型的选择</h2><p>分类模型有：（1）逻辑回归；（2）神经网络；（3）SVM</p>
<p>考虑特征维度<script type="math/tex">n</script>及样本规模<script type="math/tex">m</script>普遍使用的准则：</p>
<p>(1)如果相较于 <script type="math/tex">m</script> 而言，<script type="math/tex">n</script> 要大许多，即训练集数据量不够支持训练一个复杂的非线性模型，就选用<strong>逻辑回归</strong>模型或者<strong>不带核函数</strong>的支持向量机。</p>
<p>(2)如果 <script type="math/tex">n</script> 较小，<script type="math/tex">m</script> 大小中等，例如 <script type="math/tex">n</script> 在 <script type="math/tex">1-1000</script> 之间，而 <script type="math/tex">m</script> 在 <script type="math/tex">10-10000</script> 之间，使用<strong>高斯核函数</strong>的支持向量机</p>
<p>(3)如果 <script type="math/tex">n</script> 较小，而 <script type="math/tex">m</script> 较大，例如 <script type="math/tex">n</script> 在 <script type="math/tex">1-1000</script> 之间，而 <script type="math/tex">m</script> 大于 <script type="math/tex">50000</script>，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征（比如通过多项式扩展），然后使用<strong>逻辑回归</strong>或<strong>不带核函数</strong>的支持向量机</p>
<p>神经网络对于上述情形都有不错的适应性，但是计算性能上较慢</p>

          
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/05/斯坦福机器学习笔记-Week-9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/05/斯坦福机器学习笔记-Week-9/" itemprop="url">斯坦福机器学习笔记(Week 9)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-04T21:20:00Z">
                2019-03-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-04T05:28:14Z">
                2019-03-04
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/05/斯坦福机器学习笔记-Week-9/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/05/斯坦福机器学习笔记-Week-9/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/05/斯坦福机器学习笔记-Week-9/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week 9)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  19
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          
            <h2 id="十三、异常检测-Anomaly-Detection"><a href="#十三、异常检测-Anomaly-Detection" class="headerlink" title="十三、异常检测(Anomaly Detection)"></a>十三、异常检测(Anomaly Detection)</h2><h3 id="13-1-问题的动机"><a href="#13-1-问题的动机" class="headerlink" title="13.1 问题的动机"></a>13.1 问题的动机</h3><p><strong>异常检测</strong>是机器学习算法的一个常见应用。这种算法的一个有趣之处在于：它虽然主要用于非监督学习问题，但从某些角度看，它又类似于一些监督学习问题</p>
<h4 id="飞机引擎-QA-质量控制测试"><a href="#飞机引擎-QA-质量控制测试" class="headerlink" title="飞机引擎 QA(质量控制测试)"></a>飞机引擎 QA(质量控制测试)</h4><p>飞机引擎的一些特征变量作为这个测试的一部分，比如引擎运转时产生的热量，或者引擎的振动等等</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/141import.png" alt></p>
<p>数据集绘制成图表：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/121311212import.png" alt></p>
<blockquote>
<p>每个点、每个叉，都是无标签数据</p>
</blockquote>
<p>异常检测问题可以定义如下：有一个新的飞机引擎从生产线上流出，新飞机引擎有特征变量<script type="math/tex">x_ {test}</script> 。</p>
<p>异常检测问题就是：知道这个新的飞机引擎是否有某种异常，判断这个引擎是否需要进一步测试</p>
<p>假使数据集是正常的，希望知道新的数据<script type="math/tex">x _{test}</script>是不是异常的，即这个测试数据不属于该组数据的几率如何。</p>
<p>构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性<script type="math/tex">p(x)</script></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/142import.png" alt></p>
<blockquote>
<p>蓝圈内的数据属于该组数据的可能性较高，越是偏远的数据，属于该组数据的可能性就越低</p>
</blockquote>
<p>这种方法称为<strong>密度估计</strong>，表达如下：</p>
<script type="math/tex; mode=display">
x=
\begin{cases} \text{异常样本}, \text{if } p(x)< \epsilon \\
\text{正常样本}, \text{otherwise}
\end{cases}</script><h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><h5 id="识别欺骗"><a href="#识别欺骗" class="headerlink" title="识别欺骗"></a>识别欺骗</h5><p>例如在线采集而来的有关用户的数据，一个特征向量中可能会包含如：用户多久登录一次，访问过的页面，在论坛发布的帖子数量，甚至是打字速度等。尝试根据这些特征构建一个模型，可以用这个模型来识别那些不符合该模式的用户</p>
<h5 id="检测一个数据中心"><a href="#检测一个数据中心" class="headerlink" title="检测一个数据中心"></a>检测一个数据中心</h5><p>特征可能包含：内存使用情况，被访问的磁盘数量，CPU 的负载，网络的通信量等。根据这些特征可以构建一个模型，用来判断某些计算机是不是有可能出错</p>
<h3 id="13-2-高斯分布"><a href="#13-2-高斯分布" class="headerlink" title="13.2 高斯分布"></a>13.2 高斯分布</h3><p>变量<script type="math/tex">x</script> 符合高斯分布<script type="math/tex">X \sim N(\mu,\sigma^2)</script>则其概率密度函数为：</p>
<script type="math/tex; mode=display">
p(x; \mu, \sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}</script><p><img src="https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E6%A8%A1%E5%9E%8B.png" alt></p>
<script type="math/tex; mode=display">
\begin{aligned}
\mu_j &= \frac{1}{m}\sum\limits_{i=1}^mx_j^{(i)} \\
\sigma^2_j &= \frac{1}{m}\sum\limits_{i=1}^m(x_j^{(i)}-\mu_j)^2
\end{aligned}</script><p>高斯分布样例：</p>
<p><img src="https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E5%8F%96%E5%80%BC.png" alt></p>
<h3 id="13-3-算法"><a href="#13-3-算法" class="headerlink" title="13.3 算法"></a>13.3 算法</h3><p>异常检测算法：</p>
<ol>
<li>对于给定的数据集<script type="math/tex">{x^{(1)},x^{(2)},\cdots,x^{(m)}}, x \in R^n</script>,针对每一个特征计算<script type="math/tex">\mu</script>和<script type="math/tex">\sigma^2</script>的估计值:</li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned}
\mu_j &= \frac{1}{m}\sum\limits_{i=1}^mx_j^{(i)} \\
\sigma^2_j &= \frac{1}{m}\sum\limits_{i=1}^m(x_j^{(i)}-\mu_j)^2
\end{aligned}</script><ol>
<li>根据模型计算<script type="math/tex">p(x)</script>:</li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned}
p(x) &= p(x_1;\mu_1, \sigma^2_1)p(x_2;\mu_2, \sigma^2_2) \cdots p(x_n;\mu_n, \sigma^2_n) \\
&= \prod\limits_{j=1}^np(x_j;\mu_j,\sigma_j^2) \\
&= \prod\limits_{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})
\end{aligned}</script><ol>
<li>当<script type="math/tex">p(x)<\epsilon</script>时，为异常</li>
</ol>
<p>下图是一个由两个特征的训练集，以及特征的分布情况：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/454432import.png" alt></p>
<p>下面的三维图表表示的是密度估计函数，<script type="math/tex">z</script> 轴为根据两个特征的值所估计<script type="math/tex">p(x)</script>值：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1323import.png" alt></p>
<p>选择一个<script type="math/tex">\epsilon</script>，将<script type="math/tex">p(x)=\epsilon</script>作为判定边界，当<script type="math/tex">p(x)>\epsilon</script>时预测数据为正常数据，否则则为异常</p>
<h3 id="13-4-开发和评价一个异常检测系统"><a href="#13-4-开发和评价一个异常检测系统" class="headerlink" title="13.4 开发和评价一个异常检测系统"></a>13.4 开发和评价一个异常检测系统</h3><p>当开发一个异常检测系统时，从带标记（异常或正常）的数据着手，选择一部分正常数据用于构建<strong>训练集</strong>，用剩下的正常数据和异常数据混合的数据构成<strong>交叉检验集</strong>和<strong>测试集</strong></p>
<p>例如：有 10000 台正常引擎的数据，有 20 台异常引擎的数据。 分配如下：</p>
<ul>
<li><p>6000 台正常引擎的数据作为训练集</p>
</li>
<li><p>2000 台正常引擎和 10 台异常引擎的数据作为交叉检验集</p>
</li>
<li><p>2000 台正常引擎和 10 台异常引擎的数据作为测试集</p>
</li>
</ul>
<p>由于异常样本是非常少的，所以整个数据集是非常<strong>偏斜</strong>的，不能单纯的用预测准确率来评估算法优劣</p>
<p>具体的评价方法如下：</p>
<ol>
<li>根据测试集数据，估计特征的平均值和方差并构建<script type="math/tex">p( x )</script>函数</li>
<li>对交叉检验集，尝试使用不同的<script type="math/tex">\epsilon</script>值作为阀值，并预测数据是否异常，根据<script type="math/tex">F1</script>值或者查准率与召回率的比例来选择<script type="math/tex">\epsilon</script></li>
<li>选出<script type="math/tex">\epsilon</script>后，针对测试集进行预测，计算异常检验系统的<script type="math/tex">F1</script>值，或者查准率与召回率之比</li>
</ol>
<h3 id="13-5-异常检测与监督学习对比"><a href="#13-5-异常检测与监督学习对比" class="headerlink" title="13.5 异常检测与监督学习对比"></a>13.5 异常检测与监督学习对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><strong>有监督学习</strong></th>
<th style="text-align:center"><strong>异常检测</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">数据分布均匀</td>
<td style="text-align:center">数据非常偏斜，异常样本数目远小于正常样本数目</td>
</tr>
<tr>
<td style="text-align:center">可以根据对正样本的拟合来知道正样本的形态，从而预测新来的样本是否是正样本</td>
<td style="text-align:center">异常的类型不一，很难根据对现有的异常样本（即正样本）的拟合来判断出异常样本的形态，未来遇到的异常可能与已掌握的异常非常的不同</td>
</tr>
</tbody>
</table>
</div>
<p>应用场景：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><strong>有监督学习</strong></th>
<th style="text-align:center"><strong>异常检测</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">垃圾邮件检测</td>
<td style="text-align:center">故障检测</td>
</tr>
<tr>
<td style="text-align:center">天气预测（预测雨天、晴天、或是多云天气）</td>
<td style="text-align:center">某数据中心对于机器设备的监控</td>
</tr>
<tr>
<td style="text-align:center">癌症的分类</td>
<td style="text-align:center">制造业判断一个零部件是否异常</td>
</tr>
<tr>
<td style="text-align:center">……</td>
<td style="text-align:center">……</td>
</tr>
</tbody>
</table>
</div>
<h3 id="13-6-选择特征"><a href="#13-6-选择特征" class="headerlink" title="13.6 选择特征"></a>13.6 选择特征</h3><p>如果数据的分布不是高斯分布，异常检测算法也能够工作，但是最好还是将数据转换成高斯分布，例如使用对数函数：<script type="math/tex">x = log(x+c)</script>，其中 <script type="math/tex">c</script>为非负常数； 或者<script type="math/tex">x = x^c</script>， <script type="math/tex">c</script> 为 <script type="math/tex">0-1</script> 之间的一个分数</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/143import.png" alt></p>
<p>误差分析：</p>
<p>一个常见的问题是一些异常的数据可能也会有较高的<script type="math/tex">p(x)</script>值，因而被算法认为是正常的。这种情况下误差分析能够分析那些被算法错误预测为正常的数据，观察能否找出一些问题。可能能从问题中发现需要增加一些新的特征，增加这些新特征后获得的新算法能够更好地进行异常检测</p>
<p>异常检测误差分析：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/144import.png" alt></p>
<p>通常可以通过将一些相关的特征进行组合，来获得一些新的更好的特征（异常数据的该特征值异常地大或小）</p>
<p>在检测数据中心的计算机状况的例子中，用 CPU负载与网络通信量的比例作为一个新的特征，如果该值异常地大，便有可能意味着该服务器是陷入了一些问题中</p>
<h3 id="13-7-多元高斯分布"><a href="#13-7-多元高斯分布" class="headerlink" title="13.7 多元高斯分布"></a>13.7 多元高斯分布</h3><h4 id="服务器运转监控的问题"><a href="#服务器运转监控的问题" class="headerlink" title="服务器运转监控的问题"></a>服务器运转监控的问题</h4><p>假使有两个相关的特征，而且这两个特征的值域范围比较宽，这种情况下，一般的高斯分布模型可能不能很好地识别异常数据。其原因在于，一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。</p>
<p>下图中是两个相关特征，洋红色的线（根据 <script type="math/tex">\varepsilon</script> 的不同其范围可大可小）是一般的高斯分布模型获得的判定边界，很明显绿色的 x 所代表的数据点很可能是异常值，但是其<script type="math/tex">p (x )</script>值却仍然在正常范围内。多元高斯分布将创建像图中蓝色曲线所示的判定边界：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/422import.png" alt></p>
<p>在一般的高斯分布模型中，计算<script type="math/tex">p (x )</script>的方法是： 通过分别计算每个特征对应的几率然后将其累乘起来，在多元高斯分布模型中，将构建特征的协方差矩阵，用所有的特征一起来计算<script type="math/tex">p (x )</script></p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>多元高斯分布模型被定义为：</p>
<script type="math/tex; mode=display">
p(x;\mu,\Sigma)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^\frac{1}{2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))</script><p>$\mu$表示<strong>样本均值</strong>，<script type="math/tex">\Sigma</script>表示<strong>样本协方差矩阵</strong></p>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><ul>
<li>改变<script type="math/tex">\Sigma</script><strong>主对角线</strong>的数值可以进行不同方向的宽度拉伸：</li>
</ul>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/121111import.png" alt></p>
<ul>
<li>改变<script type="math/tex">\Sigma</script><strong>次对角线</strong>的数值可以旋转分布图像：</li>
</ul>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1111import.png" alt></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/3232import.png" alt></p>
<ul>
<li>改变<script type="math/tex">\mu</script>可以对分布图像进行位移：</li>
</ul>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/3312wimport.png" alt></p>
<h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><p><strong>多元高斯分布</strong>的异常检测算法流程如下：</p>
<ol>
<li><p>选择一些足够反映异常样本的特征<script type="math/tex">x_j</script></p>
</li>
<li><p>对各个<strong>样本</strong>进行参数估计：</p>
</li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned}
\mu &= \frac{1}{m}\sum\limits_{i=1}^mx^{(i)} \\
\Sigma &= \frac{1}{m}\sum\limits_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T=\frac{1}{m}(X-\mu)(X-\mu)^T
\end{aligned}</script><ol>
<li>当新的样本<script type="math/tex">x</script>到来时，计算<script type="math/tex">p(x)</script>：</li>
</ol>
<script type="math/tex; mode=display">
p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^\frac{1}{2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))</script><ol>
<li>如果<script type="math/tex">p(x)< \varepsilon</script>，则认为样本<script type="math/tex">x</script>是异常样本</li>
</ol>
<h4 id="多元高斯分布模型与一般高斯分布模型的差异"><a href="#多元高斯分布模型与一般高斯分布模型的差异" class="headerlink" title="多元高斯分布模型与一般高斯分布模型的差异"></a>多元高斯分布模型与一般高斯分布模型的差异</h4><p>一般的高斯分布模型只是多元高斯分布模型的一个<strong>约束</strong>，它将多元高斯分布的等高线约束到了如下所示同轴分布（概率密度的等高线是沿着轴向的）：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/2322234import.png" alt></p>
<p>一般高斯模型：</p>
<ul>
<li>需要手动创建一些特征来描述某些特征的相关性</li>
<li>计算复杂度低，适用于高维特征</li>
<li><p>在样本数目 m 较小时也工作良好</p>
</li>
<li><script type="math/tex; mode=display">\begin{aligned}
p(x) &= p(x_1;\mu_1, \sigma^2_1)p(x_2;\mu_2, \sigma^2_2) \cdots p(x_n;\mu_n, \sigma^2_n)\\&= \prod\limits_{j=1}^np(xj;\mu_j,\sigma_j^2) \\&= \prod\limits_{j=1}^n\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})\end{aligned}</script></li>
</ul>
<p>多元高斯模型：</p>
<ul>
<li>利用协方差矩阵<script type="math/tex">\Sigma</script> 获得了各个特征相关性</li>
<li>计算复杂</li>
<li>需要<script type="math/tex">\Sigma</script>可逆，亦即需要 <script type="math/tex">m>n</script> ，通常需要<script type="math/tex">m>10n</script>且各个特征不能线性相关，如不能存在 <script type="math/tex">x_2=3x_1</script> 或者<script type="math/tex">x_3=x_1+2x_2</script></li>
<li><script type="math/tex; mode=display">p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}\Sigma^\frac{1}{2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))</script></li>
</ul>
<h2 id="十四、推荐系统-Recommender-Systems"><a href="#十四、推荐系统-Recommender-Systems" class="headerlink" title="十四、推荐系统( Recommender Systems)"></a>十四、推荐系统( Recommender Systems)</h2><h3 id="14-1-问题形式化"><a href="#14-1-问题形式化" class="headerlink" title="14.1 问题形式化"></a>14.1 问题形式化</h3><p>对机器学习来说，特征是很重要的，选择的特征，将对学习算法的性能有很大的影响</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/145import.png" alt></p>
<p>标记：</p>
<ul>
<li><p><script type="math/tex">n_u</script>代表用户的数量</p>
</li>
<li><p><script type="math/tex">n_m</script>代表电影的数量</p>
</li>
<li><p>$r(i,j)$如果用户<script type="math/tex">j</script>给电影评过分则<script type="math/tex">r(i,j)=1</script></p>
</li>
<li><p><script type="math/tex">y^{(i,j)}</script>代表用户<script type="math/tex">j</script>给电影<script type="math/tex">i</script>的评分</p>
</li>
<li><p><script type="math/tex">m^{(j)}</script>代表用户<script type="math/tex">j</script>评过分的电影的总数</p>
</li>
</ul>
<h3 id="14-2-基于内容的推荐系统"><a href="#14-2-基于内容的推荐系统" class="headerlink" title="14.2 基于内容的推荐系统"></a>14.2 基于内容的推荐系统</h3><p>假设每部电影都有两个特征，如<script type="math/tex">x _1</script>代表电影的浪漫程度，<script type="math/tex">x_ 2</script>代表电影的动作程度</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/146import.png" alt></p>
<blockquote>
<p>则每部电影都有一个特征向量，如<script type="math/tex">x ^{(1)}</script>是第一部电影的特征向量为[0.9 0]</p>
</blockquote>
<h4 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h4><ul>
<li><p><script type="math/tex">\theta^{(j)}</script>用户<script type="math/tex">j</script>的参数向量</p>
</li>
<li><p><script type="math/tex">x ^{(i)}</script>电影<script type="math/tex">i</script>的特征向量</p>
</li>
<li><p>对于用户<script type="math/tex">j</script>和电影<script type="math/tex">i</script>，预测评分为：<script type="math/tex">y^{(i,j)}=(\theta^{(j)})^Tx^{(i)}</script></p>
</li>
</ul>
<p>针对用户<script type="math/tex">j</script>，该线性回归模型的代价为预测误差的平方和，加上正则化项：</p>
<script type="math/tex; mode=display">
\min_{\theta^{(j)}} = \frac{1}{2} \sum_{i:r(i,j)=1} \left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2
+ \frac{\lambda}{2} \sum_{k=1}^n (\theta_k^{(j)})^2</script><p>$i:r(i,j)=1$表示只计算那些用户<script type="math/tex">j</script>评过分的电影</p>
<p>在一般的线性回归模型中，误差项和正则项应该都是乘以<script type="math/tex">\frac{1}{2m}</script>，在这里将<script type="math/tex">m</script>去掉,并且不对<script type="math/tex">\theta^{(j)}_0</script>进行正则化处理</p>
<p>对于所有用户<script type="math/tex">1, 2, ... , n_u</script>，代价函数<script type="math/tex">J(\theta^{(1)}, \theta^{(2)}, ..., \theta^{(n_u)})</script>：</p>
<script type="math/tex; mode=display">
J(\theta^{(1)}, \theta^{(2)}, ..., \theta^{(n_u)})=\min_{\theta^{(1)}, \theta^{(2)}, ..., \theta^{(n_u)}} = \frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} \left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2
+ \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2</script><h4 id="参数更新"><a href="#参数更新" class="headerlink" title="参数更新"></a>参数更新</h4><p>使用梯度下降法来更新参数：</p>
<script type="math/tex; mode=display">
\begin{aligned}
& \text{更新偏置(插值):} \\
& \quad \theta_0^{(j)} = \theta_0^{(j)} - \alpha\sum_{i:r(i,j)=1}\big((\theta^{(j)})^T x^{(i)} - y^{(i,j)}\big) x_0^{(i)} \\
& \text{更新权重:} \\
& \quad \theta_k^{(j)} = \theta_k^{(j)} - \alpha\left(\sum_{i:r(i,j)=1}\big((\theta^{(j)})^T x^{(i)} - y^{(i,j)}\big) x_k^{(i)} + \lambda\theta_k^{(j)}\right), \quad k \neq 0
\end{aligned}</script><h3 id="14-3-协同过滤"><a href="#14-3-协同过滤" class="headerlink" title="14.3 协同过滤"></a>14.3 协同过滤</h3><p>在现实中，不会有任何网站，任何人有精力，有能力去评估每部电影所具有的一些指数。因此，基于内容的推荐系统从构架初期，可能就会遭遇非常大的阻力</p>
<p>假定先有了各个用户对电影的偏爱评估<script type="math/tex">\theta</script>:</p>
<script type="math/tex; mode=display">
\theta^{(1)} = \begin{pmatrix} 0 \\ 5 \\ 0 \end{pmatrix},
\theta^{(2)} = \begin{pmatrix} 0 \\ 5 \\ 0 \end{pmatrix},
\theta^{(3)} = \begin{pmatrix} 0 \\ 0 \\ 5 \end{pmatrix},
\theta^{(4)} = \begin{pmatrix} 0 \\ 5 \\ 0 \end{pmatrix}</script><p>并且，不知道电影的指数：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Movie/User</th>
<th style="text-align:center">Alice(1)</th>
<th style="text-align:center">Bob(2)</th>
<th style="text-align:center">Carol(3)</th>
<th style="text-align:center">Dave(4)</th>
<th style="text-align:center"><script type="math/tex">x_1</script></th>
<th style="text-align:center"><script type="math/tex">x_2</script></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Love at last</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Romance for ever</td>
<td style="text-align:center">5</td>
<td style="text-align:center">4</td>
<td style="text-align:center">?</td>
<td style="text-align:center">0</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Cute puppies of love</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
<td style="text-align:center">0</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Nonstop car chases</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
<td style="text-align:center">4</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Swords vs. karate</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
</tr>
</tbody>
</table>
</div>
<h4 id="目标优化"><a href="#目标优化" class="headerlink" title="目标优化"></a>目标优化</h4><p>通过<script type="math/tex">\theta^{(1)}, ..., \theta^{(n_u)}</script>来学习<script type="math/tex">x^{(i)}</script>：</p>
<script type="math/tex; mode=display">
\min_{x^{(i)}} = \frac{1}{2} \sum_{j:r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
+ \frac{\lambda}{2} \sum_{k=1}^n (x_k^{(i)})^2</script><p>对于所有的电影指数<script type="math/tex">x^{(1)},...,x^{(n_m)}</script>：</p>
<script type="math/tex; mode=display">
\min_{x^{(1)},...,x^{(i)},...,x^{(n_m)}} = \frac{1}{2} \sum_{i=1}^{n_m} \sum_{j:r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
+ \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2</script><h4 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h4><p>现在，拥有了评价用户的<script type="math/tex">\theta</script>和评价商品的<script type="math/tex">x</script>，并且：</p>
<ul>
<li>给定<script type="math/tex">\theta</script>及用户对商品的评价，能估计<script type="math/tex">x</script></li>
<li>给定<script type="math/tex">x</script>，又能估计<script type="math/tex">\theta</script></li>
</ul>
<p>因此，就构成了<script type="math/tex">\theta</script>−&gt;<script type="math/tex">x</script>−&gt;<script type="math/tex">\theta</script>−&gt;<script type="math/tex">x...</script>的优化序列，这便构成了协同过滤算法，即同时优化商品和用户具有的参数</p>
<h4 id="协同过滤的目标优化"><a href="#协同过滤的目标优化" class="headerlink" title="协同过滤的目标优化"></a>协同过滤的目标优化</h4><p>1.推测用户喜好：给定<script type="math/tex">x^{(1)},...,x^{(n_m)}</script>，估计<script type="math/tex">\theta^{(1)},...,\theta^{(n_u)}</script>：</p>
<script type="math/tex; mode=display">
\min_{\theta^{(1)}, ..., \theta^{(n_u)}} = \frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} \left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2
+ \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2</script><p>2.推测商品内容：给定<script type="math/tex">\theta^{(1)},...,\theta^{(n_u)}</script>，估计<script type="math/tex">x^{(1)},...,x^{(n_m)}</script>：</p>
<script type="math/tex; mode=display">
\min_{x^{(i)},...,x^{(n_m)}} = \frac{1}{2} \sum_{i=1}^{n_m} \sum_{j:r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
+ \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2</script><p>3.协同过滤：同时优化<script type="math/tex">x^{(1)},...,x^{(n_m)}</script>及<script type="math/tex">\theta^{(1)},...,\theta^{(n_u)}</script>：</p>
<script type="math/tex; mode=display">
\min J(x^{(1)},....x^{(i)},...,x^{(n_m)} ; \theta^{(1)},....\theta^{(j)} ..., \theta^{(n_u)})</script><p>亦即：</p>
<script type="math/tex; mode=display">
\min_{x^{(1)},....x^{(i)},...,x^{(n_m)} ; \theta^{(1)},....,\theta^{(j)}, ..., \theta^{(n_u)}}
\frac{1}{2} \sum_{(i,j):r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
+ \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2
+ \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2</script><p>$\sum_{(i,j):r(i,j)=1}$反映了用户和商品所有有效配对</p>
<h4 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h4><p>使用了协同过滤的推荐算法流程为：</p>
<ol>
<li>随机初始化<script type="math/tex">x^{(1)},...,x^{(n_m)}</script>,<script type="math/tex">\theta^{(1)},...,\theta^{(n_u)}</script>为一些较小值</li>
<li>使用梯度下降法来最小化<script type="math/tex">J(x^{(1)},....x^{(i)},...,x^{(n_m)} ; \theta^{(1)},....\theta^{(j)} ..., \theta^{(n_u)})</script>，<script type="math/tex">j=1,2,..,n_u</script>，<script type="math/tex">i=1,2,...,n_m</script>，参数的更新式为：</li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned}
& x_k^{(i)} = x_k^{(i)} - \alpha \left( \sum_{j:r(i,j)=1}\big((\theta^{(j)})^T x^{(i)} - y^{(i,j)}\big) \theta_k^{(j)} + \lambda x_k^{(i)}\right) \\

& \theta_k^{(j)} = \theta_k^{(j)} - \alpha\left(\sum_{i:r(i,j)=1}\big((\theta^{(j)})^T x^{(i)} - y^{(i,j)}\big) x_k^{(i)} + \lambda\theta_k^{(j)} \right)
\end{aligned}</script><p>如果用户的偏好向量为<script type="math/tex">\theta</script>，而商品的特征向量为<script type="math/tex">x</script>,则可以预测用户评价为<script type="math/tex">\theta^Tx</script></p>
<p>因为协同过滤算法<script type="math/tex">\theta</script>和<script type="math/tex">x</script>相互影响，因此，二者都没必要使用偏置<script type="math/tex">\theta_\theta</script>和<script type="math/tex">x _0</script>，即，<script type="math/tex">x \in R^n</script>,<script type="math/tex">\theta \in R^n</script></p>
<h4 id="获得类似电影"><a href="#获得类似电影" class="headerlink" title="获得类似电影"></a>获得类似电影</h4><p>当获得了电影<script type="math/tex">i</script>的特征向量后，就可以通过计算<script type="math/tex">||x^{(j)}</script>—<script type="math/tex">x^{(i)}||</script>来比较电影<script type="math/tex">j</script>与电影<script type="math/tex">i</script>的相似度。那么，给予了电影<script type="math/tex">j</script>足够好评的用户，也会被推荐到类似的电影</p>
<h3 id="14-4-向量化：低秩矩阵分解"><a href="#14-4-向量化：低秩矩阵分解" class="headerlink" title="14.4 向量化：低秩矩阵分解"></a>14.4 向量化：低秩矩阵分解</h3><p>将用户对电影的评分表格：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Movie/User</th>
<th style="text-align:center">Alice(1)</th>
<th style="text-align:center">Bob(2)</th>
<th style="text-align:center">Carol(3)</th>
<th style="text-align:center">Dave(4)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Love at last</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">Romance for ever</td>
<td style="text-align:center">5</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">Cute puppies of love</td>
<td style="text-align:center">?</td>
<td style="text-align:center">4</td>
<td style="text-align:center">0</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Nonstop car chases</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">Swords vs. karate</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
<td style="text-align:center">?</td>
</tr>
</tbody>
</table>
</div>
<p>用矩阵表示：</p>
<script type="math/tex; mode=display">
Y =
\begin{bmatrix}
5 & 5 & 0 & 0 \\
5 & ? & ? & 0 \\
? & 4 & 0 & ? \\
0 & 0 & 5 & 4 \\
0 & 0 & 5 & 0
\end{bmatrix}</script><p>用预测来描述这个矩阵：</p>
<script type="math/tex; mode=display">
Predicated =
\begin{bmatrix}
(\theta^{(1)})^T x^{(1)} & (\theta^{(2)})^T x^{(1)} & \cdots & (\theta^{(n_u)})^T x^{(1)} \\
(\theta^{(1)})^T x^{(2)} & (\theta^{(2)})^T x^{(2)} & \cdots & (\theta^{(n_u)})^T x^{(2)} \\
\vdots & \vdots & \vdots & \vdots \\
(\theta^{(1)})^T x^{(n_m)} & (\theta^{(2)})^T x^{(n_m)} & \cdots & (\theta^{(n_u)})^T x^{(n_m)}
\end{bmatrix}</script><p>令：</p>
<script type="math/tex; mode=display">
X =
\begin{bmatrix}
(x^{(1)})^T \\
(x^{(2)})^T \\
\vdots \\
(x^{(n_m)})^T
\end{bmatrix},

\Theta =
\begin{bmatrix}
(\theta^{(1)})^T \\
(\theta^{(2)})^T \\
\vdots \\
(\theta^{(n_u)})^T
\end{bmatrix}</script><p>即<script type="math/tex">X</script>的每一行描述了一部电影的内容，<script type="math/tex">\theta^T</script>的每一列描述了用户对于电影内容偏好程度，亦即，将原来稀疏的矩阵分解为了<script type="math/tex">X</script>和<script type="math/tex">\theta</script>。现在预测可以写为：</p>
<script type="math/tex; mode=display">
Predicated = X \Theta^T</script><p>用这个方法求取<script type="math/tex">X</script>和<script type="math/tex">\theta</script>，获得推荐系统需要的参数，称之为<strong>低秩矩阵分解</strong>，该方法不仅能在编程时直接通过向量化的手法获得参数，还通过矩阵分解节省了内存空间</p>
<h3 id="14-5-推行工作上的细节：均值归一化"><a href="#14-5-推行工作上的细节：均值归一化" class="headerlink" title="14.5 推行工作上的细节：均值归一化"></a>14.5 推行工作上的细节：均值归一化</h3><p>假定现在新注册了一个用户<script type="math/tex">Eve(5)</script>，他还没有对任何电影作出评价：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Movie/User</th>
<th style="text-align:center">Alice(1)</th>
<th style="text-align:center">Bob(2)</th>
<th style="text-align:center">Carol(3)</th>
<th style="text-align:center">Dave(4)</th>
<th style="text-align:center">Eve(5)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Love at last</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Romance for ever</td>
<td style="text-align:center">5</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
<td style="text-align:center">0</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Cute puppies of love</td>
<td style="text-align:center">?</td>
<td style="text-align:center">4</td>
<td style="text-align:center">0</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Nonstop car chases</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
<td style="text-align:center">4</td>
<td style="text-align:center">?</td>
</tr>
<tr>
<td style="text-align:center">Swords vs. karate</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
</tr>
</tbody>
</table>
</div>
<p>为 Eve 推荐电影：</p>
<ol>
<li>先求取各个电影的平均得分<script type="math/tex">\mu</script>：</li>
</ol>
<script type="math/tex; mode=display">
\mu =
\begin{pmatrix}
2.5 \\
2.5 \\
2 \\
2.25 \\
1.25
\end{pmatrix}</script><ol>
<li>并求取<script type="math/tex">Y</script>−<script type="math/tex">\mu</script>，对<script type="math/tex">Y</script>进行均值标准化：</li>
</ol>
<script type="math/tex; mode=display">
Y - \mu =
\begin{bmatrix}
2.5 & 2.5 & -2.5 & -2.5 & ? \\
2.5 & ? & ? & -2.5 & ? \\
? & -2 & -2 & ? & ? \\
-2.25 & -2.25 & 2.75 & 1.75 & ? \\
-1.25 & -1.25 & 3.75 & -1.25 & ?
\end{bmatrix}</script><p>对于用户<script type="math/tex">j</script>，他对电影<script type="math/tex">i</script>的评分就为：</p>
<script type="math/tex; mode=display">
y^{(i, j)} = (\theta^{(i)})^T x^{(j)} + \mu_i</script><p>Eve 对电影的评分就为：</p>
<script type="math/tex; mode=display">
y^{(i, 5)} = (\theta^{(5)})^T x^{(i)} + \mu_i = \mu_i</script><p>即，系统在用户未给出评价时，默认该用户对电影的评价与其他用户的平均评价一致。貌似利用均值标准化让用户的初始评价预测客观了些，但这也是盲目的，不准确的。实际环境中，如果一个电影确实没被评价过，那么它没有任何理由被推荐给用户</p>

          
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/05/斯坦福机器学习笔记-Week-10/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/05/斯坦福机器学习笔记-Week-10/" itemprop="url">斯坦福机器学习笔记(Week 10)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-04T21:20:00Z">
                2019-03-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-04T05:35:03Z">
                2019-03-04
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/05/斯坦福机器学习笔记-Week-10/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/05/斯坦福机器学习笔记-Week-10/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/05/斯坦福机器学习笔记-Week-10/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week 10)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          
            <h2 id="十五、大规模机器学习-Large-Scale-Machine-Learning"><a href="#十五、大规模机器学习-Large-Scale-Machine-Learning" class="headerlink" title="十五、大规模机器学习(Large Scale Machine Learning)"></a>十五、大规模机器学习(Large Scale Machine Learning)</h2><h3 id="15-1-大型数据集的学习"><a href="#15-1-大型数据集的学习" class="headerlink" title="15.1 大型数据集的学习"></a>15.1 大型数据集的学习</h3><p>如果有一个低方差的模型，增加数据集的规模可以获得更好的结果</p>
<h4 id="应该怎样应对一个有-100-万条记录的训练集？"><a href="#应该怎样应对一个有-100-万条记录的训练集？" class="headerlink" title="应该怎样应对一个有 100 万条记录的训练集？"></a>应该怎样应对一个有 100 万条记录的训练集？</h4><p>首先应该做的事是去检查一个这么大规模的训练集是否真的必要，也许只用 1000个训练集也能获得较好的效果，可以绘制学习曲线</p>
<p>来帮助判断：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/147import.png" alt></p>
<h3 id="15-2-随机梯度下降法"><a href="#15-2-随机梯度下降法" class="headerlink" title="15.2 随机梯度下降法"></a>15.2 随机梯度下降法</h3><h4 id="批量梯度下降法（Batch-gradient-descent）"><a href="#批量梯度下降法（Batch-gradient-descent）" class="headerlink" title="批量梯度下降法（Batch gradient descent）"></a>批量梯度下降法（Batch gradient descent）</h4><script type="math/tex; mode=display">
\begin{aligned}
&\text{重复直到收敛:} \\
& \quad \theta_j = \theta_j - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)},
\quad for\quad j=0,\cdots ,n
\end{aligned}</script><p>每更新一个参数<script type="math/tex">\theta_j</script>都遍历一遍样本集，在<script type="math/tex">m</script>很大时，该算法就显得比较低效。但是，批量梯度下降法能找到全局最优解：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/321`import.png" alt></p>
<h4 id="随机梯度下降法（Stochastic-gradient-descent）"><a href="#随机梯度下降法（Stochastic-gradient-descent）" class="headerlink" title="随机梯度下降法（Stochastic gradient descent）"></a>随机梯度下降法（Stochastic gradient descent）</h4><p>针对大数据集，引入了随机梯度下降法，该算法的执行过程为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\text{重复直到收敛:} \\
& \quad for\quad i=1,\cdots,m: \\
& \quad \quad \theta_j = \theta_j - \alpha(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)},
\quad for\quad j=1,\cdots,,n
\end{aligned}</script><p>相较于批量梯度下降法，随机梯度下降法每次更新<script type="math/tex">\theta_j</script>只会用当前遍历的样本。虽然外层循环仍需要遍历所有样本，但是，往往在样本尚未遍历完时就已经收敛，因此，面临大数据集时，随机梯度下降法性能卓越</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/232323232323import.png" alt></p>
<p>相较于批量梯度下降法，随机梯度下降法的曲线很曲折，倾向于找到局部最优解而不是全局最优解</p>
<h3 id="15-3-小批量梯度下降"><a href="#15-3-小批量梯度下降" class="headerlink" title="15.3 小批量梯度下降"></a>15.3 小批量梯度下降</h3><p>小批量梯度下降算法是介于批量梯度下降算法和随机梯度下降算法之间的算法</p>
<p>每计算<script type="math/tex">b</script>次训练实例，便更新一次参数<script type="math/tex">\theta</script>,假定 <script type="math/tex">b=10,m=1000</script>,小批量梯度下降法的工作过程如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\text{重复直到收敛:} \\
& \quad for\quad i=1,11,21,\cdots,991: \\
& \quad \quad \theta_j = \theta_j - \alpha\frac{1}{10}\sum_{k=i}^{i+9}(h_\theta(x^{(k)})-y^{(k)})x_j^{(k)},
\quad for\quad j=0,...,n
\end{aligned}</script><p>通常令<script type="math/tex">b</script>在<script type="math/tex">2-100</script>之间。好处在于可以用向量化的方式来循环<script type="math/tex">b</script>个训练实例</p>
<h3 id="15-4-随机梯度下降收敛"><a href="#15-4-随机梯度下降收敛" class="headerlink" title="15.4 随机梯度下降收敛"></a>15.4 随机梯度下降收敛</h3><p>通常需要绘制调试曲线来监控随机梯度的工作过程是否正确</p>
<p>在随机梯度下降中，每一次更新<script type="math/tex">\theta</script>之前都计算一次代价，然后每<script type="math/tex">X</script>次迭代后，求出这<script type="math/tex">X</script>次对训练实例计算代价的平均值，然后绘制这些平均值与<script type="math/tex">X</script>次迭代的次数之间的函数图表</p>
<p>假定误差定义为:</p>
<script type="math/tex; mode=display">
cost(\theta, (x^{(i)}, y^{(i)})) = \frac{1}{2}(h_\theta(x^{(i)})-y^{(i)})^2</script><p>则每完成 1000 次迭代，即遍历了 1000 个样本，求取平均误差并进行绘制，得到误差随迭代次数的变化曲线：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1278import.png" alt></p>
<p>遇到下面的曲线并不意味着学习率出了问题，有可能是平均间隔取的太小：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/112232import.png" alt></p>
<p>增加<script type="math/tex">X</script>来使得函数更加平缓，也许便能看出下降的趋势：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/11123import.png" alt></p>
<p>可能函数图表仍然是颠簸不平且不下降的（如洋红色线所示），那么模型本身可能存在一些错误</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/148import.png" alt></p>
<p>如果面临明显上升态势的曲线，就要考虑降低学习率<script type="math/tex">\alpha</script>：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/111111import.png" alt></p>
<p>学习率<script type="math/tex">\alpha</script>可以随着迭代次数进行优化:</p>
<script type="math/tex; mode=display">
\alpha = \frac{constant1} {iterationNumber + constant2}</script><p>随着迭代次数的增多，下降步调就会放缓，避免出现抖动：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/232323import.png" alt></p>
<blockquote>
<p>随机梯度下降法工作前，需要先乱序数据集，使得遍历样本的过程更加分散</p>
</blockquote>
<p>随着不断地靠近全局最小值，通过减小学习率，迫使算法收敛而非在最小值附近徘徊。 但是通常不需要这样做便能有非常好的效果了，对<script type="math/tex">\alpha</script>进行调整所耗费的计算通常不值得</p>
<h3 id="15-5-在线学习"><a href="#15-5-在线学习" class="headerlink" title="15.5 在线学习"></a>15.5 在线学习</h3><p><strong>在线学习算法指的是对数据流而非离线的静态数据集的学习</strong></p>
<p>在线学习的算法与随机梯度下降算法有些类似：对单一的实例进行学习，而非对一个提前定义的训练集进行循环，唯一的区别的是不会使用一个固定的数据集，而是获取一个用户样本，从那个样本中学习，然后丢弃那个样本并继续下去，如果某一种应用有一个连续的数据流，这样的算法可能会非常值得考虑</p>
<script type="math/tex; mode=display">
\begin{aligned}
& \text{Repeat forever (as long as the webside is running) \{ } \\
& \quad \text{获得关于该用户的样本} (x,y),\text{使用该样本更新} \theta: \\
& \quad \quad \theta_j= \theta_j - \alpha(h_\theta(x)-y) x_j , \quad \text{for j=0,...,n}\\\}
\end{aligned}</script><p>一旦对一个数据的学习完成了，便可以丢弃该数据，不需要再存储它了。这种方式的好处在于，算法可以很好适应用户的倾向性，针对用户的当前行为不断地更新模型以适应该用户</p>
<p>优点：如果有一个变化的用户群，又或者尝试预测的事情在缓慢变化，就像用户的品味在缓慢变化，在线学习算法可以慢慢地调试学习到的假设，将其调节更新到最新的用户行为</p>
<h3 id="15-6-映射化简和数据并行"><a href="#15-6-映射化简和数据并行" class="headerlink" title="15.6 映射化简和数据并行"></a>15.6 映射化简和数据并行</h3><p><strong>将数据集分配给多台计算机，让每一台计算机处理数据集的一个子集，然后将计算的结果汇总再求和，这样的方法叫做映射简化</strong></p>
<p>如果任何学习算法能够表达为：对训练集的函数的求和</p>
<p>那么便能将这个任务分配给多台计算机（或者同一台计算机的不同 CPU 核心），以达到加速处理的目的</p>
<p>假定有 <script type="math/tex">400</script> 个训练实例，可以将批量梯度下降的求和任务分配给 <script type="math/tex">4</script>台计算机进行处理：</p>
<ol>
<li>首先通过 <strong>Map （映射）</strong>过程来并行计算式中的求和项，每个机器被分配到 <strong>100</strong>个样本进行计算：</li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned}
temp_j^{(1)} &= \sum_{i=1}^{100}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\
temp_j^{(2)} &= \sum_{i=101}^{200}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\
temp_j^{(3)} &= \sum_{i=201}^{300}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\
temp_j^{(4)} &= \sum_{i=301}^{400}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}
\end{aligned}</script><ol>
<li>通过 <strong>Reduce（规约）</strong>操作进行求和：</li>
</ol>
<script type="math/tex; mode=display">
\theta_j = \theta_j - \alpha\frac{1}{400}(temp_j^{(1)}+temp_j^{(2)}+temp_j^{(3)}+temp_j^{(4)})</script><ul>
<li>使用多台机器进行 <strong>Map Reduce</strong>，此时，<strong>Map</strong> 任务被分配到多个机器完成：</li>
</ul>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/11212import.png" alt></p>
<ul>
<li>使用单机多核心进行 <strong>Map Reduce</strong>，此时，<strong>Map</strong> 任务被分配到多个 <strong>CPU</strong> 核心完成：</li>
</ul>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/564import.png" alt></p>
<h2 id="十六、应用实例：图片-文字识别-Application-Example-Photo-OCR"><a href="#十六、应用实例：图片-文字识别-Application-Example-Photo-OCR" class="headerlink" title="十六、应用实例：图片 文字识别(Application Example: Photo OCR)"></a>十六、应用实例：图片 文字识别(Application Example: Photo OCR)</h2><h3 id="16-1-问题描述和流程图"><a href="#16-1-问题描述和流程图" class="headerlink" title="16.1 问题描述和流程图"></a>16.1 问题描述和流程图</h3><p>图像文字识别应用所作的事是，从一张给定的图片中识别文字</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/2112import.png" alt></p>
<p>为了完成这样的工作，需要采取如下步骤：</p>
<p>1.文本检测：获得包含了文本的文本框</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/112443import.png" alt></p>
<p>2.字符分割：从文本框中分割出各个字符</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/334567import.png" alt></p>
<p>3.字符分类（识别）：字符分割中得到的只是一个个字符图形，在字符分类阶段，才能真正知道该字符类别。</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/234222import.png" alt></p>
<p>可以用任务流程图来表达这个问题，每一项任务可以由一个单独的小队来负责解决：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/contenthttps://baozou.gitbooks.io/-stanford-machine-learning/content/assets/149import.png" alt></p>
<h3 id="16-2-滑动窗口"><a href="#16-2-滑动窗口" class="headerlink" title="16.2 滑动窗口"></a>16.2 滑动窗口</h3><p><strong>滑动窗口是一项用来从图像中抽取对象的技术</strong></p>
<h4 id="文本检测中的滑动窗口"><a href="#文本检测中的滑动窗口" class="headerlink" title="文本检测中的滑动窗口"></a>文本检测中的滑动窗口</h4><p>在<strong>文本检测</strong>阶段，首先定义正、负样本，正样本图像描述了含有文本的图像，负样本描述了不含文本的图像：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/22222import.png" alt></p>
<p>通过在原图像沿行、列滑动定义好的窗口，并让窗口内图像与正负样本进行比较：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/12368import.png" alt></p>
<p>当窗口遍历过整幅图像后，获得原图像对应的掩膜，高亮度的区域都为疑似文本框的区域：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/12`import.png" alt></p>
<p>掩膜中的文本框断断续续的，因此还考虑使用<a href="https://zh.wikipedia.org/wiki/数学形态学#.E8.86.A8.E8.83.80" target="_blank" rel="noopener">形态学膨胀</a>操作来让文本框更加完整：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/12`1import.png" alt></p>
<h4 id="字符分割中的滑动窗口"><a href="#字符分割中的滑动窗口" class="headerlink" title="字符分割中的滑动窗口"></a>字符分割中的滑动窗口</h4><p>在文本检测阶段，滑动窗口是分别沿着行、列进行扫描的，因此是 <script type="math/tex">2</script> 维的扫描过程。而在<strong>字符分割</strong>过程中，同样将使用到滑动窗口技术，只是这次将窗口的高度设置为与文本框等高，只进行 <script type="math/tex">1</script>维的行扫描：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/11`import.png" alt></p>
<p>同样需要定义正负样本，来让窗口知道哪些是字符，哪些包含了字符的分界：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1`import.png" alt></p>
<h3 id="16-3-获取大量数据和人工数据"><a href="#16-3-获取大量数据和人工数据" class="headerlink" title="16.3 获取大量数据和人工数据"></a>16.3 获取大量数据和人工数据</h3><p>如果模型是低方差的，那么获得更多的数据用于训练模型，是能够有更好的效果的</p>
<p>在<strong>字符识别</strong>阶段，为了更好的完成分类识别任务，需要给系统提供尽可能多的训练图像，如果手头上拥有的图像不多，就需要人工合成更多的数据</p>
<h4 id="从零开始创造实例"><a href="#从零开始创造实例" class="headerlink" title="从零开始创造实例"></a>从零开始创造实例</h4><p>例如，收集不同的字体，并为每种字体的每个字符加上随机背景，就可以人工扩展大量的字符图像：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1`1import.png" alt></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/22`import.png" alt></p>
<h4 id="修改已有的数据"><a href="#修改已有的数据" class="headerlink" title="修改已有的数据"></a>修改已有的数据</h4><p>只要实际数据有可能和经过这样处理后的数据类似，便可以用这样的方法来创造大量的数据</p>
<p>通过扭曲字符形状来合成新数据，这也会帮助机器更好地处理发生过形态变化的图像：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1`2import.png" alt></p>
<p>为数据加上随机噪声一般不会提升模型训练质量：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/3`import.png" alt></p>
<p>获得更多数据的几种方法：</p>
<ol>
<li>人工数据合成</li>
<li>手动收集、标记数据</li>
<li>众包</li>
</ol>
<h3 id="16-4-上限分析：接下来要做的工作是什么"><a href="#16-4-上限分析：接下来要做的工作是什么" class="headerlink" title="16.4 上限分析：接下来要做的工作是什么"></a>16.4 上限分析：接下来要做的工作是什么</h3><p>上限分析，就是假定某个组件及其前面组件的精度都达到了 100%，即该组件完美地完成了任务，达到了上限，那么此时整个系统的<strong>精度能提升多少</strong></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/34`import.png" alt></p>
<p>假定整个系统的精度是 72%，令文本检测的精度是 100%（比如人工利用 PS 来定位图片中的文本框），此时，整个系统的精度能提升到 89%。即，如果付出足够多的精力来优化文本检测，那么理想情况下，能将系统的精度提升 17%：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">组件</th>
<th style="text-align:center">流水线精度</th>
<th style="text-align:center">精度提升</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">整个系统</td>
<td style="text-align:center">72%</td>
<td style="text-align:center">—</td>
</tr>
<tr>
<td style="text-align:center">文本检测</td>
<td style="text-align:center">89%</td>
<td style="text-align:center">17%</td>
</tr>
<tr>
<td style="text-align:center">字符分割</td>
<td style="text-align:center">90%</td>
<td style="text-align:center">1%</td>
</tr>
<tr>
<td style="text-align:center">字符识别</td>
<td style="text-align:center">100%</td>
<td style="text-align:center">10%</td>
</tr>
</tbody>
</table>
</div>
<p>可以看出，最值得花费精力的步骤是文本检测，最不值得花费精力的是字符分割，即便完成了 100% 的分割，最多也就对系统提升1%</p>

          
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/05/斯坦福机器学习笔记-Week-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/05/斯坦福机器学习笔记-Week-8/" itemprop="url">斯坦福机器学习笔记(Week 8)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-04T21:05:00Z">
                2019-03-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-04T05:18:58Z">
                2019-03-04
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/05/斯坦福机器学习笔记-Week-8/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/05/斯坦福机器学习笔记-Week-8/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/05/斯坦福机器学习笔记-Week-8/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week 8)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.7k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          
            <h2 id="十一、聚类-Clustering"><a href="#十一、聚类-Clustering" class="headerlink" title="十一、聚类(Clustering)"></a>十一、聚类(Clustering)</h2><h3 id="11-1-无监督学习：简介"><a href="#11-1-无监督学习：简介" class="headerlink" title="11.1 无监督学习：简介"></a>11.1 无监督学习：简介</h3><p>在无监督学习中，需要将一系列无标签的训练数据，输入到一个算法中，让计算机学习无标签数据，找到这个数据的内在结构</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/8381b424-a420-43c0-9b42-7bc62dca3530.png" alt></p>
<p>图上的数据看起来可以分成两个分开的点集（称为簇），一个能够找到圈出的这些点集的算法，就被称为<strong>聚类算法</strong></p>
<p><strong>非监督学习</strong>算法可以找到其他类型的结构或者其他的一些模式，而不只是<strong>簇</strong></p>
<p>一些应用：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/127import.png" alt></p>
<h3 id="11-2-K-均值算法"><a href="#11-2-K-均值算法" class="headerlink" title="11.2 K- 均值算法"></a>11.2 K- 均值算法</h3><h4 id="步骤描述"><a href="#步骤描述" class="headerlink" title="步骤描述"></a>步骤描述</h4><p>K-均值是一个<strong>迭代算法</strong>，假设想要将数据聚类成 <script type="math/tex">n</script> 个组，其方法为:</p>
<ol>
<li>首先选择 <script type="math/tex">k</script> 个随机的点，称为 <strong>聚类中心（cluster centroids）</strong>；</li>
<li>对于数据集中的每一个数据，按照距离 <script type="math/tex">K</script> 个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类</li>
<li>计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置</li>
<li>重复步骤 <script type="math/tex">2-4</script> 直至中心点不再变化</li>
</ol>
<p>聚类示例：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/131import.png" alt></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/132import.png" alt></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/133import.png" alt></p>
<h4 id="伪码描述"><a href="#伪码描述" class="headerlink" title="伪码描述"></a>伪码描述</h4><p>用<script type="math/tex">\mu_1,\mu_2,...,\mu_k \in R^n</script>来表示聚类中心，用<script type="math/tex">c^{(1)},c^{(2)},...,c^{(m)}</script>来存储与第 <script type="math/tex">i</script> 个实例数据最近的聚类中心的索引，K-均值算法的伪代码如下：</p>
<p><strong>分配过程</strong></p>
<p>for <script type="math/tex">i=1</script> to <script type="math/tex">m</script>：</p>
<script type="math/tex; mode=display">
c^{(i)} = \text{距} x^{(i)} \text{最近的聚类中心}</script><p>距离的计算式如下：</p>
<script type="math/tex; mode=display">
\min_k||x^{(i)}-\mu_k||^2</script><p><strong>移动过程</strong>：</p>
<p>for <script type="math/tex">k = 1</script> to <script type="math/tex">K</script>：</p>
<script type="math/tex; mode=display">
\mu_k\text{(第} k \text{个聚类中心的新位置)} = \text{第} k \text{簇的平均位置}</script><p>假设<script type="math/tex">\mu_2</script>聚类中心下分配了4个样本：</p>
<script type="math/tex; mode=display">
x^{(1)},x^{(5)},x^{(6)},x^{(10)}</script><p>亦即：</p>
<script type="math/tex; mode=display">
c^{(1)}=c^{(5)}=c^{(6)}=c^{(10)}=2</script><p>那么<script type="math/tex">\mu_2</script>将会移动到这四个样本的中心位置：</p>
<script type="math/tex; mode=display">
\mu_2=\frac{1}{4}(x^{(1)}+x^{(5)}+x^{(6)}+x^{(10)})</script><h3 id="11-3-优化目标"><a href="#11-3-优化目标" class="headerlink" title="11.3 优化目标"></a>11.3 优化目标</h3><p>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和</p>
<p>K-均值的代价函数（又称 <strong>畸变函数 Distortion function</strong>）为：</p>
<script type="math/tex; mode=display">
J(c^{(1)},c^{(2)},...,c^{(m)};\mu_1,\mu_2,...,\mu_k)=\frac{1}{m}\sum_{i=1}^m||x^{(i)}-\mu_{c_{(i)}}||^2</script><script type="math/tex; mode=display">
\mu_{c^{(i)}} = \text{样本} x^{(i)} \text{最近的聚类中心点}</script><p>优化目标便是找出使得代价函数最小的<script type="math/tex">c^{(1)},c^{(2)},...,c^{(m)}</script>和<script type="math/tex">\mu_1,\mu_2,...,\mu_k</script></p>
<p>最小化代价函数的过程：</p>
<p><strong>样本分配时</strong>：</p>
<p>第一个循环是用于减小<script type="math/tex">c^{(i)}</script>引起的代价,固定住了<script type="math/tex">\mu_1,\mu_2,...,\mu_k</script>，而关于<script type="math/tex">c^{(1)},c^{(2)},...,c^{(m)}</script>最小化了<script type="math/tex">J</script></p>
<p><strong>中心移动时</strong>：</p>
<p>第二个循环则是用于减小<script type="math/tex">\mu_i</script> 引起的代价,关于<script type="math/tex">\mu_1,\mu_2,...,\mu_k</script>最小化了<script type="math/tex">J</script></p>
<p>由于 K-Means 每次迭代过程都在最小化<script type="math/tex">J</script>，所以下面的代价函数变化曲线不会出现：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/9854import.png" alt></p>
<h3 id="11-4-随机初始化"><a href="#11-4-随机初始化" class="headerlink" title="11.4 随机初始化"></a>11.4 随机初始化</h3><p>随机初始化所有的聚类中心点：</p>
<ol>
<li>选择 <script type="math/tex">K\lt m</script>，即聚类中心点的个数要小于所有训练集实例的数量</li>
<li>随机选择 <script type="math/tex">K</script> 个训练实例，然后令 <script type="math/tex">K</script> 个聚类中心分别与这 <script type="math/tex">K</script> 个训练实例相等</li>
</ol>
<p>$K-$均值的一个问题在于可能会停留在一个局部最小值处，而这取决于初始化的情况</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/134import.png" alt></p>
<p>为了解决这个问题，只能尝试不同的初始化：</p>
<p>for <script type="math/tex">i =1</script> to <script type="math/tex">100</script>：</p>
<ol>
<li>随机初始化，执行 K-Means，得到每个所属的簇<script type="math/tex">c^{(i)}</script>，以及各聚类的中心位置<script type="math/tex">\mu</script>：<script type="math/tex; mode=display">
c^{(1)},c^{(2)},...,c^{(m)},\mu_1,\mu_2,...,\mu_k</script></li>
<li>计算失真函数<script type="math/tex">J</script>：</li>
</ol>
<p>选择这 <script type="math/tex">100</script> 次中，<script type="math/tex">J</script>最小的作为最终的聚类结果</p>
<blockquote>
<p>这种方法在 <script type="math/tex">k</script> 较小的时候<script type="math/tex">(2--10)</script>还是可行的，但是如果 <script type="math/tex">k</script>较大，这么做也可能不会有明显地改善</p>
</blockquote>
<h3 id="11-5-选择聚类数"><a href="#11-5-选择聚类数" class="headerlink" title="11.5 选择聚类数"></a>11.5 选择聚类数</h3><p>没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的</p>
<h4 id="肘部法则"><a href="#肘部法则" class="headerlink" title="肘部法则"></a>肘部法则</h4><p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/135import.png" alt></p>
<p>“肘关节”部分对应的<script type="math/tex">K</script>值就是最恰当的<script type="math/tex">K</script>值，但是并不是所有代价函数曲线都存在明显的“肘关节”，例如下面的曲线：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/776import.png" alt></p>
<h2 id="十二、降维-Dimensionality-Reduction"><a href="#十二、降维-Dimensionality-Reduction" class="headerlink" title="十二、降维(Dimensionality Reduction)"></a>十二、降维(Dimensionality Reduction)</h2><h3 id="12-1-动机一：数据压缩"><a href="#12-1-动机一：数据压缩" class="headerlink" title="12.1 动机一：数据压缩"></a>12.1 动机一：数据压缩</h3><p>数据压缩不仅允许压缩数据，因而使用较少的计算机内存或磁盘空间，而且也加快学习算法</p>
<p>使用了一条绿色直线，将各个样本投影到该直线，原来二维的特征<script type="math/tex">x = \text{(厘米,英尺)}</script>被降低为了一维<script type="math/tex">x = \text{(直线上的相对位置)}</script>：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/11231import.png" alt></p>
<p>将三维特征投影到二维平面，从而将三维特征降到了二维：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1235import.png" alt></p>
<h3 id="12-2-动机二：数据可视化"><a href="#12-2-动机二：数据可视化" class="headerlink" title="12.2 动机二：数据可视化"></a>12.2 动机二：数据可视化</h3><p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/136import.png" alt></p>
<p>使用降维的方法将其从50 维降至 2 维，将其可视化：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/137import.png" alt></p>
<p>降维的算法只负责减少维数，新产生的特征的意义必须自己去发现</p>
<h3 id="12-3-主成分分析-PCA-问题"><a href="#12-3-主成分分析-PCA-问题" class="headerlink" title="12.3 主成分分析(PCA)问题"></a>12.3 主成分分析(PCA)问题</h3><p>主成分分析（Principle Component Analysis）是最常见的降维算法</p>
<p>在 PCA中，要做的是找到一个<strong>方向向量（Vector direction）</strong>，把所有的数据都投射到该向量上时，希望投射<strong>平均均方误差</strong>能尽可能地小</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/138import.png" alt></p>
<blockquote>
<p>方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向向量作垂线的长度</p>
</blockquote>
<p>主成分分析问题的描述：</p>
<p>问题是要将 <script type="math/tex">n</script> 维数据降至<script type="math/tex">k</script> 维，目标是找到向量<script type="math/tex">u^{(1)}, u^{(2)},...,u^{(k)}</script>使得总的投射误差最小</p>
<h4 id="主成分分析与线性回归"><a href="#主成分分析与线性回归" class="headerlink" title="主成分分析与线性回归"></a>主成分分析与线性回归</h4><p>主成分分析最小化的是<strong>投射误差（Projected Error）</strong>，而线性回归尝试的是最小化<strong>预测误差</strong>。主成分分析不作任何预测, 线性回归的目的是预测结果</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/139import.png" alt></p>
<blockquote>
<p>左边的是线性回归的误差（垂直于横轴投影），右边则是主要成分分析的误差（垂直于红线投影）</p>
</blockquote>
<p>PCA 将 <script type="math/tex">n</script> 个特征降维到 <script type="math/tex">k</script> 个，可以用来进行数据压缩，如果 <script type="math/tex">100</script> 维的向量最后可以用 <script type="math/tex">10</script>维来表示，那么压缩率为 90%。 PCA要保证降维后数据的特性损失最小</p>
<h4 id="优点和缺点"><a href="#优点和缺点" class="headerlink" title="优点和缺点"></a>优点和缺点</h4><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ul>
<li>对数据进行降维。可以对新求出的“主元”向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度的保持了原有数据的信息</li>
<li>完全无参数限制。在 PCA 的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预，最后的结果只与数据相关，与用户是独立的</li>
</ul>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul>
<li>如果用户对观测对象有一定的先验知识，掌握了数据的一些特征，却无法通过参数化等方法对处理过程进行干预，可能会得不到预期的效果，效率也不高</li>
</ul>
<h3 id="12-4-主成分分析算法"><a href="#12-4-主成分分析算法" class="headerlink" title="12.4 主成分分析算法"></a>12.4 主成分分析算法</h3><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><p>将特征维度从<script type="math/tex">n</script>维降到<script type="math/tex">k</script>维。 PCA 的执行流程如下：</p>
<ol>
<li><strong>特征标准化</strong>，平衡各个特征尺度：</li>
</ol>
<script type="math/tex; mode=display">
x_j=\frac{x_j-\mu_j}{S_j}, \mu_j \text{为特征} j \text{的均值,}S_j \text{为特征} j \text{的标准差}</script><ol>
<li>计算<strong>协方差矩阵</strong><script type="math/tex">\Sigma</script>：</li>
</ol>
<script type="math/tex; mode=display">
\Sigma = \frac{1}{m}\sum\limits_{i=1}^{m}(x^{(i)})(x^{(i)})^T = \frac{1}{m} \cdot X^TX</script><ol>
<li>通过<strong>奇异值分解（SVD）</strong>，求取<script type="math/tex">\Sigma</script>的特征向量（eigenvectors）：</li>
</ol>
<script type="math/tex; mode=display">
(U,S,V^T) = SVD(\Sigma)</script><ol>
<li>从<script type="math/tex">U</script>中取出前<script type="math/tex">k</script>个左奇异向量，构成一个约减矩阵<script type="math/tex">U{reduce}</script>：</li>
</ol>
<script type="math/tex; mode=display">
U_{reduce} = (u^{(1)},u^{(2)},\cdots,u^{(k)})</script><ol>
<li>计算新的特征向量<script type="math/tex">z^{(i)}</script>：</li>
</ol>
<script type="math/tex; mode=display">
z^{(i)}=U_{reduce}^T \cdot x^{(i)}</script><p>其中 <script type="math/tex">x</script> 是 <script type="math/tex">n\times1</script> 维的，因此结果为 <script type="math/tex">k\times1</script> 维度</p>
<h3 id="12-5-选择主成分的数量"><a href="#12-5-选择主成分的数量" class="headerlink" title="12.5 选择主成分的数量"></a>12.5 选择主成分的数量</h3><p>使用如下的流程的来评估<script type="math/tex">k</script>值选取优异：</p>
<ol>
<li>求各样本的<strong>投影均方误差</strong>:</li>
</ol>
<script type="math/tex; mode=display">
\min\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}-x_{approx}^{(i)}||^2</script><ol>
<li>求数据的<strong>总方差</strong>：</li>
</ol>
<script type="math/tex; mode=display">
\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}||^2</script><ol>
<li>评估下式是否成立:</li>
</ol>
<script type="math/tex; mode=display">
\frac{\min\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}-x_{approx}^{(i)}||^2}{\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}||^2} \leq \epsilon</script><p>$\epsilon$的取值可以为<script type="math/tex">0.01,0.05,0.10,\cdots</script>，假设<script type="math/tex">\epsilon=0.01=1\%</script>，就说“特征间 99%的差异性得到保留”</p>
<h4 id="奇异值分解-SVD"><a href="#奇异值分解-SVD" class="headerlink" title="奇异值分解(SVD)"></a>奇异值分解(SVD)</h4><p>奇异值分解（singular Value Decomposition），简称SVD，线性代数中矩阵分解的方法。假如有一个矩阵A，对它进行奇异值分解，可以得到三个矩阵：</p>
<script type="math/tex; mode=display">
A = U\Sigma V^T</script><p>这三个矩阵的大小：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226342650.png" alt></p>
<p>部分奇异值分解：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226358289.png" alt></p>
<p>$r$是一个远小于<script type="math/tex">m,n</script>的数，矩阵的乘法看起来像是下面的样子：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226356370.png" alt></p>
<h4 id="更好的方式来选择-k"><a href="#更好的方式来选择-k" class="headerlink" title="更好的方式来选择 k"></a>更好的方式来选择 k</h4><p>在 Python 中调用“svd”函数的时候，获得三个参数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">U, S, VT = np.linalg.svd(A)</span><br></pre></td></tr></table></figure>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/140import.png" alt></p>
<p>$S$ 是一个 <script type="math/tex">n\times n</script> 的矩阵，只有对角线上有值</p>
<p>可以使用这个矩阵来计算平均均方误差与训练集方差的比例：</p>
<script type="math/tex; mode=display">
\frac{\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}-x_{approx}^{(i)}||^2}{\frac{1}{m}\sum\limits_{i=1}^{m}||x^{(i)}||^2} =1-\frac{\sum\limits_{i=1}^{k}S_{ii}}{\sum\limits_{i=1}^{n}S_{ii}}\leq 1\%</script><p>也就是：</p>
<script type="math/tex; mode=display">
\frac{\sum\limits_{i=1}^{k}S_{ii}}{\sum\limits_{i=1}^{n}S_{ii}}\geq99\%</script><h3 id="12-6-重建的压缩表示"><a href="#12-6-重建的压缩表示" class="headerlink" title="12.6 重建的压缩表示"></a>12.6 重建的压缩表示</h3><p>因为PCA仅保留了特征的主成分，所以PCA是一种有损的压缩方式，假定获得新特征向量为：</p>
<script type="math/tex; mode=display">
z^{(i)} = U_{reduce}^Tx^{(i)}</script><p>还原后的特征<script type="math/tex">x_{approx}</script>为：</p>
<script type="math/tex; mode=display">
x_{approx}^{(i)}=U_{reduce}z^{(i)},x_{approx}\approx x</script><p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/4567import.png" alt></p>
<p>把这个过程称为<strong>重建原始数据</strong></p>
<h3 id="12-7-主成分分析法的应用建议"><a href="#12-7-主成分分析法的应用建议" class="headerlink" title="12.7 主成分分析法的应用建议"></a>12.7 主成分分析法的应用建议</h3><h4 id="不要提前优化"><a href="#不要提前优化" class="headerlink" title="不要提前优化"></a>不要提前优化</h4><p>由于 PCA 减小了特征维度，因而有可能带来过拟合的问题。</p>
<p>PCA 不是必须的，在机器学习中，一定谨记不要提前优化，只有当算法运行效率不尽如如人意时，再考虑使用 PCA 或者其他特征降维手段来提升训练速度</p>
<h4 id="不只是加速学习"><a href="#不只是加速学习" class="headerlink" title="不只是加速学习"></a>不只是加速学习</h4><p>降低特征维度不只加速模型的训练速度，还有助于在低维空间分析数据</p>
<p>例如，一个在三维空间完成的聚类问题，可以通过 PCA 将特征降低到二维平面进行可视化分析。</p>
<p>例如下表中有将近几十个特征来描述国家的经济水平，但很难直观的看出各个国家的经济差异：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/554import.png" alt></p>
<p>借助于 PCA，将特征降低到了二维，并在二维空间进行观察，很清楚的就能发现美国和新加坡具有很高的经济水平：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/454545import.png" alt></p>

          
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/05/斯坦福机器学习笔记-Week-6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/05/斯坦福机器学习笔记-Week-6/" itemprop="url">斯坦福机器学习笔记(Week 6)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-04T19:18:00Z">
                2019-03-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-04T03:31:52Z">
                2019-03-04
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/05/斯坦福机器学习笔记-Week-6/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/05/斯坦福机器学习笔记-Week-6/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/05/斯坦福机器学习笔记-Week-6/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week 6)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          
            <h2 id="八、应用机器学习的建议-Advice-for-Applying-Machine-Learning"><a href="#八、应用机器学习的建议-Advice-for-Applying-Machine-Learning" class="headerlink" title="八、应用机器学习的建议(Advice for Applying Machine Learning)"></a>八、应用机器学习的建议(Advice for Applying Machine Learning)</h2><h3 id="8-1-决定下一步做什么"><a href="#8-1-决定下一步做什么" class="headerlink" title="8.1 决定下一步做什么"></a>8.1 决定下一步做什么</h3><p>当运用训练好了的模型来预测未知数据的时候发现有较大的误差，下一步可以做什么？</p>
<p>获得更多的训练实例——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。</p>
<ol>
<li><p>尝试减少特征的数量</p>
</li>
<li><p>尝试获得更多的特征</p>
</li>
<li><p>尝试增加多项式特征</p>
</li>
<li><p>尝试减少正则化程度 <script type="math/tex">\lambda</script></p>
</li>
<li><p>尝试增加正则化程度 <script type="math/tex">\lambda</script></p>
</li>
</ol>
<p>不应该随机选择上面的某种方法来改进算法，而是运用一些机器学习诊断法来知道上面哪些方法对算法是有效的</p>
<h3 id="8-2-评估一个假设"><a href="#8-2-评估一个假设" class="headerlink" title="8.2 评估一个假设"></a>8.2 评估一个假设</h3><p>为了检验算法是否过拟合，将数据分成训练集和测试集，通常用 70%的数据作为训练集，用剩下30%的数据作为测试集。很重要的一点是训练集和测试集均要含有各种类型的数据，通常要对数据进行“洗牌”，然后再分成训练集和测试集</p>
<p>引入如下符号：</p>
<ul>
<li><script type="math/tex">(x^{(1)},y^{(1)})</script>：训练样本</li>
<li><script type="math/tex">(x_{test}^{(1)},y_{test}^{(1)})</script>：测试样本</li>
<li><script type="math/tex">m</script>：训练集样本容量</li>
<li><script type="math/tex">m_{test}</script>：测试集样本容量</li>
</ul>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/115import.png" alt></p>
<p>测试集评估：</p>
<p>通过训练集让模型学习得出其参数后，对测试集运用该模型，有两种方式计算误差：</p>
<p>1.对于线性回归模型，利用测试集数据计算代价函数 <script type="math/tex">J</script></p>
<script type="math/tex; mode=display">
J_{test} = \frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_{\theta}(x_{test}^{(i)})-y_{test}^{(i)})^2</script><p>2.对于逻辑回归模型，测试集的代价函数为：</p>
<script type="math/tex; mode=display">
J_{test}(\theta)=-\frac{1}{m_{test}}\sum\limits_{i=1}^{m_{test}}[y_{test}^{(i)}logh_\theta(x_{test}^{(i)})+(1-y_{test}^{(i)})log(1-h_\theta(x_{test}^{(i)}))]</script><p>由于逻辑回归处理的是 0/1 分类问题，其预测结果只有正确与错误之分，所以引入<strong>误分率（Misclassification Error）,</strong>对于每一个测试集实例，计算<strong>：</strong></p>
<script type="math/tex; mode=display">
err(h_\theta(x),y)=
\begin{cases} 1,&\text{if} h_\theta(x) \geq 0.5,y=0 \quad or \quad h_\theta(x) \lt 0.5,y=1 \\
0, & \text{otherwise}
\end{cases}</script><p>然后对计算结果求平均,则逻辑回归中的测试误差可以表示为：</p>
<script type="math/tex; mode=display">
Test_{error} = \frac{1}{m_{test}}\sum\limits_{1}^{m_{test}}err(h_\theta(x_{test}^{(i)}),y_{test}^{(i)})</script><h3 id="8-3-模型选择和交叉验证集"><a href="#8-3-模型选择和交叉验证集" class="headerlink" title="8.3 模型选择和交叉验证集"></a>8.3 模型选择和交叉验证集</h3><ul>
<li><strong>训练集</strong>：60%，确定参数<script type="math/tex">\theta</script></li>
<li><p><strong>交叉验证集</strong>：20%，进行模型选择</p>
</li>
<li><p><strong>测试集</strong>：20%，评价模型预测能力</p>
</li>
</ul>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/120import.png" alt></p>
<p>模型选择的方法为：</p>
<ol>
<li><p>使用训练集训练出 10 个模型</p>
</li>
<li><p>用 10 个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）</p>
</li>
<li><p>选取代价函数值最小的模型</p>
</li>
<li><p>用步骤 3 中选出的模型对测试集计算得出推广误差（代价函数的值）</p>
</li>
</ol>
<p>三者的误差函数如下：</p>
<ul>
<li><strong>训练集误差</strong>：</li>
</ul>
<script type="math/tex; mode=display">
J_{train}(\theta) = \frac{1}{2m}\sum\limits_{i=1}^{m_{train}}(h_\theta(x_{train}^{(i)})-y_{train}^{(i)})^2</script><ul>
<li><strong>交叉验证集误差：</strong></li>
</ul>
<script type="math/tex; mode=display">
J_{cv}(\theta) = \frac{1}{2m}\sum\limits_{i=1}^{m_{cv}}(h_\theta(x_{cv}^{(i)})-y_{cv}^{(i)})^2</script><ul>
<li><strong>测试集误差：</strong></li>
</ul>
<script type="math/tex; mode=display">
J_{test}(\theta) = \frac{1}{2m}\sum\limits_{i=1}^{m_{test}}(h_\theta(x_{test}^{(i)})-y_{test}^{(i)})^2</script><h3 id="8-4-偏差与方差"><a href="#8-4-偏差与方差" class="headerlink" title="8.4 偏差与方差"></a>8.4 偏差与方差</h3><p>在机器学习中，<strong>偏差（bias）</strong>反映了模型无法描述数据规律，而<strong>方差（variance）</strong>反映了模型对训练集过度敏感，而丢失了数据规律</p>
<h4 id="多项式回归中偏差与方差"><a href="#多项式回归中偏差与方差" class="headerlink" title="多项式回归中偏差与方差"></a>多项式回归中偏差与方差</h4><p>当运行一个学习算法时，如果这个算法的表现不理想，多半是出现两种情况：要么是偏差比较大，要么是方差比较大。即出现的情况要么是<strong>欠拟合</strong>，要么是<strong>过拟合</strong>问题</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/116import.png" alt></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/117import.png" alt></p>
<p>对于训练集，当<script type="math/tex">d</script>较小时，模型拟合程度低，误差较大；随着<script type="math/tex">d</script>的增长，拟合程度提高，误差减小</p>
<p>对于交叉验证集，当<script type="math/tex">d</script>较小时，模型拟合程度低，误差较大；但是随着<script type="math/tex">d</script>的增长，误差呈现先减小后增大的趋势，转折点是模型开始过拟合训练数据集的时候</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/118import.png" alt></p>
<p>训练集误差和交叉验证集误差近似时：偏差/欠拟合</p>
<p>交叉验证集误差远大于训练集误差时：方差/过拟合</p>
<h3 id="8-5-正则化和偏差-方差"><a href="#8-5-正则化和偏差-方差" class="headerlink" title="8.5 正则化和偏差/方差"></a>8.5 正则化和偏差/方差</h3><p><strong>正规化（Regularization）</strong>解决过拟合问题：</p>
<p>$\lambda$取值越大，对参数<script type="math/tex">\theta</script>的惩罚力度就越大，能够帮助解决<strong>过拟合</strong>问题，如果惩罚过重，也会造成<strong>欠拟合</strong>问题，即会出现<strong>高偏差</strong>。如果<script type="math/tex">\lambda</script>取值较小，则意味着没有惩罚<script type="math/tex">\theta</script>，也就不能解决<strong>过拟合</strong>问题，会出现<strong>高方差</strong>：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/正规化过拟合与欠拟合.jpg" alt></p>
<hr>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1231import.png" alt></p>
<p>选择 <script type="math/tex">\lambda</script> 的方法为：</p>
<ol>
<li><p>使用训练集训练出 12 个不同程度<strong>正则化</strong>的模型</p>
</li>
<li><p>用 12 模型分别对<strong>交叉验证集</strong>计算得出<strong>交叉验证误差 </strong></p>
</li>
<li><p>选择得出交叉验证误差<strong>最小</strong>的模型</p>
</li>
<li><p>运用步骤 3 中选出模型对测试集计算得出推广误差，也可以同时将训练集和交叉验证集模型的代价函</p>
</li>
</ol>
<p>数误差与<script type="math/tex">\lambda</script>的值绘制在一张图表上：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/122import.png" alt></p>
<ul>
<li><p>当<script type="math/tex">\lambda</script>较小时，训练集误差较小（过拟合），而交叉验证集误差较大</p>
</li>
<li><p>随着<script type="math/tex">\lambda</script>的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加</p>
</li>
</ul>
<h3 id="8-6-学习曲线"><a href="#8-6-学习曲线" class="headerlink" title="8.6 学习曲线"></a>8.6 学习曲线</h3><p><strong>学习曲线</strong>是将<strong>训练集误差</strong>和<strong>交叉验证集误差</strong>作为训练集实例数量（m）的函数绘制的图表</p>
<p>当训练较少行数据的时候，训练的模型将能够非常完美地适应较少的训练数据，但是训练出来的模型却不能很好地适应<strong>交叉验证集数据</strong>或<strong>测试集数据</strong></p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/123import.png" alt></p>
<p>利用学习曲线识别高偏差/欠拟合：用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观：</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/124import.png" alt></p>
<p>在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助</p>
<p>利用学习曲线识别高方差/过拟合： 假设使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/125import.png" alt></p>
<p>在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果</p>
<h3 id="8-7-决定下一步做什么"><a href="#8-7-决定下一步做什么" class="headerlink" title="8.7 决定下一步做什么"></a>8.7 决定下一步做什么</h3><p>降低预测误差，即提高预测精度，往往会采用这些手段：</p>
<ol>
<li><p>获得更多的训练实例——解决高方差</p>
</li>
<li><p>尝试减少特征的数量——解决高方差</p>
</li>
<li><p>尝试获得更多的特征——解决高偏差</p>
</li>
<li><p>尝试增加多项式特征——解决高偏差</p>
</li>
<li><p>尝试减小正则化程度 <script type="math/tex">\lambda</script>——解决高偏差</p>
</li>
<li><p>尝试增加正则化程度 <script type="math/tex">\lambda</script>——解决高方差</p>
</li>
</ol>
<h4 id="神经网络的方差和偏差"><a href="#神经网络的方差和偏差" class="headerlink" title="神经网络的方差和偏差"></a>神经网络的方差和偏差</h4><p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/126import.png" alt></p>
<p>使用较小的神经网络，类似于<strong>参数较少</strong>的情况，容易导致<strong>高偏差</strong>和<strong>欠拟合</strong>，但计算代价较小</p>
<p>使用较大的神经网络，类似于<strong>参数较多</strong>的情况，容易导致<strong>高方差</strong>和<strong>过拟合</strong>，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据</p>
<p>通常选择较大的神经网络并采用<strong>正则化</strong>处理会比采用较小的神经网络效果要好,对于神经网络中的<strong>隐藏层</strong>的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为<strong>训练集</strong>、<strong>交叉验证集</strong>和<strong>测试集</strong>，针对不同<strong>隐藏层层数</strong>的神经网络训练神经网络， 然后选择<strong>交叉验证集</strong>代价<strong>最小</strong>的神经网络</p>
<h2 id="九、机器学习系统的设计-Machine-Learning-System-Design"><a href="#九、机器学习系统的设计-Machine-Learning-System-Design" class="headerlink" title="九、机器学习系统的设计(Machine Learning System Design)"></a>九、机器学习系统的设计(Machine Learning System Design)</h2><h3 id="9-1-首先要做什么"><a href="#9-1-首先要做什么" class="headerlink" title="9.1 首先要做什么"></a>9.1 首先要做什么</h3><p>令向量<script type="math/tex">x</script>表示垃圾邮件的特征向量，该向量包含了 100 个按字母序排序的单词特征，这些单词通常为垃圾邮件常出现的词汇：discount，deal，now 等等：</p>
<script type="math/tex; mode=display">
x_j =
\begin{cases}
1 & \text{第 j 个单词出现} \\
0 & \text{未出现}
\end{cases}</script><p>令<script type="math/tex">y</script>标签表示该邮件是否是垃圾邮件：</p>
<script type="math/tex; mode=display">
y =
\begin{cases}
1 & \text{x是垃圾邮件} \\
0 & \text{x不是垃圾邮件}
\end{cases}</script><p>那么垃圾邮件分类就是一个 <strong>0/1 分类</strong>问题，可以用<strong>逻辑回归</strong>完成</p>
<p>如何降低分类错误率：</p>
<ol>
<li><p>收集更多的数据，有更多的垃圾邮件和非垃圾邮件的样本</p>
</li>
<li><p>基于邮件的路由信息开发一系列复杂的特征</p>
</li>
<li><p>基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理</p>
</li>
<li><p>为探测刻意的拼写错误（把 watch 写成 w4tch）开发复杂的算法</p>
</li>
</ol>
<h3 id="9-2-误差分析"><a href="#9-2-误差分析" class="headerlink" title="9.2 误差分析"></a>9.2 误差分析</h3><p>构建一个学习算法的推荐方法为：</p>
<ol>
<li><p>从一个简单的能快速实现的算法开始，实现该算法并用<strong>交叉验证集</strong>数据测试这个算法</p>
</li>
<li><p>绘制学习曲线，确定面临的问题是<strong>高偏差</strong>还是<strong>高方差，</strong>决定是添加更多特征，或者增加更多数据，还是其他选择</p>
</li>
<li><p>进行误差分析：人工检查交叉验证集算法中产生预测误差的实例，看看这些实例是否有某种系统化的趋势</p>
</li>
</ol>
<p>假定交叉验证集有 500 个样本，即<script type="math/tex">m_{cv}=500</script>，模型错分了其中 100 个样本，通过下述手段进行错误分析：</p>
<ol>
<li>需要知道哪些邮件被错分了，是假冒伪劣的推销邮件？医药邮件？还是钓鱼邮件？</li>
<li>需要知道提供什么线索（特征）能帮助模型区分出这些邮件？</li>
</ol>
<p>例如，在这 100 个错分样本中，发现有 53 个样本是钓鱼邮件，就需要考虑为模型注入识别的钓鱼邮件的能力。在这 53 封钓鱼邮件中，故意使用错误拼写的邮件有 5 封，来源可疑（发送人可疑）的邮件有16 封，使用了大量煽动性标点符号的邮件有 32 封</p>
<p>对于识别钓鱼邮件来说，更适合将煽动性标点符号添加为特征，而不用再考虑去识别错误拼写</p>
<h3 id="9-3-查准率（Precision）和-召回率（Recall）"><a href="#9-3-查准率（Precision）和-召回率（Recall）" class="headerlink" title="9.3 查准率（Precision）和 召回率（Recall）"></a>9.3 查准率（Precision）和 召回率（Recall）</h3><p>将算法预测的结果分成四种情况：</p>
<ol>
<li><p>正确肯定（True Positive,TP）：预测为真，实际为真</p>
</li>
<li><p>正确否定（True Negative,TN）：预测为假，实际为假</p>
</li>
<li><p>错误肯定（False Positive,FP）：预测为真，实际为假</p>
</li>
<li><p>错误否定（False Negative,FN）：预测为假，实际为真</p>
</li>
</ol>
<h4 id="查准率（Precision）："><a href="#查准率（Precision）：" class="headerlink" title="查准率（Precision）："></a>查准率（Precision）：</h4><script type="math/tex; mode=display">
Precision = \frac{TruePos}{PredicatedPos} = \frac{TruePos}{TruePos+FalsePos}</script><p>例，在所有预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好</p>
<h4 id="召回率（Recall）："><a href="#召回率（Recall）：" class="headerlink" title="召回率（Recall）："></a>召回率（Recall）：</h4><script type="math/tex; mode=display">
Recall = \frac{TruePos}{ActualPos} = \frac{TruePos}{TruePos+FalseNeg}</script><p>例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">实际1</th>
<th style="text-align:center">实际0</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">预测1</td>
<td style="text-align:center">True Positive</td>
<td style="text-align:center">False Positive</td>
</tr>
<tr>
<td style="text-align:center">预测0</td>
<td style="text-align:center">False Negative</td>
<td style="text-align:center">True Negative</td>
</tr>
</tbody>
</table>
</div>
<h3 id="9-4-查准率和召回率之间的权衡"><a href="#9-4-查准率和召回率之间的权衡" class="headerlink" title="9.4 查准率和召回率之间的权衡"></a>9.4 查准率和召回率之间的权衡</h3><p>如果希望在非常确信的情况下预测为真（肿瘤为恶性），即希望更高的<strong>查准率</strong>，可以使用比 0.5 更大的阀值，如 0.7，0.9。这样会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。如果希望提高<strong>召回率</strong>，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查、诊断，可以使用比 0.5 更小的阀值，如 0.3。</p>
<p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/150import.png" alt></p>
<p>选择阀值的方法：计算 <strong>F 1 值（F1 Score）</strong></p>
<script type="math/tex; mode=display">
F_1 Score = 2\frac{PR}{P+R}</script><p>分子是<strong>查准率</strong>和<strong>召回率</strong>的乘积，只有二者都较高时，<script type="math/tex">F_1Score</script>才会较高，特别地：</p>
<script type="math/tex; mode=display">
\begin{aligned}
F_1 Score &= 0, \quad \text{if P=0 or R=0} \\
F_1 Score &= 1, \quad \text{if P=1 and R=1}
\end{aligned}</script><h3 id="机器学习的数据"><a href="#机器学习的数据" class="headerlink" title="机器学习的数据"></a>机器学习的数据</h3><p><img src="https://baozou.gitbooks.io/-stanford-machine-learning/content/assets/1122import.png" alt></p>
<p>什么时候采用大规模的数据集：</p>
<p>一定要保证模型拥有足够的参数（线索），对于线性回归/逻辑回归来说，就是具备足够多的特征，而对于神经网络来说，就是更多的隐藏单元。这样，足够多的特征避免了<strong>高偏差</strong>（欠拟合）问题，而足够大数据集避免了多特征容易引起的<strong>高方差</strong>（过拟合）问题。</p>

          
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/04/斯坦福机器学习笔记-Week-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/04/斯坦福机器学习笔记-Week-3/" itemprop="url">斯坦福机器学习笔记(Week  3)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-04T11:52:00Z">
                2019-03-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-03T12:20:51Z">
                2019-03-03
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/04/斯坦福机器学习笔记-Week-3/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/04/斯坦福机器学习笔记-Week-3/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/04/斯坦福机器学习笔记-Week-3/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week  3)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  13
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          <h2 id="四-、逻辑回归-Logistic-Regression）"><a href="#四-、逻辑回归-Logistic-Regression）" class="headerlink" title="四 、逻辑回归( Logistic Regression）"></a>四 、逻辑回归( Logistic Regression）</h2><h3 id="4-1-分类问题"><a href="#4-1-分类问题" class="headerlink" title="4.1 分类问题"></a>4.1 分类问题</h3><p>将<strong>因变量</strong>(dependant variable)可能属于的两个类分别称为<strong>负向类</strong>（negativeclass）和<strong>正向类</strong>（positiveclass），则因变量y∈{0,1}</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/03/04/斯坦福机器学习笔记-Week-3/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/04/斯坦福机器学习笔记-Week-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/04/斯坦福机器学习笔记-Week-5/" itemprop="url">斯坦福机器学习笔记(Week  5)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-04T04:05:00Z">
                2019-03-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-03T12:20:43Z">
                2019-03-03
              </time>
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/04/斯坦福机器学习笔记-Week-5/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/04/斯坦福机器学习笔记-Week-5/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/04/斯坦福机器学习笔记-Week-5/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week  5)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  10
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          <h2 id="七、神经网络的学习-Neural-Networks-Learning"><a href="#七、神经网络的学习-Neural-Networks-Learning" class="headerlink" title="七、神经网络的学习( Neural Networks: Learning)"></a>七、神经网络的学习( Neural Networks: Learning)</h2><h3 id="7-1-代价函数"><a href="#7-1-代价函数" class="headerlink" title="7.1 代价函数"></a>7.1 代价函数</h3><p>假设神经网络的训练样本有 <script type="math/tex">m</script>个，每个包含一组输入 <script type="math/tex">x</script>和一组输出信号 <script type="math/tex">y</script>，<script type="math/tex">L</script> 表示神经网络结构总层数，<script type="math/tex">S_l</script>表示第<script type="math/tex">l</script>层的单元个数，<script type="math/tex">S_L</script>代表最后一层中处理单元的个数</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/03/04/斯坦福机器学习笔记-Week-5/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/04/福机器学习笔记-Week-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/04/福机器学习笔记-Week-4/" itemprop="url">斯坦福机器学习笔记(Week  4)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-04T03:44:00Z">
                2019-03-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-03T12:21:00Z">
                2019-03-03
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/04/福机器学习笔记-Week-4/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/04/福机器学习笔记-Week-4/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/04/福机器学习笔记-Week-4/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week  4)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  8
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          <h2 id="六、神经网络：表述-Neural-Networks-Representation"><a href="#六、神经网络：表述-Neural-Networks-Representation" class="headerlink" title="六、神经网络：表述( Neural Networks: Representation)"></a>六、神经网络：表述( Neural Networks: Representation)</h2><h3 id="6-1-非线性假设"><a href="#6-1-非线性假设" class="headerlink" title="6.1 非线性假设"></a>6.1 非线性假设</h3><p>无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/03/04/福机器学习笔记-Week-4/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/04/斯坦福机器学习笔记-Week-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/04/斯坦福机器学习笔记-Week-1/" itemprop="url">斯坦福机器学习笔记(Week  1)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-04T03:19:00Z">
                2019-03-04
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-03T12:21:39Z">
                2019-03-03
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/04/斯坦福机器学习笔记-Week-1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/04/斯坦福机器学习笔记-Week-1/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/04/斯坦福机器学习笔记-Week-1/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week  1)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          <h2 id="一-、引言"><a href="#一-、引言" class="headerlink" title="一 、引言"></a>一 、引言</h2><h3 id="1-1-Supervised-Learning-amp-Uupervised-Learning"><a href="#1-1-Supervised-Learning-amp-Uupervised-Learning" class="headerlink" title="1.1 Supervised Learning&amp;Uupervised Learning"></a>1.1 Supervised Learning&amp;Uupervised Learning</h3><h4 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h4><p>监督学习，其基本思想是我们数据集中的每个样本都有相应的“正确答案”，再根据这些样本作出预测回归（regression）问题，即通过回归来推出一个连续的输出分类（classification）问题，其目标是推出一组离散的结果</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/03/04/斯坦福机器学习笔记-Week-1/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

      
  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.baozouai.com/2019/03/04/斯坦福机器学习笔记-Week-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="暴走">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/img/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暴走的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/04/斯坦福机器学习笔记-Week-2/" itemprop="url">斯坦福机器学习笔记(Week  2)</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-03T19:31:05Z">
                2019-03-03
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-03-03T12:21:16Z">
                2019-03-03
              </time>
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/04/斯坦福机器学习笔记-Week-2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/03/04/斯坦福机器学习笔记-Week-2/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/04/斯坦福机器学习笔记-Week-2/" class="leancloud_visitors" data-flag-title="斯坦福机器学习笔记(Week  2)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  906
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      

      
        
          <h2 id="三-、多变量线性回归-Linear-Regression-with-Multiple-Variables"><a href="#三-、多变量线性回归-Linear-Regression-with-Multiple-Variables" class="headerlink" title="三 、多变量线性回归( Linear Regression with Multiple Variables)"></a>三 、多变量线性回归( Linear Regression with Multiple Variables)</h2><h3 id="3-1-多变量梯度下降"><a href="#3-1-多变量梯度下降" class="headerlink" title="3.1 多变量梯度下降"></a>3.1 多变量梯度下降</h3><p>在多变量线性回归中的代价函数是所有建模误差的平方和，即：</p>
<script type="math/tex; mode=display">
J(\theta_0,\theta_1,...\theta_n)=\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2</script><script type="math/tex; mode=display">
h_\theta(x)=\theta^TX=\theta_0x_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n</script>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2019/03/04/斯坦福机器学习笔记-Week-2/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    <div>
     
  </div>


    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>



  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">


            
              <img class="site-author-image" itemprop="image" src="/img/avatar.png" alt="暴走">
            


              <p class="site-author-name" itemprop="name">暴走</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>
<script type="text/javascript" src="https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@1.2/dist/Meting.min.js"></script>
<div class="aplayer" data-id="D89A1236EF4D99ED641FFD846F1A23AF" data-server="kugou " data-type="song" data-autoplay="false" data-mode="single"></div>
<br>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/baozouai" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:baozouai@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>
    
    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart" aria-hidden="true"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">暴走</span>

  
</div>



  <span class="post-meta-divider">|</span>






<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共90k字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
</div>








        
      </div>
    </footer>
    
    
    
    
<!-- 代码块复制功能 -->
<script type="text/javascript" src="/js/src/clipboard.min.js"></script>  
<script type="text/javascript" src="/js/src/clipboard-use.js"></script>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  
  <script type="text/javascript" color="255,0,0" opacity="0.5" zindex="-2" count="100" src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script>












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazyload@2.0.0-beta.2/lazyload.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  




  <script type="text/javascript" src="/js/src/utils.js?v=6.0.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.0"></script>


  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"notes-iissnan"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  


















  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("S5fCBBMaimjEzLztiJKSBnbL-gzGzoHsz", "m3rlGieJoVqNqhc9YbnO52cM");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=6.0.0"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=6.0.0"></script>


  

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":80,"height":80},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
